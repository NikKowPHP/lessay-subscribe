This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: src/__mocks__/google-audio-json-reply.mock.json
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
documentation/
  flutter_integration.md
prisma/
  migrations/
    20250319101504_init/
      migration.sql
    20250319102806_change_to_string_ids/
      migration.sql
    20250319105647_add_lessons_model/
      migration.sql
    20250319105849_add_lessons_model/
      migration.sql
    20250320090900_normalize_lesson_step/
      migration.sql
    20250320091234_normalize_lesson_step/
      migration.sql
    20250320092128_normalize_lesson_step_update_lesson_table/
      migration.sql
    20250321100244_update_lesson_step_with_expected_answer_with_audios/
      migration.sql
    20250321103532_add_languages_to_assessment_lessons/
      migration.sql
    20250321120506_add_additional_fields_to_assessment_flow/
      migration.sql
    20250321131736_add_more_instruction_types_to_lesson/
      migration.sql
    20250328130253_create_audio_metrics_table/
      migration.sql
    20250328132500_add_session_recording_url_to_lesson_tables/
      migration.sql
    20250401063634_/
      migration.sql
    20250404075135_add_user_response_history_column/
      migration.sql
    20250404082007_add_max_attempts_to_lesson_step/
      migration.sql
    20250408062820_add_udpated_at_to_user/
      migration.sql
    20250408123748_add_progress_tracking/
      migration.sql
    20250410084132_add_relation_on_delete_to_all_user_containing_tables/
      migration.sql
    20250410104713_add_payments/
      migration.sql
    20250410112216_add_subscriptions/
      migration.sql
    20250411104102_add_additional_subscription_fields/
      migration.sql
    20250416133011_add_subscription_fields/
      migration.sql
    20250416134335_add_subscription_field/
      migration.sql
    migration_lock.toml
  schema.prisma
  seed.ts
public/
  robots.txt
  sitemap-0.xml
  sitemap.xml
scripts/
  export-data.js
src/
  __mocks__/
    assessment-data.mock.ts
    generated-assessment-lessons.mock.ts
    generated-audio-metrics.mock.ts
    generated-lessons.mock.ts
    tts-engine.mock.ts
  app/
    about/
      page.tsx
    api/
      mock-auth/
        route.ts
      payments/
        webhook.ts
      recording/
        route.ts
      subscribe/
        route.ts
      tts/
        route.ts
      upload-token/
        route.ts
    app/
      lessons/
        [id]/
          page.tsx
        page.tsx
      login/
        page.tsx
      onboarding/
        page.tsx
      profile/
        page.tsx
      layout.tsx
      page.tsx
    privacy/
      page.tsx
    terms/
      page.tsx
    globals.css
    layout.tsx
    page.tsx
  components/
    lessons/
      ChatInput.tsx
      ChatMessages.tsx
      lessonChat.tsx
    onboarding/
      AssessmentChat.tsx
      AssessmentStep.tsx
      LanguageSelectionStep.tsx
      LearningPurposeStep.tsx
      ProficiencyStep.tsx
      WelcomeStep.tsx
    ui/
      alert-dialog.tsx
      button.tsx
    AppLoadingIndicator.tsx
    BasicAnalysis.tsx
    CheckoutForm.tsx
    DetailedAnalysis.tsx
    FeaturesDropdown.tsx
    Footer.tsx
    Form.tsx
    HeaderWithProfile.tsx
    LoadingAnimation.tsx
    PhonemePlayer.tsx
    PostHogPageView.tsx
    Recording.tsx
    RecordingButtonConfig.tsx
    RecordingCallToAction.tsx
    RecordingHeader.tsx
    RecordingMetaScript.tsx
    ScrollButton.tsx
    Toaster.tsx
    YoutubeVideo.tsx
    YoutubeWrapper.tsx
  context/
    app-initializer-context.tsx
    auth-context.tsx
    lesson-context.tsx
    onboarding-context.tsx
    posthog-context.tsx
    recording-context.tsx
    subscription-context.tsx
    user-profile-context.tsx
  data/
    migrations/
      create_interactions_table.sql
  hooks/
    use-upload.tsx
    useError.tsx
  interfaces/
    ai-service.interface.ts
    tts.interface.ts
  lib/
    interfaces/
      all-interfaces.ts
    server-actions/
      _withErrorHandling.ts
      auth-actions.ts
      learning_progress-actions.ts
      lesson-actions.ts
      onboarding-actions.ts
      payment-actions.ts
      stt-actions.ts
      user-actions.ts
    prisma.ts
  models/
    AiResponse.model.ts
    AppAllModels.model.ts
    Language-detection.model.ts
  repositories/
    supabase/
      supabase.ts
    learning-progress.repository.ts
    lesson.repository.ts
    onboarding.repository.ts
    payment.repository.ts
    user.repository.ts
  services/
    generators/
      apiKeyGenerator.ts
      messageGenerator.ts
    ai.service.ts
    assessment-generator.service.ts
    auth.service.ts
    form.service.ts
    google-tts.service.ts
    learning-progress.service.ts
    lesson-generator.service.ts
    lesson.service.ts
    metrics.service.ts
    mock-auth-service.service.ts
    onboarding.service.ts
    payment.service.ts
    polly.service.ts
    recording.service.ts
    stt.service.ts
    supabase-auth.middleware.ts
    tts.service.ts
    user.service.ts
  utils/
    supabase/
      admin.ts
      client.ts
      server.ts
    cn.ts
    constants.ts
    google-basic-voices.util.ts
    google-hd-voices.util.ts
    logger.ts
    map-language-to-code.util.ts
    metadata.ts
    phoneme-audio.cacher.util.ts
    phoneme-audio.handler.util.ts
    polly-voice.mapper.utli.ts
    retryWithOperation.ts
    vercel_blob-upload.ts
  middleware.ts
tests/
  components/
    Recording.test.tsx
  routes/
    main.test.ts
  servises/
    ai-service.test.ts
    auth-context.test.tsx
    auth-service.test.ts
    lesson-service.test.ts
    lessonChat.test.tsx
    onboarding-service.test.ts
    onboarding-ui.test.tsx
    progress-service.test.ts
    user-context.test.tsx
    user-repository.test.ts
    user-service.test.ts
.env.example
.gitignore
.prettierrc
babel.test.babelrc
docker-compose.mac.prod.yml
docker-compose.mac.yml
docker-compose.proxy.prod.yml
docker-compose.proxy.yml
Dockerfile.mac
Dockerfile.proxy
document.md
eslint.config.mjs
exported-data.json
google9439ee28c89af9a5 (1).html
jest.config.mjs
jest.setup.mjs
next.config.ts
package.json
postcss.config.mjs
README.md
sitemap-config.mjs
tailwind.config.ts
todo.md
tsconfig-seed.json
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="prisma/migrations/20250319101504_init/migration.sql">
-- CreateEnum
CREATE TYPE "ProficiencyLevel" AS ENUM ('beginner', 'intermediate', 'advanced');

-- CreateEnum
CREATE TYPE "LessonGenerationStatus" AS ENUM ('pending', 'completed', 'failed');

-- CreateTable
CREATE TABLE "onboarding" (
    "id" TEXT NOT NULL,
    "userId" INTEGER NOT NULL,
    "steps" JSONB NOT NULL,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "learningPurpose" TEXT,
    "nativeLanguage" TEXT,
    "targetLanguage" TEXT,
    "proficiencyLevel" "ProficiencyLevel",
    "initialAssessmentCompleted" BOOLEAN NOT NULL DEFAULT false,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "onboarding_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "User" (
    "id" SERIAL NOT NULL,
    "email" TEXT NOT NULL,
    "name" TEXT,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT "User_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "assessment_lessons" (
    "id" TEXT NOT NULL,
    "userId" INTEGER NOT NULL,
    "step" INTEGER NOT NULL,
    "prompt" TEXT NOT NULL,
    "modelAnswer" TEXT NOT NULL,
    "userResponse" TEXT,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "assessment_lessons_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "onboarding_userId_key" ON "onboarding"("userId");

-- CreateIndex
CREATE UNIQUE INDEX "User_email_key" ON "User"("email");

-- AddForeignKey
ALTER TABLE "onboarding" ADD CONSTRAINT "onboarding_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "assessment_lessons" ADD CONSTRAINT "assessment_lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250319102806_change_to_string_ids/migration.sql">
/*
  Warnings:

  - The primary key for the `User` table will be changed. If it partially fails, the table could be left without primary key constraint.

*/
-- DropForeignKey
ALTER TABLE "assessment_lessons" DROP CONSTRAINT "assessment_lessons_userId_fkey";

-- DropForeignKey
ALTER TABLE "onboarding" DROP CONSTRAINT "onboarding_userId_fkey";

-- AlterTable
ALTER TABLE "User" DROP CONSTRAINT "User_pkey",
ALTER COLUMN "id" DROP DEFAULT,
ALTER COLUMN "id" SET DATA TYPE TEXT,
ADD CONSTRAINT "User_pkey" PRIMARY KEY ("id");
DROP SEQUENCE "User_id_seq";

-- AlterTable
ALTER TABLE "assessment_lessons" ALTER COLUMN "userId" SET DATA TYPE TEXT;

-- AlterTable
ALTER TABLE "onboarding" ALTER COLUMN "userId" SET DATA TYPE TEXT;

-- AddForeignKey
ALTER TABLE "onboarding" ADD CONSTRAINT "onboarding_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "assessment_lessons" ADD CONSTRAINT "assessment_lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250319105647_add_lessons_model/migration.sql">
/*
  Warnings:

  - You are about to drop the `assessment_lessons` table. If the table is not empty, all the data it contains will be lost.

*/
-- DropForeignKey
ALTER TABLE "assessment_lessons" DROP CONSTRAINT "assessment_lessons_userId_fkey";

-- DropTable
DROP TABLE "assessment_lessons";

-- CreateTable
CREATE TABLE "lessons" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "focusArea" TEXT NOT NULL,
    "targetSkills" TEXT[],
    "sequence" JSONB NOT NULL,
    "performanceMetrics" JSONB,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "lessons_pkey" PRIMARY KEY ("id")
);

-- AddForeignKey
ALTER TABLE "lessons" ADD CONSTRAINT "lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250319105849_add_lessons_model/migration.sql">
-- CreateTable
CREATE TABLE "assessment_lessons" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "step" INTEGER NOT NULL,
    "prompt" TEXT NOT NULL,
    "modelAnswer" TEXT NOT NULL,
    "userResponse" TEXT,
    "completed" BOOLEAN NOT NULL DEFAULT false,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "assessment_lessons_pkey" PRIMARY KEY ("id")
);

-- AddForeignKey
ALTER TABLE "assessment_lessons" ADD CONSTRAINT "assessment_lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250320090900_normalize_lesson_step/migration.sql">
-- CreateTable
CREATE TABLE "lesson_steps" (
    "id" TEXT NOT NULL,
    "lessonId" TEXT NOT NULL,
    "stepNumber" INTEGER NOT NULL,
    "type" TEXT NOT NULL,
    "content" TEXT NOT NULL,
    "translation" TEXT,
    "userResponse" TEXT,
    "attempts" INTEGER NOT NULL DEFAULT 0,
    "correct" BOOLEAN NOT NULL DEFAULT false,
    "lastAttemptAt" TIMESTAMP(3),
    "errorPatterns" TEXT[],
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "lesson_steps_pkey" PRIMARY KEY ("id")
);

-- AddForeignKey
ALTER TABLE "lesson_steps" ADD CONSTRAINT "lesson_steps_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "lessons"("id") ON DELETE RESTRICT ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250320091234_normalize_lesson_step/migration.sql">
/*
  Warnings:

  - Changed the type of `type` on the `lesson_steps` table. No cast exists, the column would be dropped and recreated, which cannot be done if there is data, since the column is required.

*/
-- CreateEnum
CREATE TYPE "LessonStepType" AS ENUM ('prompt', 'model_answer', 'user_answer', 'new_word', 'practice');

-- AlterTable
ALTER TABLE "lesson_steps" DROP COLUMN "type",
ADD COLUMN     "type" "LessonStepType" NOT NULL;
</file>

<file path="prisma/migrations/20250320092128_normalize_lesson_step_update_lesson_table/migration.sql">
/*
  Warnings:

  - You are about to drop the column `sequence` on the `lessons` table. All the data in the column will be lost.

*/
-- AlterTable
ALTER TABLE "lessons" DROP COLUMN "sequence";
</file>

<file path="prisma/migrations/20250321100244_update_lesson_step_with_expected_answer_with_audios/migration.sql">
-- AlterTable
ALTER TABLE "lesson_steps" ADD COLUMN     "contentAudioUrl" TEXT,
ADD COLUMN     "expectedAnswer" TEXT,
ADD COLUMN     "expectedAnswerAudioUrl" TEXT;
</file>

<file path="prisma/migrations/20250321103532_add_languages_to_assessment_lessons/migration.sql">
/*
  Warnings:

  - Added the required column `sourceLanguage` to the `assessment_lessons` table without a default value. This is not possible if the table is not empty.
  - Added the required column `targetLanguage` to the `assessment_lessons` table without a default value. This is not possible if the table is not empty.

*/
-- AlterTable
ALTER TABLE "assessment_lessons" ADD COLUMN     "sourceLanguage" TEXT NOT NULL,
ADD COLUMN     "targetLanguage" TEXT NOT NULL;
</file>

<file path="prisma/migrations/20250321120506_add_additional_fields_to_assessment_flow/migration.sql">
/*
  Warnings:

  - You are about to drop the column `modelAnswer` on the `assessment_lessons` table. All the data in the column will be lost.
  - You are about to drop the column `prompt` on the `assessment_lessons` table. All the data in the column will be lost.
  - You are about to drop the column `step` on the `assessment_lessons` table. All the data in the column will be lost.
  - You are about to drop the column `userResponse` on the `assessment_lessons` table. All the data in the column will be lost.
  - A unique constraint covering the columns `[userId]` on the table `assessment_lessons` will be added. If there are existing duplicate values, this will fail.

*/
-- CreateEnum
CREATE TYPE "AssessmentStepType" AS ENUM ('question', 'user_response', 'feedback', 'instruction', 'summary');

-- AlterTable
ALTER TABLE "assessment_lessons" DROP COLUMN "modelAnswer",
DROP COLUMN "prompt",
DROP COLUMN "step",
DROP COLUMN "userResponse",
ADD COLUMN     "description" TEXT,
ADD COLUMN     "metrics" JSONB,
ADD COLUMN     "proposedTopics" TEXT[],
ADD COLUMN     "summary" TEXT;

-- CreateTable
CREATE TABLE "assessment_steps" (
    "id" TEXT NOT NULL,
    "assessmentId" TEXT NOT NULL,
    "stepNumber" INTEGER NOT NULL,
    "type" "AssessmentStepType" NOT NULL,
    "content" TEXT NOT NULL,
    "contentAudioUrl" TEXT,
    "translation" TEXT,
    "expectedAnswer" TEXT,
    "expectedAnswerAudioUrl" TEXT,
    "maxAttempts" INTEGER NOT NULL DEFAULT 3,
    "userResponse" TEXT,
    "attempts" INTEGER NOT NULL DEFAULT 0,
    "correct" BOOLEAN NOT NULL DEFAULT false,
    "lastAttemptAt" TIMESTAMP(3),
    "feedback" TEXT,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "assessment_steps_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "assessment_lessons_userId_key" ON "assessment_lessons"("userId");

-- AddForeignKey
ALTER TABLE "assessment_steps" ADD CONSTRAINT "assessment_steps_assessmentId_fkey" FOREIGN KEY ("assessmentId") REFERENCES "assessment_lessons"("id") ON DELETE CASCADE ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250321131736_add_more_instruction_types_to_lesson/migration.sql">
-- AlterEnum
-- This migration adds more than one value to an enum.
-- With PostgreSQL versions 11 and earlier, this is not possible
-- in a single migration. This can be worked around by creating
-- multiple migrations, each migration adding only one value to
-- the enum.


ALTER TYPE "LessonStepType" ADD VALUE 'instruction';
ALTER TYPE "LessonStepType" ADD VALUE 'summary';
</file>

<file path="prisma/migrations/20250328130253_create_audio_metrics_table/migration.sql">
-- CreateEnum
CREATE TYPE "LearningTrajectory" AS ENUM ('steady', 'accelerating', 'plateauing');

-- CreateEnum
CREATE TYPE "LanguageInfluenceLevel" AS ENUM ('minimal', 'moderate', 'strong');

-- CreateEnum
CREATE TYPE "SpeechRateEvaluation" AS ENUM ('slow', 'appropriate', 'fast');

-- CreateEnum
CREATE TYPE "HesitationFrequency" AS ENUM ('rare', 'occasional', 'frequent');

-- CreateEnum
CREATE TYPE "PriorityLevel" AS ENUM ('low', 'medium', 'high');

-- CreateEnum
CREATE TYPE "SeverityLevel" AS ENUM ('minor', 'moderate', 'major');

-- CreateEnum
CREATE TYPE "VocabularyRange" AS ENUM ('limited', 'adequate', 'extensive');

-- CreateEnum
CREATE TYPE "ComprehensionLevel" AS ENUM ('poor', 'fair', 'good', 'excellent');

-- CreateTable
CREATE TABLE "audio_metrics" (
    "id" TEXT NOT NULL,
    "lessonId" TEXT,
    "assessmentLessonId" TEXT,
    "pronunciationScore" DOUBLE PRECISION NOT NULL,
    "fluencyScore" DOUBLE PRECISION NOT NULL,
    "grammarScore" DOUBLE PRECISION NOT NULL,
    "vocabularyScore" DOUBLE PRECISION NOT NULL,
    "overallPerformance" DOUBLE PRECISION NOT NULL,
    "proficiencyLevel" TEXT NOT NULL,
    "learningTrajectory" "LearningTrajectory" NOT NULL,
    "pronunciationAssessment" JSONB NOT NULL,
    "fluencyAssessment" JSONB NOT NULL,
    "grammarAssessment" JSONB NOT NULL,
    "vocabularyAssessment" JSONB NOT NULL,
    "exerciseCompletion" JSONB NOT NULL,
    "suggestedTopics" TEXT[],
    "grammarFocusAreas" TEXT[],
    "vocabularyDomains" TEXT[],
    "nextSkillTargets" TEXT[],
    "preferredPatterns" TEXT[],
    "effectiveApproaches" TEXT[],
    "audioRecordingUrl" TEXT,
    "recordingDuration" DOUBLE PRECISION,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "audio_metrics_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "audio_metrics_lessonId_key" ON "audio_metrics"("lessonId");

-- CreateIndex
CREATE UNIQUE INDEX "audio_metrics_assessmentLessonId_key" ON "audio_metrics"("assessmentLessonId");

-- AddForeignKey
ALTER TABLE "audio_metrics" ADD CONSTRAINT "audio_metrics_lessonId_fkey" FOREIGN KEY ("lessonId") REFERENCES "lessons"("id") ON DELETE SET NULL ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "audio_metrics" ADD CONSTRAINT "audio_metrics_assessmentLessonId_fkey" FOREIGN KEY ("assessmentLessonId") REFERENCES "assessment_lessons"("id") ON DELETE SET NULL ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250328132500_add_session_recording_url_to_lesson_tables/migration.sql">
-- AlterTable
ALTER TABLE "assessment_lessons" ADD COLUMN     "sessionRecordingUrl" TEXT;

-- AlterTable
ALTER TABLE "lessons" ADD COLUMN     "sessionRecordingUrl" TEXT;
</file>

<file path="prisma/migrations/20250401063634_/migration.sql">
/*
  Warnings:

  - The values [user_response] on the enum `AssessmentStepType` will be removed. If these variants are still used in the database, this will fail.
  - The values [model_answer,user_answer] on the enum `LessonStepType` will be removed. If these variants are still used in the database, this will fail.

*/
-- AlterEnum
BEGIN;
CREATE TYPE "AssessmentStepType_new" AS ENUM ('question', 'feedback', 'instruction', 'summary');
ALTER TABLE "assessment_steps" ALTER COLUMN "type" TYPE "AssessmentStepType_new" USING ("type"::text::"AssessmentStepType_new");
ALTER TYPE "AssessmentStepType" RENAME TO "AssessmentStepType_old";
ALTER TYPE "AssessmentStepType_new" RENAME TO "AssessmentStepType";
DROP TYPE "AssessmentStepType_old";
COMMIT;

-- AlterEnum
BEGIN;
CREATE TYPE "LessonStepType_new" AS ENUM ('prompt', 'feedback', 'new_word', 'practice', 'instruction', 'summary');
ALTER TABLE "lesson_steps" ALTER COLUMN "type" TYPE "LessonStepType_new" USING ("type"::text::"LessonStepType_new");
ALTER TYPE "LessonStepType" RENAME TO "LessonStepType_old";
ALTER TYPE "LessonStepType_new" RENAME TO "LessonStepType";
DROP TYPE "LessonStepType_old";
COMMIT;
</file>

<file path="prisma/migrations/20250404075135_add_user_response_history_column/migration.sql">
-- AlterTable
ALTER TABLE "assessment_steps" ADD COLUMN     "userResponseHistory" JSONB;

-- AlterTable
ALTER TABLE "lesson_steps" ADD COLUMN     "userResponseHistory" JSONB;
</file>

<file path="prisma/migrations/20250404082007_add_max_attempts_to_lesson_step/migration.sql">
-- AlterTable
ALTER TABLE "lesson_steps" ADD COLUMN     "maxAttempts" INTEGER NOT NULL DEFAULT 3;
</file>

<file path="prisma/migrations/20250408062820_add_udpated_at_to_user/migration.sql">
/*
  Warnings:

  - Added the required column `updatedAt` to the `User` table without a default value. This is not possible if the table is not empty.

*/
-- AlterTable
ALTER TABLE "User" ADD COLUMN     "updatedAt" TIMESTAMP(3) NOT NULL;
</file>

<file path="prisma/migrations/20250408123748_add_progress_tracking/migration.sql">
-- CreateEnum
CREATE TYPE "MasteryLevel" AS ENUM ('NotStarted', 'Seen', 'Learning', 'Practiced', 'Known', 'Mastered');

-- CreateTable
CREATE TABLE "learning_progress" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "estimatedProficiencyLevel" "ProficiencyLevel" NOT NULL DEFAULT 'beginner',
    "overallScore" DOUBLE PRECISION,
    "learningTrajectory" "LearningTrajectory" NOT NULL DEFAULT 'steady',
    "strengths" TEXT[],
    "weaknesses" TEXT[],
    "lastLessonCompletedAt" TIMESTAMP(3),
    "lastAssessmentCompletedAt" TIMESTAMP(3),
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "learning_progress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "topic_progress" (
    "id" TEXT NOT NULL,
    "learningProgressId" TEXT NOT NULL,
    "topicName" TEXT NOT NULL,
    "masteryLevel" "MasteryLevel" NOT NULL DEFAULT 'NotStarted',
    "lastStudiedAt" TIMESTAMP(3),
    "relatedLessonIds" TEXT[],
    "relatedAssessmentIds" TEXT[],
    "score" DOUBLE PRECISION,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "topic_progress_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "word_progress" (
    "id" TEXT NOT NULL,
    "learningProgressId" TEXT NOT NULL,
    "word" TEXT NOT NULL,
    "translation" TEXT,
    "masteryLevel" "MasteryLevel" NOT NULL DEFAULT 'Seen',
    "timesCorrect" INTEGER NOT NULL DEFAULT 0,
    "timesIncorrect" INTEGER NOT NULL DEFAULT 0,
    "firstSeenAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "lastReviewedAt" TIMESTAMP(3),
    "relatedLessonStepIds" TEXT[],
    "relatedAssessmentStepIds" TEXT[],
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "word_progress_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "learning_progress_userId_key" ON "learning_progress"("userId");

-- CreateIndex
CREATE UNIQUE INDEX "topic_progress_learningProgressId_topicName_key" ON "topic_progress"("learningProgressId", "topicName");

-- CreateIndex
CREATE INDEX "word_progress_learningProgressId_masteryLevel_idx" ON "word_progress"("learningProgressId", "masteryLevel");

-- CreateIndex
CREATE UNIQUE INDEX "word_progress_learningProgressId_word_key" ON "word_progress"("learningProgressId", "word");

-- AddForeignKey
ALTER TABLE "learning_progress" ADD CONSTRAINT "learning_progress_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE CASCADE ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "topic_progress" ADD CONSTRAINT "topic_progress_learningProgressId_fkey" FOREIGN KEY ("learningProgressId") REFERENCES "learning_progress"("id") ON DELETE CASCADE ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "word_progress" ADD CONSTRAINT "word_progress_learningProgressId_fkey" FOREIGN KEY ("learningProgressId") REFERENCES "learning_progress"("id") ON DELETE CASCADE ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250410084132_add_relation_on_delete_to_all_user_containing_tables/migration.sql">
-- DropForeignKey
ALTER TABLE "assessment_lessons" DROP CONSTRAINT "assessment_lessons_userId_fkey";

-- DropForeignKey
ALTER TABLE "lessons" DROP CONSTRAINT "lessons_userId_fkey";

-- DropForeignKey
ALTER TABLE "onboarding" DROP CONSTRAINT "onboarding_userId_fkey";

-- AddForeignKey
ALTER TABLE "onboarding" ADD CONSTRAINT "onboarding_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE CASCADE ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "assessment_lessons" ADD CONSTRAINT "assessment_lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE CASCADE ON UPDATE CASCADE;

-- AddForeignKey
ALTER TABLE "lessons" ADD CONSTRAINT "lessons_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE CASCADE ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250410104713_add_payments/migration.sql">
-- CreateEnum
CREATE TYPE "PaymentStatus" AS ENUM ('PENDING', 'PROCESSING', 'SUCCEEDED', 'FAILED', 'REQUIRES_ACTION', 'CANCELED');

-- CreateTable
CREATE TABLE "payments" (
    "id" TEXT NOT NULL,
    "userId" TEXT NOT NULL,
    "stripePaymentIntentId" TEXT NOT NULL,
    "status" "PaymentStatus" NOT NULL DEFAULT 'PENDING',
    "amount" INTEGER NOT NULL,
    "currency" TEXT NOT NULL,
    "productId" TEXT,
    "productType" TEXT,
    "errorMessage" TEXT,
    "metadata" JSONB,
    "createdAt" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updatedAt" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "payments_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "payments_stripePaymentIntentId_key" ON "payments"("stripePaymentIntentId");

-- CreateIndex
CREATE INDEX "payments_userId_idx" ON "payments"("userId");

-- AddForeignKey
ALTER TABLE "payments" ADD CONSTRAINT "payments_userId_fkey" FOREIGN KEY ("userId") REFERENCES "User"("id") ON DELETE CASCADE ON UPDATE CASCADE;
</file>

<file path="prisma/migrations/20250410112216_add_subscriptions/migration.sql">
/*
  Warnings:

  - A unique constraint covering the columns `[subscriptionId]` on the table `User` will be added. If there are existing duplicate values, this will fail.

*/
-- CreateEnum
CREATE TYPE "SubscriptionStatus" AS ENUM ('NONE', 'TRIAL', 'ACTIVE', 'CANCELED', 'PAST_DUE');

-- AlterTable
ALTER TABLE "User" ADD COLUMN     "subscriptionEndDate" TIMESTAMP(3),
ADD COLUMN     "subscriptionId" TEXT,
ADD COLUMN     "subscriptionStatus" "SubscriptionStatus" NOT NULL DEFAULT 'NONE';

-- CreateIndex
CREATE UNIQUE INDEX "User_subscriptionId_key" ON "User"("subscriptionId");
</file>

<file path="prisma/migrations/20250411104102_add_additional_subscription_fields/migration.sql">
-- AlterEnum
ALTER TYPE "SubscriptionStatus" ADD VALUE 'EXPIRED';

-- AlterTable
ALTER TABLE "User" ADD COLUMN     "billingCycle" TEXT,
ADD COLUMN     "paymentMethodId" TEXT,
ADD COLUMN     "subscriptionPlan" TEXT,
ADD COLUMN     "subscriptionStartDate" TIMESTAMP(3),
ADD COLUMN     "trialEndDate" TIMESTAMP(3),
ADD COLUMN     "trialStartDate" TIMESTAMP(3);

-- AlterTable
ALTER TABLE "payments" ADD COLUMN     "isRecurring" BOOLEAN DEFAULT false,
ADD COLUMN     "relatedSubscriptionId" TEXT,
ADD COLUMN     "subscriptionPlan" TEXT;
</file>

<file path="prisma/migrations/migration_lock.toml">
# Please do not edit this file manually
# It should be added in your version-control system (e.g., Git)
provider = "postgresql"
</file>

<file path="public/robots.txt">
# *
User-agent: *
Allow: /
Disallow: /api/*

# Host
Host: https://lessay-app.vercel.app

# Sitemaps
Sitemap: https://lessay-app.vercel.app/sitemap.xml
Sitemap: https://lessay-app.vercel.app/server-sitemap.xml
</file>

<file path="public/sitemap.xml">
<?xml version="1.0" encoding="UTF-8"?>
<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
<sitemap><loc>https://lessay-app.vercel.app/sitemap-0.xml</loc></sitemap>
<sitemap><loc>https://lessay-app.vercel.app/server-sitemap.xml</loc></sitemap>
</sitemapindex>
</file>

<file path="scripts/export-data.js">
import { PrismaClient } from '@prisma/client';
import fs from 'fs';

const prisma = new PrismaClient();

async function exportData() {
  const data = await prisma.assessmentLesson.findMany({
    include: {
      steps: true, // Include related AssessmentStep records
    },
  });

  fs.writeFileSync('exported-data.json', JSON.stringify(data, null, 2));
  console.log('Data exported to exported-data.json');
}

exportData()
  .catch((e) => {
    console.error(e);
    process.exit(1);
  })
  .finally(async () => {
    await prisma.$disconnect();
  });
</file>

<file path="src/__mocks__/assessment-data.mock.ts">
export const assessmentMockDataJson = [
  {
    "id": "cm8zq3y9p000lov11yk76hai8",
    "userId": "mock-user-id",
    "description": "Comprehensive German language assessment",
    "completed": false,
    "sourceLanguage": "English",
    "targetLanguage": "German",
    "metrics": {
      "accuracy": 0,
      "strengths": [],
      "weaknesses": [],
      "grammarScore": 0,
      "overallScore": 0,
      "vocabularyScore": 0,
      "pronunciationScore": 0
    },
    "proposedTopics": [],
    "summary": null,
    "createdAt": "2025-04-02T09:27:19.357Z",
    "updatedAt": "2025-04-02T09:27:19.357Z",
    "sessionRecordingUrl": null,
    "steps": [
      {
        "id": "cm8zq3yal000nov11y1a1gxij",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 1,
        "type": "instruction",
        "content": "Welcome to your language assessment. I'll ask you a series of questions to evaluate your current knowledge of German. This will help me create a personalized learning plan for you. Let's begin!",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586027458-content_step_1.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:27:54.248Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.384Z",
        "updatedAt": "2025-04-02T09:27:54.250Z"
      },
      {
        "id": "cm8zq3yb4000pov11b62vi1h2",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 4,
        "type": "question",
        "content": "How do you ask 'Where is the bathroom?' in German?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586031665-content_step_4.mp3",
        "translation": "Wie fragt man 'Wo ist die Toilette?' auf Deutsch?",
        "expectedAnswer": "Wo ist die Toilette?",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743586032301-answer_step_4.mp3",
        "maxAttempts": 3,
        "userResponse": "Wo ist die Toilette?",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:28:23.215Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:28:23.217Z"
      },
      {
        "id": "cm8zq3yb7000rov11othb9q4c",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 5,
        "type": "feedback",
        "content": "Excellent! 'Wo ist die Toilette?' is the correct way to ask where the bathroom is in German. Now, let's move on to ordering.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586033765-content_step_5.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:28:31.014Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:28:31.016Z"
      },
      {
        "id": "cm8zq3yb7000tov11k2ex383b",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 9,
        "type": "summary",
        "content": "Great work on completing the assessment! Based on your responses, we'll create a personalized learning plan to help you improve your German skills.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586039354-content_step_9.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:29:34.527Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:29:34.529Z"
      },
      {
        "id": "cm8zq3yb9000xov11n0dkqg65",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 8,
        "type": "question",
        "content": "How do you ask for the time in German?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586037127-content_step_8.mp3",
        "translation": "Wie fragt man nach der Uhrzeit auf Deutsch?",
        "expectedAnswer": "Wie spät ist es?",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743586037742-answer_step_8.mp3",
        "maxAttempts": 3,
        "userResponse": "Wie spät ist es?",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:29:25.752Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:29:25.753Z"
      },
      {
        "id": "cm8zq3yb9000wov11dwekist4",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 6,
        "type": "question",
        "content": "How would you order a coffee in German?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586034501-content_step_6.mp3",
        "translation": "Wie bestellt man einen Kaffee auf Deutsch?",
        "expectedAnswer": "Einen Kaffee, bitte.",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743586035148-answer_step_6.mp3",
        "maxAttempts": 3,
        "userResponse": "Einen Kaffee, bitte.",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:29:10.331Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:29:10.332Z"
      },
      {
        "id": "cm8zq3ybf0013ov11rgzeykhs",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 3,
        "type": "feedback",
        "content": "Great job! You answered correctly. 'Hallo, ich heiße...' is how you introduce yourself in German. Let's try another phrase.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586030655-content_step_3.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:28:09.547Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:28:09.548Z"
      },
      {
        "id": "cm8zq3ybf0011ov11kzadgt8k",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 2,
        "type": "question",
        "content": "How do you say 'Hello, my name is...' in German?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586028405-content_step_2.mp3",
        "translation": "Wie sagt man 'Hallo, mein Name ist...' auf Deutsch?",
        "expectedAnswer": "Hallo, ich heiße...",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743586029026-answer_step_2.mp3",
        "maxAttempts": 3,
        "userResponse": "Hallo, ich heiße...",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:28:00.371Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:28:00.372Z"
      },
      {
        "id": "cm8zq3ybf0012ov11ygose4p7",
        "assessmentId": "cm8zq3y9p000lov11yk76hai8",
        "stepNumber": 7,
        "type": "feedback",
        "content": "Perfect! 'Einen Kaffee, bitte' is exactly how you would order a coffee in German. Let's move on to asking about time.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743586036451-content_step_7.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-02T09:29:16.942Z",
        "feedback": null,
        "createdAt": "2025-04-02T09:27:19.385Z",
        "updatedAt": "2025-04-02T09:29:16.944Z"
      }
    ]
  }
]


export const assessmentMockData2 = [
  {
    "id": "cm91dx28m0001lh1176u9k5qd",
    "userId": "mock-user-id",
    "description": "Comprehensive German language assessment",
    "completed": false,
    "sourceLanguage": "English",
    "targetLanguage": "German",
    "metrics": {
      "accuracy": 0,
      "strengths": [],
      "weaknesses": [],
      "grammarScore": 0,
      "overallScore": 0,
      "vocabularyScore": 0,
      "pronunciationScore": 0
    },
    "proposedTopics": [],
    "summary": null,
    "createdAt": "2025-04-03T13:21:34.870Z",
    "updatedAt": "2025-04-03T13:21:34.870Z",
    "sessionRecordingUrl": null,
    "steps": [
      {
        "id": "cm91dx29e0003lh11uflo309z",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 2,
        "type": "question",
        "content": "Choose the correct German translation for 'Hello'.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686482848-content_step_2.mp3",
        "translation": null,
        "expectedAnswer": "Hallo",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686483482-answer_step_2.mp3",
        "maxAttempts": 3,
        "userResponse": "Hallo",
        "attempts": 2,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:29.937Z",
        "feedback": "Correct! 'Hallo' is the most common way to say 'Hello' in German. Other options include 'Guten Tag' (Good day) and 'Guten Morgen' (Good morning).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:29.939Z"
      },
      {
        "id": "cm91dx2a10008lh1170jfw7kt",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 6,
        "type": "question",
        "content": "Choose the correct article for 'Tisch' (table).",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686489957-content_step_6.mp3",
        "translation": null,
        "expectedAnswer": "der",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686490561-answer_step_6.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "The correct article is 'der'. Therefore, it is 'der Tisch'. Remember that German nouns have genders (masculine, feminine, or neuter) which determine the article.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx2a4000elh113tt2ahgu",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 7,
        "type": "question",
        "content": "What is the past participle of the verb 'essen' (to eat)?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686491655-content_step_7.mp3",
        "translation": null,
        "expectedAnswer": "gegessen",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686492409-answer_step_7.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "The correct past participle is 'gegessen'. This is used to form the perfect tense (e.g., Ich habe gegessen - I have eaten).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx2a3000alh11cch5c4m4",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 4,
        "type": "question",
        "content": "Complete the sentence: Ich _____ ein Buch.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686486272-content_step_4.mp3",
        "translation": "I _____ a book.",
        "expectedAnswer": "lese",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686486956-answer_step_4.mp3",
        "maxAttempts": 3,
        "userResponse": "This is a mock response different from the expected",
        "attempts": 8,
        "correct": false,
        "lastAttemptAt": "2025-04-03T13:25:33.501Z",
        "feedback": "The correct answer is 'lese'. The verb 'lesen' (to read) is conjugated to 'lese' in the first person singular (ich).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:25:33.502Z"
      },
      {
        "id": "cm91dx2a3000clh11zhfgy3hk",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 8,
        "type": "summary",
        "content": "Thank you for completing the assessment! Based on your responses, we have a better understanding of your German language skills. We're excited to help you on your language learning journey, no matter your level. Let's get started!",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686494861-content_step_8.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": null,
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx29s0005lh113q4tud6e",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 1,
        "type": "instruction",
        "content": "Welcome to our German language assessment! This short quiz will help us determine your current German proficiency level. Please answer each question to the best of your ability. Don't worry if you don't know all the answers – this is just to help us personalize your learning experience. Viel Glück! (Good luck!)",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686481755-content_step_1.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:16.551Z",
        "feedback": null,
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:16.552Z"
      },
      {
        "id": "cm91dx2a6000glh11ezdyqlwf",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 3,
        "type": "question",
        "content": "What is the German word for 'thank you'?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686484428-content_step_3.mp3",
        "translation": null,
        "expectedAnswer": "Danke",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686485129-answer_step_3.mp3",
        "maxAttempts": 3,
        "userResponse": "Danke",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:36.332Z",
        "feedback": "'Danke' is correct! You can also say 'Vielen Dank' for 'Thank you very much'.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:36.333Z"
      },
      {
        "id": "cm91dx2a7000hlh111peyaxaj",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 5,
        "type": "question",
        "content": "Translate the following sentence into German: 'My name is John.'",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686488193-content_step_5.mp3",
        "translation": null,
        "expectedAnswer": "Ich heiße John",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686488904-answer_step_5.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "Correct! 'Ich heiße John' is the most common way to say 'My name is John'. Another option is 'Mein Name ist John'.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      }
    ]
  }
]
</file>

<file path="src/__mocks__/generated-assessment-lessons.mock.ts">
import {  AssessmentStepType } from "@prisma/client";
import { AssessmentLesson as AssessmentLessonModel } from "@/models/AppAllModels.model";
import logger from "@/utils/logger";

export const MockAssessmentGeneratorService = {
  generateAudioForStep: async function(
    content: string,
    language: string = "English"
  ) {
    logger.info(`Generating audio for step and language: ${content} ${language}`);
    // Return a mock base64 audio string that can be converted to Buffer
    return "UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA="; // Very short silent audio in base64
  },
  generateAssessmentLesson: async function(
    sourceLanguage: string = "English",
    targetLanguage: string = "German"
  ) {
    // Only support English to German for now
    if (sourceLanguage !== "English" || targetLanguage !== "German") {
      console.warn("Currently only English to German assessments are fully supported in mock data");
    }

    const assessmentLessonSteps = [
      {
        stepNumber: 1,
        type: AssessmentStepType.instruction,
        content: "Welcome to your language assessment. I'll ask you a series of questions to evaluate your current knowledge of German. This will help me create a personalized learning plan for you. Let's begin!",
        // contentAudioUrl: "/audio-test.mp3",
        maxAttempts: 1,
        attempts: 0,
        correct: false
      },
      {
        stepNumber: 2,
        type: AssessmentStepType.question,
        content: "How do you say 'Hello, my name is...' in German?",
        // contentAudioUrl: "/audio-test.mp3",
        translation: "Wie sagt man 'Hallo, mein Name ist...' auf Deutsch?",
        expectedAnswer: "Hallo, ich heiße...",
        // expectedAnswerAudioUrl: "/audio-test.mp3",
        maxAttempts: 3,
        attempts: 0,
        correct: false
      },
      {
        stepNumber: 3,
        type: AssessmentStepType.feedback,
        content: "Great job! You answered correctly. 'Hallo, ich heiße...' is how you introduce yourself in German. Let's try another phrase.",
        // contentAudioUrl: "/audio-test.mp3",
        maxAttempts: 1,
        attempts: 0,
        correct: true
      },
      {
        stepNumber: 4,
        type: AssessmentStepType.question,
        content: "How do you ask 'Where is the bathroom?' in German?",
        // contentAudioUrl: "/audio-test.mp3",
        translation: "Wie fragt man 'Wo ist die Toilette?' auf Deutsch?",
        expectedAnswer: "Wo ist die Toilette?",
        // expectedAnswerAudioUrl: "/audio-test.mp3",
        maxAttempts: 3,
        attempts: 0,
        correct: false
      },
      {
        stepNumber: 5,
        type: AssessmentStepType.feedback,
        content: "Excellent! 'Wo ist die Toilette?' is the correct way to ask where the bathroom is in German. Now, let's move on to ordering.",
        // contentAudioUrl: "/audio-test.mp3",
        maxAttempts: 1,
        attempts: 0,
        correct: true
      },
      {
        stepNumber: 6, 
        type: AssessmentStepType.question,
        content: "How would you order a coffee in German?",
        // contentAudioUrl: "/audio-test.mp3",
        translation: "Wie bestellt man einen Kaffee auf Deutsch?",
        expectedAnswer: "Einen Kaffee, bitte.",
        // expectedAnswerAudioUrl: "/audio-test.mp3",
        maxAttempts: 3,
        attempts: 0,
        correct: false
      },
      {
        stepNumber: 7,
        type: AssessmentStepType.feedback,
        content: "Perfect! 'Einen Kaffee, bitte' is exactly how you would order a coffee in German. Let's move on to asking about time.",
        // contentAudioUrl: "/audio-test.mp3",
        maxAttempts: 1,
        attempts: 0,
        correct: true
      },
      {
        stepNumber: 8,
        type: AssessmentStepType.question,
        content: "How do you ask for the time in German?",
        // contentAudioUrl: "/audio-test.mp3",
        translation: "Wie fragt man nach der Uhrzeit auf Deutsch?",
        expectedAnswer: "Wie spät ist es?",
        // expectedAnswerAudioUrl: "/audio-test.mp3",
        maxAttempts: 3,
        attempts: 0,
        correct: false
      },
      {
        stepNumber: 9,
        type: AssessmentStepType.summary,
        content: "Great work on completing the assessment! Based on your responses, we'll create a personalized learning plan to help you improve your German skills.",
        // contentAudioUrl: "/audio-test.mp3",
        maxAttempts: 1,
        attempts: 0,
        correct: false
      }
    ];

    console.log(`Generated assessment with ${assessmentLessonSteps.length} steps`);
    return {
      steps: assessmentLessonSteps,
      targetLanguage,
      sourceLanguage
    };
  },

  generateAssessmentResult: async function(
    assessmentLesson: AssessmentLessonModel,
    userResponse: string
  ) {
    // Calculate mock scores
    const correctSteps = assessmentLesson.steps.filter(step => 
      step.type === AssessmentStepType.question && step.correct
    );
    const totalQuestions = assessmentLesson.steps.filter(step => 
      step.type === AssessmentStepType.question
    ).length;
    
    // Calculate a basic accuracy score based on how many questions were answered correctly
    const accuracy = totalQuestions > 0 ? (correctSteps.length / totalQuestions) * 100 : 70;
    
    // Generate random scores within reasonable ranges
    const pronunciationScore = Math.floor(Math.random() * 30) + 60; // 60-90
    const grammarScore = Math.floor(Math.random() * 30) + 60; // 60-90
    const vocabularyScore = Math.floor(Math.random() * 30) + 60; // 60-90
    
    // Overall score is an average of the other scores
    const overallScore = Math.floor((accuracy + pronunciationScore + grammarScore + vocabularyScore) / 4);
    
    // Create mock strengths and weaknesses based on the scores
    const strengths = [];
    const weaknesses = [];
    
    if (pronunciationScore > 75) strengths.push("Good pronunciation of basic phrases");
    else weaknesses.push("Pronunciation of certain words needs improvement");
    
    if (grammarScore > 75) strengths.push("Understanding of basic grammar structures");
    else weaknesses.push("Grammar usage in complex sentences");
    
    if (vocabularyScore > 75) strengths.push("Good grasp of essential vocabulary");
    else weaknesses.push("Limited vocabulary range");
    
    // Add some general strengths/weaknesses
    strengths.push("Willingness to communicate");
    if (Math.random() > 0.5) strengths.push("Good comprehension of simple phrases");
    
    weaknesses.push("Confidence in speaking");
    if (Math.random() > 0.5) weaknesses.push("Word order in questions");
    
    // Generate proposed topics based on target language
    const proposedTopics = [
      "Basic Greetings and Introductions",
      "Everyday Conversations",
      "Travel Vocabulary",
      "Food and Dining",
      "Shopping and Numbers"
    ];
    
    // Create a summary
    const summaryParts = [
      `Based on your assessment, you've demonstrated ${overallScore > 75 ? "good" : "basic"} proficiency in ${assessmentLesson.targetLanguage}.`,
      `Your strengths include ${strengths.slice(0, 2).join(" and ")}.`,
      `Areas for improvement include ${weaknesses.slice(0, 2).join(" and ")}.`,
      "We recommend starting with focused lessons on basic conversational phrases and gradually expanding your vocabulary."
    ];
    
    const summary = summaryParts.join(" ");
    
    return {
      metrics: {
        accuracy,
        pronunciationScore,
        grammarScore,
        vocabularyScore,
        overallScore,
        strengths,
        weaknesses
      },
      proposedTopics,
      summary
    };
  }
};

// Adding the IAssessmentGeneratorService interface to lib/interfaces/all-interfaces.ts
// You'll need to add this interface to your project:
/*
export interface IAssessmentGeneratorService {
  generateAssessmentLesson: (userId: string, sourceLanguage?: string, targetLanguage?: string) => Promise<any>;
}
*/
</file>

<file path="src/__mocks__/generated-audio-metrics.mock.ts">
// Mock Audio Metrics Data - based on the response format from messageGenerator.ts
export const mockAudioMetrics: Record<string, unknown> = {
  // Top-level metrics (0-100 scale)
  pronunciationScore: 78.5,
  fluencyScore: 82.3,
  grammarScore: 75.0, 
  vocabularyScore: 80.2,
  overallPerformance: 79.0,
  
  // CEFR level and trajectory
  proficiencyLevel: "B1",
  learningTrajectory: "accelerating",
  
  // Detailed pronunciation assessment
  pronunciationAssessment: {
    overall_score: 78.5,
    native_language_influence: {
      level: "moderate",
      specific_features: [
        "vowel substitution in stressed syllables",
        "consonant simplification in word-final positions",
        "retroflex consonant pronunciation"
      ]
    },
    phoneme_analysis: [
      {
        phoneme: "ð",
        target_realization: "ð",
        user_realization: "d",
        accuracy: 65,
        examples: ["the", "other", "them"]
      },
      {
        phoneme: "æ",
        target_realization: "æ",
        user_realization: "ɛ",
        accuracy: 70,
        examples: ["cat", "that", "map"]
      },
      {
        phoneme: "ɹ",
        target_realization: "ɹ",
        user_realization: "ɾ",
        accuracy: 75,
        examples: ["red", "around", "very"]
      }
    ],
    problematic_sounds: ["ð", "æ", "ŋ", "θ"],
    strengths: [
      "consistent production of diphthongs",
      "accurate stress patterns in multi-syllable words",
      "good control of plosive consonants"
    ],
    areas_for_improvement: [
      "dental fricatives (th sounds)",
      "vowel distinction in minimal pairs",
      "nasal consonant clarity"
    ]
  },
  
  // Detailed fluency assessment
  fluencyAssessment: {
    overall_score: 82.3,
    speech_rate: {
      words_per_minute: 105,
      evaluation: "appropriate"
    },
    hesitation_patterns: {
      frequency: "occasional",
      average_pause_duration: 0.8,
      typical_contexts: [
        "before complex grammatical structures",
        "when searching for specific vocabulary",
        "after being asked a new question"
      ]
    },
    rhythm_and_intonation: {
      naturalness: 76,
      sentence_stress_accuracy: 82,
      intonation_pattern_accuracy: 78
    }
  },
  
  // Detailed grammar assessment
  grammarAssessment: {
    overall_score: 75.0,
    error_patterns: [
      {
        category: "verb tense",
        description: "inconsistent use of past tense forms",
        examples: ["yesterday I go to the store", "she didn't went"],
        frequency: "occasional",
        severity: "moderate"
      },
      {
        category: "article usage",
        description: "omission of definite articles",
        examples: ["I went to store", "he is best student"],
        frequency: "frequent",
        severity: "minor"
      },
      {
        category: "subject-verb agreement",
        description: "third person singular present tense errors",
        examples: ["she play piano", "it make sense"],
        frequency: "occasional",
        severity: "moderate"
      }
    ],
    grammar_rules_to_review: [
      {
        rule: "past tense irregular verbs",
        priority: "high",
        examples: ["go/went", "buy/bought", "think/thought"]
      },
      {
        rule: "definite article usage",
        priority: "medium",
        examples: ["the hospital", "the university", "the best"]
      },
      {
        rule: "subject-verb agreement",
        priority: "high",
        examples: ["she plays", "he works", "it costs"]
      }
    ],
    grammar_strengths: [
      "consistent word order in statements",
      "accurate use of common prepositions",
      "good command of present simple tense"
    ]
  },
  
  // Detailed vocabulary assessment
  vocabularyAssessment: {
    overall_score: 80.2,
    range: "adequate",
    appropriateness: 85,
    precision: 78,
    areas_for_expansion: [
      {
        topic: "emotions and feelings",
        suggested_vocabulary: ["frustrated", "anxious", "relieved", "delighted", "concerned"]
      },
      {
        topic: "academic discussion",
        suggested_vocabulary: ["analyze", "evaluate", "consider", "perspective", "assertion"]
      },
      {
        topic: "daily routines",
        suggested_vocabulary: ["commute", "manage", "schedule", "appointment", "organize"]
      }
    ]
  },
  
  // Exercise completion assessment
  exerciseCompletion: {
    overall_score: 81.5,
    exercises_analyzed: [
      {
        prompt: "Describe your typical morning routine.",
        expected_answer: "Free response focusing on daily activities using present simple.",
        user_response: "I wake up at 7, then I eating breakfast and go to work by bus.",
        accuracy: 85,
        error_analysis: "One verb tense error (eating instead of eat)"
      },
      {
        prompt: "What did you do last weekend?",
        expected_answer: "Free response using past tense verbs.",
        user_response: "Last weekend I went to the park and play football with friends.",
        accuracy: 80,
        error_analysis: "Mixed tense usage (went vs play)"
      },
      {
        prompt: "How would you improve public transportation in your city?",
        expected_answer: "Conditional/hypothetical structures with modal verbs.",
        user_response: "I think we need more buses and the trains should be more frequent.",
        accuracy: 90,
        error_analysis: "Good modal verb usage, clear structure"
      }
    ],
    comprehension_level: "good"
  },
  
  // Learning recommendations
  suggestedTopics: [
    "Past Tense Narratives",
    "Describing Emotions and Feelings",
    "Daily Routines and Habits",
    "Making Comparisons"
  ],
  grammarFocusAreas: [
    "Past Tense Forms",
    "Articles (a/an/the)",
    "Subject-Verb Agreement"
  ],
  vocabularyDomains: [
    "Emotional Expression",
    "Academic Discussion",
    "Work and Daily Life"
  ],
  nextSkillTargets: [
    "Proper use of articles in complex phrases",
    "Past simple vs present perfect distinction",
    "Expansion of descriptive vocabulary"
  ],
  
  // Learning style observations
  preferredPatterns: [
    "visual learning with examples",
    "interactive practice over theory",
    "responds well to error correction"
  ],
  effectiveApproaches: [
    "conversational practice with feedback",
    "pattern recognition exercises",
    "situational role-playing"
  ],
  
  // Metadata
  audioRecordingUrl: "https://api.example.com/recordings/lesson123.mp3",
  recordingDuration: 325.5 // seconds
};
</file>

<file path="src/__mocks__/tts-engine.mock.ts">
import { ITTS } from "@/interfaces/tts.interface";

export const mockTtsEngine: ITTS = {
  synthesizeSpeech: async (text: string, language: string, voice: string) => {
    console.warn('Replace this with actual TTS engine implementation');
    return Buffer.from(`Generated audio for: ${text} (${language}, ${voice})`);
  }
};
</file>

<file path="src/app/about/page.tsx">
import Footer from "@/components/Footer";
import type { Metadata } from 'next';

export const metadata: Metadata = {
  title: "About Us - Accent & Pronunciation Analysis | lessay",
  description: "Discover how lessay is revolutionizing accent and pronunciation analysis with AI technology. Learn about our mission to provide detailed feedback on your pronunciation and accent characteristics.",
  openGraph: {
    title: "About lessay - AI-Powered Accent and Pronunciation Analysis",
    description: "Learn about lessay's innovative approach to accent and pronunciation analysis using AI technology and personalized feedback.",
  },
};

export default function About() {
  return (
    <div className="flex flex-col items-center justify-items-center  sm:p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-8 row-start-2 items-center max-w-full sm:max-w-[1000px]">
        <div className="text-center">
          <h1 className="text-4xl sm:text-5xl font-bold mb-4">
            <span className="bg-gradient-to-r from-black to-black/70 dark:from-white dark:to-white/70 inline-block text-transparent bg-clip-text">
              lessay
            </span>
          </h1>
          <p className="text-lg text-gray-600 dark:text-gray-300">
            Analyze your accent, not the fluff
          </p>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl dark:border-white/[.145]">
          <h2 className="text-xl font-semibold mb-4 text-center">About lessay</h2>
          <div className="space-y-6">
            <p className="text-base text-gray-600 dark:text-gray-400">
              lessay is an innovative AI-powered platform specializing in detailed accent and pronunciation analysis. We focus on providing personalized feedback to help you refine your spoken language skills. We believe in efficiency, personalized learning, and making accent improvement effective.
            </p>
            <p className="text-base text-gray-600 dark:text-gray-400">
              Our platform uses cutting-edge AI to assess your pronunciation and accent characteristics, providing tailored insights. By identifying key areas for improvement, lessay helps you enhance your clarity and confidence in speaking.
            </p>
          </div>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl ">
          <h3 className="text-xl font-semibold mb-4 text-center">Our Mission</h3>
          <p className="text-base text-gray-600 dark:text-gray-400">
            At lessay, our mission is to revolutionize accent and pronunciation analysis by delivering tailored feedback—specific to your unique speaking style—so you can achieve clear and confident communication in the most efficient way possible.
          </p>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl ">
          <h3 className="text-xl font-semibold mb-4 text-center">Our Vision</h3>
          <p className="text-base text-gray-600 dark:text-gray-400">
            We envision a world where everyone has access to detailed, personalized accent and pronunciation analysis. lessay empowers you to refine your speaking style, unlocking new opportunities for connection and growth.
          </p>
        </div>
      </main>

      <Footer />
    </div>
  );
}
</file>

<file path="src/app/api/mock-auth/route.ts">
import { NextRequest, NextResponse } from 'next/server';
import logger from '@/utils/logger';



const DATA = {
  access_token: `mock-access-token-${Date.now()}`,
  refresh_token: `mock-refresh-token-${Date.now()}`,
  expires_in: 3600,
  token_type: 'Bearer',
  user: {
    id: 'mock-user-id',
    email: 'mock.email@example.com',
    aud: 'authenticated',
    role: 'authenticated',
    app_metadata: {},
    user_metadata: {},
    identities: [],
    factors: [],
    created_at: new Date().toISOString(),
    updated_at: new Date().toISOString(),
    email_confirmed_at: new Date().toISOString(),
    phone_confirmed_at: new Date().toISOString(),
    last_sign_in_at: new Date().toISOString(),
  }
};
// In-memory store for mock sessions
let mockSessionStore: any = null;

export async function POST(req: NextRequest) {
  try {
    const { action, email, password } = await req.json();

    logger.info('POST IN mock auth route', action, email, password);

    switch (action) {
      case 'login':
        const loginSession = {
          access_token: `mock-access-token-${Date.now()}`,
          refresh_token: `mock-refresh-token-${Date.now()}`,
          expires_in: 3600,
          token_type: 'Bearer',
          user: {
            id: 'mock-user-id',
            email: email,
            aud: 'authenticated',
            role: 'authenticated',
            app_metadata: {},
            user_metadata: {},
            identities: [],
            factors: [],
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString(),
            email_confirmed_at: new Date().toISOString(),
            phone_confirmed_at: new Date().toISOString(),
            last_sign_in_at: new Date().toISOString(),
          }
        };
        mockSessionStore = loginSession;
        return NextResponse.json({ user: loginSession.user, session: loginSession });

      case 'register':
        const registerSession = {
          access_token: `mock-reg-access-token-${Date.now()}`,
          refresh_token: `mock-reg-refresh-token-${Date.now()}`,
          expires_in: 3600,
          token_type: 'Bearer',
          user: {
            id: 'mock-user-id',
            email: email,
            aud: 'authenticated',
            role: 'authenticated',
            app_metadata: {},
            user_metadata: {},
            identities: [],
            factors: [],
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString(),
            email_confirmed_at: new Date().toISOString(),
            phone_confirmed_at: new Date().toISOString(),
            last_sign_in_at: new Date().toISOString(),
          }
        };
        mockSessionStore = registerSession;
        return NextResponse.json({ user: registerSession.user, session: registerSession });

      case 'logout':
        mockSessionStore = null;
        return NextResponse.json({ success: true });

      case 'getSession':
        return NextResponse.json({ session: DATA });

      case 'googleLogin':
        const googleSession = {
          access_token: `mock-google-access-token-${Date.now()}`,
          refresh_token: `mock-google-refresh-token-${Date.now()}`,
          expires_in: 3600,
          token_type: 'Bearer',
          user: {
            id: 'mock-google-user-id',
            email: 'mock.google@example.com',
            aud: 'authenticated',
            role: 'authenticated',
            app_metadata: { provider: 'google' },
            user_metadata: {},
            identities: [],
            factors: [],
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString(),
            email_confirmed_at: new Date().toISOString(),
            phone_confirmed_at: new Date().toISOString(),
            last_sign_in_at: new Date().toISOString(),
          }
        };
        mockSessionStore = googleSession;
        return NextResponse.json({ success: true });

      default:
        return NextResponse.json(
          { message: "Invalid action" },
          { status: 400 }
        );
    }
  } catch (error: unknown) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error("Mock auth error:", errorMessage);
    return NextResponse.json(
      { message: "Mock auth failed", error: errorMessage },
      { status: 500 }
    );
  }
}
</file>

<file path="src/app/api/payments/webhook.ts">
// // src/app/api/payments/webhook.ts
// import type { NextApiRequest, NextApiResponse } from 'next';
// import { PaymentService } from '@/services/payment.service';
// import { PaymentRepository } from '@/repositories/payment.repository'; // Import concrete repository
// import logger from '@/utils/logger';
// import { buffer } from 'micro';

// export const config = {
//   api: {
//     bodyParser: false,
//   },
// };

// // Helper function to instantiate the service with its dependencies
// function createPaymentService(): PaymentService {
//   const paymentRepository = new PaymentRepository(); // Create instance of repository
//   return new PaymentService(paymentRepository); // Inject repository into service
// }

// export default async function handler(req: NextApiRequest, res: NextApiResponse) {
//   if (req.method !== 'POST') {
//     res.setHeader('Allow', 'POST');
//     return res.status(405).end('Method Not Allowed');
//   }

//   const sig = req.headers['stripe-signature'];
//   let rawBody: Buffer;

//   try {
//     rawBody = await buffer(req);
//   } catch (error: any) {
//     logger.error('Error reading webhook request body:', error);
//     return res.status(400).json({ error: 'Could not read request body.' });
//   }

//   if (!sig) {
//     logger.error('Webhook error: Missing stripe-signature header');
//     return res.status(400).send('Webhook Error: Missing signature');
//   }


//   try {
//     const paymentService = createPaymentService(); // Use helper
//     await paymentService.handleWebhook(rawBody, sig);
//     logger.info('Stripe webhook processed successfully.');
//     return res.status(200).json({ received: true });

//   } catch (error: any) {
//     logger.error('Error processing Stripe webhook:', { error: error.message });
//     let statusCode = 400;
//     if (error.message.includes('Webhook secret not configured')) {
//       statusCode = 500;
//     } else if (error.message.includes('signature verification failed')) {
//       statusCode = 400; // Bad request due to signature
//     }
//     // Log the specific error message from Stripe if available
//     const errorMessage = error.message || 'Unknown webhook error';
//     return res.status(statusCode).json({ error: `Webhook Error: ${errorMessage}` });
//   }
// }
</file>

<file path="src/app/api/recording/route.ts">
// 'use server'
import { NextRequest, NextResponse } from 'next/server';
import RecordingService from '@/services/recording.service';
import logger from '@/utils/logger';
import { mockDetailedResponse, mockResponse } from '@/models/AiResponse.model';
import formidable, { IncomingForm, Fields, File } from 'formidable';
import { readFile } from 'fs/promises';
import { Readable } from 'stream';
import { IncomingMessage } from 'http';

export const config = {
  api: {
    bodyParser: false, // Disable default body parsing
  },
};

// Helper: Convert NextRequest into a Node.js-expected fake request
async function parseForm(
  req: NextRequest
): Promise<{ fields: Record<string, string[]>; files: Record<string, File[]> }> {
  // Read the full request body as a Buffer
  const buf = Buffer.from(await req.arrayBuffer());
  
  // Create a Node.js readable stream from the Buffer
  const stream = new Readable();
  stream.push(buf);
  stream.push(null);

  // Convert NextRequest headers (a Headers object) into a plain object
  const headersObj: Record<string, string> = {};
  req.headers.forEach((value, key) => {
    headersObj[key] = value;
  });
  
  // Ensure content-length is present – use the buffer length if not provided
  if (!headersObj['content-length']) {
    headersObj['content-length'] = buf.length.toString();
  }

  // Create a "fake" request by merging the stream with the headers.
  const fakeReq = Object.assign(stream, { headers: headersObj });

  return new Promise((resolve, reject) => {
    const form = new IncomingForm();
    form.parse(fakeReq as unknown as IncomingMessage, (err, fields, files) => {
      if (err) {
        return reject(err);
      }
      // Type assertion to Fields<string>
      const typedFields = fields as Fields<string>;
      // Convert formidable fields to the desired type
      const parsedFields: Record<string, string[]> = {};
      for (const key in typedFields) {
        const value = typedFields[key];
        if (value !== undefined) {
          parsedFields[key] = Array.isArray(value) ? value : [value];
        }
      }
      // Type assertion to Record<string, formidable.File[]>
      const parsedFiles = files as Record<string, formidable.File[]>;
      resolve({ fields: parsedFields, files: parsedFiles });
    });
  });
}

export async function POST(req: NextRequest) {
  let formData;
  try {
    // Try to parse the form; if it fails, it's due to invalid form data.
    formData = await parseForm(req);
  } catch (parseError: unknown) {
    const errorMessage = parseError instanceof Error ? parseError.message : 'Unknown parse error';
    logger.error("Form parsing error:", errorMessage);
    // Return 400 for invalid form data instead of 500.
    return NextResponse.json(
      { message: "Missing required fields", error: errorMessage },
      { status: 400 }
    );
  }
  
  try {
    const { fields, files } = formData;

    const audioFile = files.audio?.[0];
    const recordingTime = fields.recordingTime?.[0];
    const recordingSize = fields.recordingSize?.[0];
    const isDeepAnalysis = fields.isDeepAnalysis?.[0] === 'true';

    logger.log('isDeepAnalysis:', isDeepAnalysis);
    if (!audioFile || !recordingTime || !recordingSize) {
      return NextResponse.json(
        { message: "Missing required fields" },
        { status: 400 }
      );
    }

    const userIP =
      req.headers.get('x-real-ip') || req.headers.get('x-forwarded-for') || '';

    // logger.log('User IP:', userIP);


    // Read file buffer from the temporary file location provided by formidable
    const audioBuffer = await readFile(audioFile.filepath);
    
    const recordingService = new RecordingService();
    const fileUri = await recordingService.uploadFile(
      audioBuffer,
      audioFile.mimetype || 'audio/aac-adts',
      audioFile.originalFilename || 'recording.aac'
    );
    logger.log("File URI:", fileUri);

    let aiResponse;
    if (process.env.MOCK_AI_RESPONSE === 'true') {
      aiResponse = isDeepAnalysis ? mockDetailedResponse : mockResponse;
    } else {
      aiResponse = await recordingService.submitRecording(
        userIP,
        fileUri,  // Now using file URI instead of base64
        Number(recordingTime),
        Number(recordingSize),
        isDeepAnalysis
      );
    }
    logger.log("AI Response:", aiResponse);

    return NextResponse.json(
      { message: "Recording data received successfully", aiResponse },
      { status: 200 }
    );
  } catch (error: unknown) {
    const errorMessage =
      error instanceof Error ? error.message : 'An unknown error occurred';
    logger.error("Subscription error:", errorMessage);
    return NextResponse.json(
      { message: "Internal server error", error: errorMessage },
      { status: 500 }
    );
  }
}
</file>

<file path="src/app/api/subscribe/route.ts">
'use server'
import { NextResponse } from 'next/server';
import { supabase } from '@/repositories/supabase/supabase';
import logger from '@/utils/logger';

export async function POST(req: Request) {
  try {
    const payload = await req.json();
    const { email } = payload;

    // Validate email
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    if (!email || !emailRegex.test(email)) {
      return NextResponse.json(
        { message: "Invalid email address" },
        { status: 400 }
      );
    }

    // Allow payload to specify a source, otherwise default to 'web'
    const source = payload.source || 'web';

    // Retrieve additional metadata (IP address)
    const ip_address =
      req.headers.get("x-forwarded-for") ||
      req.headers.get("x-real-ip") ||
      "";

    // Check if email already exists
    const { data } = await supabase.from('waitlist').select('*').eq('email', email);
    if (data && data.length > 0) {
      return NextResponse.json(
        { message: "Email already exists" },
        { status: 200 }
      );
    }

    // Insert the email along with additional metadata into the "waitlist" table
    const { error } = await supabase
      .from('waitlist')
      .insert([{ email, ip_address, source, status: "pending" }]);

    if (error) {
      return NextResponse.json(
        { message: error.message },
        { status: 500 }
      );
    }

    return NextResponse.json(
      { message: "Subscription successful" },
      { status: 200 }
    );
  } catch (error) {
    logger.error("Subscription error:", error);
    return NextResponse.json(
      { message: "Internal server error" },
      { status: 500 }
    );
  }
}

export async function GET(req: Request) {
  const ip_address =
    req.headers.get("x-forwarded-for") ||
    req.headers.get("x-real-ip") ||
    "";

  if (process.env.MOCK_AI_RESPONSE === 'true') {
    return NextResponse.json(
      { message: "Subscription successful", isSubscribed: true },
      { status: 200 }
    );
  }
  const { data, error } = await supabase.from('waitlist').select('*').eq('ip_address', ip_address);
  if (error) {
    return NextResponse.json(
      { message: error.message, isSubscribed: false },
      { status: 500 }
    );
  }
  return NextResponse.json(
    { message: "Subscription successful", isSubscribed: data.length > 0 },
    { status: 200 }
  );
}
</file>

<file path="src/app/api/tts/route.ts">
// 'use server'
import { NextRequest, NextResponse } from 'next/server';
import logger from '@/utils/logger';
import { TTS } from '@/services/tts.service';
import { PollyService } from '@/services/polly.service';

export async function POST(req: NextRequest) {
  try {
    const { text, language } = await req.json();

    if (!text || !language) {
      return NextResponse.json(
        { message: "Missing required fields: text, language" },
        { status: 400 }
      );
    }

    const ttsService = new TTS(new PollyService());
    const audioBuffer = await ttsService.generateAudio(text, language);
    console.log('audioBuffer', audioBuffer.length.toString());

    return new NextResponse(audioBuffer, {
      status: 200,
      headers: {
        'Content-Type': 'audio/mpeg',
        'Content-Length': audioBuffer.length.toString()
      }
    });
  } catch (error: unknown) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    logger.error("Phoneme generation error:", errorMessage);
    return NextResponse.json(
      { message: "Phoneme generation failed", error: errorMessage },
      { status: 500 }
    );
  }
}
</file>

<file path="src/app/api/upload-token/route.ts">
import { handleUpload, type HandleUploadBody } from '@vercel/blob/client';
import { NextResponse } from 'next/server';
import logger from '@/utils/logger';

export async function POST(request: Request) {
  // You could add auth checking here to ensure only authorized users can upload
  try {
    // Parse the incoming request as JSON
    const body = await request.json() as HandleUploadBody;
    
    // Use handleUpload to generate the token and handle everything
    const jsonResponse = await handleUpload({
      body,
      request,
      onBeforeGenerateToken: async (pathname, clientPayload) => {
        logger.log('onBeforeGenerateToken', pathname, clientPayload);
        
        // This determines the allowed file types and sizes
        return {
          allowedContentTypes: ['image/jpeg', 'image/png', 'image/gif', 'image/webp', 'image/avif', 'application/pdf'],
          maximumSizeInBytes: 10 * 1024 * 1024, // 10MB file size limit
        };
      },
      onUploadCompleted: async ({ blob, tokenPayload }) => {
        // This callback only works when deployed (not on localhost)
        logger.log('Upload completed:', blob, tokenPayload);
      },
    });
    logger.log('jsonResponse in upload-token', jsonResponse)
    return NextResponse.json(jsonResponse);
  } catch (error) {
    logger.log('Error generating upload token:', error);
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 400 }
    );
  }
}
</file>

<file path="src/app/privacy/page.tsx">
import Footer from "@/components/Footer";
import type { Metadata } from 'next';

export const metadata: Metadata = {
  title: "Privacy Policy | lessay",
  description: "Learn how lessay protects your data and privacy while delivering personalized accent and pronunciation analysis experiences through our AI-powered platform.",
  openGraph: {
    title: "Privacy Policy - lessay Accent & Pronunciation Analysis Platform",
    description: "Understanding how lessay handles your data and protects your privacy while analyzing your accent and pronunciation.",
  },
};

export default function Privacy() {
  return (
    <div className="flex flex-col items-center justify-items-center sm:p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-8 row-start-2 items-center max-w-full sm:max-w-[1000px]">
        <div className="text-center">
          <h1 className="text-4xl sm:text-5xl font-bold mb-4">
            <span 
              style={{ 
                WebkitTextFillColor: "transparent",
                WebkitBackgroundClip: "text"
              }}
              className="bg-gradient-to-r from-black to-black/70 dark:from-white dark:to-white/70 inline-block !text-transparent bg-clip-text"
            >
              lessay
            </span>
          </h1>
          <p className="text-lg text-gray-600 dark:text-gray-300">
            Analyze your accent, not the fluff
          </p>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl">
          <h2 className="text-xl font-semibold mb-4 text-center">Data Collection</h2>
          <div className="space-y-6">
            <div className="space-y-4">
              <h3 className="font-semibold">Speaking Data</h3>
              <p className="text-gray-600 dark:text-gray-400">
                We collect data about your speaking patterns, including:
                <ul className="list-disc pl-6 mt-2">
                  <li>Pronunciation of specific phonemes</li>
                  <li>Rhythm and intonation patterns</li>
                  <li>Accent characteristics</li>
                  <li>Phonological features and speech patterns</li>
                </ul>
              </p>
            </div>

            <div className="space-y-4">
              <h3 className="font-semibold">User Information</h3>
              <p className="text-gray-600 dark:text-gray-400">
                We store information you provide directly:
                <ul className="list-disc pl-6 mt-2">
                  <li>Email address for account notifications</li>
                  <li>Native language (for accent analysis)</li>
                  <li>Regional background information</li>
                  <li>Speaking proficiency self-assessment</li>
                </ul>
              </p>
            </div>
          </div>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl">
          <div className="space-y-6">
            <div className="space-y-4">
              <h3 className="font-semibold text-center">Data Usage</h3>
              <p className="text-gray-600 dark:text-gray-400">
                Your data helps us:
                <ul className="list-disc pl-6 mt-2">
                  <li>Identify your accent and pronunciation patterns</li>
                  <li>Analyze phonological features and prosodic elements</li>
                  <li>Generate personalized improvement suggestions</li>
                  <li>Improve our AI models for accent analysis</li>
                </ul>
              </p>
            </div>

            {/* <div className="space-y-4">
              <h3 className="font-semibold text-center">Email Communications</h3>
              <p className="text-gray-600 dark:text-gray-400">
                We use your email to:
                <ul className="list-disc pl-6 mt-2">
                  <li>Provide detailed accent analysis results</li>
                  <li>Share pronunciation improvement recommendations</li>
                  <li>Inform about new accent analysis features</li>
                  <li>Send security-related announcements</li>
                </ul>
              </p>
            </div> */}
          </div>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl">
          <div className="space-y-6">
            <div className="space-y-4">
              <h3 className="font-semibold text-center">Your Rights</h3>
              <p className="text-gray-600 dark:text-gray-400">
                You can:
                <ul className="list-disc pl-6 mt-2">
                  <li>Request access to your collected speaking data</li>
                  <li>Correct inaccurate accent or linguistic information</li>
                  <li>Delete your speaking profile and analysis history</li>
                  <li>Opt-out of non-essential communications</li>
                </ul>
              </p>
            </div>
          </div>
        </div>
      </main>

      <Footer />
    </div>
  );
}
</file>

<file path="src/app/terms/page.tsx">
import Footer from "@/components/Footer";
import type { Metadata } from 'next';

export const metadata: Metadata = {
  title: "Terms of Service | lessay",
  description: "Read lessay's terms of service for our AI-powered accent and pronunciation analysis platform. Learn about our policies, user responsibilities, and data handling practices.",
  openGraph: {
    title: "Terms of Service - lessay Accent & Pronunciation Analysis Platform",
    description: "Important information about using lessay's AI-powered accent and pronunciation analysis platform.",
  },
};

export default function Terms() {
  return (
    <div className="flex flex-col items-center justify-items-center sm:p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-8 row-start-2 items-center max-w-full sm:max-w-[1000px]">
        <div className="text-center">
          <h1 className="text-4xl sm:text-5xl font-bold mb-4">
            <span 
              style={{ 
                WebkitTextFillColor: "transparent",
                WebkitBackgroundClip: "text"
              }}
              className="bg-gradient-to-r from-black to-black/70 dark:from-white dark:to-white/70 inline-block !text-transparent bg-clip-text"
            >
              lessay
            </span>
          </h1>
          <p className="text-lg text-gray-600 dark:text-gray-300">
            Analyze your accent, not the fluff
          </p>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl">
          <h2 className="text-xl font-semibold mb-4 text-center">Terms of Service</h2>
          <div className="space-y-6">
            <p className="text-base text-gray-600 dark:text-gray-400">
              By using lessay AI-powered accent and pronunciation analysis platform, you agree to these Terms. Our technology provides detailed feedback on your pronunciation patterns, accent characteristics, and phonological features.
            </p>

            <div className="space-y-4">
              <h3 className="font-semibold">1. Acceptance of Terms</h3>
              <p className="text-gray-600 dark:text-gray-400">
                Accessing or using our AI-powered accent analysis constitutes agreement to these Terms. We analyze your speech patterns and provide personalized feedback to help improve your pronunciation.
              </p>
            </div>

            <div className="space-y-4">
              <h3 className="font-semibold">2. User Responsibilities</h3>
              <p className="text-gray-600 dark:text-gray-400">
                You agree to provide authentic speech samples for analysis and not misuse our accent detection algorithms. Analysis reports and phonological assessments are for personal use only.
              </p>
            </div>

            <div className="space-y-4">
              <h3 className="font-semibold">3. AI-Generated Analysis</h3>
              <p className="text-gray-600 dark:text-gray-400">
                Our platform employs advanced linguistics algorithms to analyze accents, identify phonemes, and assess prosodic features. While we strive for accuracy in accent identification, results may vary based on speech clarity.
              </p>
            </div>
            
            <div className="space-y-4">
              <h3 className="font-semibold">4. Subscription & Access</h3>
              <p className="text-gray-600 dark:text-gray-400">
                During our beta phase, you join a waitlist for early access to our accent analysis technology. Future subscriptions will auto-renew but can be canceled anytime through your account settings.
              </p>
            </div>
            
            <div className="space-y-4">
              <h3 className="font-semibold">5. Data Processing</h3>
              <p className="text-gray-600 dark:text-gray-400">
                We process your speech recordings to identify accent characteristics, phonological patterns, and pronunciation features. Audio recordings are not permanently stored after analysis is complete.
              </p>
            </div>
          </div>
        </div>

        <div className="w-full max-w-md sm:max-w-lg lg:max-w-xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl">
          <div className="space-y-6">
            <div className="space-y-4">
              <h3 className="font-semibold text-center">Updates to Terms</h3>
              <p className="text-gray-600 dark:text-gray-400">
                As our pronunciation and accent analysis algorithms evolve, we may update these Terms. Continued use after changes constitutes acceptance of new AI-driven analysis features and policies.
              </p>
            </div>
          </div>
        </div>
      </main>

      <Footer />
    </div>
  );
}
</file>

<file path="src/app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  /* Neutral Colors */
  --neutral-1: #ffffff;
  --neutral-2: #fafafa;
  --neutral-3: #f5f5f5;
  --neutral-4: #f0f0f0;
  --neutral-5: #d9d9d9;
  --neutral-6: #bfbfbf;
  --neutral-7: #8c8c8c;
  --neutral-8: #595959;
  --neutral-9: #434343;
  --neutral-10: #262626;
  --neutral-11: #1f1f1f;
  --neutral-12: #141414;

  /* Accent Colors */
  --accent-1: #e6f7ff;
  --accent-2: #bae7ff;
  --accent-3: #91d5ff;
  --accent-4: #69c0ff;
  --accent-5: #40a9ff;
  --accent-6: #1890ff;
  --accent-7: #096dd9;
  --accent-8: #0050b3;
  --accent-9: #003a8c;
  --accent-10: #002766;

  /* Semantic Colors */
  --background: var(--neutral-1);
  --foreground: var(--neutral-12);
  --primary: var(--accent-6);
  --secondary: var(--neutral-3);
  --success: #52c41a;
  --warning: #faad14;
  --error: #ff4d4f;
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: 'Segoe UI', sans-serif;
}

.text-transparent {
  -webkit-text-fill-color: transparent;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(-1rem);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.animate-fade-in {
  animation: fadeIn 0.3s ease-out;
}

.dark {
  /* Dark mode colors if needed */
}
</file>

<file path="src/app/layout.tsx">
import './globals.css';
import { SpeedInsights } from '@vercel/speed-insights/next';
import { Analytics } from '@vercel/analytics/react';
import { ErrorProvider } from '@/hooks/useError';
import { PostHogProvider } from '@/context/posthog-context';





import { siteMetadata } from '@/utils/metadata';
export const metadata = siteMetadata;

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <head>
        {/* Add preconnect for critical third-party resources */}
        <link rel="preconnect" href="https://fonts.googleapis.com" />
        <link href="https://fonts.cdnfonts.com/css/segoe-ui-4?styles=18006,18005,18004,18003" rel="stylesheet"></link>

        {/* Add preload for critical assets */}
        <link rel="preload" as="image" href="/og-image.webp" />
      </head>
      <body
        className={`antialiased relative`}
      >
        <ErrorProvider>
          <PostHogProvider>{children}</PostHogProvider>
        </ErrorProvider>
        <SpeedInsights />
        <Analytics />
      </body>
    </html>
  );
}
</file>

<file path="src/app/page.tsx">
import dynamic from 'next/dynamic';
import { Suspense } from 'react';
import SubscriptionForm from '../components/Form';
import type { Metadata } from 'next';
import Script from 'next/script';
import YouTubeVideoWrapper from '@/components/YoutubeWrapper';
import { SubscriptionProvider } from '@/context/subscription-context';
import { RecordingProvider } from '@/context/recording-context';

const FeaturesDropdown = dynamic(
  () => import('../components/FeaturesDropdown'),
  {
    loading: () => (
      <div className="animate-pulse h-40 bg-gray-200 rounded-xl" />
    ),
    ssr: true,
  }
);

const Footer = dynamic(() => import('@/components/Footer'), {
  ssr: true,
});

const Recording = dynamic(() => import('../components/Recording'), {
  ssr: true,
  loading: () => <div className="animate-pulse h-40 bg-gray-200 rounded-xl" />,
});

export const metadata: Metadata = {
  title: 'AI Accent & Pronunciation Analysis | lessay',
  description:
    "Get instant AI-powered feedback on your accent, pronunciation patterns, and speech characteristics. Join lessay's waitlist for advanced accent analysis.",
  keywords: [
    'accent analysis',
    'pronunciation feedback',
    'accent detection',
    'speech analysis',
    'phonological assessment',
  ],
  openGraph: {
    title: 'AI-Powered Accent & Pronunciation Analysis | lessay',
    description:
      'Revolutionary AI technology for detailed accent assessment and pronunciation feedback',
    images: [
      {
        url: '/og-accent-analysis.jpg',
        width: 1200,
        height: 630,
        alt: 'AI Accent Analysis Interface',
      },
    ],
  },
  twitter: {
    card: 'summary_large_image',
    title: 'AI Accent & Pronunciation Analysis | lessay',
    description:
      'Get instant feedback on your accent and pronunciation with AI technology',
    images: ['/og-accent-analysis.jpg'],
  },
};

export default function Home() {
  const generateJsonLd = () => ({
    '@context': 'https://schema.org',
    '@type': 'FAQPage',
    mainEntity: [
      {
        '@type': 'Question',
        name: 'How does the AI accent analysis work?',
        acceptedAnswer: {
          '@type': 'Answer',
          text: 'Our AI system analyzes your speech patterns, pronunciation, and phonological features using advanced machine learning models to provide detailed feedback on your accent characteristics.',
        },
      },
      {
        '@type': 'Question',
        name: 'What languages are supported for accent analysis?',
        acceptedAnswer: {
          '@type': 'Answer',
          text: 'The system currently supports accent analysis for 50+ languages including English, Spanish, Mandarin, French, and German, identifying regional accents and pronunciation patterns.',
        },
      },
    ],
  });

  const jsonLd = generateJsonLd();

  const videoId = process.env.NEXT_PUBLIC_YOUTUBE_VIDEO_ID;

  return (
    <SubscriptionProvider>
      <RecordingProvider>
        <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-2 sm:p-8 pb-20 gap-16  font-sans max-w-4xl mx-auto">
          <main className="flex flex-col gap-8 row-start-2 items-center max-w-full sm:max-w-[1000px]">
            <div className="text-center">
              <h1 className="text-4xl sm:text-5xl font-bold mb-4">
                <span className="bg-gradient-to-r from-black to-black/70 dark:from-white dark:to-white/70 inline-block bg-clip-text text-transparent">
                  lessay
                </span>
              </h1>
              <p className="text-lg text-gray-600 dark:text-gray-300">
                Analyze your accent, not the fluff
              </p>
            </div>

            <div
              id="waitlist"
              className="sticky top-8 w-full max-w-4xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl border border-black/[.08] dark:border-white/[.145]"
            >
              <h2 className="text-xl font-semibold mb-2 text-center">
                Join the waitlist
              </h2>
              <p className="text-sm text-gray-600 dark:text-gray-400 mb-4 text-center">
                Be the first to experience advanced AI accent and pronunciation
                analysis.
              </p>
              <Suspense
                fallback={
                  <div className="animate-pulse h-10 bg-gray-200 rounded w-full" />
                }
              >
                <SubscriptionForm />
              </Suspense>
            </div>

            <Suspense
              fallback={
                <div className="animate-pulse h-40 bg-gray-200 rounded-xl" />
              }
            >
              <Recording />
            </Suspense>

            <Suspense
              fallback={
                <div className="animate-pulse h-40 bg-gray-200 rounded-xl" />
              }
            >
              <FeaturesDropdown />
            </Suspense>

            <div>
              <h3 className="text-xl font-semibold mb-2 text-center">
                Contact Us
              </h3>
              <a href="mailto:lessay.tech@gmail.com">lessay.tech@gmail.com</a>
            </div>
          </main>

          <Suspense fallback={<div className="h-20" />}>
            <Footer />
          </Suspense>

          <Script
            id="json-ld"
            type="application/ld+json"
            strategy="afterInteractive"
            dangerouslySetInnerHTML={{ __html: JSON.stringify(jsonLd) }}
          />
        </div>
      </RecordingProvider>
    </SubscriptionProvider>
  );
}
</file>

<file path="src/components/lessons/ChatMessages.tsx">
import logger from '@/utils/logger';
import React, { useEffect, useRef } from 'react';

export interface ChatMessage {
  type: 'prompt' | 'response';
  content: string;
}

interface ChatMessagesProps {
  messages: ChatMessage[];
}

const ChatMessages = React.memo(function ChatMessages({
  messages,
}: ChatMessagesProps) {
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const containerRef = useRef<HTMLDivElement>(null);

  // Scroll to bottom when messages change
  useEffect(() => {
    logger.info('ChatMessages: Attempting to scroll to bottom');
    if (containerRef.current) {
      containerRef.current.scrollTo({
        top: containerRef.current.scrollHeight,
        behavior: 'smooth',
      });
      logger.info('ChatMessages: Scrolled to bottom', {
        scrollTop: containerRef.current.scrollTop,
        scrollHeight: containerRef.current.scrollHeight,
      });
    }
  }, [messages]);

  return (
    <div ref={containerRef} className="h-full p-4 space-y-4 overflow-y-auto">
      {messages.map((msg, index) => {
        const isSpecialMessage =
          msg.type === 'prompt' &&
          (msg.content.includes('Instruction:') ||
            msg.content.includes('Summary:'));

        return (
          <div
            key={index}
            className={`flex ${
              msg.type === 'prompt' ? 'justify-start' : 'justify-end'
            }`}
          >
            <div
              className={`
              max-w-[75%] p-3 rounded shadow-sm
              ${
                isSpecialMessage
                  ? 'bg-accent-1 border-l-4 border-accent-6 text-neutral-12'
                  : msg.type === 'prompt'
                  ? 'bg-neutral-1 text-neutral-12'
                  : 'bg-accent-9 text-white'
              }
            `}
            >
              {isSpecialMessage && (
                <div className="text-xs font-semibold text-accent-6 mb-1 uppercase">
                  {msg.content.includes('Instruction:')
                    ? 'Instruction'
                    : 'Summary'}
                </div>
              )}
              <div>
                {isSpecialMessage
                  ? msg.content
                      .replace('Instruction:', '')
                      .replace('Summary:', '')
                  : msg.content}
              </div>
            </div>
          </div>
        );
      })}
      <div ref={messagesEndRef} />
    </div>
  );
});

export default ChatMessages;
</file>

<file path="src/components/onboarding/AssessmentChat.tsx">
import React, { useState, useEffect, useRef, useMemo } from 'react';
import { AssessmentLesson, AssessmentStep } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { mapLanguageToCode } from '@/utils/map-language-to-code.util';

// Add this interface at the top of the file
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}

interface SpeechRecognition extends EventTarget {
  new (): SpeechRecognition;
  start(): void;
  stop(): void;
  abort(): void;
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  onstart: (() => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: Event) => void) | null;
  onend: (() => void) | null;
}

declare global {
  interface Window {
    webkitSpeechRecognition: SpeechRecognition;
  }
}

interface AssessmentChatProps {
  lesson: AssessmentLesson;
  onComplete: () => void;
  loading: boolean;
  targetLanguage: string;
  onStepComplete: (step: AssessmentStep, userResponse: string) => Promise<void>;
}

export default function AssessmentChat({
  lesson,
  onComplete,
  loading,
  targetLanguage,
  onStepComplete,
}: AssessmentChatProps) {
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [userResponse, setUserResponse] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [feedback, setFeedback] = useState('');
  const [assessmentComplete, setAssessmentComplete] = useState(false);
  const [chatHistory, setChatHistory] = useState<
    Array<{ type: 'prompt' | 'response'; content: string }>
  >([]);
  const [realtimeTranscript, setRealtimeTranscript] = useState('');
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);

  const recognitionRef = useRef<any>(null);
  const chatMessagesRef = useRef<HTMLDivElement>(null);

  const showMockButtons = useMemo(() => {
    return process.env.NEXT_PUBLIC_MOCK_USER_RESPONSES === 'true';
  }, []);

  // Get current step from the single lesson
  const currentStep = lesson?.steps[currentStepIndex];

  // Rehydrate the entire UI state
  useEffect(() => {
    if (lesson) {
      // Find the first incomplete step
      const firstIncompleteStepIndex = lesson.steps.findIndex(
        (step) => !step.correct && step.attempts < step.maxAttempts
      );
      const stepIndex = firstIncompleteStepIndex !== -1 ? firstIncompleteStepIndex : 0;
      setCurrentStepIndex(stepIndex);

      // Build chat history
      const history: Array<{ type: 'prompt' | 'response'; content: string }> = [];

      // Add all completed steps and the next incomplete one
      for (let i = 0; i <= stepIndex; i++) {
        const step = lesson.steps[i];
        if (step) {
          history.push({ type: 'prompt', content: step.content });

          if (step.userResponse) {
            history.push({ type: 'response', content: step.userResponse });
          }
        }
      }

      setChatHistory(history);

      // Start listening if on an unanswered step
      if (
        lesson.steps[stepIndex] &&
        !lesson.steps[stepIndex].userResponse &&
        recognitionRef.current
      ) {
        startListening();
      }
    }
  }, [lesson]);


  useEffect(() => {

    setupSpeechRecognition()

  }, [currentStepIndex, lesson, targetLanguage])

  // Function to reset the silence timer
  const resetSilenceTimer = () => {
    // Clear any existing timer
    if (silenceTimerRef.current) {
      clearTimeout(silenceTimerRef.current);
    }
    
    // Set new timer for 4 seconds (4000 ms)
    silenceTimerRef.current = setTimeout(() => {
      if (isListening) {
        setRealtimeTranscript('');
        logger.info('Reset transcript due to 4 seconds of silence');
      }
    }, 4000);
  };

  // Setup speech recognition
  const setupSpeechRecognition = () => {
    if (!('webkitSpeechRecognition' in window)) {
      logger.error('Speech recognition not supported in this browser');
      return;
    }

    const recognition = new window.webkitSpeechRecognition();
    recognition.lang = mapLanguageToCode(targetLanguage);
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onstart = () => {
      logger.info('Speech recognition started');
      setIsListening(true);
      resetSilenceTimer(); // Start the silence timer when recognition starts
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      const transcript = Array.from(event.results)
        .map((result) => result[0].transcript)
        .join('');
      
      setRealtimeTranscript(transcript); // Update realtime transcript
      setUserResponse(transcript);
      resetSilenceTimer(); // Reset the timer on new speech
    };

    recognition.onerror = (event) => {
      logger.error('Speech recognition error:', event);
    };

    recognition.onend = () => {
      logger.info('Speech recognition ended');
      setIsListening(false);
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current); // Clear timer when recognition ends
      }
    };

    recognitionRef.current = recognition;
  };

  // Clean up the silence timer on component unmount
  useEffect(() => {
    return () => {
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
      }
    };
  }, []);

  // Scroll to bottom when chat history changes
  useEffect(() => {
    if (chatMessagesRef.current) {
      chatMessagesRef.current.scrollTop = chatMessagesRef.current.scrollHeight;
    }
  }, [chatHistory]);

  // Check if response is correct (this can be enhanced with more sophisticated matching)
  const isResponseCorrect = (
    response: string,
    expectedAnswer: string | null
  ): boolean => {
    if (!expectedAnswer) return true;
    // Simple string comparison - this should be more sophisticated in production
    return response.toLowerCase().includes(expectedAnswer.toLowerCase());
  };

  const handleSubmit = async (
    step: AssessmentStep,
    response: string
  ) => {
    if (isListening) {
      pauseListening();
    }

    try {
      setFeedback('Processing...')
      if (step.type === 'instruction' || step.type === 'summary') {
        // Mark as seen/acknowledged
        await onStepComplete(step, "Acknowledged");
        
        // Move to the next step
        const nextStepIndex = currentStepIndex + 1;
        if (nextStepIndex < lesson.steps.length) {
          setCurrentStepIndex(nextStepIndex);
          const nextStep = lesson.steps[nextStepIndex];
          
          // Add acknowledgment and next prompt to chat history
          setChatHistory(prev => [
            ...prev, 
            { type: 'response', content: 'OK, got it!' },
            { type: 'prompt', content: nextStep.content }
          ]);
          
          setUserResponse('');
        } else {
          // If this was the last step, complete the lesson
          onComplete();
        }
        return;
      }
      // Add response to chat history
      setChatHistory((prev) => [
        ...prev,
        { type: 'response', content: response },
      ]);

      // Mark step as correct

      // Check if current lesson is complete or move to next step
      if (currentStepIndex < lesson.steps.length - 1) {
        // Move to next step
        const nextStepIndex = currentStepIndex + 1;
        setCurrentStepIndex(nextStepIndex);
        setUserResponse('');

        // Add next prompt to chat history
        setTimeout(() => {
          const nextStep = lesson.steps[nextStepIndex];
          if (nextStep) {
            setChatHistory((prev) => [
              ...prev,
              { type: 'prompt', content: nextStep.content },
            ]);
            startListening();
          }
        }, 1000);
      } else {
        // All steps complete
        setAssessmentComplete(true);
      }
    } catch (error) {
      setFeedback('Error processing response');
    }
  };

  const startListening = () => {
    if (!recognitionRef.current) return;

    try {
      recognitionRef.current.start();
    } catch (error) {
      // Already started error can occur when continuous is true
      console.log('Recognition already started');
    }
  };

  const pauseListening = () => {
    if (!recognitionRef.current) return;
    recognitionRef.current.stop();
  };

  const toggleListening = () => {
    if (isListening) {
      pauseListening();
    } else {
      startListening();
    }
  };

  const handleMockResponse = (matchesModel: boolean) => {
    if (!lesson || !currentStep) return;

    const response = matchesModel
      ? currentStep.expectedAnswer || 'Correct mock answer'
      : 'This is a mock response that does not match the expected answer';

    setUserResponse(response);

    if (matchesModel) {
      handleSubmit(currentStep, response);
    }
  };

  if (!lesson) {
    return (
      <div className="flex justify-center items-center py-12">
        <div className="animate-spin mr-3 h-5 w-5 text-accent-6">
          <svg
            xmlns="http://www.w3.org/2000/svg"
            fill="none"
            viewBox="0 0 24 24"
          >
            <circle
              className="opacity-25"
              cx="12"
              cy="12"
              r="10"
              stroke="currentColor"
              strokeWidth="4"
            ></circle>
            <path
              className="opacity-75"
              fill="currentColor"
              d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
            ></path>
          </svg>
        </div>
        <span className="text-neutral-9">Loading assessment...</span>
      </div>
    );
  }

  if (assessmentComplete) {
    return (
      <div className="text-center animate-fade-in">
        <h2 className="text-2xl font-semibold text-foreground mb-4">
          Assessment Complete!
        </h2>
        <p className="text-neutral-8 mb-6">
          Thank you for completing the assessment. We&apos;ll prepare your
          personalized lessons.
        </p>
        <button
          onClick={onComplete}
          disabled={loading}
          className="py-2.5 px-4 bg-primary hover:bg-accent-7 text-neutral-1 rounded-md transition-colors 
                   focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                   font-medium text-sm flex items-center justify-center mx-auto"
        >
          {loading ? (
            <span className="flex items-center">
              <svg
                className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1"
                xmlns="http://www.w3.org/2000/svg"
                fill="none"
                viewBox="0 0 24 24"
              >
                <circle
                  className="opacity-25"
                  cx="12"
                  cy="12"
                  r="10"
                  stroke="currentColor"
                  strokeWidth="4"
                ></circle>
                <path
                  className="opacity-75"
                  fill="currentColor"
                  d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                ></path>
              </svg>
              Processing...
            </span>
          ) : (
            'Continue to Lessons'
          )}
        </button>
      </div>
    );
  }

  return (
    <div className="flex flex-col h-[calc(100vh-13rem)] border border-neutral-5 rounded-md bg-neutral-2 overflow-hidden shadow-sm animate-fade-in">
      {/* Chat Header */}
      <div className="p-4 bg-foreground text-neutral-1">
        <h2 className="text-lg font-semibold flex items-center justify-center">
          <svg
            className="w-5 h-5 mr-2"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
            xmlns="http://www.w3.org/2000/svg"
          >
            <path
              strokeLinecap="round"
              strokeLinejoin="round"
              strokeWidth={2}
              d="M8 10h.01M12 10h.01M16 10h.01M9 16H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-5l-5 5v-5z"
            />
          </svg>
          Language Assessment
          
          {/* Step progress indicator */}
          {currentStep && ` - Step ${currentStepIndex + 1}/${lesson.steps.length}`}
        </h2>
      </div>

      {/* Chat Messages */}
      <div
        ref={chatMessagesRef}
        className="flex-1 p-4 overflow-y-auto space-y-4 bg-neutral-1"
      >
        {chatHistory.map((message, index) => (
          <div
            key={index}
            className={`flex ${
              message.type === 'prompt' ? 'justify-start' : 'justify-end'
            }`}
          >
            <div
              className={`max-w-[75%] p-3 rounded-lg ${
                message.type === 'prompt'
                  ? 'bg-neutral-3 text-foreground'
                  : 'bg-accent-6 text-neutral-1'
              }`}
            >
              {message.content}
            </div>
          </div>
        ))}
      </div>

      {/* User Input Area */}
      <div className="border-t border-neutral-4 p-4 bg-neutral-1">
        {/* Real-time Transcription Display */}
        <div className="mb-4 min-h-[60px] p-3 border border-neutral-5 rounded-md bg-neutral-2 text-foreground">
          {realtimeTranscript ||
            (isListening ? (
              <span className="text-accent-6 flex items-center">
                <svg
                  className="animate-pulse w-4 h-4 mr-2"
                  fill="currentColor"
                  viewBox="0 0 24 24"
                >
                  <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z" />
                  <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z" />
                </svg>
                Listening...
              </span>
            ) : (
              <span className="text-neutral-8">Ready to speak...</span>
            ))}
        </div>

        {feedback && (
          <div className="text-sm text-neutral-7 mb-3 px-1">{feedback}</div>
        )}

        {/* Mock Response Buttons */}
        {showMockButtons && (
          <div className="flex space-x-3 mb-4">
            <button
              type="button"
              onClick={() => handleMockResponse(true)}
              className="flex-1 py-2 px-3 border border-transparent rounded-md shadow-sm text-sm font-medium text-neutral-1 bg-success hover:bg-success/90 transition-colors focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-success"
            >
              Mock Correct Response
            </button>
            <button
              type="button"
              onClick={() => handleMockResponse(false)}
              className="flex-1 py-2 px-3 border border-transparent rounded-md shadow-sm text-sm font-medium text-neutral-1 bg-error hover:bg-error/90 transition-colors focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-error"
            >
              Mock Incorrect Response
            </button>
          </div>
        )}

        {/* Controls */}
        <div className="flex space-x-3">
          <button
            type="button"
            onClick={toggleListening}
            disabled={loading || !currentStep}
            className={`flex-1 py-2.5 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-offset-2 disabled:opacity-50 flex items-center justify-center ${
              isListening
                ? 'bg-warning hover:bg-warning/90 text-neutral-12 focus:ring-warning'
                : 'bg-accent-6 hover:bg-accent-7 text-neutral-1 focus:ring-accent-6'
            }`}
          >
            {isListening ? (
              <>
                <svg
                  className="w-4 h-4 mr-2"
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth={2}
                    d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z"
                  />
                </svg>
                Pause Listening
              </>
            ) : (
              <>
                <svg
                  className="w-4 h-4 mr-2"
                  fill="none"
                  stroke="currentColor"
                  viewBox="0 0 24 24"
                >
                  <path
                    strokeLinecap="round"
                    strokeLinejoin="round"
                    strokeWidth={2}
                    d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"
                  />
                </svg>
                Start Listening
              </>
            )}
          </button>

          <button
            type="button"
            onClick={() =>
              currentStep &&
              handleSubmit(currentStep, userResponse)
            }
            disabled={!userResponse || loading || !currentStep}
            className="flex-1 py-2.5 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-neutral-1 bg-primary hover:bg-accent-7 transition-colors focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-accent-8 disabled:opacity-50 flex items-center justify-center"
          >
            <svg
              className="w-4 h-4 mr-2"
              fill="none"
              stroke="currentColor"
              viewBox="0 0 24 24"
            >
              <path
                strokeLinecap="round"
                strokeLinejoin="round"
                strokeWidth={2}
                d="M14 5l7 7m0 0l-7 7m7-7H3"
              />
            </svg>
            Skip & Continue
          </button>
        </div>
      </div>

      {/* Progress Bar */}
      <div className="w-full bg-neutral-3 h-1.5">
        <div
          className="bg-accent-6 h-1.5 transition-all duration-300"
          style={{
            width: `${((currentStepIndex + 1) / lesson.steps.length) * 100}%`,
          }}
        ></div>
      </div>
    </div>
  );
}
</file>

<file path="src/components/ui/alert-dialog.tsx">
"use client"

import * as React from "react"
import * as AlertDialogPrimitive from "@radix-ui/react-alert-dialog"

import { buttonVariants } from "@/components/ui/button" // Import styled button variants
import { cn } from "@/utils/cn"

const AlertDialog = AlertDialogPrimitive.Root

const AlertDialogTrigger = AlertDialogPrimitive.Trigger

const AlertDialogPortal = AlertDialogPrimitive.Portal

const AlertDialogOverlay = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Overlay>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Overlay>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Overlay
    className={cn(
      "fixed inset-0 z-50 bg-neutral-12/60 backdrop-blur-sm data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0", // Using dark neutral with opacity for overlay
      className
    )}
    {...props}
    ref={ref}
  />
))
AlertDialogOverlay.displayName = AlertDialogPrimitive.Overlay.displayName

const AlertDialogContent = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Content>
>(({ className, ...props }, ref) => (
  <AlertDialogPortal>
    <AlertDialogOverlay />
    <AlertDialogPrimitive.Content
      ref={ref}
      className={cn(
        "fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border border-neutral-4 bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] rounded-lg", // Fluent uses larger radius, lg=8px
        className
      )}
      {...props}
    />
  </AlertDialogPortal>
))
AlertDialogContent.displayName = AlertDialogPrimitive.Content.displayName

const AlertDialogHeader = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col space-y-2 text-center sm:text-left", // Standard header layout
      className
    )}
    {...props}
  />
)
AlertDialogHeader.displayName = "AlertDialogHeader"

const AlertDialogFooter = ({
  className,
  ...props
}: React.HTMLAttributes<HTMLDivElement>) => (
  <div
    className={cn(
      "flex flex-col-reverse sm:flex-row sm:justify-end sm:space-x-2", // Actions typically on the right
      className
    )}
    {...props}
  />
)
AlertDialogFooter.displayName = "AlertDialogFooter"

const AlertDialogTitle = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Title>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Title>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Title
    ref={ref}
    className={cn("text-lg font-semibold text-foreground", className)} // Standard title styling
    {...props}
  />
))
AlertDialogTitle.displayName = AlertDialogPrimitive.Title.displayName

const AlertDialogDescription = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Description>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Description>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Description
    ref={ref}
    className={cn("text-sm text-neutral-7", className)} // Muted text color for description
    {...props}
  />
))
AlertDialogDescription.displayName =
  AlertDialogPrimitive.Description.displayName

const AlertDialogAction = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Action>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Action>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Action
    ref={ref}
    // Use the styled button variants here! Apply primary or destructive as needed.
    className={cn(buttonVariants({ variant: "primary" }), className)} // Default action uses primary button
    {...props}
  />
))
AlertDialogAction.displayName = AlertDialogPrimitive.Action.displayName

const AlertDialogCancel = React.forwardRef<
  React.ElementRef<typeof AlertDialogPrimitive.Cancel>,
  React.ComponentPropsWithoutRef<typeof AlertDialogPrimitive.Cancel>
>(({ className, ...props }, ref) => (
  <AlertDialogPrimitive.Cancel
    ref={ref}
    // Use the styled button variants here! Usually the default/secondary style.
    className={cn(
      buttonVariants({ variant: "default" }), // Cancel uses default/secondary button
      "mt-2 sm:mt-0", // Add margin for mobile stacking
      className
    )}
    {...props}
  />
))
AlertDialogCancel.displayName = AlertDialogPrimitive.Cancel.displayName

export {
  AlertDialog,
  AlertDialogPortal,
  AlertDialogOverlay,
  AlertDialogTrigger,
  AlertDialogContent,
  AlertDialogHeader,
  AlertDialogFooter,
  AlertDialogTitle,
  AlertDialogDescription,
  AlertDialogAction,
  AlertDialogCancel,
}
</file>

<file path="src/components/ui/button.tsx">
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"
import { cn } from "@/utils/cn"


const buttonVariants = cva(
  "inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-semibold ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-neutral-7 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50",
  {
    variants: {
      variant: {
        default: // Fluent's Secondary Button
          "bg-neutral-2 text-neutral-11 shadow-sm hover:bg-neutral-4 border border-neutral-5",
        primary: // Fluent's Primary Button
          "bg-primary text-neutral-1 shadow hover:bg-accent-7", // Using accent-7 as hover state
        destructive: // Fluent's Destructive Button
          "bg-error text-neutral-1 shadow-sm hover:bg-red-700", // Assuming --error is red, using darker red for hover
        subtle: // Fluent's Subtle Button
          "bg-transparent text-primary hover:bg-accent-1",
        ghost: // Fluent's Ghost Button (similar to subtle but often used differently)
          "bg-transparent hover:bg-neutral-2 text-foreground hover:text-foreground",
        link: // Standard link style
          "text-primary underline-offset-4 hover:underline",
        outline: // Standard outline
          "border border-neutral-5 bg-background shadow-sm hover:bg-neutral-2 hover:text-neutral-11",
      },
      size: {
        default: "h-9 px-4 py-2", // Fluent default is often 32px or 36px height
        sm: "h-8 rounded-md px-3 text-xs", // Fluent small
        lg: "h-10 rounded-md px-8", // Fluent large
        icon: "h-9 w-9", // For icon buttons
      },
    },
    defaultVariants: {
      variant: "default", // Use Fluent's secondary as default
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
  VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }
</file>

<file path="src/components/BasicAnalysis.tsx">
import { AIResponse } from "@/models/AiResponse.model";
import PhonemePlayer from "./PhonemePlayer";

export const BasicAnalysis = ({aiResponse}: {aiResponse: AIResponse}) => {
  return !aiResponse ? null : (
    <div className="w-full mt-8 space-y-6">
    {/* Language & Accent Identification */}
    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
      {/* Language Detection Card */}
      <div className="flex justify-between items-center p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <div>
          <h3 className="font-semibold text-lg">
            {aiResponse.language_analyzed}
          </h3>
          <p className="text-sm text-gray-600 dark:text-gray-400">
            Language Detected
          </p>
        </div>
      </div>

      {/* Accent Identification Card */}
      <div className="flex justify-between items-center p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <div>
          <h3 className="font-semibold text-lg">
            {aiResponse.accent_identification.specific_accent}
          </h3>
          <p className="text-sm text-gray-600 dark:text-gray-400">
            Accent Type: {aiResponse.accent_identification.accent_type}
          </p>
        </div>
        <div className="flex items-center">
          <span className="inline-flex items-center px-3 py-1 rounded-full text-sm font-medium bg-blue-100 dark:bg-blue-900 text-blue-800 dark:text-blue-200">
            {aiResponse.accent_identification.accent_strength}
          </span>
        </div>
      </div>
    </div>

    {/* Speaker Background */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h3 className="font-semibold mb-2">Speaker Background</h3>
      <div className="space-y-2">
        <p className="text-gray-700 dark:text-gray-300">
          <span className="font-medium">Native Language:</span> {aiResponse.speaker_background.probable_native_language}
        </p>
        <p className="text-gray-700 dark:text-gray-300">
          <span className="font-medium">Probable Region:</span> {aiResponse.speaker_background.probable_region}
        </p>
        <div className="mt-3">
          <p className="font-medium">Supporting Evidence:</p>
          <span className="font-medium">Suporting Evidence: </span> {aiResponse.speaker_background.supporting_evidence}
        </div>
      </div>
    </div>

    {/* Phonological Assessment */}
    <div className="space-y-4">
      <h3 className="font-semibold">Pronunciation Analysis</h3>
      <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
        {aiResponse.language_specific_phonological_assessment.map(
          (assessment: {
            phoneme: string;
            example: string;
            analysis: string;
            IPA_target: string;
            IPA_observed: string;
          }, index: number) => (
            <div
              key={index}
              className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg"
            >
              <div className="flex justify-between mb-2">
                <span className="font-medium">
                  {assessment.phoneme}
                </span>
                <span className="text-sm text-gray-600 dark:text-gray-400">
                  in &quot;{assessment.example}&quot;
                </span>
              </div>
              <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                {assessment.analysis}
              </p>
              <div className="flex justify-between text-sm items-center">
                <div className="flex items-center gap-2">
                  <span>Target: {assessment.IPA_target}</span>
                  <PhonemePlayer 
                    ipa={assessment.IPA_target} 
                    language={aiResponse.analyzed_language_code} 
                    size="sm" 
                  />
                </div>
                <div className="flex items-center gap-2">
                  <span>Observed: {assessment.IPA_observed}</span>
                  <PhonemePlayer 
                    ipa={assessment.IPA_observed} 
                    language={aiResponse.analyzed_language_code} 
                    size="sm" 
                  />
                </div>
              </div>
            </div>
          )
        )}
      </div>
    </div>

    {/* Suprasegmental Features */}
    <div className="space-y-4">
      <h3 className="font-semibold">Rhythm, Intonation & Stress</h3>
      <div className="grid grid-cols-1 gap-4">
        {aiResponse.suprasegmental_features_analysis.map(
          (feature: {
            feature: string;
            observation: string;
            comparison: string;
          }, index: number) => (
            <div
              key={index}
              className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg"
            >
              <div className="flex justify-between mb-2">
                <span className="font-medium">{feature.feature}</span>
              </div>
              <p className="text-sm text-gray-700 dark:text-gray-300 mb-2">
                {feature.observation}
              </p>
              <p className="text-xs text-gray-600 dark:text-gray-400 italic">
                {feature.comparison}
              </p>
            </div>
          )
        )}
      </div>
    </div>

    {/* Diagnostic Accent Markers */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h3 className="font-semibold mb-3">Diagnostic Accent Markers</h3>
      <div className="space-y-3">
        {aiResponse.diagnostic_accent_markers.map((marker: {
          feature: string;
          description: string;
          association: string;
        }, index: number) => (
          <div key={index} className="border-b border-gray-200 dark:border-gray-700 pb-3 last:border-0 last:pb-0">
            <p className="font-medium">{marker.feature}</p>
            <p className="text-sm text-gray-700 dark:text-gray-300">{marker.description}</p>
            <p className="text-xs text-gray-600 dark:text-gray-400 mt-1">
              <span className="italic">Association:</span> {marker.association}
            </p>
          </div>
        ))}
      </div>
    </div>

    {/* Proficiency Assessment */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h3 className="font-semibold mb-3">Proficiency Assessment</h3>
      <div className="grid grid-cols-2 md:grid-cols-4 gap-3 mb-4">
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-blue-600 dark:text-blue-400">
            {aiResponse.proficiency_assessment.intelligibility}
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">Intelligibility</p>
        </div>
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-green-600 dark:text-green-400">
            {aiResponse.proficiency_assessment.fluency}
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">Fluency</p>
        </div>
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-purple-600 dark:text-purple-400">
            {aiResponse.proficiency_assessment.CEFR_level}
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">CEFR Level</p>
        </div>
      </div>
    </div>

    {/* Improvement Suggestions */}
    <div className="space-y-4">
      <h3 className="font-semibold">Improvement Suggestions</h3>
      <div className="space-y-4">
        {aiResponse.improvement_suggestions.map((suggestion: {
          focus_area: string;
          importance: "High" | "Medium" | "Low";
          exercises: string[];
        }, index: number) => (
          <div key={index} className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
            <div className="flex justify-between items-center mb-2">
              <h4 className="font-medium">{suggestion.focus_area}</h4>
              <span className={`px-2 py-1 rounded-full text-xs font-medium 
                ${suggestion.importance === 'High' ? 'bg-red-100 text-red-800 dark:bg-red-900 dark:text-red-200' :
                suggestion.importance === 'Medium' ? 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200' :
                'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200'}`}>
                {suggestion.importance} Priority
              </span>
            </div>
            <ul className="list-disc list-inside space-y-1">
              {suggestion.exercises.map((exercise, idx) => (
                <li key={idx} className="text-sm text-gray-700 dark:text-gray-300">{exercise}</li>
              ))}
            </ul>
          </div>
        ))}
      </div>
    </div>
  </div>
  )
}
</file>

<file path="src/components/CheckoutForm.tsx">
// import React, { useState, useEffect } from 'react';
// import {
//   PaymentElement,
//   Elements,
//   useStripe,
//   useElements
// } from '@stripe/react-stripe-js';
// import { loadStripe, StripeElementsOptions } from '@stripe/stripe-js';
// import { createPaymentIntentAction } from '@/lib/server-actions/payment-actions';

// const stripePromise = loadStripe(process.env.NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY!);

// interface CheckoutFormProps {
//   product: {
//     id: string;
//     type: string;
//     name: string;
//     amount: number;
//     currency: string;
//   };
// }

// // Inner form component remains largely the same
// const InnerForm: React.FC<CheckoutFormProps> = ({ product }) => {
//   const stripe = useStripe();
//   const elements = useElements();
//   const [errorMessage, setErrorMessage] = useState<string | null>(null);
//   const [isLoading, setIsLoading] = useState(false);

//   const handleSubmit = async (event: React.FormEvent) => {
//     event.preventDefault();
//     setErrorMessage(null);

//     if (!stripe || !elements) {
//       setErrorMessage("Payment system not ready.");
//       return;
//     }

//     setIsLoading(true);

//     // Confirm the payment (this part stays the same)
//     const { error } = await stripe.confirmPayment({
//       elements,
//       confirmParams: {
//         return_url: `${process.env.NEXT_PUBLIC_APP_BASE_URL}/payment-status`,
//         // receipt_email: 'customer@example.com', // Get from user profile if needed
//       },
//     });

//     if (error.type === "card_error" || error.type === "validation_error") {
//       setErrorMessage(error.message || 'An unexpected error occurred.');
//     } else if (error) {
//       setErrorMessage("An unexpected error occurred during payment confirmation.");
//     }
//     // If successful, the user is redirected to return_url, so setLoading(false)
//     // might not be reached unless there's an immediate error.
//     setIsLoading(false);
//   };

//   return (
//     <form onSubmit={handleSubmit}>
//       <PaymentElement />
//       <button disabled={isLoading || !stripe || !elements} style={{ marginTop: '20px' }}>
//         {isLoading ? 'Processing...' : `Pay $${product.amount.toFixed(2)}`}
//       </button>
//       {errorMessage && <div style={{ color: 'red', marginTop: '10px' }}>{errorMessage}</div>}
//     </form>
//   );
// };


// // Main component wrapper - Updated to call the Server Action
// const CheckoutForm: React.FC<CheckoutFormProps> = (props) => {
//   const [clientSecret, setClientSecret] = useState<string | null>(null);
//   const [loadingSecret, setLoadingSecret] = useState(true);
//   const [fetchError, setFetchError] = useState<string | null>(null);

//   useEffect(() => {
//     const fetchIntent = async () => {
//       setLoadingSecret(true);
//       setFetchError(null);
//       try {
//         // --- CALL SERVER ACTION ---
//         const result = await createPaymentIntentAction(props.product);
//         // --------------------------

//         if (result.error) {
//           throw new Error(result.error);
//         }
//         if (!result.clientSecret) {
//           throw new Error('Failed to retrieve payment details.'); // Should not happen if error is null
//         }
//         setClientSecret(result.clientSecret);
//       } catch (error: any) {
//         console.error("Error fetching client secret:", error);
//         setFetchError(error.message || 'Could not initialize payment.');
//       } finally {
//         setLoadingSecret(false);
//       }
//     };
//     fetchIntent();
//   }, [props.product]); // Re-fetch if product changes

//   const options: StripeElementsOptions | undefined = clientSecret
//     ? { clientSecret, appearance: { theme: 'stripe' } }
//     : undefined;

//   if (loadingSecret) return <div>Loading Payment Details...</div>;
//   if (fetchError) return <div style={{ color: 'red' }}>Error: {fetchError}</div>;
//   if (!clientSecret || !options) return <div>Could not initialize payment form. Please refresh.</div>;

//   return (
//     <Elements stripe={stripePromise} options={options}>
//       <InnerForm {...props} /> {/* Pass product props down */}
//     </Elements>
//   );
// };

// export default CheckoutForm;
</file>

<file path="src/components/DetailedAnalysis.tsx">
import { DetailedAIResponse } from "@/models/AiResponse.model";
import PhonemePlayer from "./PhonemePlayer";

export const DetailedAnalysis = ({detailedAiResponse}: {detailedAiResponse: DetailedAIResponse}) => {
  return !detailedAiResponse ? null : (
    <div className="mt-8 space-y-6">
    <h2 className="text-xl font-semibold mb-4">Detailed Accent Analysis</h2>
    <p className="text-sm text-gray-600 dark:text-gray-400 mb-4">
      The audio of phonetics is just an approximation of the actual pronunciation due to limitations with text-to-speech technology.
    </p>
    
    {/* Accent Analysis Section */}
    <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
      {/* Accent Classification */}
      <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <h3 className="font-semibold mb-3">Accent Classification</h3>
        <div className="space-y-2">
          <p className="flex justify-between">
            <span>Language Analyzed:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.language_analyzed}
            </span>
          </p>
          <p className="flex justify-between">
            <span>Accent Type:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.accent_classification.accent_type}
            </span>
          </p>
          <p className="flex flex-col md:flex-row justify-between">
            <span>Specific Accent:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.accent_classification.specific_accent}
            </span>
          </p>
          <p className="flex  justify-between">
            <span>Confidence:</span>
            <span className="text-green-600">
              {detailedAiResponse.accent_analysis.accent_classification.confidence_level}%
            </span>
          </p>
          <p className="flex  justify-between">
            <span>Accent Strength:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.accent_classification.accent_strength}
            </span>
          </p>
        </div>
      </div>

      {/* Speaker Background */}
      <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <h3 className="font-semibold mb-3">Speaker Background</h3>
        <div className="space-y-2">
          <p className="flex justify-between">
            <span>Probable L1:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.speaker_background.probable_native_language}
            </span>
          </p>
          <p className="flex justify-between">
            <span>Probable Region:</span>
            <span className="font-medium">
              {detailedAiResponse.accent_analysis.speaker_background.probable_region}
            </span>
          </p>
          <p className="flex justify-between">
            <span>Confidence:</span>
            <span className="text-green-600">
              {detailedAiResponse.accent_analysis.speaker_background.confidence_level}%
            </span>
          </p>
          <div className="mt-2">
            <p className="text-sm text-gray-600 dark:text-gray-400 mb-1">Supporting Evidence:</p>
            <ul className="list-disc list-inside text-sm">
              {detailedAiResponse.accent_analysis.speaker_background.supporting_evidence.map(
                (evidence: string, index: number) => (
                  <li key={index}>{evidence}</li>
                )
              )}
            </ul>
          </div>
        </div>
      </div>
    </div>

    {/* Phonetic Analysis */}
    <div className="space-y-4">
      <h3 className="font-semibold">Detailed Phonetic Analysis</h3>
      
      {/* Vowel Production */}
      <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <h4 className="font-medium mb-3">Vowel Production</h4>
        <div className="space-y-3">
          {detailedAiResponse.phonetic_analysis.vowel_production.map(
            (vowel: {
              phoneme: string;
              standard_realization: string;
              observed_realization: string;
              example_word: string;
              timestamp: number;
              analysis: string;
              accent_marker: boolean;
            }
            , index: number) => (
              <div key={index} className="border-b border-gray-200 dark:border-gray-700 pb-2 last:border-0">
                <div className="flex justify-between mb-1">
                  <span className="font-medium">{vowel.phoneme}</span>
                  <span className="text-sm text-gray-600">at {vowel.timestamp}s</span>
                </div>
                <p className="text-sm mb-1">Example: &quot;{vowel.example_word}&quot;</p>
                <div className="flex flex-col sm:flex-row gap-2 justify-between text-sm">
                  <div className="flex items-center gap-2">
                    <span className="font-bold">Standard: {vowel.standard_realization}</span>
                    <PhonemePlayer 
                      ipa={vowel.phoneme} 
                      language={detailedAiResponse.accent_analysis.analyzed_language_code} 
                      size="sm" 
                    />
                  </div>
                  <div className="flex items-center gap-2">
                    <span className="font-bold">Observed: {vowel.observed_realization}</span>
                    <PhonemePlayer 
                      ipa={vowel.observed_realization.split(' ')[0]} 
                      language={detailedAiResponse.accent_analysis.analyzed_language_code} 
                      size="sm" 
                    />
                  </div>
                </div>
                <p className="text-sm text-gray-600 mt-1">{vowel.analysis}</p>
                {vowel.accent_marker && (
                  <span className="inline-block mt-1 px-2 py-0.5 bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200 text-xs rounded-full">
                    Accent marker
                  </span>
                )}
              </div>
            )
          )}
        </div>
      </div>

      {/* Consonant Production */}
      <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
        <h4 className="font-medium mb-3">Consonant Production</h4>
        <div className="space-y-3">
          {detailedAiResponse.phonetic_analysis.consonant_production.map(
            (consonant: {
              phoneme: string;
              standard_realization: string;
              observed_realization: string;
              example_word: string;
              timestamp: number;
              analysis: string;
              accent_marker: boolean;
            }, index: number) => (
              <div key={index} className="border-b border-gray-200 dark:border-gray-700 pb-2 last:border-0">
                <div className="flex justify-between mb-1">
                  <span className="font-medium">{consonant.phoneme}</span>
                  <span className="text-sm text-gray-600">at {consonant.timestamp}s</span>
                </div>
                <p className="text-sm mb-1">Example: &quot;{consonant.example_word}&quot;</p>
                <div className="flex flex-col sm:flex-row gap-2 justify-between text-sm">
                  <div className="flex items-center gap-2">
                    <span className="font-bold">Standard: {consonant.standard_realization}</span>
                    <PhonemePlayer 
                      ipa={consonant.phoneme} 
                      language={detailedAiResponse.accent_analysis.analyzed_language_code} 
                      size="sm" 
                    />
                  </div>
                  <div className="flex items-center gap-2">
                    <span className="font-bold">Observed: {consonant.observed_realization}</span>
                    <PhonemePlayer 
                      ipa={consonant.observed_realization.split(' ')[0]} 
                      language={detailedAiResponse.accent_analysis.analyzed_language_code} 
                      size="sm" 
                    />
                  </div>
                </div>
                <p className="text-sm text-gray-600 mt-1">{consonant.analysis}</p>
                {consonant.accent_marker && (
                  <span className="inline-block mt-1 px-2 py-0.5 bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200 text-xs rounded-full">
                    Accent marker
                  </span>
                )}
              </div>
            )
          )}
        </div>
      </div>
    </div>

    {/* Prosodic Features */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h4 className="font-medium mb-3">Prosodic Features</h4>
      <div className="space-y-4">
        {/* Rhythm Patterns */}
        <div>
          <h5 className="text-sm font-medium mb-2">Rhythm Patterns</h5>
          <p className="text-sm mb-2">
            {detailedAiResponse.prosodic_features.rhythm_patterns.description}
          </p>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-2 mb-2">
            <div className="text-sm">
              <span className="font-medium">Standard Pattern:</span> {detailedAiResponse.prosodic_features.rhythm_patterns.standard_pattern}
            </div>
            <div className="text-sm">
              <span className="font-medium">Observed Pattern:</span> {detailedAiResponse.prosodic_features.rhythm_patterns.observed_pattern}
            </div>
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400 italic">
            Association: {detailedAiResponse.prosodic_features.rhythm_patterns.accent_association}
          </p>
        </div>

        {/* Stress Patterns */}
        <div>
          <h5 className="text-sm font-medium mb-2">Stress Patterns</h5>
          <div className="space-y-2">
            <div>
              <p className="text-sm font-medium">Word Level:</p>
              <p className="text-sm">{detailedAiResponse.prosodic_features.stress_patterns.word_level.description}</p>
              <p className="text-xs text-gray-600 dark:text-gray-400 italic">
                Association: {detailedAiResponse.prosodic_features.stress_patterns.word_level.accent_association}
              </p>
            </div>
            <div>
              <p className="text-sm font-medium">Sentence Level:</p>
              <p className="text-sm">{detailedAiResponse.prosodic_features.stress_patterns.sentence_level.description}</p>
              <p className="text-xs text-gray-600 dark:text-gray-400 italic">
                Association: {detailedAiResponse.prosodic_features.stress_patterns.sentence_level.accent_association}
              </p>
            </div>
          </div>
        </div>

        {/* Intonation */}
        <div>
          <h5 className="text-sm font-medium mb-2">Intonation</h5>
          <ul className="list-disc list-inside text-sm mb-1">
            {detailedAiResponse.prosodic_features.intonation.patterns.map((pattern: string, index: number) => (
              <li key={index}>{pattern}</li>
            ))}
          </ul>
          <p className="text-xs text-gray-600 dark:text-gray-400 italic">
            Association: {detailedAiResponse.prosodic_features.intonation.accent_association}
          </p>
        </div>
      </div>
    </div>

    {/* Diagnostic Accent Markers */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h4 className="font-medium mb-3">Diagnostic Accent Markers</h4>
      <div className="space-y-4">
        {detailedAiResponse.diagnostic_accent_markers.map((marker: {
          feature: string;
          description: string;
          example: string;
          timestamp: number;
          accent_association: string;
          frequency: string;
        }, index: number) => (
          <div key={index} className="border-l-4 border-yellow-500 pl-4">
            <div className="flex justify-between mb-1">
              <h5 className="font-medium">{marker.feature}</h5>
              <span className="text-xs text-gray-600">Frequency: {marker.frequency}</span>
            </div>
            <p className="text-sm mb-1">{marker.description}</p>
            <p className="text-sm mb-1">Example: &quot;{marker.example}&quot; (at {marker.timestamp}s)</p>
            <p className="text-xs text-gray-600 dark:text-gray-400 italic">
              Association: {marker.accent_association}
            </p>
          </div>
        ))}
      </div>
    </div>

    {/* Proficiency Assessment */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h4 className="font-medium mb-3">Proficiency Assessment</h4>
      <div className="grid grid-cols-2 md:grid-cols-4 gap-3 mb-4">
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-blue-600 dark:text-blue-400">
            {detailedAiResponse.proficiency_assessment.intelligibility_score}%
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">Intelligibility</p>
        </div>
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-green-600 dark:text-green-400">
            {detailedAiResponse.proficiency_assessment.fluency_rating}%
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">Fluency</p>
        </div>
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-purple-600 dark:text-purple-400">
            {detailedAiResponse.proficiency_assessment.comprehensibility}%
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">Comprehensibility</p>
        </div>
        <div className="text-center p-2 bg-gray-100 dark:bg-gray-800 rounded-lg">
          <div className="text-xl font-bold text-orange-600 dark:text-orange-400">
            {detailedAiResponse.proficiency_assessment.CEFR_pronunciation_level}
          </div>
          <p className="text-xs text-gray-600 dark:text-gray-400">CEFR Level</p>
        </div>
      </div>
      <p className="text-sm italic">
        {detailedAiResponse.proficiency_assessment.accent_impact_assessment}
      </p>
    </div>

    {/* Improvement Plan */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h4 className="font-medium mb-3">Personalized Improvement Plan</h4>
      <div className="space-y-4">
        {detailedAiResponse.improvement_plan.priority_areas.map(
          (area: {
            focus: string;
            importance: "High" | "Medium" | "Low";
            exercises: string[];
            expected_timeline: string;
          }, index: number) => (
            <div key={index} className="border-l-4 border-blue-500 pl-4">
              <h5 className="font-medium">{area.focus}</h5>
              <div className="flex items-center gap-2 my-1">
                <span className={`px-2 py-0.5 rounded-full text-xs ${
                  area.importance === 'High'
                    ? 'bg-red-100 text-red-800 dark:bg-red-900 dark:text-red-200'
                    : area.importance === 'Medium'
                    ? 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200'
                    : 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200'
                }`}>
                  {area.importance} priority
                </span>
                <span className="text-sm text-gray-600">{area.expected_timeline}</span>
              </div>
              <ul className="list-disc list-inside text-sm">
                {area.exercises.map((exercise, i) => (
                  <li key={i}>{exercise}</li>
                ))}
              </ul>
            </div>
          )
        )}
      </div>
      
      {/* Recommended Resources */}
      <div className="mt-4">
        <h5 className="text-sm font-medium mb-2">Recommended Resources</h5>
        <ul className="list-disc list-inside text-sm">
          {detailedAiResponse.improvement_plan.recommended_resources.map(
            (resource: string, index: number) => (
              <li key={index}>{resource}</li>
            )
          )}
        </ul>
      </div>
      
      {/* Practice Strategies */}
      <div className="mt-4">
        <h5 className="text-sm font-medium mb-2">Practice Strategies</h5>
        <ul className="list-disc list-inside text-sm">
          {detailedAiResponse.improvement_plan.practice_strategies.map(
            (strategy: string, index: number) => (
              <li key={index}>{strategy}</li>
            )
          )}
        </ul>
      </div>
    </div>

    {/* Linguistic Background Insights */}
    <div className="p-4 bg-gray-50 dark:bg-gray-900/50 rounded-lg">
      <h4 className="font-medium mb-3">Linguistic Background Insights</h4>
      <div className="space-y-3">
        <div>
          <h5 className="text-sm font-medium mb-1">L1 Transfer Effects</h5>
          <ul className="list-disc list-inside text-sm">
            {detailedAiResponse.linguistic_background_insights.probable_l1_transfer_effects.map(
              (effect: string, index: number) => (
                <li key={index}>{effect}</li>
              )
            )}
          </ul>
        </div>
        <div>
          <h5 className="text-sm font-medium mb-1">Cultural Speech Patterns</h5>
          <ul className="list-disc list-inside text-sm">
            {detailedAiResponse.linguistic_background_insights.cultural_speech_patterns.map(
              (pattern: string, index: number) => (
                <li key={index}>{pattern}</li>
              )
            )}
          </ul>
        </div>
        {detailedAiResponse.linguistic_background_insights.multilingual_influences.length > 0 && (
          <div>
            <h5 className="text-sm font-medium mb-1">Multilingual Influences</h5>
            <ul className="list-disc list-inside text-sm">
              {detailedAiResponse.linguistic_background_insights.multilingual_influences.map(
                (influence: string, index: number) => (
                  <li key={index}>{influence}</li>
                )
              )}
            </ul>
          </div>
        )}
      </div>
    </div>
  </div>
  )
}
</file>

<file path="src/components/FeaturesDropdown.tsx">
"use client";

import { useState } from "react";
import { Mic  } from "lucide-react";

interface FeatureCardProps {
  title: string;
  description: string;
  icon: React.ReactNode;
}

function FeatureCard({ title, description, icon }: FeatureCardProps) {
  return (
    <div className="p-6 rounded-xl border border-black/[.08] dark:border-white/[.145] transition-all">
      <div className="flex items-start space-x-4">
        <div className="bg-gradient-to-b from-black/[.08] to-black/[.04] dark:from-white/[.08] dark:to-white/[.04] rounded-lg p-2">
          {icon}
        </div>
        <div>
          <h2 className="font-semibold mb-1">{title}</h2>
          <p className="text-sm text-gray-600 dark:text-gray-400">{description}</p>
        </div>
      </div>
    </div>
  );
}

export default function FeaturesDropdown() {
  const [open, setOpen] = useState(false);

  const features = [
    {
      title: "Pronunciation Analysis: How it works",
      description:
        "Our AI uses Automatic Speech Recognition (ASR) and advanced acoustic modeling to analyze your speech. Leveraging a massive language model, it evaluates phonetic features, prosodic elements, directly from the audio, providing a comprehensive pronunciation assessment.",
        icon: <Mic className="w-5 h-5" />,
    },
    // {
    //   title: "Adaptive Learning",
    //   description:
    //     "Our algorithms tailor lessons to your current level and learning style.",
    //     icon: <GraduationCap className="w-5 h-5" />,
    // },
    // {
    //   title: "Smart Progress",
    //   description: "Focus on what matters - skip what you already know.",
    //   icon: <Lightbulb className="w-5 h-5" />,
    // }
  ];

  return (
    <div className="w-full">
      <div className="flex justify-center sm:justify-start">
        <button
          onClick={() => setOpen(!open)}
          className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-black dark:hover:bg-white hover:text-white dark:hover:text-black text-sm sm:text-base h-10 sm:h-12 px-6 sm:px-8 group"
        >
          {open ? "Hide Details" : "How it works"}
          <svg
            className={`w-4 h-4 ml-2 transition-transform duration-300 ${
              open ? "rotate-90" : ""
            }`}
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              strokeLinecap="round"
              strokeLinejoin="round"
              strokeWidth={2}
              d="M14 5l7 7m0 0l-7 7m7-7H3"
            />
          </svg>
        </button>
      </div>
      <div
        className={`overflow-hidden transition-all duration-300 mt-4 ${
          open ? "max-h-[500px] opacity-100" : "max-h-0 opacity-0"
        }`}
      >
        <div className="grid grid-cols-1 gap-3">
          {features.map((feature, index) => (
            <FeatureCard
              key={index}
              title={feature.title}
              description={feature.description}
              icon={feature.icon}
            />
          ))}
        </div>
      </div>
    </div>
  );
}
</file>

<file path="src/components/Footer.tsx">
import Link from "next/link";



export default function Footer() {
  return (<footer className="row-start-3 flex gap-6 flex-wrap items-center justify-center text-sm text-gray-600 dark:text-gray-400">
    <Link className="hover:text-purple-600 dark:hover:text-purple-400 transition-colors" href="/">
      Home
    </Link>
    <Link className="hover:text-purple-600 dark:hover:text-purple-400 transition-colors" href="/about">
      About
    </Link>
    <Link className="hover:text-purple-600 dark:hover:text-purple-400 transition-colors" href="/terms">
      Terms
    </Link>
    <Link className="hover:text-purple-600 dark:hover:text-purple-400 transition-colors" href="/privacy">
      Privacy
    </Link>
  </footer>
  )
}
</file>

<file path="src/components/Form.tsx">
'use client';

import { useSubscription } from '@/context/subscription-context';

export default function SubscriptionForm() {
  const { handleSubmit, status, email, setEmail, errorMessage } = useSubscription();



  return (
    <div className="w-full ">
      <form onSubmit={handleSubmit}>
        <div className="relative">
          <input
            type="email"
            value={email}
            onChange={(e) => setEmail(e.target.value)}
            placeholder="Enter your email"
            className="w-full px-4 py-3 sm:px-6 sm:py-4 rounded-full border border-black/[.08] dark:border-white/[.145] 
                   bg-transparent  outline-none focus:border-black/20 dark:focus:border-white/30
                   transition-colors font-[family-name:var(--font-geist-sans)]"
            disabled={status === 'loading' || status === 'success'}
          />
          <button
            type="submit"
            disabled={status === 'loading' || status === 'success'}
            className="absolute right-2 top-1/2 -translate-y-1/2 px-4 py-1.5   sm:px-6 sm:py-3
                   bg-foreground text-background rounded-full text-sm
                   hover:bg-[#383838] dark:hover:bg-[#ccc] transition-colors
                   disabled:opacity-50 disabled:cursor-not-allowed"
          >
            {status === 'loading'
              ? '...'
              : status === 'success'
              ? '✓'
              : 'Subscribe'}
          </button>
        </div>
        {status === 'error' && (
          <p className="mt-2 text-sm text-red-600 dark:text-red-400">
            {errorMessage}
          </p>
        )}
      </form>

      {status === 'success' && (
        <p className="mt-2 text-sm text-green-600 dark:text-green-400">
          Thanks for subscribing!
        </p>
      )}
      <p className="mt-2 text-xs text-gray-500 dark:text-gray-400 text-center">
        We collect your email to gauge interest in our service and understand user engagement. <b>We will not send you any unsolicited messages.</b>
      </p>
    </div>
  );
}
</file>

<file path="src/components/HeaderWithProfile.tsx">
'use client';

import { User } from 'lucide-react';
import Link from 'next/link';

export default function HeaderWithProfile() {
  return (
    <header className="bg-white shadow-sm sticky top-0 z-10">
      <div className="container mx-auto px-4 h-14 flex justify-end items-center">
        <Link href="/app/profile" title="User Profile">
          <User className="h-6 w-6 text-gray-600 hover:text-gray-900" />
        </Link>
      </div>
    </header>
  );
}
</file>

<file path="src/components/LoadingAnimation.tsx">
export const LoadingAnimation = () => {
  return (
    <div className="flex flex-col items-center space-y-4 my-8">
      <div className="relative w-16 h-16">
        <div className="absolute top-0 left-0 w-full h-full">
          <div className="w-16 h-16 border-4 border-gray-200 dark:border-gray-700 border-solid rounded-full animate-spin border-t-blue-600 dark:border-t-blue-400"></div>
        </div>
        <div className="absolute top-0 left-0 w-full h-full flex items-center justify-center">
          <div className="w-8 h-8 bg-white dark:bg-black rounded-full"></div>
        </div>
      </div>
      <p className="text-sm text-gray-600 dark:text-gray-400 animate-pulse">
        Analyzing your accent...
      </p>
  </div>
  )
}
</file>

<file path="src/components/PhonemePlayer.tsx">
'use client';

import { useRef, useState } from 'react';
import logger from '@/utils/logger';
import { fetchPollyAudio } from '@/utils/phoneme-audio.handler.util';
import { cacheAudio, getCachedAudio } from '@/utils/phoneme-audio.cacher.util';

interface PhonemePlayerProps {
  ipa: string;
  language?: string;
  size?: 'sm' | 'md' | 'lg';
}


const PhonemePlayer: React.FC<PhonemePlayerProps> = ({ 
  ipa, 
  language = 'en-US',
  size = 'md'
}) => {
  const [isPlaying, setIsPlaying] = useState(false);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [isLoading, setIsLoading] = useState(false);


  const playPhoneme = async () => {
    if (isPlaying || isLoading) return;
    
    setIsLoading(true);
    
    try {

      const cleanIpa = ipa.replace(/[\[\]\/]/g, '');
      const cachedAudio = getCachedAudio(cleanIpa, language);

      let audioUrl: string;
      
      if (cachedAudio) {
        audioUrl = `data:audio/mpeg;base64,${cachedAudio}`;
      } else {
        audioUrl = await fetchPollyAudio(ipa, language);
        await cacheAudio(cleanIpa, language, audioUrl);
      }

      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current = null;
      }

      const audio = new Audio(audioUrl);
      audioRef.current = audio;
      
      audio.addEventListener('play', () => {
        setIsPlaying(true);
        setIsLoading(false);
      });

      audio.addEventListener('ended', () => {
        setIsPlaying(false);
        audioRef.current = null;
      });

      audio.addEventListener('error', () => {
        setIsPlaying(false);
        setIsLoading(false);
        audioRef.current = null;
        logger.error("Audio playback failed");
      });

      await audio.play();
    } catch (error) {
      setIsLoading(false);
      logger.error("Playback error:", error);
    }
  };

  const sizeClasses = {
    sm: 'w-6 h-6 text-xs',
    md: 'w-8 h-8 text-sm',
    lg: 'w-10 h-10 text-base'
  };
  
  return (
    <button
      onClick={playPhoneme}
      disabled={isLoading || isPlaying}
      aria-label={`Play ${ipa} pronunciation`}
      className={`
        ${sizeClasses[size]} 
        rounded-full 
        flex items-center justify-center
        bg-blue-100 hover:bg-blue-200 
        dark:bg-blue-900 dark:hover:bg-blue-800
        text-blue-600 dark:text-blue-300
        focus:outline-none focus:ring-2 focus:ring-blue-500
        transition-colors
        ${(isLoading || isPlaying) ? 'opacity-60' : ''}
      `}
    >
      {isLoading ? (
        <span className="animate-spin">⏳</span>
      ) : isPlaying ? (
        <span className="animate-pulse">◼</span>
      ) : (
        <span>▶</span>
      )}
    </button>
  );
};

export default PhonemePlayer;
</file>

<file path="src/components/PostHogPageView.tsx">
// app/PostHogPageView.jsx
'use client'

import { usePathname, useSearchParams } from "next/navigation"
import { useEffect, Suspense } from "react"
import { usePostHog } from 'posthog-js/react'

function PostHogPageView() {
  const pathname = usePathname()
  const searchParams = useSearchParams()
  const posthog = usePostHog()

  // Track pageviews
  useEffect(() => {
    if (pathname && posthog) {
      let url = window.origin + pathname
      if (searchParams.toString()) {
        url = url + "?" + searchParams.toString();
      }

      posthog.capture('$pageview', { '$current_url': url })
    }
  }, [pathname, searchParams, posthog])
  
  return null
}

export default function SuspendedPostHogPageView() {
  return <Suspense fallback={null}>
    <PostHogPageView />
  </Suspense>
}
</file>

<file path="src/components/Recording.tsx">
'use client';

import { DetailedAnalysis } from './DetailedAnalysis';
import { BasicAnalysis } from './BasicAnalysis';
import { RecordingCallToAction } from './RecordingCallToAction';
import { LoadingAnimation } from './LoadingAnimation';
import { RecordingHeader } from './RecordingHeader';
import { ButtonConfig } from './RecordingButtonConfig';
import { useRecordingContext } from '@/context/recording-context';
import { MetaScript } from './RecordingMetaScript';



export default function Recording() {

  const {
    audioURL,
    aiResponse,
    detailedAiResponse,
    isProcessing,
    resetRecording,
    isDeepAnalysis,
    setIsDeepAnalysis,
    posthogCapture,
  } = useRecordingContext();

  



 
  const onWaitlistClick = () => {
    window.scrollTo({ top: 0, behavior: 'smooth' });
    posthogCapture('join_waitlist_clicked');
  };


  const onResetRecordingClick = () => {
    posthogCapture('try_another_recording_clicked');
    resetRecording();
  };

  const onDeepAnalysisClick = () => {
    setIsDeepAnalysis(!isDeepAnalysis);
    posthogCapture('deep_analysis_toggled');
  };



  const RecordingButtons = () => {
    return (
      <div className="flex items-center gap-4">
      {(() => {
        const { text, action, disabled, className } = ButtonConfig();
        return (
          <button
            onClick={action}
            disabled={disabled}
            className={`
            px-6 py-2 rounded-full font-medium transition-all duration-200
            border border-black dark:border-white
            text-black dark:text-white
            ${className}
          `}
          >
            {text}
          </button>
        );
      })()}

      <button
        onClick={onDeepAnalysisClick}
        className={`
          px-6 py-2 rounded-full font-medium transition-all duration-200
          ${isDeepAnalysis ? 'bg-blue-500 text-white' : 'border border-blue-500 text-blue-500 hover:bg-blue-500 hover:text-white'}
          
        `}
      >
        Deep Analysis
      </button>
    </div>
      )
  }

  

 


const DeepAnalysisMessage = () => {
  return (
    <div className="mt-2">
    <p className="text-sm text-gray-600 dark:text-gray-400">
      Please provide a minimum 1 minute of recording for deep
      analysis.
    </p>
  </div>
  )
}
const WordsDisclaimer = () => {
  return (
    <div className="mt-2">
      <p className="text-sm text-gray-600 dark:text-gray-400 text-center">
        To ensure unbiased analysis, please avoid using terms related to specific
        demographics such as race, religion, gender, or nationality. Focus on
        using neutral and objective language. Additionally, to ensure broad
        applicability and understanding, avoid using country-specific terms,
        proper names, or other language that may be regionally exclusive. Aim
        for precise definitions and clear, detailed analysis using generic and
        widely understood language.
      </p>
    </div>
  );
};
  

  return (
    <section
      aria-label="Voice Recording and Accent Analysis"
      className="w-full max-w-4xl bg-white/80 dark:bg-black/80 backdrop-blur-sm p-6 rounded-xl border border-black/[.08] dark:border-white/[.145]"
    >
      <MetaScript />

      <article itemScope itemType="https://schema.org/HowTo">

        <RecordingHeader />
 
 

        <div className="flex flex-col items-center space-y-6">
       
          <RecordingButtons />

      

          {/* Conditional message for Deep Analysis */}
          {isDeepAnalysis && (
           <DeepAnalysisMessage />
          )}

          <WordsDisclaimer />

          {/* Audio Player */}
          {audioURL && (
            <div className="w-full max-w-md">
              <audio src={audioURL} controls className="w-full " />
            </div>
          )}

          {/* Loading Animation */}
          {isProcessing && (
            <LoadingAnimation />
          )}

          {/* AI Response */}
          {!isProcessing && aiResponse && (
            <BasicAnalysis aiResponse={aiResponse} />
          )}

          {/* Detailed Accent Analysis Section */}
          {!isProcessing && detailedAiResponse && (
              <DetailedAnalysis detailedAiResponse={detailedAiResponse} />
          )}
          {/* Call to Action */}
          {!isProcessing && (aiResponse || detailedAiResponse) && (
            <RecordingCallToAction onWaitlistClick={onWaitlistClick} onResetRecordingClick={onResetRecordingClick} />
          )}
        </div>
      </article>
    </section>
   
  );
}
</file>

<file path="src/components/RecordingButtonConfig.tsx">
import { useRecordingContext } from '@/context/recording-context';

export const ButtonConfig = () => {
  const { isProcessing, isRecording, isProcessed, startRecording, stopRecording, resetRecording } = useRecordingContext();

  if (isProcessing) {
    return {
      text: 'Processing...',
      action: () => {},
      disabled: true,
      className: 'opacity-50 cursor-not-allowed',
    };
  }
  if (isRecording) {
    return {
      text: (
        <span className="flex items-center">
          <span className="animate-pulse mr-2 text-red-500">●</span> Stop
          Recording
        </span>
      ),
      action: stopRecording,
      disabled: false,
      className:
        'bg-black text-white dark:bg-white dark:text-black hover:opacity-90',
    };
  }
  if (isProcessed) {
    return {
      text: 'Record Again',
      action: resetRecording,
      disabled: false,
      className:
        'hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black',
    };
  }
  return {
    text: 'Start Recording',
    action: startRecording,
    disabled: false,
    className:
      'hover:bg-black hover:text-white dark:hover:bg-white dark:hover:text-black',
  };
};
</file>

<file path="src/components/RecordingCallToAction.tsx">
export const RecordingCallToAction = ({onWaitlistClick, onResetRecordingClick}: {onWaitlistClick: () => void, onResetRecordingClick: () => void}) => {
  return (
    <div className="p-6 bg-gradient-to-r from-black/5 to-black/10 dark:from-white/5 dark:to-white/10 rounded-lg w-full">
    <div className="max-w-2xl mx-auto text-center space-y-4">
      <h3 className="text-xl font-semibold">
        Ready to Improve Your Pronunciation And Accent?
      </h3>
      <p className="text-gray-700 dark:text-gray-300">
        Join our waitlist to start speaking like a native.
      </p>
      <div className="flex flex-col sm:flex-row gap-4 justify-center items-center">
        <button
          onClick={onWaitlistClick}
          className="px-6 py-2 rounded-lg font-medium transition-all duration-200 
                   bg-black text-white dark:bg-white dark:text-black 
                   hover:opacity-90 hover:scale-105"
        >
          Join Waitlist
        </button>
        <button
          onClick={onResetRecordingClick}
          className="px-6 py-2 rounded-lg font-medium transition-all duration-200 
                   border border-black/10 dark:border-white/10
                   hover:bg-black/5 dark:hover:bg-white/5"
        >
          Try Another Recording
        </button>
      </div>
      <p className="text-sm text-gray-600 dark:text-gray-400 mt-4">
        ✨ Get early access and special perks when we launch!
      </p>
    </div>
  </div>
  )
}
</file>

<file path="src/components/RecordingHeader.tsx">
export const RecordingHeader = () => {
  return (
      <header className="text-center mb-8">
        <h1 itemProp="name" className="text-2xl font-semibold mb-3">
      Speak & Uncover Your Accent
    </h1>
    <div itemProp="description" className="space-y-2">
      <p className="text-lg text-gray-700 dark:text-gray-300">
        Record your voice in any language and reveal the subtle impact of
        your native tongue.
      </p>
      <p className="text-sm text-gray-600 dark:text-gray-400">
        We will provide detailed insights into how your background shapes
        your pronunciation, rhythm, and overall speaking style.
      </p>
      <p className="text-xs text-gray-500 dark:text-gray-400 mt-2">
        We do not store your audio recordings. By submitting, you consent to sending your voice recording to our AI system for processing. We only store metric information to improve our service. The audio is deleted immediately from the server and is not used for training purposes.
      </p>
    </div>
  </header>
)
}
</file>

<file path="src/components/RecordingMetaScript.tsx">
export const MetaScript = () => {
  return (
    <script
    type="application/ld+json"
    dangerouslySetInnerHTML={{
      __html: JSON.stringify({
        '@context': 'https://schema.org',
        '@type': 'HowTo',
        name: 'Analyze Your Accent with AI',
        description:
          'Get instant AI-powered feedback on your pronunciation, fluency, and accent characteristics in any language',
        estimatedCost: {
          '@type': 'MonetaryAmount',
          currency: 'USD',
          value: '0',
        },
        tool: [
          {
            '@type': 'HowToTool',
            name: 'Microphone',
          },
        ],
        step: [
          {
            '@type': 'HowToStep',
            name: 'Allow Microphone Access',
            text: 'Grant microphone permissions when prompted to enable voice recording',
            url: 'https://yourdomain.com#recording',
          },
          {
            '@type': 'HowToStep',
            name: 'Start Recording',
            text: 'Click the start button and speak clearly in any language',
            url: 'https://yourdomain.com#recording',
          },
          {
            '@type': 'HowToStep',
            name: 'Complete Recording',
            text: 'Click stop when finished to submit your recording',
            url: 'https://yourdomain.com#recording',
          },
          {
            '@type': 'HowToStep',
            name: 'Get Analysis',
            text: 'Receive detailed AI analysis of your pronunciation and accent characteristics',
            url: 'https://yourdomain.com#analysis',
          },
        ],
        totalTime: 'PT2M',
      }),
    }}
  />
  )
}
</file>

<file path="src/components/ScrollButton.tsx">
"use client";

export default function ScrollButton() {
  const handleClick = () => {
    const features = document.getElementById("features");
    if (features) {
      features.scrollIntoView({ behavior: "smooth" });
    }
  };

  return (
    <button
      onClick={handleClick}
      className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-black dark:hover:bg-white hover:text-white dark:hover:text-black text-sm sm:text-base h-10 sm:h-12 px-6 sm:px-8 group"
    >
      How it works
      <svg
        className="w-4 h-4 ml-2 transition-transform group-hover:translate-x-1"
        fill="none"
        stroke="currentColor"
        viewBox="0 0 24 24"
      >
        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14 5l7 7m0 0l-7 7m7-7H3" />
      </svg>
    </button>
  );
}
</file>

<file path="src/components/Toaster.tsx">
import { Toaster as HotToast } from 'react-hot-toast'

export function Toaster() {
  return (
    <HotToast />
  )
}
</file>

<file path="src/components/YoutubeVideo.tsx">
'use client'
import React, { useEffect, useRef } from 'react';

interface YouTubeVideoProps {
  videoId: string;
  pageLoaded: boolean;
}

const YouTubeVideo: React.FC<YouTubeVideoProps> = ({ videoId, pageLoaded }) => {
  const iframeRef = useRef<HTMLIFrameElement>(null);

  useEffect(() => {
   
    const observer = new IntersectionObserver(
      (entries) => {
        entries.forEach((entry) => {
          if (entry.isIntersecting && iframeRef.current) {
            // Autoplay the video when the iframe is in view
            iframeRef.current.src = `https://www.youtube.com/embed/${videoId}?autoplay=1&mute=1`;
          } else if (iframeRef.current) {
            // Stop the video when the iframe is out of view
            iframeRef.current.src = `https://www.youtube.com/embed/${videoId}`;
          }
        });
      },
      {
        root: null, // Use the viewport as the root
        threshold: 0.5, // Trigger when 50% of the video is visible
      }
    );

    if (iframeRef.current) {
      observer.observe(iframeRef.current);
    }

    return () => {
      if (iframeRef.current) {
        observer.unobserve(iframeRef.current);
      }
    };
  }, [videoId, pageLoaded]);

  return (
    <div className="relative w-full max-w-4xl border border-red-500 rounded-xl">
      <div className="relative pt-[56.25%]">

      
      <iframe
        ref={iframeRef}
        className="absolute top-0 left-0 w-full h-full rounded-xl"
        src={`https://www.youtube.com/embed/${videoId}`}
        title="YouTube video player"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowFullScreen
        />
        </div>
    </div>
  );
};

export default YouTubeVideo;
</file>

<file path="src/components/YoutubeWrapper.tsx">
'use client'
import { useEffect, useState } from 'react'
import YouTubeVideo from './YoutubeVideo'

const YouTubeVideoWrapper = ({ videoId }: { videoId: string }) => {
  const [isClient, setIsClient] = useState(false)

  useEffect(() => {
    setIsClient(true)
  }, [])

  if (!isClient) {
    return <div className="animate-pulse h-40 bg-gray-200 rounded-xl" />
  }

  return <YouTubeVideo videoId={videoId} pageLoaded={isClient} />
}

export default YouTubeVideoWrapper
</file>

<file path="src/context/posthog-context.tsx">
// app/providers.jsx
'use client'
import posthog from 'posthog-js'
import { PostHogProvider as PHProvider } from 'posthog-js/react'
import { useEffect } from 'react'
import SuspendedPostHogPageView from '@/components/PostHogPageView'

export function PostHogProvider({ children }: { children: React.ReactNode }) {
  useEffect(() => {
    if (!process.env.NEXT_PUBLIC_POSTHOG_KEY) {
      console.log('PostHog key is not set')
      return
    }
    if (!process.env.NEXT_PUBLIC_POSTHOG_HOST) {
      console.log('PostHog host is not set')
      return
    }
    if (process.env.NEXT_PUBLIC_ENVIRONMENT !== 'production') {
     return 
    }
    posthog.init(process.env.NEXT_PUBLIC_POSTHOG_KEY, {
      api_host: process.env.NEXT_PUBLIC_POSTHOG_HOST,
      person_profiles: 'always', // or 'always' to create profiles for anonymous users as well
      capture_pageview: false, // Disable automatic pageview capture, as we capture manually
      capture_pageleave: true
    })
  }, [])

  return (
    <PHProvider client={posthog}>
      <SuspendedPostHogPageView />
      {children}
    </PHProvider>
  )
}
</file>

<file path="src/context/recording-context.tsx">
// File: /src/context/recording-context.tsx
'use client';
import { createContext, useContext, ReactNode, useState, useRef, useEffect } from 'react';
import { useError } from '@/hooks/useError';
import { useSubscription } from './subscription-context';
import { AIResponse, DetailedAIResponse } from '@/models/AiResponse.model';
import React from 'react';

import posthog from 'posthog-js';
import logger from '@/utils/logger';


type RecordingContextType = {
  isRecording: boolean;
  setIsRecording: (isRecording: boolean) => void;
  audioURL: string | null;
  setAudioURL: (audioURL: string | null) => void;
  isProcessed: boolean;
  isProcessing: boolean;
  setIsProcessing: (isProcessing: boolean) => void;
  setIsProcessed: (isProcessed: boolean) => void;
  aiResponse: AIResponse | null;
  setAiResponse: (aiResponse: AIResponse | null) => void;
  detailedAiResponse: DetailedAIResponse | null;
  setDetailedAiResponse: (detailedAiResponse: DetailedAIResponse | null) => void;
  maxRecordingAttempts: number;
  recordingAttempts: number;
  setRecordingAttempts: (recordingAttempts: number) => void;
  isDeepAnalysis: boolean;
  setIsDeepAnalysis: (isDeepAnalysis: boolean) => void;
  startRecording: () => void;
  stopRecording: () => void;
  resetRecording: () => void;
  posthogCapture: (event: string) => void;
};

const MAX_RECORDING_TIME_MS = 600000; // 10 minutes
const ATTEMPTS_RESET_TIME_MS = 3600000; // 1 hour

const RecordingContext = createContext<RecordingContextType | null>(null);

export const RecordingProvider = ({ children }: { children: ReactNode }) => {

const { showError } = useError();
  const { isSubscribed, isSubscribedBannerShowed, setIsSubscribedBannerShowed } = useSubscription();

  const [isRecording, setIsRecording] = useState(false);
  const isRecordingRef = useRef(isRecording);
  useEffect(() => {
    isRecordingRef.current = isRecording;
  }, [isRecording]);

  const [audioURL, setAudioURL] = useState<string | null>(null);
  const [isProcessed, setIsProcessed] = useState(false);
  const [aiResponse, setAiResponse] = useState<AIResponse | null>(null);
  const [detailedAiResponse, setDetailedAiResponse] = useState<DetailedAIResponse | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isDeepAnalysis, setIsDeepAnalysis] = useState(false);
  const [maxRecordingAttempts, setMaxRecordingAttempts] = useState(2);
  const [recordingAttempts, setRecordingAttempts] = useState<number>(() => {
    if (typeof window === 'undefined') return 0; // SSR
    const storedAttempts = localStorage.getItem('recordingAttempts');
    const storedTimestamp = localStorage.getItem('attemptsTimestamp');

    if (storedAttempts && storedTimestamp) {
      const attempts = parseInt(storedAttempts, 10);
      const timestamp = parseInt(storedTimestamp, 10);
      const now = Date.now();

      if (now - timestamp < ATTEMPTS_RESET_TIME_MS) {
        return attempts;
      }
    }
    return 0;
  });

  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const recordingTimerInterval = useRef<NodeJS.Timeout | null>(null);
  const streamRef = useRef<MediaStream | null>(null); // Ref to hold the stream

  const isDeepAnalysisRef = useRef(isDeepAnalysis);
  useEffect(() => {
    isDeepAnalysisRef.current = isDeepAnalysis;
  }, [isDeepAnalysis]);

  const updateIsDeepAnalysis = (value: boolean) => {
    setIsDeepAnalysis(value);
    isDeepAnalysisRef.current = value;
  };

  useEffect(() => {
    if (typeof window === 'undefined') return; // SSR
    localStorage.setItem('recordingAttempts', recordingAttempts.toString());
    if (recordingAttempts === 0) {
      localStorage.setItem('attemptsTimestamp', Date.now().toString());
    }
  }, [recordingAttempts]);

  useEffect(() => {
    if (isSubscribed) {
      setMaxRecordingAttempts(1000);
      if (!isSubscribedBannerShowed) {
        showError(
          'You are subscribed to the waitlist. You can now record unlimited times.',
          'success'
        );
        setIsSubscribedBannerShowed(true);
      }
    }
  }, [isSubscribed, isSubscribedBannerShowed, showError, setIsSubscribedBannerShowed]); // Added dependencies

  // Cleanup stream on component unmount
  useEffect(() => {
    return () => {
      streamRef.current?.getTracks().forEach(track => track.stop());
    };
  }, []);


  const posthogCapture = (event: string) => {
    if (process.env.NEXT_PUBLIC_ENVIRONMENT === 'production') {
      posthog?.capture(event);
    }
  };

  const handleSend = async (
    audioFile: File,
    recTime: number,
    recSize: number,
    deepAnalysis: boolean
  ) => {
    if (!audioFile || !recTime || !recSize) {
      showError('No audio recorded. Please try again.', 'warning');
      return;
    }

    setIsProcessing(true);
    try {
      const formData = new FormData();
      formData.append('audio', audioFile);
      formData.append('recordingTime', recTime.toString());
      formData.append('recordingSize', recSize.toString());
      if (deepAnalysis) {
        formData.append('isDeepAnalysis', 'true');
      }

      const response = await fetch('/api/recording', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) throw new Error(`Server error: ${response.status}`);

      const data = await response.json();
      console.log('API Response:', data);

      if (deepAnalysis) {
        const detailedResponse = data.aiResponse as DetailedAIResponse;
        setDetailedAiResponse(detailedResponse);
        console.log('Detailed AI Response:', detailedResponse);
      } else {
        const standardResponse = data.aiResponse as AIResponse;
        setAiResponse(standardResponse);
        console.log('Standard AI Response:', standardResponse);
      }
      // Set isProcessed to true only on successful processing
      setIsProcessed(true);

    } catch (error) {
      logger.error('Error sending recording:', error);
      showError('Failed to process recording. Please try again.', 'error');
      // Do not set isProcessed to true on error
    } finally {
      setIsProcessing(false); // This remains in finally
    }
  };


  const startRecording = async () => {
    const isDev = process.env.NEXT_PUBLIC_ENVIRONMENT === 'development';
    logger.log('startRecording', isDev, recordingAttempts, maxRecordingAttempts);

    if ((recordingAttempts >= maxRecordingAttempts) && !isDev) {
      showError(
        `You have reached the maximum number of recording attempts (${maxRecordingAttempts}) in the last hour. Subscribe to our waitlist to get unlimited analyses.`,
        'warning'
      );
      return;
    }

    // Stop any existing stream before starting a new one
    streamRef.current?.getTracks().forEach(track => track.stop());
    streamRef.current = null;
    // Clear previous timer if any
    if (recordingTimerInterval.current) {
      clearInterval(recordingTimerInterval.current);
      recordingTimerInterval.current = null;
    }


    try {
      // Reset states before starting
      setIsProcessed(false);
      setAiResponse(null);
      setDetailedAiResponse(null);
      setAudioURL(null);
      audioChunks.current = []; // Clear previous audio chunks

      // Check if mediaDevices API is supported
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('Media devices API not supported in this browser');
      }

      logger.log('startRecording', isDev, recordingAttempts, maxRecordingAttempts);
      // Check if any audio input devices are available
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioDevices = devices.filter(
        (device) => device.kind === 'audioinput'
      );

      if (audioDevices.length === 0) {
        throw new Error('No audio input devices found');
      }

      // Request microphone permission with constraints
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        },
        video: false,
      });
      streamRef.current = stream; // Store the stream

      // Only proceed if we got the stream successfully
      const mimeType = MediaRecorder.isTypeSupported('audio/webm')
        ? 'audio/webm'
        : 'audio/mp4';

      mediaRecorder.current = new MediaRecorder(stream, {
        mimeType: mimeType,
      });

      // --- Assign handlers directly ---
      mediaRecorder.current.ondataavailable = (event) => {
        if (event.data.size > 0) { // Ensure blob is not empty
           audioChunks.current.push(event.data);
        }
      };

      mediaRecorder.current.onstop = async () => {
          logger.log('onstop triggered'); // Add logging
          if (audioChunks.current.length === 0) {
             logger.warn('No audio chunks recorded.');
             setIsProcessing(false); // Ensure processing state is reset if no data
             return; // Don't proceed if no data
          }

          const audioBlob = new Blob(audioChunks.current, { type: mimeType });
          const url = URL.createObjectURL(audioBlob);
          setAudioURL(url);
          logger.log('audioURL set:', url);

          const endTime = Date.now();
          const timeDiff = endTime - startTimeRef.current;
          const blobSize = audioBlob.size;

          // Create File object for upload
          const audioFile = new File([audioBlob], 'recording.aac', {
            type: 'audio/aac-adts', // Adjust if needed, though often server-side handles conversion
          });

          // Call handleSend which now also sets isProcessed on success
          await handleSend(audioFile, timeDiff, blobSize, isDeepAnalysisRef.current);

          // No need to set isProcessed here anymore
          // Stop stream tracks associated with this recording
          streamRef.current?.getTracks().forEach((track) => track.stop());
          streamRef.current = null; // Clear the ref after stopping
      };
      // --- End handler assignment ---

      // Start recording
      mediaRecorder.current.start();
      setIsRecording(true);
      isRecordingRef.current = true; // Sync ref state
      startTimeRef.current = Date.now();

      // Increment recording attempts
      setRecordingAttempts((prevAttempts) => prevAttempts + 1);

      // Set up timer to stop recording after MAX_RECORDING_TIME_MS
      recordingTimerInterval.current = setInterval(() => {
        if (isRecordingRef.current) { // Use ref for checking inside interval
          const elapsedTime = Date.now() - startTimeRef.current;
          if (elapsedTime >= MAX_RECORDING_TIME_MS) {
            logger.log('Max recording time reached, stopping.');
            stopRecording(); // stopRecording will trigger onstop
            showError(
              `Maximum recording time reached (${MAX_RECORDING_TIME_MS / 60000} minutes). Recording stopped.`,
              'warning'
            );
            // Interval cleared in stopRecording
          }
        } else {
           // Clear interval if recording is stopped externally
           if (recordingTimerInterval.current) {
             clearInterval(recordingTimerInterval.current);
             recordingTimerInterval.current = null;
           }
        }
      }, 1000); // Check every 1 second

    } catch (error: unknown) {
      setIsRecording(false);
      isRecordingRef.current = false; // Sync ref state on error
      logger.error('Error starting recording:', error);
      // Clear timer on error
      if (recordingTimerInterval.current) {
        clearInterval(recordingTimerInterval.current);
        recordingTimerInterval.current = null;
      }
      // Stop stream tracks on error
      streamRef.current?.getTracks().forEach(track => track.stop());
      streamRef.current = null;

      // Handle specific errors
      if (error instanceof Error) {
        switch (error.name) {
          case 'NotAllowedError':
            showError(
              'Microphone access denied. Please allow microphone access and try again.',
              'error'
            );
            break;
          case 'NotFoundError':
            showError(
              'No microphone found. Please connect a microphone and try again.',
              'error'
            );
            break;
          case 'NotReadableError':
            showError(
              'Microphone is already in use. Please close other applications using the microphone.',
              'error'
            );
            break;
          default:
            if (
              error.message ===
              'Media devices API not supported in this browser'
            ) {
              showError(
                'Your browser does not support audio recording. Please try a modern browser like Chrome or Firefox.',
                'error'
              );
            } else if (error.message === 'No audio input devices found') {
              showError(
                'No microphone detected. Please connect a microphone and try again.',
                'error'
              );
            } else {
              showError(
                `Could not start recording: ${error.message}`, // Include error message
                'error'
              );
            }
        }
      } else {
         showError('An unknown error occurred while starting recording.', 'error');
      }
    }
  };

  const stopRecording = () => {
    logger.log('stopRecording called. Current state:', mediaRecorder.current?.state);
    if (mediaRecorder.current && mediaRecorder.current.state === 'recording') {
      mediaRecorder.current.stop(); // This will trigger the 'onstop' event handler asynchronously
      setIsRecording(false);
      isRecordingRef.current = false; // Sync ref state
      // Clear interval timer
      if (recordingTimerInterval.current) {
        clearInterval(recordingTimerInterval.current);
        recordingTimerInterval.current = null;
      }
      // Note: Stream tracks are stopped in the 'onstop' handler now
      posthogCapture('stop_recording_clicked');
    } else {
        logger.warn('stopRecording called but recorder not in recording state.');
        // Ensure stream is stopped even if recorder state is unexpected
        streamRef.current?.getTracks().forEach(track => track.stop());
        streamRef.current = null;
        // Reset recording state just in case
        setIsRecording(false);
        isRecordingRef.current = false;
    }
  };


  const resetRecording = () => {
    setAudioURL(null);
    setAiResponse(null);
    setDetailedAiResponse(null);
    setIsProcessed(false);
    setIsProcessing(false); // Also reset processing state
    // Stop any active recording/stream if reset is called unexpectedly
    if (isRecordingRef.current) {
        stopRecording();
    } else {
        // Ensure stream is stopped if reset is called while not recording
        streamRef.current?.getTracks().forEach(track => track.stop());
        streamRef.current = null;
    }
    // Clear audio chunks
    audioChunks.current = [];
  };

  const value: RecordingContextType = {
    isRecording,
    setIsRecording,
    audioURL,
    setAudioURL,
    isProcessed,
    setIsProcessed,
    aiResponse,
    setAiResponse,
    detailedAiResponse,
    setDetailedAiResponse,
    isProcessing,
    setIsProcessing,
    maxRecordingAttempts,
    recordingAttempts,
    isDeepAnalysis,
    setIsDeepAnalysis: updateIsDeepAnalysis,
    startRecording,
    stopRecording,
    resetRecording,
    posthogCapture,
    setRecordingAttempts
  };

  return (
    <RecordingContext.Provider value={value}>
      {children}
    </RecordingContext.Provider>
  );
};

export const useRecordingContext = () => {
  const context = useContext(RecordingContext);
  if (!context) {
    throw new Error('useRecordingContext must be used within a RecordingProvider');
  }
  return context;
};
</file>

<file path="src/context/subscription-context.tsx">
"use client";

import { createContext, useState, useEffect, useContext } from 'react';
import { useError } from '@/hooks/useError';
import logger from '@/utils/logger';
import { FormService } from '@/services/form.service';

interface SubscriptionContextType {
  isSubscribed: boolean;
  setIsSubscribed: (isSubscribed: boolean) => void;
  isSubscribedBannerShowed: boolean;
  setIsSubscribedBannerShowed: (isSubscribedBannerShowed: boolean) => void;
  checkSubscription: () => Promise<void>;
  handleSubmit: (e: React.FormEvent) => Promise<void>;
  status: 'idle' | 'loading' | 'success' | 'error';
  email: string;
  setEmail: (email: string) => void;
  errorMessage: string;
  setErrorMessage: (errorMessage: string) => void;
}

const SubscriptionContext = createContext<SubscriptionContextType | undefined>(undefined);

export const SubscriptionProvider = ({ children }: { children: React.ReactNode }) => {
  const [email, setEmail] = useState('');
  const [status, setStatus] = useState<
    'idle' | 'loading' | 'success' | 'error'
  >('idle');
  const [errorMessage, setErrorMessage] = useState('');
  const [isSubscribed, setIsSubscribed] = useState(false);
  const [isSubscribedBannerShowed, setIsSubscribedBannerShowed] = useState(false);
  const { showError } = useError();

  useEffect(() => {
    checkSubscription();
  }, []);

  const checkSubscription = async () => {
    try {
      const response = await fetch('/api/subscribe', {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
      });

      if (!response.ok) {
        throw new Error(`Server responded with status: ${response.status}`);
      }

      const data = await response.json();
      setIsSubscribed(data.isSubscribed);
    } catch (error: unknown) {
      logger.error("Error checking subscription:", error);
      showError(
        'Failed to check your subscription status. Please try again later.',
        'error'
      );
    }
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setStatus('loading');
    setErrorMessage('');

    try {
      await FormService.submitEmail(email);
      setStatus('success');
      setEmail('');
      setIsSubscribed(true);
    } catch (error) {
      setStatus('error');
      setErrorMessage(
        error instanceof Error ? error.message : 'Subscription failed'
      );
    }
  };

  const value: SubscriptionContextType = {
    isSubscribed,
    setIsSubscribed,
    isSubscribedBannerShowed,
    setIsSubscribedBannerShowed,
    checkSubscription,
    handleSubmit,
    status,
    email,
    setEmail,
    errorMessage,
    setErrorMessage
  };

  return (
    <SubscriptionContext.Provider value={value}>
      {children}
    </SubscriptionContext.Provider>
  );
};

export const useSubscription = () => {
  const context = useContext(SubscriptionContext);
  if (!context) {
    throw new Error('useSubscription must be used within a SubscriptionProvider');
  }
  return context;
};
</file>

<file path="src/data/migrations/create_interactions_table.sql">
CREATE TABLE interactions (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_ip TEXT,
  timestamp TIMESTAMP WITH TIME ZONE,
  recording_size INTEGER,
  response_time INTEGER,
  ai_response_length INTEGER,
  recording_time INTEGER,
  ai_response JSONB,
  recording JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc', now())
);
</file>

<file path="src/hooks/use-upload.tsx">
import { useCallback } from "react";
import { upload } from "@vercel/blob/client";
import logger from "@/utils/logger";



export const useUpload = () => {
  const uploadFile = async (file: File, pathPrefix: string): Promise<string> => {
    const filename = `${pathPrefix}/${Date.now()}-${file.name}`;
    const blob = await upload(filename, file, {
      access: "public",
      handleUploadUrl: "/api/upload-token",
      clientPayload: JSON.stringify({
        __development__: "bypass-auth-for-localhost",
      }),
      onUploadProgress: ({ percentage }) =>
        logger.log(`Upload progress: ${percentage}%`),
    });
    return blob.url;
  };

  return { uploadFile };
};
</file>

<file path="src/hooks/useError.tsx">
'use client';

import logger from '@/utils/logger';
import React, { createContext, useContext, useCallback } from 'react';
import toast, { Toaster } from 'react-hot-toast';

export type ErrorType = 'error' | 'warning' | 'info' | 'success';

export interface ErrorMessage {
  message: string;
  type: ErrorType;
  id?: string;
}

interface ErrorContextType {
  showError: (message: string, type?: ErrorType) => void;
}

const ErrorContext = createContext<ErrorContextType | undefined>(undefined);

export function ErrorProvider({ children }: { children: React.ReactNode }) {
  const showError = useCallback((message: string, type: ErrorType = 'error') => {
    logger.log("Showing error:", message, type);
    
    switch (type) {
      case 'error':
        toast.error(message, {
          duration: 5000,
          style: {
            background: '#EF4444',
            color: '#fff',
          },
          icon: '❌',
        });
        break;
      case 'warning':
        toast(message, {
          duration: 5000,
          style: {
            background: '#F59E0B',
            color: '#000',
          },
          icon: '⚠️',
        });
        break;
      case 'info':
        toast(message, {
          duration: 5000,
          style: {
            background: '#3B82F6',
            color: '#fff',
          },
          icon: 'ℹ️',
        });
        break;
      case 'success':
        toast.success(message, {
          duration: 5000,
          style: {
            background: '#10B981',
            color: '#fff',
          },
          icon: '✅',
        });
        break;
    }
  }, []);

  return (
    <ErrorContext.Provider value={{ showError }}>
      {children}
      <Toaster
        position="top-center"
        reverseOrder={false}
        gutter={8}
        containerClassName=""
        containerStyle={{}}
        toastOptions={{
          // Default options for all toasts
          className: '',
          duration: 5000,
          style: {
            background: '#363636',
            color: '#fff',
            padding: '16px',
            borderRadius: '8px',
            fontSize: '14px',
            maxWidth: '500px',
            display: 'flex',
            alignItems: 'center',
            gap: '8px',
          },
          // Custom success styles
          success: {
            style: {
              background: '#10B981',
            },
          },
          // Custom error styles
          error: {
            style: {
              background: '#EF4444',
            },
          },
        }}
      />
    </ErrorContext.Provider>
  );
}

export function useError() {
  const context = useContext(ErrorContext);
  if (context === undefined) {
    throw new Error('useError must be used within an ErrorProvider');
  }
  return context;
}
</file>

<file path="src/interfaces/ai-service.interface.ts">
export interface IAIService {
   generateContent(fileUri: string, userMessage: string, systemMessage: string, model: string): Promise<Record<string, unknown>>
}

export interface IUploadableAIService extends IAIService {
  uploadFile(
    audioBuffer: Buffer,
    mimeType: string,
    fileName: string
  ): Promise<string> 
}
</file>

<file path="src/interfaces/tts.interface.ts">
export interface ITTS {
  synthesizeSpeech(text: string, language: string, voice: string): Promise<string>;
  getVoice(language: string, quality: 'basic' | 'hd'): string;
}
</file>

<file path="src/lib/server-actions/learning_progress-actions.ts">
'use server';

import { LearningProgressRepository } from '@/repositories/learning-progress.repository';
import LearningProgressService from '@/services/learning-progress.service';
import { LearningProgressModel, WordProgressModel } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { MasteryLevel } from '@prisma/client';

// Helper function to instantiate the service
function createLearningProgressService() {
  const repository = new LearningProgressRepository();
  // Inject other dependencies if needed
  return new LearningProgressService(repository);
}

/**
 * Gets the overall learning progress summary for a user.
 */
export async function getLearningProgressAction(userId: string): Promise<LearningProgressModel | null> {
  if (!userId) {
    logger.error('getLearningProgressAction called without userId');
    return null;
  }
  try {
    const progressService = createLearningProgressService();
    // Decide whether to get details or just summary based on use case
    // return await progressService.getLearningProgress(userId);
    return await progressService.getLearningProgressWithDetails(userId); // Example: get details
  } catch (error) {
    logger.error('Error in getLearningProgressAction:', { userId, error });
    return null; // Return null on error to the client
  }
}

/**
 * Gets words the user needs to practice (e.g., Seen, Learning, Practiced levels).
 */
export async function getPracticeWordsAction(userId: string): Promise<WordProgressModel[]> {
   if (!userId) {
     logger.error('getPracticeWordsAction called without userId');
     return [];
   }
   try {
     const progressService = createLearningProgressService();
     const progress = await progressService.getLearningProgress(userId);
     if (!progress) return [];

     const repo = new LearningProgressRepository(); // Or get from service if exposed
     return await repo.getWordsByMastery(progress.id, [
       MasteryLevel.Seen,
       MasteryLevel.Learning,
       MasteryLevel.Practiced,
       MasteryLevel.Known, // Include known for occasional review
     ]);
   } catch (error) {
     logger.error('Error in getPracticeWordsAction:', { userId, error });
     return [];
   }
}

// Add other actions as needed, e.g., getTopicProgressAction, getWordProgressAction
</file>

<file path="src/lib/prisma.ts">
import { PrismaClient } from '@prisma/client'

// Prevent multiple instances of Prisma Client in development
declare global {
  var prisma: PrismaClient | undefined
}

function createPrismaClient() {
  try {
    return new PrismaClient({
      log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
    })
  } catch (e) {
    console.error('Failed to create Prisma Client:', e)
    throw new Error(`Prisma Client initialization failed. Please check your database connection and run 'npx prisma generate'.`)
  }
}

// Use the globally cached instance in development to prevent connection issues during hot reload
const prisma = global.prisma || createPrismaClient()

if (process.env.NODE_ENV !== 'production') global.prisma = prisma

export default prisma
</file>

<file path="src/models/AiResponse.model.ts">
export interface PhonemeAnalysis {
  phoneme: string;
  example: string;
  analysis: string;
  IPA_target: string;
  IPA_observed: string;
}

export interface SuprasegmentalFeatureAnalysis {
  feature: string;
  observation: string;
}

export interface AIResponse {
  language_analyzed: string;
  analyzed_language_code: string;
  accent_identification: {
    accent_type: string;
    specific_accent: string;
    confidence_level: string;
    accent_strength: string;
  },
  speaker_background: {
    probable_native_language: string;
    probable_region: string;
    confidence: string;
    supporting_evidence: string[];
  },
  language_specific_phonological_assessment: [
    {
      phoneme: string;
      example: string;
      analysis: string;
      IPA_target: string;
      IPA_observed: string;
    }
  ],
  suprasegmental_features_analysis: {
    feature: string;
    observation: string;
    comparison: string;
  }[];
  diagnostic_accent_markers: {
    feature: string;
    description: string;
    association: string;
  }[];
  proficiency_assessment: {
    intelligibility: string;
    fluency: string;
    CEFR_level: string;
  };
  improvement_suggestions: {
    focus_area: string;
    importance: "High" | "Medium" | "Low";
    exercises: string[];
  }[];
}




// Define a new interface for the detailed deep analysis response
export interface DetailedAIResponse {
  accent_analysis: {
    language_analyzed: string; 
    analyzed_language_code: string;
    accent_classification: {
      accent_type: string;
      specific_accent: string;
      confidence_level: number;
      accent_strength: string;
    };
    speaker_background: {
      probable_native_language: string;
      probable_region: string;
      confidence_level: number;
      supporting_evidence: string[];
    };
  };
  phonetic_analysis: {
    vowel_production: Array<{
      phoneme: string;
      standard_realization: string;
      observed_realization: string;
      example_word: string;
      timestamp: number;
      analysis: string;
      accent_marker: boolean;
    }>;
    consonant_production: Array<{
      phoneme: string;
      standard_realization: string;
      observed_realization: string;
      example_word: string;
      timestamp: number;
      analysis: string;
      accent_marker: boolean;
    }>;
  };
  prosodic_features: {
    rhythm_patterns: {
      description: string;
      standard_pattern: string;
      observed_pattern: string;
      accent_association: string;
    };
    stress_patterns: {
      word_level: {
        description: string;
        accent_association: string;
      };
      sentence_level: {
        description: string;
        accent_association: string;
      };
    };
    intonation: {
      patterns: string[];
      accent_association: string;
    };
  };
  diagnostic_accent_markers: Array<{
    feature: string;
    description: string;
    example: string;
    timestamp: number;
    accent_association: string;
    frequency: string;
  }>;
  proficiency_assessment: {
    intelligibility_score: number;
    fluency_rating: number;
    comprehensibility: number;
    CEFR_pronunciation_level: "A1" | "A2" | "B1" | "B2" | "C1" | "C2";
    accent_impact_assessment: string;
  };
  improvement_plan: {
    priority_areas: Array<{
      focus: string;
      importance: "High" | "Medium" | "Low";
      exercises: string[];
      expected_timeline: string;
    }>;
    recommended_resources: string[];
    practice_strategies: string[];
  };
  linguistic_background_insights: {
    probable_l1_transfer_effects: string[];
    cultural_speech_patterns: string[];
    multilingual_influences: string[];
  };
}



export const mockResponse = {
  language_analyzed: "German",
  analyzed_language_code: "de-DE",
  accent_identification: {
    accent_type: "Non-native accent",
    specific_accent: "Slavic-influenced German",
    confidence_level: "95%",
    accent_strength: "Moderate",
  },
  speaker_background: {
    probable_native_language: "Russian",
    probable_region: "Eastern Europe",
    confidence: "90%",
    supporting_evidence: ["trilled /r/ substitution"],
  },
  language_specific_phonological_assessment: [
    {
      phoneme: "/r/",
      example: "andere",
      analysis: "The speaker uses an alveolar trill instead of the standard uvular fricative.",
      IPA_target: "ʁ",
      IPA_observed: "[r]",
    },
  ],
  suprasegmental_features_analysis: [
    {
      feature: "Rhythm/Intonation/Stress",
      observation: "Slightly syllable-timed rhythm with less variation in intonation.",
      comparison: "Deviates from the stress-timed rhythm of standard German.",
    },
  ],
  diagnostic_accent_markers: [
    {
      feature: "Alveolar trill for /r/",
      description: "Use of [r] instead of the uvular fricative [ʁ].",
      association: "Common in Slavic languages.",
    },
  ],
  proficiency_assessment: {
    intelligibility: "80%",
    fluency: "75%",
    CEFR_level: "B1",
  },
  improvement_suggestions: [
    {
      focus_area: "Pronunciation of /r/",
      importance: "High",
      exercises: ["Practice uvular fricative [ʁ] using minimal pairs."],
    },
  ],
};

export const mockDetailedResponse = {
  accent_analysis: {
    language_analyzed: "English",
    analyzed_language_code: "en-US",
    accent_classification: {
      accent_type: "Non-native accent",
      specific_accent: "Eastern European-influenced English",
      confidence_level: 90,
      accent_strength: "Moderate",
    },
    speaker_background: {
      probable_native_language: "Polish",
      probable_region: "Eastern Europe",
      confidence_level: 85,
      supporting_evidence: [
        "Devoicing of voiced consonants in certain contexts",
        "Monophthongization of certain diphthongs",
      ],
    },
  },
  phonetic_analysis: {
    vowel_production: [
      {
        phoneme: "/æ/",
        standard_realization: "/æ/ (as in 'cat')",
        observed_realization: "/ɛ/ (closer to 'bet')",
        example_word: "platform",
        timestamp: 0.9,
        analysis:
          "The speaker tends to raise and front the /æ/ vowel, resulting in a sound closer to /ɛ/. This is a common feature in speakers whose native languages have a different vowel inventory.",
        accent_marker: true,
      },
      {
        phoneme: "/ʌ/",
        standard_realization: "/ʌ/ (as in 'cut')",
        observed_realization: "/a/ (more open and back)",
        example_word: "understanding",
        timestamp: 25.2,
        analysis:
          "The /ʌ/ vowel is often produced as a more open /a/ sound, influenced by vowel systems where these distinctions are less pronounced.",
        accent_marker: true,
      },
      {
        phoneme: "/ɪ/",
        standard_realization: "/ɪ/ (as in 'bit')",
        observed_realization: "/i/ (closer to 'beet')",
        example_word: "rigid",
        timestamp: 0.18,
        analysis:
          "Tendency to raise /ɪ/ towards /i/, reducing the distinction between these two vowels. This is also common for native speakers of some European languages",
        accent_marker: true,
      },
    ],
    consonant_production: [
      {
        phoneme: "/θ/",
        standard_realization: "/θ/ (as in 'think')",
        observed_realization: "/t/ or /s/",
        example_word: "through",
        timestamp: 4.4,
        analysis:
          "The dental fricative /θ/ is often replaced with /t/, a common substitution influenced by the phonological systems of many languages that do not have this sound.",
        accent_marker: true,
      },
      {
        phoneme: "/ð/",
        standard_realization: "/ð/ (as in 'this')",
        observed_realization: "/d/ or /z/",
        example_word: "this",
        timestamp: 9.1,
        analysis:
          "Similar to /θ/, the /ð/ sound is frequently replaced with /d/ due to the absence of this voiced dental fricative in many languages. Sometimes realized as /z/.",
        accent_marker: true,
      },
      {
        phoneme: "/v/",
        standard_realization: "/v/ (as in 'very')",
        observed_realization: "/w/",
        example_word: "various",
        timestamp: 29.1,
        analysis:
          "The /v/ is sometimes realized as /w/, indicating influence from languages with a similar but distinct sound. Common in some dialects of Slavic languages.",
        accent_marker: true,
      },
    ],
  },
  prosodic_features: {
    rhythm_patterns: {
      description:
        "The speaker exhibits a tendency towards syllable-timed rhythm rather than the stress-timed rhythm characteristic of native English speech.",
      standard_pattern: "Stress-timed rhythm",
      observed_pattern: "Syllable-timed rhythm",
      accent_association: "Eastern European languages",
    },
    stress_patterns: {
      word_level: {
        description: "Occasional misplacement of stress within words",
        accent_association: "L1 interference",
      },
      sentence_level: {
        description: "Less emphasis on content words compared to function words",
        accent_association: "Monotone delivery",
      },
    },
    intonation: {
      patterns: ["Limited pitch range compared to native English speakers"],
      accent_association: "Eastern European languages",
    },
  },
  diagnostic_accent_markers: [
    {
      feature: "Substitution of /θ/ and /ð/",
      description: "Replacing dental fricatives with alveolar stops or fricatives.",
      example: "'think' sounding like 'tink'",
      timestamp: 4.4,
      accent_association: "Common in many languages",
      frequency: "Frequent",
    },
    {
      feature: "Vowel raising/fronting",
      description: "Raising and fronting of low vowels, particularly /æ/ and /ʌ/.",
      example: "'cat' sounding like 'ket'",
      timestamp: 0.9,
      accent_association: "Eastern European languages",
      frequency: "Occasional",
    },
    {
      feature: "Syllable-timed rhythm",
      description: "Equalizing syllable durations.",
      example: "Speech sounds more monotone",
      timestamp: 29.1,
      accent_association: "Slavic languages",
      frequency: "Frequent",
    },
  ],
  proficiency_assessment: {
    intelligibility_score: 80,
    fluency_rating: 75,
    comprehensibility: 85,
    CEFR_pronunciation_level: "B2",
    accent_impact_assessment:
      "The speaker demonstrates good overall proficiency in English, but the non-native accent is noticeable and can occasionally require listeners to pay closer attention.",
  },
  improvement_plan: {
    priority_areas: [
      {
        focus: "Dental Fricatives (/θ/ and /ð/)",
        importance: "High",
        exercises: [
          "Minimal pair drills (e.g., 'thin' vs. 'tin', 'this' vs. 'dis')",
          "Tongue placement exercises using a mirror",
          "Reading aloud with conscious attention to these sounds",
        ],
        expected_timeline: "6-8 weeks",
      },
      {
        focus: "Vowel Quality (especially /æ/ and /ʌ/)",
        importance: "Medium",
        exercises: [
          "Listening to native speakers and imitating their vowel sounds",
          "Using visual aids (e.g., vowel charts) to understand tongue placement",
          "Recording and comparing own pronunciation with native speakers",
        ],
        expected_timeline: "4-6 weeks",
      },
      {
        focus: "Prosody and Rhythm",
        importance: "Medium",
        exercises: [
          "Shadowing native speakers (imitating their intonation and rhythm)",
          "Practicing sentence stress and reduction of unstressed syllables",
          "Marking stressed syllables in written text and practicing aloud",
        ],
        expected_timeline: "8-10 weeks",
      },
    ],
    recommended_resources: [
      "Online pronunciation courses (e.g., Rachel's English)",
      "Interactive phonetic apps (e.g., Sounds Right)",
      "Recordings of native English speakers (podcasts, audiobooks)",
    ],
    practice_strategies: [
      "Consistent daily practice (15-30 minutes)",
      "Focusing on one specific sound or prosodic feature at a time",
      "Seeking feedback from native English speakers",
      "Using a recording device to monitor progress",
    ],
  },
  linguistic_background_insights: {
    probable_l1_transfer_effects: [
      "Devoicing of voiced consonants",
      "Monophthongization of diphthongs",
    ],
    cultural_speech_patterns: ["Direct communication style"],
    multilingual_influences: [],
  },
};
</file>

<file path="src/models/Language-detection.model.ts">
export interface LanguageDetectionResponse {
  language: string;
  confidence: number;
  possible_alternatives: string[];
  language_family: string;
}
</file>

<file path="src/repositories/supabase/supabase.ts">
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL || '';
const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY || '';
const supabaseServiceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY || '';

export const supabase = createClient(supabaseUrl, supabaseAnonKey);

export const getSession = async () => {
  const { data: { session }, error } = await supabase.auth.getSession()
  if (error) throw error
  return session
}
</file>

<file path="src/repositories/learning-progress.repository.ts">
import logger from '@/utils/logger';
import { LearningProgressModel, TopicProgressModel, WordProgressModel } from '@/models/AppAllModels.model';
import prisma from '@/lib/prisma';
import { MasteryLevel, Prisma } from '@prisma/client';

// Define the interface matching Prisma models but using TS models
export interface ILearningProgressRepository {
  getLearningProgress(userId: string): Promise<LearningProgressModel | null>;
  getLearningProgressWithDetails(userId: string): Promise<LearningProgressModel | null>; // Includes topics/words
  upsertLearningProgress(userId: string, data: Prisma.LearningProgressUncheckedCreateInput | Prisma.LearningProgressUpdateInput): Promise<LearningProgressModel>;
  upsertTopicProgress(learningProgressId: string, topicData: Prisma.TopicProgressUncheckedCreateInput | Prisma.TopicProgressUpdateInput): Promise<TopicProgressModel>;
  upsertWordProgress(learningProgressId: string, wordData: Prisma.WordProgressUncheckedCreateInput | Prisma.WordProgressUpdateInput): Promise<WordProgressModel>;
  getTopicProgress(learningProgressId: string, topicName: string): Promise<TopicProgressModel | null>;
  getWordProgress(learningProgressId: string, word: string): Promise<WordProgressModel | null>;
  getWordsByMastery(learningProgressId: string, masteryLevels: MasteryLevel[]): Promise<WordProgressModel[]>;
}

export class LearningProgressRepository implements ILearningProgressRepository {
  // If row-level security or user context from auth is needed, re-add it.

  constructor() {
    // Constructor can be empty or take Prisma client if not using global instance
  }

  async getLearningProgress(userId: string): Promise<LearningProgressModel | null> {
    try {
      const progress = await prisma.learningProgress.findUnique({
        where: { userId },
      });
      return progress as LearningProgressModel | null; // Cast needed if types differ slightly
    } catch (error) {
      logger.error('Error fetching learning progress:', { userId, error });
      throw error;
    }
  }

  async getLearningProgressWithDetails(userId: string): Promise<LearningProgressModel | null> {
    try {
      const progress = await prisma.learningProgress.findUnique({
        where: { userId },
        include: {
          topics: { orderBy: { updatedAt: 'desc' }, take: 20 }, // Limit included items
          words: { orderBy: { updatedAt: 'desc' }, take: 50 }, // Limit included items
        },
      });
      return progress as LearningProgressModel | null;
    } catch (error) {
      logger.error('Error fetching learning progress with details:', { userId, error });
      throw error;
    }
  }


  async upsertLearningProgress(userId: string, data: Prisma.LearningProgressUncheckedCreateInput | Prisma.LearningProgressUpdateInput): Promise<LearningProgressModel> {
    try {
      const progress = await prisma.learningProgress.upsert({
        where: { userId },
        update: data as Prisma.LearningProgressUpdateInput,
        create: {
          ...(data as Prisma.LearningProgressUncheckedCreateInput),
          userId // Ensure userId is always set in create
        }
      });
      return progress as LearningProgressModel;
    } catch (error) {
      logger.error('Error upserting learning progress:', { userId, data, error });
      throw error;
    }
  }

  async upsertTopicProgress(learningProgressId: string, topicData: Prisma.TopicProgressUncheckedCreateInput | Prisma.TopicProgressUpdateInput): Promise<TopicProgressModel> {
    const topicName = (topicData as any).topicName;
    if (!topicName) {
      throw new Error('topicName is required for upserting TopicProgress');
    }
    try {
      const { learningProgressId: _, ...cleanData } = topicData as any; // Exclude learningProgressId from spread
      const topicProgress = await prisma.topicProgress.upsert({
        where: { learningProgressId_topicName: { learningProgressId, topicName } },
        update: topicData as Prisma.TopicProgressUpdateInput,
        create: {
          ...cleanData,
          learningProgress: { connect: { id: learningProgressId } } // Use relation instead of direct ID
        } as unknown as Prisma.TopicProgressCreateInput
      });
      return topicProgress as TopicProgressModel;
    } catch (error) {
      logger.error('Error upserting topic progress:', { learningProgressId, topicData, error });
      throw error;
    }
  }

  async upsertWordProgress(learningProgressId: string, wordData: Prisma.WordProgressUncheckedCreateInput | Prisma.WordProgressUpdateInput): Promise<WordProgressModel> {
    const word = (wordData as any).word;
    if (!word) {
      throw new Error('word is required for upserting WordProgress');
    }
    try {
      const { learningProgressId: _, ...cleanData } = wordData as any; // Exclude learningProgressId from spread
      const wordProgress = await prisma.wordProgress.upsert({
        where: { learningProgressId_word: { learningProgressId, word } },
        update: wordData as Prisma.WordProgressUpdateInput,
        create: {
          ...cleanData,
          learningProgress: { connect: { id: learningProgressId } } // Use relation instead of direct ID
        } as unknown as Prisma.WordProgressCreateInput
      });
      return wordProgress as WordProgressModel;
    } catch (error) {
      logger.error('Error upserting word progress:', { learningProgressId, wordData, error });
      throw error;
    }
  }

  async getTopicProgress(learningProgressId: string, topicName: string): Promise<TopicProgressModel | null> {
    try {
      const topicProgress = await prisma.topicProgress.findUnique({
        where: { learningProgressId_topicName: { learningProgressId, topicName } },
      });
      return topicProgress as TopicProgressModel | null;
    } catch (error) {
      logger.error('Error fetching topic progress:', { learningProgressId, topicName, error });
      throw error;
    }
  }

  async getWordProgress(learningProgressId: string, word: string): Promise<WordProgressModel | null> {
    try {
      const wordProgress = await prisma.wordProgress.findUnique({
        where: { learningProgressId_word: { learningProgressId, word } },
      });
      return wordProgress as WordProgressModel | null;
    } catch (error) {
      logger.error('Error fetching word progress:', { learningProgressId, word, error });
      throw error;
    }
  }

  async getWordsByMastery(learningProgressId: string, masteryLevels: MasteryLevel[]): Promise<WordProgressModel[]> {
    try {
      const words = await prisma.wordProgress.findMany({
        where: {
          learningProgressId,
          masteryLevel: { in: masteryLevels },
        },
        orderBy: { lastReviewedAt: 'asc' }, // Prioritize words not reviewed recently
        take: 100, // Limit results
      });
      return words as WordProgressModel[];
    } catch (error) {
      logger.error('Error fetching words by mastery:', { learningProgressId, masteryLevels, error });
      throw error;
    }
  }
}
</file>

<file path="src/repositories/lesson.repository.ts">
import { ILessonRepository } from '@/lib/interfaces/all-interfaces'
import logger from '@/utils/logger'
import { LessonModel, LessonStep, OnboardingModel } from '@/models/AppAllModels.model'
import prisma from '@/lib/prisma'
import { createSupabaseServerClient } from '@/utils/supabase/server'
import { cookies } from 'next/headers'
import { SupabaseClient } from '@supabase/supabase-js'

export class LessonRepository implements ILessonRepository {
  private supabase: SupabaseClient | null = null

  constructor() {
    if (typeof window === 'undefined') {
      this.supabase = null
      this.getSupabaseClient = async () => {
        if (!this.supabase) {
          this.supabase = await createSupabaseServerClient() as SupabaseClient | null
        }
        return this.supabase
      }
    }
  }

  private getSupabaseClient?: () => Promise<SupabaseClient | null>

  async getSession() {
    if (typeof window === 'undefined' && this.getSupabaseClient) {
      const supabase = await this.getSupabaseClient()
      if (!supabase) {
        throw new Error('No auth service available')
      }
      const {
        data: { session },
        error,
      } = await supabase.auth.getSession()
      if (error || !session?.user?.id) {
        throw new Error('Unauthorized')
      }
      return session
    }
    throw new Error('No auth service available')
  }

  async getLessons(): Promise<LessonModel[]> {
    try {
      const session = await this.getSession()
      return await prisma.lesson.findMany({
        where: { userId: session.user.id },
        orderBy: { createdAt: 'desc' },
        include: { steps: true }
      })
    } catch (error) {
      logger.error('Error fetching lessons:', error)
      throw error
    }
  }

  async getLessonById(lessonId: string): Promise<LessonModel | null> {
    try {
      const session = await this.getSession()
      return await prisma.lesson.findUnique({
        where: { 
          id: lessonId,
          userId: session.user.id
        },
        include: { steps: true }
      })
    } catch (error) {
      logger.error('Error fetching lesson:', error)
      return null
    }
  }

  async createLesson(lessonData: {
    focusArea: string
    targetSkills: string[]
    steps: LessonStep[]
  }): Promise<LessonModel> {
    try {
      const session = await this.getSession()
      return await prisma.lesson.create({
        data: {
          userId: session.user.id,
          lessonId: `lesson-${Date.now()}`,
          focusArea: lessonData.focusArea,
          targetSkills: lessonData.targetSkills,
          steps: {
            create: lessonData.steps.map(step => ({
              stepNumber: step.stepNumber,
              type: step.type,
              content: step.content,
              translation: step.translation,
              attempts: step.attempts || 0,
              correct: step.correct || false,
              errorPatterns: step.errorPatterns || [],
              expectedAnswer: step.expectedAnswer || null,
              expectedAnswerAudioUrl: step.expectedAnswerAudioUrl || null,
              contentAudioUrl: step.contentAudioUrl || null
            }))
          },
          completed: false,
          createdAt: new Date(),
          updatedAt: new Date()
        },
        include: {
          steps: true
        }
      })
    } catch (error) {
      logger.error('Error creating lesson:', error)
      throw error
    }
  }

  async updateLesson(lessonId: string, lessonData: Partial<LessonModel>): Promise<LessonModel> {
    try {
      const session = await this.getSession()
      
      // Remove related fields from direct spread to handle them properly
      const { steps, audioMetrics, ...otherData } = lessonData
      
      // Prepare data object for update
      const data: any = {
        ...otherData,
        performanceMetrics: otherData.performanceMetrics ? 
          JSON.parse(JSON.stringify(otherData.performanceMetrics)) : 
          undefined,
      }
      
      // Handle steps relationship if provided
      if (steps) {
        data.steps = {
          deleteMany: {}, // Delete existing steps
          create: steps.map(step => ({
            stepNumber: step.stepNumber,
            type: step.type,
            content: step.content,
            translation: step.translation,
            attempts: step.attempts || 0,
            correct: step.correct || false,
            errorPatterns: step.errorPatterns || [],
            expectedAnswer: step.expectedAnswer || null,
            expectedAnswerAudioUrl: step.expectedAnswerAudioUrl || null,
            contentAudioUrl: step.contentAudioUrl || null
          }))
        }
      }
      
      // Handle audioMetrics relationship if provided
      if (audioMetrics) {
        data.audioMetrics = {
          upsert: {
            create: {
              // Required fields for creating new audio metrics
              pronunciationScore: audioMetrics.pronunciationScore,
              fluencyScore: audioMetrics.fluencyScore,
              grammarScore: audioMetrics.grammarScore,
              vocabularyScore: audioMetrics.vocabularyScore,
              overallPerformance: audioMetrics.overallPerformance,
              proficiencyLevel: audioMetrics.proficiencyLevel,
              learningTrajectory: audioMetrics.learningTrajectory,
              pronunciationAssessment: audioMetrics.pronunciationAssessment,
              fluencyAssessment: audioMetrics.fluencyAssessment,
              grammarAssessment: audioMetrics.grammarAssessment,
              vocabularyAssessment: audioMetrics.vocabularyAssessment,
              exerciseCompletion: audioMetrics.exerciseCompletion,
              suggestedTopics: audioMetrics.suggestedTopics,
              grammarFocusAreas: audioMetrics.grammarFocusAreas,
              vocabularyDomains: audioMetrics.vocabularyDomains,
              nextSkillTargets: audioMetrics.nextSkillTargets,
              preferredPatterns: audioMetrics.preferredPatterns,
              effectiveApproaches: audioMetrics.effectiveApproaches
            },
            update: {
              // Fields to update if audio metrics already exist
              pronunciationScore: audioMetrics.pronunciationScore,
              fluencyScore: audioMetrics.fluencyScore,
              grammarScore: audioMetrics.grammarScore,
              vocabularyScore: audioMetrics.vocabularyScore,
              overallPerformance: audioMetrics.overallPerformance,
              proficiencyLevel: audioMetrics.proficiencyLevel,
              learningTrajectory: audioMetrics.learningTrajectory,
              pronunciationAssessment: audioMetrics.pronunciationAssessment,
              fluencyAssessment: audioMetrics.fluencyAssessment,
              grammarAssessment: audioMetrics.grammarAssessment,
              vocabularyAssessment: audioMetrics.vocabularyAssessment,
              exerciseCompletion: audioMetrics.exerciseCompletion,
              suggestedTopics: audioMetrics.suggestedTopics,
              grammarFocusAreas: audioMetrics.grammarFocusAreas,
              vocabularyDomains: audioMetrics.vocabularyDomains,
              nextSkillTargets: audioMetrics.nextSkillTargets,
              preferredPatterns: audioMetrics.preferredPatterns,
              effectiveApproaches: audioMetrics.effectiveApproaches
            }
          }
        }
      }
      
      const updatedLesson = await prisma.lesson.update({
        where: { 
          id: lessonId,
          userId: session.user.id
        },
        data: data,
        include: { steps: true, audioMetrics: true }
      })
      
      return updatedLesson as LessonModel
    } catch (error) {
      logger.error('Error updating lesson:', error)
      throw error
    }
  }

  async completeLesson(lessonId: string, performanceMetrics?: {
    accuracy?: number
    pronunciationScore?: number
    errorPatterns?: string[]
  }): Promise<LessonModel> {
    try {
      const session = await this.getSession()
      return await prisma.lesson.update({
        where: { 
          id: lessonId,
          userId: session.user.id
        },
        data: { 
          completed: true,
          performanceMetrics
        },
        include: { steps: true }
      })
    } catch (error) {
      logger.error('Error completing lesson:', error)
      throw error
    }
  }

  async deleteLesson(lessonId: string): Promise<void> {
    try {
      const session = await this.getSession()
      await prisma.lesson.delete({
        where: { 
          id: lessonId,
          userId: session.user.id
        }
      })
    } catch (error) {
      logger.error('Error deleting lesson:', error)
      throw error
    }
  }

  async getStepHistory(lessonId: string, stepId: string): Promise<LessonStep[]> {
    return prisma.lessonStep.findMany({
      where: { lessonId, stepNumber: parseInt(stepId) }
    })
  }

  async recordStepAttempt(lessonId: string, stepId: string, data: {
    userResponse: string
    correct: boolean
  }): Promise<LessonStep> {
    // Convert stepId to number and find by stepNumber
    const stepNumber = parseInt(stepId)
    
    // First get the existing step to validate existence
    const existingStep = await prisma.lessonStep.findFirst({
      where: { 
        lessonId,
        id: stepId,
      }
    })

    if (!existingStep) {
      throw new Error(`Step ${stepNumber} not found in lesson ${lessonId}`)
    }
    logger.info('existingStep in repo', { existingStep })
    // 2. Get existing response history
    let responseHistory: string[] = [];
    try {
      responseHistory = existingStep.userResponseHistory
        ? JSON.parse(existingStep.userResponseHistory as string)
        : [];
    } catch (e) {
      logger.error('Error parsing response history', { error: e });
      responseHistory = [];
    }
    responseHistory.push(data.userResponse);
    // Update using the database ID from existing step
    return prisma.lessonStep.update({
      where: { 
        id: existingStep.id,
        lessonId 
      },
      data: {
        attempts: { increment: 1 },
        userResponse: data.userResponse,
        userResponseHistory: JSON.stringify(responseHistory),
        correct: data.correct,
        lastAttemptAt: new Date()
      }
    })
  }
}
</file>

<file path="src/repositories/onboarding.repository.ts">
import {
  OnboardingModel,
  AssessmentLesson,
  AssessmentStep,
  AudioMetrics,
  PronunciationAssessment,
  FluencyAssessment,
  GrammarAssessment,
  VocabularyAssessment,
  ExerciseCompletion,
} from '@/models/AppAllModels.model';
import { IOnboardingRepository } from '@/lib/interfaces/all-interfaces';
import logger from '@/utils/logger';
import prisma from '@/lib/prisma';
import { JsonValue } from 'type-fest';
import { PrismaClient, Prisma } from '@prisma/client';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import { cookies } from 'next/headers';
import { SupabaseClient } from '@supabase/supabase-js';

export class OnboardingRepository implements IOnboardingRepository {
  private supabase: SupabaseClient | null = null;

  constructor() {
    if (typeof window === 'undefined') {
      this.supabase = null;
      this.getSupabaseClient = async () => {
        if (!this.supabase) {
          this.supabase = await createSupabaseServerClient() as SupabaseClient | null;
        }
        return this.supabase;
      };
    }
  }

  private getSupabaseClient?: () => Promise<SupabaseClient | null>;

  async getSession() {
    if (typeof window === 'undefined' && this.getSupabaseClient) {
      const supabase = await this.getSupabaseClient();
      if (!supabase) {
        throw new Error('No auth service available')
      }
      const {
        data: { session },
        error,
      } = await supabase.auth.getSession();
      if (error || !session?.user?.id) {
        throw new Error('Unauthorized');
      }
      return session;
    }
    throw new Error('No auth service available');
  }

  async getOnboarding(): Promise<OnboardingModel | null> {
    try {
      const session = await this.getSession();
      return await prisma.onboarding.findUnique({
        where: { userId: session.user.id },
      });
    } catch (error) {
      logger.error('Error fetching onboarding:', error);
      return null;
    }
  }

  async createOnboarding(): Promise<OnboardingModel> {
    try {
      const session = await this.getSession();

      // Check if onboarding already exists
      const existingOnboarding = await prisma.onboarding.findUnique({
        where: { userId: session.user.id },
      });

      if (existingOnboarding) {
        return existingOnboarding;
      }

      return await prisma.onboarding.create({
        data: {
          userId: session.user.id,
          steps: {},
          completed: false,
        },
      });
    } catch (error) {
      logger.error('Error creating onboarding:', error);
      throw error;
    }
  }

  async updateOnboarding(step: string, formData: any): Promise<OnboardingModel> {
    try {
      const session = await this.getSession();
      const onboarding = await prisma.onboarding.findUnique({
        where: { userId: session.user.id },
      });

      if (!onboarding) {
        throw new Error('Onboarding not found');
      }

      const steps = onboarding.steps as { [key: string]: boolean };
      steps[step] = true;

      // Only update fields that are present in formData
      const updateData: any = {
        steps: steps,
        ...(formData?.nativeLanguage && { nativeLanguage: formData.nativeLanguage }),
        ...(formData?.targetLanguage && { targetLanguage: formData.targetLanguage }),
        ...(formData?.learningPurpose && { learningPurpose: formData.learningPurpose }),
        ...(formData?.proficiencyLevel && { proficiencyLevel: formData.proficiencyLevel }),
      };

      return await prisma.onboarding.update({
        where: { userId: session.user.id },
        data: updateData
      });
    } catch (error) {
      logger.error('Error updating onboarding:', error);
      throw error;
    }
  }

  async completeOnboarding(): Promise<OnboardingModel> {
    try {
      const session = await this.getSession();
      return await prisma.onboarding.update({
        where: { userId: session.user.id },
        data: {
          completed: true,
          createdAt: new Date(),
          updatedAt: new Date(),
          initialAssessmentCompleted: true,
        },
      });
    } catch (error) {
      logger.error('Error completing onboarding:', error);
      throw error;
    }
  }

  async deleteOnboarding(): Promise<void> {
    try {
      const session = await this.getSession();
      await prisma.onboarding.delete({
        where: { userId: session.user.id },
      });
    } catch (error) {
      logger.error('Error deleting onboarding:', error);
      throw error;
    }
  }

  async getStatus(): Promise<boolean> {
    const onboarding = await this.getOnboarding();
    return onboarding?.completed ?? false;
  }

  async getUserAssessment(): Promise<AssessmentLesson | null> {
    try {
      const session = await this.getSession();
      return await prisma.assessmentLesson.findFirst({
        where: {
          userId: session.user.id,
          completed: false,
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error fetching user assessment:', error);
      throw error;
    }
  }

  async getAssessmentLesson(): Promise<AssessmentLesson | null> {
    try {
      // Validate the user has permission to access this data
      const session = await this.getSession();
      if (!session.user.id) {
        throw new Error('Unauthorized');
      }

      return await prisma.assessmentLesson.findUnique({
        where: { userId: session.user.id },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error fetching assessment lessons:', error);
      return null;
    }
  }
  async getAssessmentLessonById(
    lessonId: string
  ): Promise<AssessmentLesson | null> {
    try {
      // Validate the user has permission to access this data
      const session = await this.getSession();
      if (!session.user.id) {
        throw new Error('Unauthorized');
      }

      return await prisma.assessmentLesson.findUnique({
        where: { id: lessonId },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error fetching assessment lessons:', error);
      return null;
    }
  }

  async completeAssessmentLesson(
    assessment: AssessmentLesson,
    data: {
      summary: string;
      metrics: any;
      proposedTopics: string[];
    }
  ): Promise<AssessmentLesson> {
    try {
      if (!assessment) {
        throw new Error('Assessment lesson not found or unauthorized');
      }

      // Mark the assessment as completed
      return await prisma.assessmentLesson.update({
        where: { id: assessment.id },
        data: {
          completed: true,
          summary: data.summary,
          metrics: data.metrics,
          proposedTopics: data.proposedTopics,
          updatedAt: new Date(),
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error completing assessment lesson:', error);
      throw error;
    }
  }

  async createUserAssessment(
    sourceLanguage: string,
    targetLanguage: string
  ): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();

      // Check if assessment already exists
      const existingAssessment = await prisma.assessmentLesson.findUnique({
        where: { userId: session.user.id },
        include: {
          steps: true,
        },
      });

      if (existingAssessment) {
        return existingAssessment;
      }

      // Create new assessment
      return await prisma.assessmentLesson.create({
        data: {
          userId: session.user.id,
          description: `${targetLanguage} language assessment`,
          completed: false,
          sourceLanguage,
          targetLanguage,
          metrics: {
            accuracy: 0,
            pronunciationScore: 0,
            grammarScore: 0,
            vocabularyScore: 0,
            overallScore: 0,
            strengths: [],
            weaknesses: [],
          },
          proposedTopics: [],
          steps: {
            create: [], // Steps will be added separately
          },
        },
        include: {
          steps: true,
        },
      });
    } catch (error) {
      logger.error('Error creating user assessment:', error);
      throw error;
    }
  }

  async createAssessmentLesson(
    userId: string,
    assessment: Omit<AssessmentLesson, 'id' | 'createdAt' | 'updatedAt'>
  ): Promise<AssessmentLesson> {
    try {
      // First create the assessment lesson
      const createdAssessment = await prisma.assessmentLesson.create({
        data: {
          userId,
          description: assessment.description,
          completed: assessment.completed,
          sourceLanguage: assessment.sourceLanguage,
          targetLanguage: assessment.targetLanguage,
          metrics: assessment.metrics as any, // Type cast to handle Prisma JSON type
          proposedTopics: assessment.proposedTopics,
          summary: assessment.summary,
        },
      });

      // Then create all the steps associated with it
      const createdSteps = await Promise.all(
        assessment.steps.map((step) =>
          prisma.assessmentStep.create({
            data: {
              assessmentId: createdAssessment.id,
              stepNumber: step.stepNumber,
              type: step.type,
              content: step.content,
              contentAudioUrl: step.contentAudioUrl,
              translation: step.translation,
              expectedAnswer: step.expectedAnswer,
              expectedAnswerAudioUrl: step.expectedAnswerAudioUrl,
              maxAttempts: step.maxAttempts || 3,
              attempts: step.attempts || 0,
              correct: step.correct || false,
              feedback: step.feedback,
            },
          })
        )
      );

      // Return the assessment with its steps
      return {
        ...createdAssessment,
        steps: createdSteps,
      };
    } catch (error) {
      logger.error('Error creating assessment lesson:', error);
      throw error;
    }
  }

  async getAssessmentById(id: string): Promise<AssessmentLesson | null> {
    try {
      return await prisma.assessmentLesson.findUnique({
        where: { id },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error(`Error fetching assessment with id ${id}:`, error);
      throw error;
    }
  }

  async completeAssessment(): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();
      const result = await prisma.assessmentLesson.update({
        where: { userId: session.user.id },
        data: {
          completed: true,
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });

      // Also update onboarding to mark assessment as completed
      await prisma.onboarding.update({
        where: { userId: session.user.id },
        data: {
          initialAssessmentCompleted: true,
        },
      });

      return result;
    } catch (error) {
      logger.error('Error completing assessment:', error);
      throw error;
    }
  }

  async completeAssessmentStep(
    stepId: string,
    userResponse: string,
    correct: boolean
  ): Promise<AssessmentStep> {
    try {
      const step = await prisma.assessmentStep.findUnique({
        where: { id: stepId },
      });

      if (!step) {
        throw new Error('Assessment step not found');
      }

      return await prisma.assessmentStep.update({
        where: { id: stepId },
        data: {
          userResponse,
          attempts: { increment: 1 },
          correct,
          lastAttemptAt: new Date(),
        },
      });
    } catch (error) {
      logger.error('Error completing assessment step:', error);
      throw error;
    }
  }

  async updateAssessmentMetrics(metrics: {
    accuracy?: number;
    pronunciationScore?: number;
    grammarScore?: number;
    vocabularyScore?: number;
    overallScore?: number;
    strengths?: string[];
    weaknesses?: string[];
  }): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();
      return await prisma.assessmentLesson.update({
        where: { userId: session.user.id },
        data: {
          metrics,
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error updating assessment metrics:', error);
      throw error;
    }
  }

  async updateProposedTopics(topics: string[]): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();
      return await prisma.assessmentLesson.update({
        where: { userId: session.user.id },
        data: {
          proposedTopics: topics,
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error updating proposed topics:', error);
      throw error;
    }
  }

  async updateAssessmentSummary(summary: string): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();
      return await prisma.assessmentLesson.update({
        where: { userId: session.user.id },
        data: {
          summary,
        },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
        },
      });
    } catch (error) {
      logger.error('Error updating assessment summary:', error);
      throw error;
    }
  }

  async addAssessmentStep(step: {
    stepNumber: number;
    type: any; // Using any for simplicity, but should match AssessmentStepType
    content: string;
    contentAudioUrl?: string;
    translation?: string;
    expectedAnswer?: string;
    expectedAnswerAudioUrl?: string;
    maxAttempts?: number;
    feedback?: string;
  }): Promise<AssessmentStep> {
    try {
      const session = await this.getSession();
      const assessment = await prisma.assessmentLesson.findUnique({
        where: { userId: session.user.id },
      });

      if (!assessment) {
        throw new Error('Assessment not found');
      }

      return await prisma.assessmentStep.create({
        data: {
          assessmentId: assessment.id,
          stepNumber: step.stepNumber,
          type: step.type,
          content: step.content,
          contentAudioUrl: step.contentAudioUrl,
          translation: step.translation,
          expectedAnswer: step.expectedAnswer,
          expectedAnswerAudioUrl: step.expectedAnswerAudioUrl,
          maxAttempts: step.maxAttempts || 3,
          feedback: step.feedback,
          attempts: 0,
          correct: false,
        },
      });
    } catch (error) {
      logger.error('Error adding assessment step:', error);
      throw error;
    }
  }

  async updateStepFeedback(
    stepId: string,
    feedback: string
  ): Promise<AssessmentStep> {
    try {
      return await prisma.assessmentStep.update({
        where: { id: stepId },
        data: {
          feedback,
        },
      });
    } catch (error) {
      logger.error('Error updating step feedback:', error);
      throw error;
    }
  }

  async getNextIncompleteStep(): Promise<AssessmentStep | null> {
    try {
      const session = await this.getSession();
      const assessment = await prisma.assessmentLesson.findUnique({
        where: { userId: session.user.id },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
            where: {
              correct: false,
            },
          },
        },
      });

      if (!assessment || assessment.steps.length === 0) {
        return null;
      }

      return assessment.steps[0];
    } catch (error) {
      logger.error('Error getting next incomplete step:', error);
      throw error;
    }
  }

  async recordStepAttempt(
    lessonId: string,
    stepId: string,
    data: {
      userResponse: string;
      correct: boolean;
    }
  ): Promise<AssessmentStep> {
    try {
      const session = await this.getSession();

      // First verify this assessment belongs to the current user
      const assessment = await prisma.assessmentLesson.findFirst({
        where: {
          id: lessonId,
          userId: session.user.id,
        },
        include: {
          steps: true,
        },
      });

      if (!assessment) {
        throw new Error('Assessment lesson not found or unauthorized');
      }

      // Find the step
      const step = assessment.steps.find((s) => s.id === stepId);
      if (!step) {
        throw new Error('Step not found in the assessment');
      }
      logger.info('existingStep in repo', { step })
      // 2. Get existing response history
      let responseHistory: string[] = [];
      try {
        responseHistory = step.userResponseHistory
          ? JSON.parse(step.userResponseHistory as string)
          : [];
      } catch (e) {
        logger.error('Error parsing response history', { error: e });
        responseHistory = [];
      }
      responseHistory.push(data.userResponse);

      // Update the step with the attempt data
      return await prisma.assessmentStep.update({
        where: { id: stepId },
        data: {
          userResponse: data.userResponse,
          userResponseHistory: JSON.stringify(responseHistory),
          attempts: { increment: 1 },
          correct: data.correct,
          lastAttemptAt: new Date(),
        },
      });
    } catch (error) {
      logger.error('Error recording assessment step attempt:', error);
      throw error;
    }
  }

  async updateOnboardingAssessmentLesson(lessonId: string, lessonData: Partial<AssessmentLesson>): Promise<AssessmentLesson> {
    try {
      const session = await this.getSession();

      // First verify this assessment belongs to the current user
      const assessment = await prisma.assessmentLesson.findUnique({
        where: { id: lessonId },
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
          audioMetrics: true
        },
      });

      if (!assessment) {
        throw new Error('Assessment lesson not found');
      }

      if (assessment.userId !== session.user.id) {
        throw new Error('Unauthorized: You cannot update this assessment');
      }

      // Extract the data to update
      const dataToUpdate: any = {};
      
      // Only include fields that are allowed to be updated
      if (lessonData.completed !== undefined) dataToUpdate.completed = lessonData.completed;
      if (lessonData.description !== undefined) dataToUpdate.description = lessonData.description;
      if (lessonData.sourceLanguage !== undefined) dataToUpdate.sourceLanguage = lessonData.sourceLanguage;
      if (lessonData.targetLanguage !== undefined) dataToUpdate.targetLanguage = lessonData.targetLanguage;
      if (lessonData.metrics !== undefined) dataToUpdate.metrics = lessonData.metrics;
      if (lessonData.proposedTopics !== undefined) dataToUpdate.proposedTopics = lessonData.proposedTopics;
      if (lessonData.summary !== undefined) dataToUpdate.summary = lessonData.summary;
      if (lessonData.sessionRecordingUrl !== undefined) dataToUpdate.sessionRecordingUrl = lessonData.sessionRecordingUrl;

      // Handle audio metrics separately if included in the update
      if (lessonData.audioMetrics) {
        await this.updateAssessmentAudioMetrics(lessonId, assessment.audioMetrics, lessonData.audioMetrics);
      }

      // Update the assessment lesson
      const updatedAssessment = await prisma.assessmentLesson.update({
        where: { id: lessonId },
        data: dataToUpdate,
        include: {
          steps: {
            orderBy: {
              stepNumber: 'asc',
            },
          },
          audioMetrics: true
        },
      });
      
      // Transform to application model
      return this.mapPrismaAssessmentToAppModel(updatedAssessment);
    } catch (error) {
      logger.error('Error updating assessment lesson:', error);
      throw error;
    }
  }

  /**
   * Update or create audio metrics for an assessment lesson
   */
  private async updateAssessmentAudioMetrics(
    lessonId: string, 
    existingMetrics: any | null,
    newMetrics: AudioMetrics
  ): Promise<void> {
    try {
      // Create data object for Prisma with proper JSON handling
      const metricsData = {
        pronunciationScore: newMetrics.pronunciationScore,
        fluencyScore: newMetrics.fluencyScore,
        grammarScore: newMetrics.grammarScore,
        vocabularyScore: newMetrics.vocabularyScore,
        overallPerformance: newMetrics.overallPerformance,
        proficiencyLevel: newMetrics.proficiencyLevel,
        learningTrajectory: newMetrics.learningTrajectory,
        // Convert complex objects to JSON for storage
        pronunciationAssessment: newMetrics.pronunciationAssessment as unknown as Prisma.InputJsonValue,
        fluencyAssessment: newMetrics.fluencyAssessment as unknown as Prisma.InputJsonValue,
        grammarAssessment: newMetrics.grammarAssessment as unknown as Prisma.InputJsonValue,
        vocabularyAssessment: newMetrics.vocabularyAssessment as unknown as Prisma.InputJsonValue,
        exerciseCompletion: newMetrics.exerciseCompletion as unknown as Prisma.InputJsonValue,
        // Arrays
        suggestedTopics: newMetrics.suggestedTopics,
        grammarFocusAreas: newMetrics.grammarFocusAreas,
        vocabularyDomains: newMetrics.vocabularyDomains,
        nextSkillTargets: newMetrics.nextSkillTargets,
        preferredPatterns: newMetrics.preferredPatterns,
        effectiveApproaches: newMetrics.effectiveApproaches,
        // Optional fields
        audioRecordingUrl: newMetrics.audioRecordingUrl,
        recordingDuration: newMetrics.recordingDuration,
      };

      // If audio metrics already exist, update them
      if (existingMetrics) {
        await prisma.audioMetrics.update({
          where: { id: existingMetrics.id },
          data: metricsData
        });
      } 
      // If audio metrics don't exist, create them
      else {
        await prisma.audioMetrics.create({
          data: {
            ...metricsData,
            // Link to the assessment lesson
            assessmentLesson: {
              connect: { id: lessonId }
            }
          }
        });
      }
    } catch (error) {
      logger.error('Error updating audio metrics:', error);
      throw error;
    }
  }

  /**
   * Maps Prisma assessment model to application model with proper type handling
   */
  private mapPrismaAssessmentToAppModel(assessment: any): AssessmentLesson {
    // Handle the case where audioMetrics is null
    let audioMetricsModel = null;
    
    if (assessment.audioMetrics) {
      // Transform JSON fields to their typed counterparts
      audioMetricsModel = {
        ...assessment.audioMetrics,
        // Type cast JSON fields to their strongly-typed interfaces
        pronunciationAssessment: assessment.audioMetrics.pronunciationAssessment as unknown as PronunciationAssessment,
        fluencyAssessment: assessment.audioMetrics.fluencyAssessment as unknown as FluencyAssessment,
        grammarAssessment: assessment.audioMetrics.grammarAssessment as unknown as GrammarAssessment,
        vocabularyAssessment: assessment.audioMetrics.vocabularyAssessment as unknown as VocabularyAssessment,
        exerciseCompletion: assessment.audioMetrics.exerciseCompletion as unknown as ExerciseCompletion,
      };
    }
    
    // Return the properly typed model
    return {
      ...assessment,
      audioMetrics: audioMetricsModel,
    } as AssessmentLesson;  // Explicitly cast the entire result
  }
}
</file>

<file path="src/services/generators/apiKeyGenerator.ts">
class ApiKeyGenerator {
  private static instance: ApiKeyGenerator;
  private apiKeys: string[] = [];
  private currentIndex: number = 0;
  
  private constructor() {
    this.instantiateApiKeys();
  }

  public static getInstance(): ApiKeyGenerator {
    if (!ApiKeyGenerator.instance) {
      ApiKeyGenerator.instance = new ApiKeyGenerator();
    }
    return ApiKeyGenerator.instance;
  }

  public getApiKey(): string {
    return this.getNextApiKey();
  }

  private instantiateApiKeys(): void {
    let index = 1;
    while (process.env[`AI_API_KEY_${index}`]) {
      this.apiKeys.push(process.env[`AI_API_KEY_${index}`] as string);
      index++;
    }
  }

  private getNextApiKey(): string {
    const currentApiKey = this.apiKeys[this.currentIndex];
    const apiKeysLength = this.apiKeys.length;
    this.currentIndex = (this.currentIndex + 1) % apiKeysLength;

    return currentApiKey;
  }

}

export default ApiKeyGenerator;
</file>

<file path="src/services/generators/messageGenerator.ts">
import { AssessmentLesson, LessonModel } from "@/models/AppAllModels.model";
import { LanguageDetectionResponse } from "@/models/Language-detection.model";


class MessageGenerator {
  constructor() { }
 

  public generateTargetLanguageDetectionPrompt(): {
    userPrompt: string;
    systemPrompt: string;
  } {
    const userMessage = this.generateLanguageDetectionUserMessage();
    const systemMessage = this.generateLanguageDetectionSystemMessage();
    return {
      userPrompt: userMessage,
      systemPrompt: systemMessage
    }
  }

  public generatePersonalizedPrompts(detectedLanguage: LanguageDetectionResponse, isDeepAnalysis: boolean): {
    userPrompt: string;
    systemPrompt: string;
  } {
    const { userMessage, systemMessage } = this.getPromptsBasedOnLanguageAndAnalysis(detectedLanguage, isDeepAnalysis);

    return {
      userPrompt: userMessage,
      systemPrompt: systemMessage
    }
  }


  // TODO: finish the generation of prompts for lesson recording analysis
  public generateLessonRecordingAnalysisPrompts
  (targetLanguage: string, nativeLanguage: string, lessonData: LessonModel | AssessmentLesson): {
    userPrompt: string;
      systemPrompt: string;
  } {
    const userMessage = this.generateLessonRecordingUserPrompt(targetLanguage, nativeLanguage, lessonData)
    const systemMessage = this.generateLessonRecordingSystemPrompt(targetLanguage, nativeLanguage, lessonData)

    return {
      userPrompt: userMessage,
      systemPrompt: systemMessage
    }
  }
  private generateLessonRecordingUserPrompt(targetLanguage: string, nativeLanguage: string, lessonData: LessonModel | AssessmentLesson): string {
    // Extract lesson specifics to focus the analysis
    const lessonType = 'id' in lessonData && 'lessonId' in lessonData ? 'practice lesson' : 'assessment';
    const focusArea = 'focusArea' in lessonData ? lessonData.focusArea : '';
    const targetSkills = 'targetSkills' in lessonData ? lessonData.targetSkills.join(', ') : '';
    
    const specificInstructions = lessonType === 'assessment' 
      ? `This is an assessment to evaluate the learner's overall language proficiency.` 
      : `This is a practice lesson focused on "${focusArea}" targeting: ${targetSkills}.`;
    
    return `
      Analyze this ${targetLanguage} language recording from a ${lessonType}. ${specificInstructions}
      
      The user's native language is ${nativeLanguage}. Provide a comprehensive analysis including:
      
      1. Pronunciation accuracy assessment:
         - Phoneme-level analysis with specific examples
         - Accent characteristics and influence of ${nativeLanguage}
         - Key pronunciation patterns or errors that need attention
      
      2. Fluency and rhythm evaluation:
         - Speech rate and natural flow
         - Hesitations and pausing patterns
         - Intonation and stress placement accuracy
      
      3. Grammar and structure analysis:
         - Grammatical patterns and errors
         - Common mistakes related to ${nativeLanguage} interference
         - ${lessonType === 'practice lesson' ? 'Progress on targeted grammar points from the lesson' : 'Overall grammar proficiency assessment'}
      
      4. Vocabulary usage:
         - Appropriateness and accuracy of vocabulary
         - Range and diversity relative to ${lessonType === 'practice lesson' ? 'the lesson topic' : 'expected proficiency level'}
         - Word choice precision and naturalness
      
      5. Task completion assessment:
         - How well the user completed the ${lessonType === 'practice lesson' ? 'practice exercises' : 'assessment questions'}
         - Comprehension of instructions and questions
         - Appropriateness of responses to prompts
      
      6. Detailed metrics and scoring (0-100 scale):
         - Pronunciation score
         - Fluency score
         - Grammar accuracy
         - Vocabulary appropriateness
         - Overall performance
      
      7. Learning progression insights:
         - ${lessonType === 'practice lesson' ? '3-5 suggested topics that build on this lesson' : '3-5 recommended focus areas based on this assessment'}
         - Specific grammar rules that need further practice
         - Vocabulary domains to expand
         - Next skill targets for improvement
      
      8. Personalized learning strategy:
         - Patterns in learning style observed
         - Most effective practice approaches for this learner
         - Estimated proficiency level (CEFR: A1-C2)
         - Prioritized improvement plan
      
      Format your analysis in clear, structured JSON according to the specified format.
    `;
  }

  private generateLessonRecordingSystemPrompt(targetLanguage: string, nativeLanguage: string, lessonData: LessonModel | AssessmentLesson): string {
    // Extract expected answers to compare against
    const lessonSteps = lessonData.steps;
    const isAssessment = !('lessonId' in lessonData);
    
    // Extract different types of exercises to better focus the analysis
    const expectedAnswers = lessonSteps
      .filter(step => step.expectedAnswer)
      .map(step => {
        const stepType = 'type' in step ? 
          (step.type as string) : 
          (isAssessment ? 'question' : 'prompt');
        
        return {
          type: stepType,
          prompt: step.content || '',
          expected: step.expectedAnswer || '',
          translation: step.translation || null
        };
      });
    
    const previousMetrics = 'performanceMetrics' in lessonData && lessonData.performanceMetrics 
      ? JSON.stringify(lessonData.performanceMetrics) 
      : null;
    
    return `
      You are Dr. Sarah Chen-Martinez, PhD in Applied Linguistics and Phonetics from Cambridge University,
      with 20 years of expertise in language acquisition, pronunciation training, and adaptive learning technologies.
      
      Your task is to analyze this ${targetLanguage} language recording from a learner whose native language is ${nativeLanguage}.
      ${isAssessment ? 'This is an assessment to evaluate the learner\'s overall language proficiency.' : 
        'This is a practice lesson focused on specific skills and topics.'}
      
      Expected exercises in this ${isAssessment ? 'assessment' : 'lesson'} included:
      ${JSON.stringify(expectedAnswers, null, 2)}
      
      ${previousMetrics ? `Previous performance metrics:\n${previousMetrics}` : ''}
      
      Provide your analysis as a valid JSON object with the following structure:
      
      \`\`\`json
      {
        "pronunciation_assessment": {
          "overall_score": number (0-100),
          "native_language_influence": {
            "level": "string (minimal|moderate|strong)",
            "specific_features": ["array of string descriptions"]
          },
          "phoneme_analysis": [
            {
              "phoneme": "string (IPA symbol)",
              "target_realization": "string (IPA for standard ${targetLanguage})",
              "user_realization": "string (IPA for user's pronunciation)",
              "accuracy": number (0-100),
              "examples": ["array of words/phrases from the recording"]
            }
          ],
          "problematic_sounds": ["array of IPA symbols"],
          "strengths": ["array of string descriptions"],
          "areas_for_improvement": ["array of string descriptions"]
        },
        "fluency_assessment": {
          "overall_score": number (0-100),
          "speech_rate": {
            "words_per_minute": number,
            "evaluation": "string (slow|appropriate|fast)"
          },
          "hesitation_patterns": {
            "frequency": "string (rare|occasional|frequent)",
            "average_pause_duration": number (seconds),
            "typical_contexts": ["array of string descriptions"]
          },
          "rhythm_and_intonation": {
            "naturalness": number (0-100),
            "sentence_stress_accuracy": number (0-100),
            "intonation_pattern_accuracy": number (0-100)
          }
        },
        "grammar_assessment": {
          "overall_score": number (0-100),
          "error_patterns": [
            {
              "category": "string (e.g., verb tense, word order)",
              "description": "string",
              "examples": ["array of examples from recording"],
              "frequency": "string (rare|occasional|frequent)",
              "severity": "string (minor|moderate|major)"
            }
          ],
          "grammar_rules_to_review": [
            {
              "rule": "string",
              "priority": "string (high|medium|low)",
              "examples": ["array of examples"]
            }
          ],
          "grammar_strengths": ["array of string descriptions"]
        },
        "vocabulary_assessment": {
          "overall_score": number (0-100),
          "range": "string (limited|adequate|extensive)",
          "appropriateness": number (0-100),
          "precision": number (0-100),
          "areas_for_expansion": [
            {
              "topic": "string",
              "suggested_vocabulary": ["array of words/phrases"]
            }
          ]
        },
        "exercise_completion": {
          "overall_score": number (0-100),
          "exercises_analyzed": [
            {
              "prompt": "string (the exercise/question)",
              "expected_answer": "string",
              "user_response": "string (what was detected in audio)",
              "accuracy": number (0-100),
              "error_analysis": "string (if applicable)"
            }
          ],
          "comprehension_level": "string (excellent|good|fair|poor)"
        },
        "performance_metrics": {
          "pronunciation_score": number (0-100),
          "fluency_score": number (0-100),
          "grammar_accuracy": number (0-100),
          "vocabulary_score": number (0-100),
          "overall_performance": number (0-100),
          "strengths": ["array of string descriptions"],
          "weaknesses": ["array of string descriptions"]
        },
        "adaptive_learning_suggestions": {
          "suggested_topics": ["array of 3-5 topics for future lessons"],
          "grammar_focus_areas": ["array of grammar rules to practice"],
          "vocabulary_domains": ["array of vocabulary areas to expand"],
          "next_skill_targets": ["array of skills to focus on next"],
          "learning_style_observations": {
            "preferred_patterns": ["array of observed learning patterns"],
            "effective_approaches": ["array of approaches that seem effective for this learner"]
          }
        },
        "progress_tracking": {
          "improvement_since_last_assessment": ${previousMetrics ? "\"string assessment of improvement\"" : "null"},
          "learning_trajectory": "string (steady|accelerating|plateauing)",
          "estimated_proficiency_level": "string (CEFR level: A1|A2|B1|B2|C1|C2)",
          "time_to_next_level_estimate": "string"
        }
      }
      \`\`\`
      
      Important guidelines:
      1. Base all assessments on concrete evidence from the audio recording
      2. Compare user's responses against the expected answers provided
      3. Be specific and actionable in your feedback
      4. Use IPA symbols for phonetic transcriptions
      5. Include examples from the user's speech when possible
      6. For practice lessons, focus more on the specific skills being targeted
      7. For assessments, provide a broader evaluation of overall proficiency
      8. Ensure the JSON is valid and properly formatted
      
      Your analysis will directly inform this learner's personalized curriculum, so your detailed assessment is crucial for their language learning journey.
    `;
  }



  

  private getPromptsBasedOnLanguageAndAnalysis(detectedLanguage: LanguageDetectionResponse, isDeepAnalysis: boolean): {
    userMessage: string;
    systemMessage: string;
  } {
    let userMessage
    let systemMessage
    if (isDeepAnalysis) {
      userMessage = this.generateDetailedAccentAnalysisPrompt(detectedLanguage.language);
      systemMessage = this.generateDetailedAccentAnalysisInstruction(detectedLanguage.language);
    } else {
      userMessage = this.generateBasicUserMessage(detectedLanguage.language);
      systemMessage = this.generateBasicSystemMessage(detectedLanguage.language);
    }
    return {
      userMessage,
      systemMessage
    };
  }


  private generateLanguageDetectionUserMessage(): string {
    return `
      Please identify the language being spoken in the provided audio sample.
      Focus only on language identification with high accuracy.
      Return your analysis in the specified JSON format.
    `;
  }

  private generateLanguageDetectionSystemMessage(): string {
    return `
      You are Dr. Lessay, PhD in Applied Linguistics from Cambridge University with 15 years experience 
      in language identification and phonological analysis. Your expertise covers over 100 languages and their
      regional variants. Your task is to identify the language in the provided audio sample with high accuracy.

      Analyze the phonological patterns, prosody, and distinctive features of the speech to identify the language.
      
      Respond ONLY with a valid JSON object using this exact structure:
      \`\`\`json
      {
        "language": "Name of identified language",
        "confidence": "Confidence level (0-100)",
        "possible_alternatives": ["Alternative language 1", "Alternative language 2"],
        "language_family": "Indo-European/Sino-Tibetan/etc"
      }
      \`\`\`

      Do not include any additional text, explanations, or notes outside of the JSON object.
      Ensure the JSON is valid and properly formatted.
    `;
  }


  private generateBasicUserMessage(analysisLanguage: string): string {
    return `
      Please analyze this spoken ${analysisLanguage} sample and provide feedback:
  
      Your analysis should focus on:
      1. Accent identification within ${analysisLanguage} (regional accent or non-native accent)
      2. Confidence level in accent identification (%)
      3. Probable native language/region of the speaker based on accent characteristics
      4. Accent characteristics specific to this speaker's ${analysisLanguage}:
         - Vowel and consonant pronunciation patterns
         - Intonation and rhythm deviations from standard ${analysisLanguage}
         - Influence of speaker's probable native language
      5. 2-3 most noticeable accent markers in speaker's ${analysisLanguage}
      6. Suggested focus areas for improving ${analysisLanguage} pronunciation
      
      Use direct speech.
      Format response in clear sections with linguistic terminology explained in parentheses.
    `;
  }

  private generateBasicSystemMessage(analysisLanguage: string): string {
    return `
      You are Dr. Sarah Chen-Martinez, PhD in Applied Linguistics from Cambridge University with 15 years experience 
      in ${analysisLanguage} speech analysis and accent coaching. Your expertise spans all regional and non-native 
      accents of ${analysisLanguage}, including detailed knowledge of phonetic variations, prosodic features, 
      and common pronunciation patterns from speakers of different linguistic backgrounds.
      
      Your task is to analyze this ${analysisLanguage} speech sample, identify the speaker's accent characteristics, 
      determine their likely linguistic background, and provide feedback in JSON format.
  
      Follow this JSON structure:
      \`\`\`json
        {
          "language_analyzed": "${analysisLanguage}",
          "analyzed_language_code": "BCP-47 code (e.g. en-US, de-DE, zh-CN) of ${analysisLanguage}",
          "accent_identification": {
            "accent_type": "Regional or Non-native accent classification",
            "specific_accent": "Detailed accent identification (e.g., Indian English, Mexican Spanish)",
            "confidence_level": "Confidence Level (%)",
            "accent_strength": "Mild/Moderate/Strong"
          },
          "speaker_background": {
            "probable_native_language": "User's probable native language",
            "probable_region": "User's probable region/country",
            "confidence": "Confidence level (%)",
            "supporting_evidence": "Specific accent features supporting this conclusion"
          },
          "language_specific_phonological_assessment": [
            {
              "phoneme": "Specific ${analysisLanguage} phoneme",
              "example": "Example word",
              "analysis": "Analysis of the phoneme pronunciation",
              "IPA_target": "IPA target for standard ${analysisLanguage}",
              "IPA_observed": "IPA observed in speaker"
            }
          ],
          "suprasegmental_features_analysis": [
            {
              "feature": "Rhythm/Intonation/Stress",
              "observation": "Observation of feature in speaker's ${analysisLanguage}",
              "comparison": "Comparison to standard ${analysisLanguage}"
            }
          ],
          "diagnostic_accent_markers": [
            {
              "feature": "Specific accent marker",
              "description": "Description of the feature",
              "association": "Language/region this feature is associated with"
            }
          ],
          "proficiency_assessment": {
            "intelligibility": "Rating of ${analysisLanguage} intelligibility (0-100)",
            "fluency": "Rating of ${analysisLanguage} fluency (0-100)",
            "CEFR_level": "Estimated pronunciation proficiency level"
          },
          "improvement_suggestions": [
            {
              "focus_area": "Specific area to improve",
              "importance": "High/Medium/Low",
              "exercises": ["Suggested exercises"]
            }
          ]
        }
      \`\`\`
  
      Ensure the response is a valid JSON containing a single object with the above fields, and that all feedback is expressed in direct speech.
    `;
  }


  private generateDetailedAccentAnalysisPrompt(analysisLanguage: string): string {
    return `
      Perform a detailed linguistic analysis of this ${analysisLanguage} speech sample, focusing on accent identification and characteristics.
      
      Your analysis should cover:
  
      1. **Accent Identification and Classification:**
         - Precise identification of speaker's ${analysisLanguage} accent (regional or non-native)
         - Confidence assessment of accent classification
         - Accent strength and consistency evaluation
         - Probable native language/region and supporting evidence
  
      2. **Detailed Phonetic Analysis:**
         - Individual ${analysisLanguage} phoneme articulation patterns
         - ${analysisLanguage} vowel quality and placement compared to standard pronunciation
         - ${analysisLanguage} consonant production and modifications
         - Sound substitutions and adaptations characteristic of specific accents
         - Precise IPA transcriptions of notable examples, comparing standard vs. observed pronunciation
  
      3. **Prosodic Features:**
         - ${analysisLanguage} speech rhythm and timing patterns
         - Stress placement at word and sentence level
         - ${analysisLanguage} intonation contours and pitch patterns
         - Voice quality characteristics 
         - Speaking rate and fluency markers
  
      4. **Accent Markers and Native Language Influence:**
         - Key features indicating speaker's language background
         - Cross-linguistic influence patterns from probable native language
         - Notable deviations from standard ${analysisLanguage} pronunciation
         - Unique characteristics that help identify speaker's origin
  
      5. **Proficiency Assessment:**
         - Intelligibility rating in ${analysisLanguage}
         - Communication effectiveness
         - Overall fluency evaluation
         - Impact of accent on comprehensibility
  
      6. **Targeted Improvement Areas:**
         - Priority ${analysisLanguage} pronunciation targets
         - Specific exercises and practice focuses
         - Recommended learning strategies based on identified accent
         - Progress tracking metrics
  
      Format your response according to the specified JSON structure, ensuring all technical terms are explained clearly.
      Provide specific examples from the speech sample to support your analysis.
    `;
  }

  /**
   * Generates a detailed system instruction for accent analysis.
   * This instructs the AI (acting as a language analysis expert) to perform a deep accent and phonetic analysis in its output.
   */
  private generateDetailedAccentAnalysisInstruction(analysisLanguage: string): string {
    return `
     You are Dr. Sarah Chen-Martinez, PhD in Applied Linguistics and Phonetics from Cambridge University, 
    with 20 years of expertise in ${analysisLanguage} accent analysis, speech pathology, and phonetics. 
    You have published extensively on ${analysisLanguage} phonology and have worked with speakers from over 
    100 different language backgrounds learning ${analysisLanguage}. You can identify subtle 
    accent features that indicate a speaker's native language and regional background based on their 
    ${analysisLanguage} pronunciation patterns.
  
      Analyze this ${analysisLanguage} speech sample to identify the speaker's accent characteristics, determine their 
      linguistic background, and provide detailed feedback. Structure your response in the following JSON format:
  
      \`\`\`json
      {
        "accent_analysis": {
          "language_analyzed": "${analysisLanguage}",
          "analyzed_language_code": "BCP-47 code (e.g. en-US, de-DE, zh-CN) of ${analysisLanguage}",
          "accent_classification": {
            "accent_type": "Regional/Non-native accent",
            "specific_accent": "Detailed accent identification",
            "confidence_level": "number (0-100)",
            "accent_strength": "string (mild|moderate|strong)"
          },
          "speaker_background": {
            "probable_native_language": "string",
            "probable_region": "string",
            "confidence_level": "number (0-100)",
            "supporting_evidence": ["phonological features supporting this conclusion"]
          }
        },
        "phonetic_analysis": {
          "vowel_production": [
            {
              "phoneme": "string (IPA)",
              "standard_realization": "string (IPA for standard ${analysisLanguage})",
              "observed_realization": "string (IPA for speaker's pronunciation)",
              "example_word": "string",
              "timestamp": "number (seconds)",
              "analysis": "string",
              "accent_marker": "boolean - whether this is a characteristic of identified accent"
            }
          ],
          "consonant_production": [
            {
              "phoneme": "string (IPA)",
              "standard_realization": "string (IPA for standard ${analysisLanguage})",
              "observed_realization": "string (IPA for speaker's pronunciation)",
              "example_word": "string",
              "timestamp": "number (seconds)",
              "analysis": "string",
              "accent_marker": "boolean - whether this is a characteristic of identified accent"
            }
          ]
        },
        "prosodic_features": {
          "rhythm_patterns": {
            "description": "string",
            "standard_pattern": "description of standard ${analysisLanguage} rhythm",
            "observed_pattern": "description of speaker's rhythm",
            "accent_association": "string - what accent this pattern is associated with"
          },
          "stress_patterns": {
            "word_level": {
              "description": "string",
              "accent_association": "string"
            },
            "sentence_level": {
              "description": "string",
              "accent_association": "string"
            }
          },
          "intonation": {
            "patterns": ["string"],
            "accent_association": "string - what accent these patterns are associated with"
          }
        },
        "diagnostic_accent_markers": [
          {
            "feature": "string",
            "description": "string",
            "example": "string",
            "timestamp": "number (seconds)",
            "accent_association": "string - what accent/language this feature is associated with",
            "frequency": "string (rare|occasional|frequent)"
          }
        ],
        "proficiency_assessment": {
          "intelligibility_score": "number (0-100)",
          "fluency_rating": "number (0-100)",
          "comprehensibility": "number (0-100)",
          "CEFR_pronunciation_level": "string (A1|A2|B1|B2|C1|C2)",
          "accent_impact_assessment": "string - how accent affects communication"
        },
        "improvement_plan": {
          "priority_areas": [
            {
              "focus": "string",
              "importance": "string (high|medium|low)",
              "exercises": ["string"],
              "expected_timeline": "string"
            }
          ],
          "recommended_resources": ["string"],
          "practice_strategies": ["string - specifically for identified accent"]
        },
        "linguistic_background_insights": {
          "probable_l1_transfer_effects": ["string"],
          "cultural_speech_patterns": ["string"],
          "multilingual_influences": ["string - if applicable"]
        }
      }
      \`\`\`
  
      Important Instructions:
      1. Maintain strict JSON format compliance
      2. Provide detailed, specific examples from the audio
      3. Include timestamps where relevant
      4. Use IPA symbols for all phonetic transcriptions
      5. Ensure all accent classifications and language background assessments are justified with specific observations
      6. Keep technical terminology but provide clear explanations
      7. Make recommendations specific and actionable for the identified accent
      8. Base all assessments on concrete evidence from the audio sample
  
      Your analysis should be thorough yet accessible, professional yet engaging, and always supported by specific examples from the speech sample.
    `;
  }
}

export default MessageGenerator;
</file>

<file path="src/services/ai.service.ts">
import logger from '@/utils/logger';
import axios from 'axios';
import { HttpsProxyAgent } from 'https-proxy-agent';
import FormData from 'form-data';
import ApiKeyGenerator from './generators/apiKeyGenerator';
import { IUploadableAIService } from '@/interfaces/ai-service.interface';

  export const models = {
    gemini_2_5_pro_exp: "gemini-2.5-pro-exp-03-05",
    gemini_2_0_flash_exp: "gemini-2.0-flash-exp",
    gemini_2_0_thinking_exp: "gemini-2.0-flash-thinking-exp-01-21",
    gemini_2_0_flash: "gemini-2.0-flash",
    gemini_2_0_flash_lite: "gemini-2.0-flash-lite-preview-02-05",
  }
interface GeminiResponse  {
  candidates: {
    content: {
      parts: {
        text: string;
      }[];
      role: string;
    };
    finishReason: string;
    avgLogprobs: number;
  }[];
  usageMetadata: {
    promptTokenCount: number;
    candidatesTokenCount: number;
    totalTokenCount: number;
    promptTokensDetails: {
      modality: string;
      tokenCount: number;
    }[];
    candidatesTokensDetails: {
      modality: string;
      tokenCount: number;
    }[];
  };
  modelVersion: string;
}

// Type augmentation to include 'agent' in RequestInit
declare global {
  interface RequestInit {
    agent?: unknown; // Allow any type for agent
  }
}

class AIService implements  IUploadableAIService{
  private apiKey: string;
  private proxyAgent: unknown | undefined;

  constructor() {
    this.apiKey = ApiKeyGenerator.getInstance().getApiKey();
    this.proxyAgent = this.createProxyAgent();
  }


  /**
   * Create and return a proxy agent if proxy environment variables are defined.
   */
  private createProxyAgent(): unknown | undefined {
    // Use HTTPS proxy preferentially; fallback to HTTP proxy.
    const proxyUrl = process.env.HTTPS_PROXY ||
                     process.env.HTTP_PROXY ||
                     process.env.https_proxy ||
                     process.env.http_proxy;
                     
    if (proxyUrl) {
      try {
        logger.log(`Using proxy: ${proxyUrl}`);
        return new HttpsProxyAgent(proxyUrl);
      } catch (err) {
        logger.error("Error creating proxy agent:", err);
        return undefined;
      }
    }
    return undefined;
  }

  /**
   * A generic helper function to retry an async operation.
   * Retries the operation up to "attempts" times with an increasing delay.
   */
  private async retryOperation<T>(operation: () => Promise<T>, attempts = 3, delayMs = 1000): Promise<T> {
    let lastError: unknown;
    for (let attempt = 0; attempt < attempts; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error;
        logger.error(`Operation failed, attempt ${attempt + 1} of ${attempts}.`, error);
        if (attempt < attempts - 1) {
          // Exponential backoff: wait longer with each attempt.
          await new Promise(resolve => setTimeout(resolve, delayMs * (attempt + 1)));
        }
      }
    }
    throw lastError;
  }
  // {
  //   "error": {
  //     "code": 429,
  //     "message": "Resource has been exhausted (e.g. check quota).",
  //     "status": "RESOURCE_EXHAUSTED"
  //   }
  // }
  

  /**
   * Upload file using a single multipart/related request.
   *
   * This method emulates the Google AI Studio curl example:
   *
   * curl "https://generativelanguage.googleapis.com/upload/v1beta/files?key=${API_KEY}" \
   *   -H "X-Goog-Upload-Command: start, upload, finalize" \
   *   -H "X-Goog-Upload-Header-Content-Length: NUM_BYTES" \
   *   -H "X-Goog-Upload-Header-Content-Type: MIME_TYPE" \
   *   -H "Content-Type: application/json" \
   *   -d "{'file': {'display_name': 'DISPLAY_NAME'}}" \
   *   --data-binary "@FILENAME"
   *
   * The multipart request includes both the JSON metadata and the binary file.
   */
  async uploadFile(audioBuffer: Buffer, mimeType: string, displayName: string): Promise<string> {
    const uploadUrl = `https://generativelanguage.googleapis.com/upload/v1beta/files?key=${this.apiKey}`;
    
    // Create a new FormData instance.
    const form = new FormData();
    // Append the JSON metadata.
    form.append('metadata', JSON.stringify({ file: { display_name: displayName } }), {
      contentType: 'application/json'
    });
    // Append the binary file.
    form.append('file', audioBuffer, {
      filename: displayName,
      contentType: mimeType,
      knownLength: audioBuffer.length
    });

    // Build the headers (note: form.getHeaders() returns necessary multipart boundaries).
    const headers = {
      ...form.getHeaders(),
      'X-Goog-Upload-Command': 'start, upload, finalize',
      'X-Goog-Upload-Header-Content-Length': audioBuffer.length.toString(),
      'X-Goog-Upload-Header-Content-Type': mimeType,
    };

    const config: Record<string, unknown> = {
      headers,
      maxContentLength: Infinity,
      maxBodyLength: Infinity
    };

    if (this.proxyAgent) {
      config.httpsAgent = this.proxyAgent;
      config.proxy = false;
    }

    return await this.retryOperation(async () => {
      const response = await axios.post(uploadUrl, form, config);
      logger.log("Upload response:", response.data);
      // Return the file URI from the response.
      return response.data.file.uri;
    });
  }

  async generateContent(fileUri: string, userMessage: string, systemMessage: string, model: string): Promise<Record<string, unknown>> {
    const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${this.apiKey}`;
    
    const data = {
      contents: [{
        role: "user",
        parts: [
          ...(fileUri ? [{
            fileData: {
              fileUri: fileUri,
              mimeType: "audio/webm"
            }
          }] : []),
          { text: userMessage }
        ]
      }],
      systemInstruction: {
        role: "system",
        parts: [{ text: systemMessage }]
      },
      generationConfig: {
        temperature: 0.3,
        // topK: 64,
        topP: 0.95,
        maxOutputTokens: 8192,
        responseMimeType: "application/json"
      }
    };

    const config: Record<string, unknown> = {
      headers: {
        'Content-Type': 'application/json'
      }
    };

    if (this.proxyAgent) {
      config.httpsAgent = this.proxyAgent;
      config.proxy = false;
    }

    return await this.retryOperation(async () => {
      try {
        const response = await axios.post<GeminiResponse>(url, data, config);
        
        // Extract the JSON string from the response
        const jsonString = response.data.candidates[0].content.parts[0].text;
        const cleanedJson = jsonString
          .replace(/```json/g, '')
          .replace(/```/g, '')
          .trim();
        logger.log("Cleaned JSON:", cleanedJson)

        try {
          const analysisData = JSON.parse(cleanedJson);
          console.log("Analysis Data:", analysisData);

          if (Array.isArray(analysisData)) {
            if (analysisData.length === 0) {
              throw new Error("Empty analysis array");
            }
            return analysisData[0];
          }
          // Return the first item in the array as that's our analysis
          return analysisData;
        } catch (parseError) {
          let errorMessage = 'Unknown parsing error';
          if (parseError instanceof Error) {
            errorMessage = parseError.message;
          }
          logger.error("Error parsing Gemini response:", {
            error: parseError,
            response: response.data,
            cleanedJson
          });
          throw new Error(`Failed to parse AI response: ${errorMessage}`);
        }
      } catch (error) {
        if (axios.isAxiosError(error)) {
          const errorDetails = {
            status: error.response?.status,
            statusText: error.response?.statusText,
            data: error.response?.data,
            config: {
              url: error.config?.url,
              method: error.config?.method,
              headers: error.config?.headers,
              data: error.config?.data
            }
          };
          
          logger.error("Detailed API error:", errorDetails);
          throw new Error(`API request failed: ${error.response?.status} ${error.response?.statusText} - ${JSON.stringify(error.response?.data)}`);
        }
        logger.error("Unexpected error in generateContent:", error);
        throw new Error(`Unexpected error: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    });
  }
}

export default AIService;
</file>

<file path="src/services/auth.service.ts">
// import { User, Session } from '@supabase/supabase-js'
// import { AuthChangeEvent } from '@supabase/supabase-js'
// import { MockAuthService } from './mock-auth-service.service'
// import logger from '@/utils/logger'
// import { createClient } from '@supabase/supabase-js'

// export interface IAuthService {
//   login(email: string, password: string): Promise<{ user: User | null; session: Session | null }>
//   register(email: string, password: string): Promise<{ user: User | null; session: Session | null }>
//   loginWithGoogle(): Promise<void>
//   logout(): Promise<void>
//   getSession(): Promise<Session | null>
//   onAuthStateChange(callback: (event: any, session: Session | null) => Promise<void> | void): any
//   deleteUserById(userId: string): Promise<{ error: any | null }>
// } 



// // Use environment variables directly for client creation
// const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL || ''
// const supabaseAnonKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY || ''
// // const supabaseServiceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY || ''


// // let supabaseAdmin: ReturnType<typeof createClient> | null = null;
// // if (supabaseServiceRoleKey && typeof window === 'undefined') { // Ensure server-side context
// //   try {
// //     supabaseAdmin = createClient(supabaseUrl, supabaseServiceRoleKey, {
// //       auth: {
// //         autoRefreshToken: false,
// //         persistSession: false
// //       }
// //     });
// //     logger.info('Supabase Admin client initialized successfully.');
// //   } catch (error) {
// //     logger.error('Failed to initialize Supabase Admin client:', error);
// //   }
// // } else if (supabaseServiceRoleKey && typeof window !== 'undefined') {
// //   logger.warn('Attempted to initialize Supabase Admin client in a browser environment. This is unsafe.');
// // } else if (!supabaseServiceRoleKey) {
// //   logger.warn('SUPABASE_SERVICE_ROLE_KEY is not set. Admin operations will not be available.');
// // }




// export function getAuthServiceBasedOnEnvironment() {
//   logger.info('using the enviroment to get the auth service based on enviroment', process.env.NEXT_PUBLIC_MOCK_AUTH);

//   if (process.env.NEXT_PUBLIC_MOCK_AUTH === 'true') {
//     const mockAuthService = new MockAuthService()
//     logger.info('using mock auth service');
//     if (mockAuthService instanceof MockAuthService) {
//       (mockAuthService as any).API_URL = `http://localhost:3000/api/mock-auth`;
//     }
//     return mockAuthService
//   }

//   return new SupabaseAuthService()
// }
</file>

<file path="src/services/form.service.ts">
import logger from "@/utils/logger";

export class FormService {
  static async submitEmail(email: string, source= 'website'): Promise<boolean> {
    // Validate email format
    if (!this.validateEmail(email)) {
      throw new Error('Please enter a valid email address');
    }

    const payload = {
      email,
      source, // additional field to track the source of submission
      // You could add more fields here if needed, e.g., languagePreference: 'en'
    };
    try {
      let response;

      if (process.env.NODE_ENV === 'development') {
        response = { ok: true, json: () => Promise.resolve({ isSubscribed: true }) };

      } else { 
        response = await fetch('/api/subscribe', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify(payload),
      });

      }
      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.message || 'Subscription failed');
      }

      return true;
    } catch (error) {
      logger.error(error as string);
      throw new Error('Network error. Please try again.');
    }
  }

  private static validateEmail(email: string): boolean {
    const re = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    return re.test(email);
  }
}
</file>

<file path="src/services/google-tts.service.ts">
import { ITTS } from '@/interfaces/tts.interface';
import logger from '@/utils/logger';
import axios from 'axios';
import { GoogleAuth, GoogleAuthOptions } from 'google-auth-library';
import { HttpsProxyAgent } from 'https-proxy-agent';
import mockAudioJsonReply from '@/__mocks__/google-audio-json-reply.mock.json'
import { mapLanguageToGoogleHDVoice } from '../utils/google-hd-voices.util';
import { mapLanguageToGoogleBasicVoice } from '@/utils/google-basic-voices.util';

export class GoogleTTS implements ITTS {
  private auth: GoogleAuth;

  private googleProjectId: string;

  private proxyAgent: unknown | undefined;

  // TODO: refactor constructor
  constructor() {
    this.validateEnvironment(); // Checks required vars like GOOGLE_CLOUD_PROJECT
    const projectId = process.env.GOOGLE_CLOUD_PROJECT!;
    this.googleProjectId = projectId;
    this.proxyAgent = this.createProxyAgent();

    const authOptions: GoogleAuthOptions = {
      scopes: ['https://www.googleapis.com/auth/cloud-platform'],
    };

    // Check if running in an environment with Base64 credentials
    if (process.env.GOOGLE_CREDENTIALS_BASE64) {
      let decodedCredentials = '';
      try {
        logger.info(
          'Found GOOGLE_CREDENTIALS_BASE64, decoding and using for Google Auth.'
        );
        let rawBase64 = process.env.GOOGLE_CREDENTIALS_BASE64.trim();

        rawBase64 = rawBase64.replace(/%/g, '');
        decodedCredentials = Buffer.from(rawBase64, 'base64').toString();
        logger.info(
          'Decoded Credentials (first 100 chars):',
          decodedCredentials.substring(0, 100) + '...'
        );

        const credentials = JSON.parse(decodedCredentials);
        authOptions.credentials = credentials;

        if (
          credentials.project_id &&
          credentials.project_id !== this.googleProjectId
        ) {
          logger.warn(
            `Project ID mismatch: GOOGLE_CLOUD_PROJECT is ${this.googleProjectId}, but credentials file has ${credentials.project_id}. Using ID from credentials.`
          );
          this.googleProjectId = credentials.project_id;
        }
      } catch (error) {
        logger.error(
          'Failed to decode/parse GOOGLE_CREDENTIALS_BASE64. Decoded string causing error (first 100 chars):',
          decodedCredentials
            ? decodedCredentials.substring(0, 100) + '...'
            : 'Input string was empty, invalid Base64, or not captured.'
        );
        logger.error('Underlying Error:', error);
        throw new Error(
          'Failed to initialize Google Auth from Base64 credentials. Check Base64 encoding and JSON validity.'
        );
      }
    } else if (process.env.GOOGLE_APPLICATION_CREDENTIALS) {
      logger.info(
        `Using GOOGLE_APPLICATION_CREDENTIALS file path for Google Auth: ${process.env.GOOGLE_APPLICATION_CREDENTIALS}`
      );
    } else {
      logger.warn(
        'Neither GOOGLE_CREDENTIALS_BASE64 nor GOOGLE_APPLICATION_CREDENTIALS is set. Attempting Application Default Credentials (ADC).'
      );
    }

    // Initialize GoogleAuth
    try {
      this.auth = new GoogleAuth(authOptions);
    } catch (authError) {
      logger.error('Failed to initialize GoogleAuth instance:', authError);
      throw new Error(
        `Google Auth initialization failed: ${
          authError instanceof Error ? authError.message : String(authError)
        }`
      );
    }

    if (!this.googleProjectId) {
      logger.error(
        'Google Project ID could not be determined after auth setup.'
      );
      throw new Error(
        "Google Project ID is missing. Set GOOGLE_CLOUD_PROJECT or ensure credentials file contains 'project_id'."
      );
    } else {
      logger.info(
        `GoogleTTS service initialized for project: ${this.googleProjectId}`
      );
    }
  } // End of constructor

  private createProxyAgent(): unknown | undefined {
    const proxyUrl =
      process.env.HTTPS_PROXY ||
      process.env.HTTP_PROXY ||
      process.env.https_proxy ||
      process.env.http_proxy;

    if (proxyUrl) {
      try {
        logger.log(`Using proxy: ${proxyUrl}`);
        return new HttpsProxyAgent(proxyUrl);
      } catch (err) {
        logger.error('Error creating proxy agent:', err);
        return undefined;
      }
    }
    return undefined;
  }

  public async synthesizeSpeech(
    text: string,
    language: string,
    voice: string
  ): Promise<string> {
    try {
      // Get auth client and token
      const client = await this.auth.getClient();
      const token = await client.getAccessToken();
      const accessToken = token.token;

      // Map full language name to language code if needed
      const languageCode = this.mapLanguageToCode(language);

      // Prepare request data for Google TTS API
      const requestData = {
        input: {
          text: text,
        },
        voice: {
          languageCode: languageCode,
          name: voice,
        },
        audioConfig: {
          audioEncoding: 'LINEAR16',
        },
      };

      logger.info('requestData for google tts', requestData);

      const config: Record<string, unknown> = {
        method: 'post',
        url: 'https://texttospeech.googleapis.com/v1/text:synthesize',
        headers: {
          'Content-Type': 'application/json',
          'X-Goog-User-Project': this.googleProjectId,
          Authorization: `Bearer ${accessToken}`,
        },
        data: requestData,
        timeout: 10000,
        responseType: 'text',
        validateStatus: () => true,
      };

      if (this.proxyAgent) {
        config.httpsAgent = this.proxyAgent;
        config.proxy = false;
      }

      const mockReturnData = false;

      if (mockReturnData) {
        return mockAudioJsonReply.audioContent;
      } 
      const response = await axios(config);

      // Detect proxy interference by checking for HTML response
      if (
        typeof response.data === 'string' &&
        response.data.includes('</html>')
      ) {
        logger.error('Proxy interference detected', {
          status: response.status,
          data: response.data.substring(0, 200), // Log first 200 chars of HTML
        });
        throw new Error(
          'Network gateway error occurred - received HTML response instead of API response'
        );
      }


      // Try to parse JSON if we got through proxy
      const responseData =
        typeof response.data === 'string'
          ? JSON.parse(response.data)
          : response.data;

      // Handle HTTP errors
      if (response.status >= 400) {
        logger.error('Google TTS API Error:', {
          status: response.status,
          errorDetails: responseData?.error || 'No error details',
        });
        throw new Error(
          `Google TTS API Error: ${response.status} - ${
            responseData?.error?.message || 'Unknown error'
          }`
        );
      }

      if (!responseData?.audioContent) {
        logger.error(
          'Invalid response structure from Google TTS API:',
          responseData
        );
        throw new Error(
          'Malformed response from Google TTS - missing audioContent'
        );
      }

      return responseData.audioContent; // base64 string
    } catch (error) {
      if (axios.isAxiosError(error)) {
        if (error.code === 'ECONNABORTED') {
          logger.warn('Google TTS request timeout');
          throw new Error('Google TTS request timed out');
        }
        if (
          error.response?.data &&
          typeof error.response.data === 'string' &&
          error.response.data.includes('</html>')
        ) {
          logger.error('Proxy interference detected in error response');
          throw new Error(
            'Persistent proxy interference - check network configuration'
          );
        }
      }

      logger.error('Google TTS synthesis error:', error);
      throw new Error(
        `Failed to synthesize speech: ${
          error instanceof Error ? error.message : 'Unknown error'
        }`
      );
    }
  }

  // Helper method to map full language names to BCP-47 language codes
  private mapLanguageToCode(language: string): string {
    const languageMap: Record<string, string> = {
      english: 'en-US',
      'english (us)': 'en-US',
      'english (uk)': 'en-GB',
      'english (australia)': 'en-AU',
      'english (india)': 'en-IN',
      german: 'de-DE',
      french: 'fr-FR',
      spanish: 'es-ES',
      italian: 'it-IT',
      portuguese: 'pt-PT',
      'portuguese (brazil)': 'pt-BR',
      dutch: 'nl-NL',
      polish: 'pl-PL',
      swedish: 'sv-SE',
      danish: 'da-DK',
      norwegian: 'nb-NO',
      finnish: 'fi-FI',
      czech: 'cs-CZ',
      slovak: 'sk-SK',
      hungarian: 'hu-HU',
      romanian: 'ro-RO',
      greek: 'el-GR',
      japanese: 'ja-JP',
      korean: 'ko-KR',
      chinese: 'cmn-CN',
      'chinese (mandarin)': 'cmn-CN',
      'chinese (cantonese)': 'yue-HK',
      vietnamese: 'vi-VN',
      thai: 'th-TH',
      indonesian: 'id-ID',
      malay: 'ms-MY',
      hindi: 'hi-IN',
      tamil: 'ta-IN',
      bengali: 'bn-IN',
      arabic: 'ar-XA',
      turkish: 'tr-TR',
      hebrew: 'he-IL',
      persian: 'fa-IR',
      russian: 'ru-RU',
      ukrainian: 'uk-UA',
      filipino: 'fil-PH',
      swahili: 'sw-KE',
    };

    // Normalize and look up language code
    const normalizedLanguage = language.toLowerCase().trim();

    // Direct match
    if (normalizedLanguage in languageMap) {
      return languageMap[normalizedLanguage];
    }

    // Partial match
    for (const [key, code] of Object.entries(languageMap)) {
      if (
        normalizedLanguage.includes(key) ||
        key.includes(normalizedLanguage)
      ) {
        return code;
      }
    }

    // Default fallback
    logger.warn(
      `No language code mapping found for: ${language}, using en-US as default`
    );
    return 'en-US';
  }

  public getVoice(language: string, quality: 'basic' | 'hd'): string {
    logger.info(`Getting voice for language: ${language}`);

    // Map of languages to their best available Google TTS voices
    const voice = quality === 'hd' ? mapLanguageToGoogleHDVoice(language) : mapLanguageToGoogleBasicVoice(language);

    logger.info(`Voice for language ${language}: ${voice}`);

    return voice;
  }

  private validateEnvironment(): void {
    // Only GOOGLE_CLOUD_PROJECT is strictly required beforehand now.
    // The credentials can come from either Base64 or file path, checked in constructor.
    const requiredVars = ['GOOGLE_CLOUD_PROJECT'];

    const missingVars = requiredVars.filter((v) => !process.env[v]);
    if (missingVars.length > 0) {
      throw new Error(
        `Missing required environment variables: ${missingVars.join(', ')}`
      );
    }

    // Add a check: EITHER Base64 OR file path should be present, or warn about ADC.
    if (
      !process.env.GOOGLE_CREDENTIALS_BASE64 &&
      !process.env.GOOGLE_APPLICATION_CREDENTIALS
    ) {
      logger.warn(
        'Neither GOOGLE_CREDENTIALS_BASE64 nor GOOGLE_APPLICATION_CREDENTIALS environment variables are set. Google Auth will attempt Application Default Credentials (ADC). This might not work in all environments without specific configuration.'
      );
    }
    if (
      process.env.GOOGLE_CREDENTIALS_BASE64 &&
      process.env.GOOGLE_APPLICATION_CREDENTIALS
    ) {
      logger.warn(
        'Both GOOGLE_CREDENTIALS_BASE64 and GOOGLE_APPLICATION_CREDENTIALS are set. Using GOOGLE_CREDENTIALS_BASE64.'
      );
    }
  }
}
</file>

<file path="src/services/learning-progress.service.ts">
import { ILearningProgressRepository, LearningProgressRepository } from '@/repositories/learning-progress.repository';
import { LearningProgressModel, LessonModel, AssessmentLesson, TopicProgressModel, WordProgressModel, AudioMetrics } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { MasteryLevel, ProficiencyLevel, LearningTrajectory } from '@prisma/client';

export default class LearningProgressService {
  private progressRepository: ILearningProgressRepository;

  // TODO: Inject services needed for context if required (e.g., UserService for profile data)
  constructor(progressRepository: ILearningProgressRepository) {
    this.progressRepository = progressRepository;
  }

  async getLearningProgress(userId: string): Promise<LearningProgressModel | null> {
    return this.progressRepository.getLearningProgress(userId);
  }

  async getLearningProgressWithDetails(userId: string): Promise<LearningProgressModel | null> {
    return this.progressRepository.getLearningProgressWithDetails(userId);
  }

  /**
   * Updates the user's learning progress after completing a lesson.
   */
  async updateProgressAfterLesson(userId: string, lesson: LessonModel): Promise<void> {
    logger.info('Updating learning progress after lesson', { userId, lessonId: lesson.id });
    try {
      let progress = await this.progressRepository.getLearningProgress(userId);
      if (!progress) {
        progress = await this.progressRepository.upsertLearningProgress(userId, {
          userId: userId, // Ensure userId is passed on creation
          estimatedProficiencyLevel: ProficiencyLevel.beginner, // Default or derive from onboarding
          learningTrajectory: LearningTrajectory.steady,
          strengths: [],
          weaknesses: [],
        });
      }

      const learningProgressId = progress.id;
      const now = new Date();

      // 1. Update Topic Progress
      const topicName = lesson.focusArea; // Assuming focusArea is the primary topic
      if (topicName) {
        await this.updateTopicProgress(learningProgressId, topicName, lesson.id, null, lesson.performanceMetrics, lesson.audioMetrics);
      }
      // Also consider targetSkills as potential topics
      for (const skill of lesson.targetSkills) {
         await this.updateTopicProgress(learningProgressId, skill, lesson.id, null, lesson.performanceMetrics, lesson.audioMetrics);
      }


      // 2. Update Word Progress (Iterate through lesson steps)
      for (const step of lesson.steps) {
        if (step.type === 'new_word' || step.type === 'practice') {
          // Extract word (assuming content or expectedAnswer holds the word)
          const word = step.expectedAnswer || step.content; // Adjust logic as needed
          const translation = step.translation;
          if (word) {
            await this.updateWordProgress(learningProgressId, word, translation, step.id, null, step.correct, step.attempts > 0);
          }
        }
        // Potentially extract words from 'prompt' content too using NLP (more advanced)
      }

      // 3. Recalculate Overall Progress (Simplified example)
      // TODO: Implement more sophisticated calculation logic, potentially using AI
      const updatedOverall = this.calculateOverallProgress(progress, lesson.performanceMetrics, lesson.audioMetrics);

      // 4. Save updated overall progress
      const { userId: _, ...updateData } = updatedOverall;
      await this.progressRepository.upsertLearningProgress(userId, {
        ...updateData,
        lastLessonCompletedAt: now,
        updatedAt: now,
      });

      logger.info('Successfully updated learning progress after lesson', { userId, lessonId: lesson.id });

    } catch (error) {
      logger.error('Error updating learning progress after lesson:', { userId, lessonId: lesson.id, error });
      // Decide if this error should propagate or just be logged
    }
  }

  /**
   * Updates the user's learning progress after completing an assessment.
   */
  async updateProgressAfterAssessment(userId: string, assessment: AssessmentLesson): Promise<void> {
     logger.info('Updating learning progress after assessment', { userId, assessmentId: assessment.id });
      try {
        let progress = await this.progressRepository.getLearningProgress(userId);
        if (!progress) {
          progress = await this.progressRepository.upsertLearningProgress(userId, {
            userId: userId,
            estimatedProficiencyLevel: assessment.audioMetrics?.proficiencyLevel 
              ? this.mapCefrToProficiency(assessment.audioMetrics.proficiencyLevel) 
              : ProficiencyLevel.beginner,
            learningTrajectory: LearningTrajectory.steady,
            strengths: [],
            weaknesses: [],
          });
        }

        const learningProgressId = progress.id;
        const now = new Date();

        // 1. Update Topic Progress (using proposedTopics)
        for (const topicName of assessment.proposedTopics) {
           await this.updateTopicProgress(learningProgressId, topicName, null, assessment.id, assessment.metrics, assessment.audioMetrics);
        }
        // Potentially analyze steps for topics if proposedTopics is empty

        // 2. Update Word Progress (Iterate through assessment steps)
         for (const step of assessment.steps) {
           if (step.type === 'question') {
             const word = step.expectedAnswer; // Assuming expectedAnswer is relevant
             const translation = step.translation;
             if (word) {
                await this.updateWordProgress(learningProgressId, word, translation, null, step.id, step.correct, step.attempts > 0);
             }
             // Could also analyze step.content for words
           }
         }

        // 3. Recalculate Overall Progress
        // TODO: Implement more sophisticated calculation logic
        const updatedOverall = this.calculateOverallProgress(progress, assessment.metrics, assessment.audioMetrics);

         // 4. Save updated overall progress
         const { userId: __, ...assessmentUpdateData } = updatedOverall;
         await this.progressRepository.upsertLearningProgress(userId, {
           ...assessmentUpdateData,
           lastAssessmentCompletedAt: now,
           updatedAt: now,
         });

         logger.info('Successfully updated learning progress after assessment', { userId, assessmentId: assessment.id });

      } catch (error) {
        logger.error('Error updating learning progress after assessment:', { userId, assessmentId: assessment.id, error });
      }
  }

  // --- Helper Methods ---

  private async updateTopicProgress(
    learningProgressId: string,
    topicName: string,
    lessonId: string | null,
    assessmentId: string | null,
    metrics: any, // Lesson or Assessment metrics
    audioMetrics?: AudioMetrics | null
  ): Promise<void> {
    if (!topicName) return;

    const existingTopic = await this.progressRepository.getTopicProgress(learningProgressId, topicName);
    const now = new Date();
    let score = existingTopic?.score || 0;
    let masteryLevel = existingTopic?.masteryLevel || MasteryLevel.NotStarted;

    // Basic logic: Improve score/mastery on completion/good performance
    // TODO: Refine this logic based on actual metrics content
    const lessonScore = metrics?.overallScore ?? (metrics?.accuracy ?? 0); // Example score extraction
    const audioScore = audioMetrics?.overallPerformance ?? lessonScore; // Prefer audio score if available

    if (lessonId || assessmentId) { // If studied in this session
      masteryLevel = this.advanceMastery(masteryLevel, audioScore >= 70); // Advance if score is good
      score = (score + audioScore) / 2; // Simple averaging
    }

    const updateData: Partial<TopicProgressModel> & { topicName: string } = {
        topicName,
        masteryLevel,
        score: Math.round(score),
        lastStudiedAt: now,
        relatedLessonIds: existingTopic?.relatedLessonIds ?? [],
        relatedAssessmentIds: existingTopic?.relatedAssessmentIds ?? [],
        updatedAt: now,
    };

    if (lessonId) {
        (updateData.relatedLessonIds as string[]).push(lessonId);
    }
    if (assessmentId) {
        (updateData.relatedAssessmentIds as string[]).push(assessmentId);
    }

    await this.progressRepository.upsertTopicProgress(learningProgressId, updateData);
  }

  private async updateWordProgress(
    learningProgressId: string,
    word: string,
    translation: string | null | undefined,
    lessonStepId: string | null,
    assessmentStepId: string | null,
    wasCorrect: boolean,
    wasAttempted: boolean
  ): Promise<void> {
    if (!word || !wasAttempted) return; // Only track attempted words

    const existingWord = await this.progressRepository.getWordProgress(learningProgressId, word);
    const now = new Date();

    let timesCorrect = existingWord?.timesCorrect || 0;
    let timesIncorrect = existingWord?.timesIncorrect || 0;
    let masteryLevel = existingWord?.masteryLevel || MasteryLevel.Seen;

    if (wasCorrect) {
      timesCorrect++;
      masteryLevel = this.advanceMastery(masteryLevel, true);
    } else {
      timesIncorrect++;
      masteryLevel = this.regressMastery(masteryLevel); // Regress slightly on incorrect
    }

     const updateData: Partial<WordProgressModel> & { word: string } = {
        word,
        translation: translation ?? existingWord?.translation,
        masteryLevel,
        timesCorrect,
        timesIncorrect,
        lastReviewedAt: now,
        relatedLessonStepIds: existingWord?.relatedLessonStepIds ?? [],
        relatedAssessmentStepIds: existingWord?.relatedAssessmentStepIds ?? [],
        updatedAt: now,
    };

     if (lessonStepId) {
        (updateData.relatedLessonStepIds as string[]).push(lessonStepId);
    }
    if (assessmentStepId) {
        (updateData.relatedAssessmentStepIds as string[]).push(assessmentStepId);
    }

     // Set firstSeenAt only if it's a new word
     const createData = { ...updateData, firstSeenAt: now };

    await this.progressRepository.upsertWordProgress(
        learningProgressId,
        existingWord ? updateData : createData // Use updateData for update, createData for create
    );
  }

  private calculateOverallProgress(
      currentProgress: LearningProgressModel,
      metrics: any, // Lesson or Assessment metrics
      audioMetrics?: AudioMetrics | null
  ): Omit<Partial<LearningProgressModel>, 'topics' | 'words'> {
      // Simplified Example: Average score, update proficiency based on audio metrics
      // TODO: Implement sophisticated logic using historical data, AI analysis of strengths/weaknesses

      const newOverallScore = audioMetrics?.overallPerformance ?? metrics?.overallScore ?? metrics?.accuracy ?? currentProgress.overallScore ?? 0;
      const currentOverallScore = currentProgress.overallScore || 0;

      // Simple averaging - weight new score more
      const calculatedScore = (currentOverallScore * 0.3) + (newOverallScore * 0.7);

      let estimatedProficiencyLevel = currentProgress.estimatedProficiencyLevel;
      let learningTrajectory = currentProgress.learningTrajectory;

      // Update proficiency based on AudioMetrics CEFR level if available
      if (audioMetrics?.proficiencyLevel) {
          const audioProficiency = this.mapCefrToProficiency(audioMetrics.proficiencyLevel);
          if (audioProficiency && this.proficiencyLevelToInt(audioProficiency) > this.proficiencyLevelToInt(estimatedProficiencyLevel)) {
              estimatedProficiencyLevel = audioProficiency; // Update if higher
          }
      }

      // Update trajectory based on score change and audio trajectory
      if (audioMetrics?.learningTrajectory) {
          learningTrajectory = audioMetrics.learningTrajectory;
      } else if (calculatedScore > currentOverallScore + 5) {
          learningTrajectory = LearningTrajectory.accelerating;
      } else if (calculatedScore < currentOverallScore - 5) {
          learningTrajectory = LearningTrajectory.plateauing; // Or needs attention
      } else {
          learningTrajectory = LearningTrajectory.steady;
      }

      // Update strengths/weaknesses (simple example: add from metrics)
      const strengths = new Set([...currentProgress.strengths, ...(metrics?.strengths || []), ...(audioMetrics?.grammarAssessment?.grammar_strengths || [])]);
      const weaknesses = new Set([...currentProgress.weaknesses, ...(metrics?.weaknesses || []), ...(audioMetrics?.pronunciationAssessment?.areas_for_improvement || [])]);

      return {
          overallScore: Math.round(calculatedScore),
          estimatedProficiencyLevel: estimatedProficiencyLevel || ProficiencyLevel.beginner,
          learningTrajectory,
          strengths: Array.from(strengths).slice(-10), // Limit size
          weaknesses: Array.from(weaknesses).slice(-10), // Limit size
      };
  }

  // --- Mastery Level Logic ---
   private advanceMastery(currentLevel: MasteryLevel, correct: boolean): MasteryLevel {
    if (!correct) return currentLevel; // Only advance if correct

    switch (currentLevel) {
      case MasteryLevel.NotStarted: return MasteryLevel.Seen;
      case MasteryLevel.Seen:       return MasteryLevel.Learning;
      case MasteryLevel.Learning:   return MasteryLevel.Practiced;
      case MasteryLevel.Practiced:  return MasteryLevel.Known;
      case MasteryLevel.Known:      return MasteryLevel.Mastered;
      case MasteryLevel.Mastered:   return MasteryLevel.Mastered; // Stays mastered
      default:                      return currentLevel;
    }
  }

  private regressMastery(currentLevel: MasteryLevel): MasteryLevel {
     switch (currentLevel) {
      // Don't regress too harshly initially
      case MasteryLevel.NotStarted: return MasteryLevel.NotStarted;
      case MasteryLevel.Seen:       return MasteryLevel.Seen;
      // Regress if learning or practiced
      case MasteryLevel.Learning:   return MasteryLevel.Seen;
      case MasteryLevel.Practiced:  return MasteryLevel.Learning;
      case MasteryLevel.Known:      return MasteryLevel.Practiced;
      case MasteryLevel.Mastered:   return MasteryLevel.Known; // Drop from mastered if incorrect
      default:                      return currentLevel;
    }
  }

  // --- Proficiency Level Mapping ---
  private mapCefrToProficiency(cefr: string): ProficiencyLevel {
      cefr = cefr.toUpperCase();
      if (cefr.startsWith('A1') || cefr.startsWith('A2')) return ProficiencyLevel.beginner;
      if (cefr.startsWith('B1') || cefr.startsWith('B2')) return ProficiencyLevel.intermediate;
      if (cefr.startsWith('C1') || cefr.startsWith('C2')) return ProficiencyLevel.advanced;
      return ProficiencyLevel.beginner; // Default fallback instead of null
  }

  private proficiencyLevelToInt(level: ProficiencyLevel): number {
      switch(level) {
          case ProficiencyLevel.beginner: return 1;
          case ProficiencyLevel.intermediate: return 2;
          case ProficiencyLevel.advanced: return 3;
          default: return 0;
      }
  }
}
</file>

<file path="src/services/metrics.service.ts">
import logger from "@/utils/logger";
import { supabase } from "@/repositories/supabase/supabase";
import { LanguageDetectionResponse } from "@/models/Language-detection.model";

class MetricsService {
  constructor() {}

  async collectInteractionData(userIP: string, recording: string, aiResponse: Record<string, unknown>, recordingTime: number, responseTime: number, recordingSize: number, languageDetection: LanguageDetectionResponse): Promise<void> {
    try {
      // Collect relevant data
      const timestamp = new Date();
      const aiResponseLength = JSON.stringify(aiResponse).length;

      // Structure the data
      const interactionData = {
        user_ip: userIP,
        timestamp,
        recording_size: recordingSize,
        response_time: responseTime,
        ai_response_length: aiResponseLength,
        recording_time: recordingTime,
        ai_response: aiResponse,
        recording: recording.length,
        language_detection: languageDetection,
      };

      // Store the data in Supabase
      if (process.env.MOCK_AI_RESPONSE !== 'true' && process.env.NODE_ENV === 'production') {
        await this.storeInteractionData(interactionData);
      }

      logger.log("Interaction data collected and stored:", interactionData);
    } catch (error) {
      logger.error("Error collecting interaction data:", error);
    }
  }

  private async storeInteractionData(data: Record<string, unknown>): Promise<void> {
    try {
      const { error } = await supabase
        .from('interactions')
        .insert([data]);

      if (error) {
        logger.error("Error storing interaction data in Supabase:", error);
        throw error;
      } else {
        logger.log("Interaction data stored in Supabase:", data);
      }
    } catch (error) {
      logger.error("Error storing interaction data:", error);
    }
  }
}

export default MetricsService;
</file>

<file path="src/services/mock-auth-service.service.ts">
// src/services/mock-auth-service.service.ts
import { Session, User, AuthChangeEvent, Subscription } from '@supabase/supabase-js'
import logger from '@/utils/logger'

// In-memory store for the mock session (persists only while the server process runs)
let mockSessionStore: Session | null = null;

// Store the auth state callback globally within this module for the mock service
let globalAuthStateCallback: ((event: AuthChangeEvent, session: Session | null) => Promise<void> | void) | null = null;

// Helper to notify auth state change
const notifyAuthStateChange = (event: AuthChangeEvent, session: Session | null) => {
  if (globalAuthStateCallback) {
    // Use Promise.resolve().then() to mimic async behavior of real auth changes
    Promise.resolve().then(() => {
      if (globalAuthStateCallback) { // Check again inside the promise in case it was unset
        globalAuthStateCallback(event, session);
      }
    });
  }
};

export class MockAuthService {


  private authStateCallback: ((event: AuthChangeEvent, session: Session | null) => Promise<void> | void) | null = null;
  private readonly API_URL = '/api/mock-auth';



  async login(email: string, password: string): Promise<{ user: User | null; session: Session | null }> {



    logger.log('login (mocked)', email, password);
    const response = await fetch(this.API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        action: 'login',
        email,
        password
      })
    });

    if (!response.ok) {
      throw new Error('Mock login failed');
    }

    const { user, session } = await response.json();

    if (this.authStateCallback) {
      this.authStateCallback('SIGNED_IN', session);
    }

    return { user, session };
  }

  async logout(): Promise<void> {
    logger.log('logout (mocked)');
    await fetch(this.API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        action: 'logout'
      })
    });

    if (this.authStateCallback) {
      this.authStateCallback('SIGNED_OUT', null);
    }
  }

  async getSession(): Promise<Session | null> {
    const response = await fetch(this.API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        action: 'getSession'
      })
    });

    if (!response.ok) {
      return null;
    }

    const { session } = await response.json();
    return session;
  }




  async register(email: string, password: string): Promise<{ user: User | null; session: Session | null }> {
    logger.log('register (mocked)', email, password);
    const response = await fetch(this.API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        action: 'register',
        email,
        password
      })
    });

    if (!response.ok) {
      throw new Error('Mock registration failed');
    }

    const { user, session } = await response.json();

    if (this.authStateCallback) {
      this.authStateCallback('SIGNED_IN', session);
    }

    return { user, session };
  }

  async loginWithGoogle(): Promise<void> {
    logger.log('loginWithGoogle (mocked)');
    const response = await fetch(this.API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        action: 'googleLogin'
      })
    });

    if (!response.ok) {
      throw new Error('Mock Google login failed');
    }

    const { session } = await response.json();

    if (this.authStateCallback) {
      this.authStateCallback('SIGNED_IN', session);
    }
  }


  // Mock implementation for deleteUserById
  async deleteUserById(userId: string): Promise<{ error: any | null }> {
    logger.log(`deleteUserById (mocked) for user: ${userId}`, { apiUrl: this.API_URL });

    // Simulate API call
    const response = await fetch(this.API_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ action: 'deleteUser', userId }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      logger.error('Mock deleteUserById failed:', { status: response.status, error: errorText });
      return { error: { message: `Mock delete failed: ${errorText}` } };
    }

    // If the deleted user was the currently logged-in user, clear the session
    if (mockSessionStore?.user?.id === userId) {
      logger.log(`Deleted user ${userId} was the logged-in user. Clearing mock session.`);
      mockSessionStore = null;
      notifyAuthStateChange('SIGNED_OUT', null);
    }

    logger.info(`Mock deleteUserById successful for user: ${userId}`);
    return { error: null };
  }

  onAuthStateChange(callback: (event: AuthChangeEvent, session: Session | null) => Promise<void> | void) {
    logger.log('onAuthStateChange (mocked) - setting up listener');
    globalAuthStateCallback = callback; // Store the callback globally for this module

    // Immediately notify with the current state
    const currentSession = mockSessionStore ? { ...mockSessionStore } : null;
    const initialEvent: AuthChangeEvent = currentSession ? 'INITIAL_SESSION' : 'SIGNED_OUT';
    notifyAuthStateChange(initialEvent, currentSession);


    // Return a mock subscription object with an unsubscribe method
    return {
      data: {
        subscription: {
          unsubscribe: () => {
            logger.log('Mock auth state subscription unsubscribed');
            globalAuthStateCallback = null; // Clear the global callback
          }
        } as Subscription
      }
    };
  }
}
</file>

<file path="src/services/polly.service.ts">
import {
  Engine, 
  OutputFormat, 
  TextType,
  VoiceId,
  LanguageCode,
  PollyClient,
  SynthesizeSpeechCommand
} from "@aws-sdk/client-polly";
import { Readable } from 'stream';
import logger from '@/utils/logger';
import { ITTS } from '@/interfaces/tts.interface';
import { NodeHttpHandler } from "@aws-sdk/node-http-handler";
import { ProxyAgent } from 'proxy-agent';

export class PollyService implements ITTS {
  private pollyClient!: PollyClient;

  constructor() {
    this.initializePolly();
  }

  getVoice(voice: string): VoiceId {
    return VoiceId[voice as keyof typeof VoiceId];
  }

  private initializePolly(): void {
    this.validateEnvironment();
    
    const config = {
      region: process.env.AWS_POLLY_REGION,
      credentials: {
        accessKeyId: process.env.AWS_POLLY_ACCESS_KEY!,
        secretAccessKey: process.env.AWS_POLLY_SECRET_KEY!
      },
      requestHandler: process.env.HTTPS_PROXY 
        ? new NodeHttpHandler({
            httpAgent: new ProxyAgent(),
            httpsAgent: new ProxyAgent()
          })
        : undefined
    };

    this.pollyClient = new PollyClient(config);
  }

  public async synthesizeSpeech(text: string, language: string, voice: string): Promise<string> {
    try {
      const params = this.createSynthesisParams(text, language, voice);
      const command = new SynthesizeSpeechCommand(params);
      const response = await this.pollyClient.send(command);
      
      if (!response.AudioStream) {
        throw new Error('No audio stream received from Polly');
      }
      console.log('audio generated successfully', response.AudioStream);

      const buffer = await this.streamToBuffer(response.AudioStream as Readable);
      return buffer.toString('base64');
    } catch (error) {
      logger.error('Polly synthesis error:', error);
      throw new Error('Failed to synthesize speech');
    }
  }

  private createSynthesisParams(text: string, language: string, voice: string) {
    return {
      Text: text,
      LanguageCode: language as LanguageCode, // Cast to enum type
      VoiceId: voice as VoiceId, // Cast to enum type
      OutputFormat: OutputFormat.MP3,
      Engine: Engine.NEURAL,
      TextType: TextType.SSML
    };
  }

  private async streamToBuffer(stream: Readable): Promise<Buffer> {
    return new Promise((resolve, reject) => {
      const chunks: Uint8Array[] = [];
      stream.on('data', (chunk) => chunks.push(chunk));
      stream.on('error', reject);
      stream.on('end', () => resolve(Buffer.concat(chunks)));
    });
  }

  private validateEnvironment(): void {
    const requiredVars = [
      'AWS_POLLY_ACCESS_KEY',
      'AWS_POLLY_SECRET_KEY',
      'AWS_POLLY_REGION'
    ];

    const missingVars = requiredVars.filter(v => !process.env[v]);
    if (missingVars.length > 0) {
      throw new Error(`Missing required environment variables: ${missingVars.join(', ')}`);
    }
  }
}
</file>

<file path="src/services/supabase-auth.middleware.ts">
import { createServerClient } from '@supabase/ssr'
import { NextResponse, type NextRequest } from 'next/server'

export async function middleware(request: NextRequest) {
  let response = NextResponse.next({
    request: {
      headers: request.headers,
    },
  })

  const supabase = createServerClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
    {
      cookies: {
        get(name: string) {
          return request.cookies.get(name)?.value
        },
        set(name: string, value: string, options) {
          request.cookies.set({ name, value, ...options })
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          })
          response.cookies.set({ name, value, ...options })
        },
        remove(name: string, options) {
          request.cookies.set({ name, value: '', ...options })
          response = NextResponse.next({
            request: {
              headers: request.headers,
            },
          })
          response.cookies.set({ name, value: '', ...options })
        },
      },
    }
  )

  // Validate session before page loads
  const { data: { user } } = await supabase.auth.getUser()

  // Protect authenticated routes
  if (!user && request.nextUrl.pathname.startsWith('/app')) {
    return NextResponse.redirect(new URL('/app/login', request.url))
  }

  // Protect auth routes for logged-in users
  if (user && request.nextUrl.pathname.startsWith('/app/login')) {
    return NextResponse.redirect(new URL('/app/lessons', request.url))
  }

  return response
}

export const config = {
  matcher: [
    '/app/:path*', // Protect all app routes
    '/api/auth/:path*' // Protect auth API routes
  ]
}
</file>

<file path="src/services/tts.service.ts">
import { ITTS } from "@/interfaces/tts.interface";
import { getTtsVoiceId } from "@/utils/polly-voice.mapper.utli";

export class TTS {

  private ttsEngine: ITTS;
  constructor(ttsEngine: ITTS) {
    this.ttsEngine = ttsEngine;
  }

  public async generateAudio(text: string, language: string) {
    const voice = this.voiceToUse(language);
    return await this.ttsEngine.synthesizeSpeech(text, language, voice);
  }

  private voiceToUse(language: string) {
    return getTtsVoiceId(language);
  }
}
</file>

<file path="src/utils/supabase/client.ts">
import { createBrowserClient } from '@supabase/ssr'

export function createClient() {
  return createBrowserClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
  )
}
</file>

<file path="src/utils/cn.ts">
// src/lib/utils.ts
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge"

/**
 * Conditionally merges CSS class names.
 * Uses clsx to handle conditional classes and tailwind-merge to resolve conflicts.
 * @param inputs - Class names or conditional class objects.
 * @returns A string of merged class names.
 */
export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

// You can add other utility functions to this file as needed.
</file>

<file path="src/utils/constants.ts">
export const baseUrl = process.env.NEXT_PUBLIC_BASE_URL?.startsWith("http")
  ? process.env.NEXT_PUBLIC_BASE_URL
  : "https://lessay-app.vercel.app";
</file>

<file path="src/utils/google-basic-voices.util.ts">
export const mapLanguageToGoogleBasicVoice = (language: string): string => {
  const languageMap: Record<string, string> = {
   // European languages
   german: 'de-DE-Wavenet-F',
   french: 'fr-FR-Wavenet-A',
   spanish: 'es-ES-Wavenet-C',
   italian: 'it-IT-Wavenet-A',
   portuguese: 'pt-BR-Wavenet-A',
   dutch: 'nl-NL-Wavenet-B',
   polish: 'pl-PL-Wavenet-A',
   swedish: 'sv-SE-Wavenet-A',
   danish: 'da-DK-Wavenet-A',
   norwegian: 'nb-NO-Wavenet-E',
   finnish: 'fi-FI-Wavenet-A',
   czech: 'cs-CZ-Wavenet-A',
   slovak: 'sk-SK-Wavenet-A',
   hungarian: 'hu-HU-Wavenet-A',
   romanian: 'ro-RO-Wavenet-A',
   greek: 'el-GR-Wavenet-A',
   english: 'en-US-Chirp3-HD-Aoede',

   // Asian languages
   japanese: 'ja-JP-Wavenet-B',
   korean: 'ko-KR-Wavenet-A',
   chinese: 'cmn-CN-Wavenet-A', // Mandarin
   vietnamese: 'vi-VN-Wavenet-A',
   thai: 'th-TH-Wavenet-C',
   indonesian: 'id-ID-Wavenet-A',
   malay: 'ms-MY-Wavenet-A',
   hindi: 'hi-IN-Wavenet-A',
   tamil: 'ta-IN-Wavenet-A',
   bengali: 'bn-IN-Wavenet-A',

   // Middle Eastern languages
   arabic: 'ar-XA-Wavenet-B',
   turkish: 'tr-TR-Wavenet-A',
   hebrew: 'he-IL-Wavenet-A',
   persian: 'fa-IR-Wavenet-A',

   // Other languages
   russian: 'ru-RU-Wavenet-D',
   ukrainian: 'uk-UA-Wavenet-A',
   filipino: 'fil-PH-Wavenet-A',
   swahili: 'sw-KE-Wavenet-A',
  };

  // Convert to lowercase and remove any whitespace
  const normalizedLanguage = language.toLowerCase().trim();
  
  // Return the mapped code or default to English
  return languageMap[normalizedLanguage] || 'en-US-Chirp3-HD-F';
};
</file>

<file path="src/utils/google-hd-voices.util.ts">
export const mapLanguageToGoogleHDVoice = (language: string): string => {
  const languageMap: Record<string, string> = {
   // European languages
   german: 'de-DE-Chirp3-HD-Aoede',
   french: 'fr-FR-Chirp3-HD-Aoede',
   spanish: 'es-ES-Chirp3-HD-Aoede',
   italian: 'it-IT-Chirp3-HD-Aoede',
   portuguese: 'pt-BR-Chirp3-HD-Aoede',
   dutch: 'nl-NL-Chirp3-HD-Aoede',
   polish: 'pl-PL-Chirp3-HD-Aoede',
   swedish: 'sv-SE-Chirp3-HD-Aoede',
   danish: 'da-DK-Chirp3-HD-Aoede',
   norwegian: 'nb-NO-Chirp3-HD-Aoede',
   finnish: 'fi-FI-Chirp3-HD-Aoede',
   czech: 'cs-CZ-Chirp3-HD-Aoede',
   slovak: 'sk-SK-Chirp3-HD-Aoede',
   hungarian: 'hu-HU-Chirp3-HD-Aoede',
   romanian: 'ro-RO-Chirp3-HD-Aoede',
   greek: 'el-GR-Chirp3-HD-Aoede',
   english: 'en-US-Chirp3-HD-Aoede',
   // Asian languages
   japanese: 'ja-JP-Chirp3-HD-Aoede',
   korean: 'ko-KR-Chirp3-HD-Aoede',
   chinese: 'cmn-CN-Chirp3-HD-Aoede', // Mandarin
   vietnamese: 'vi-VN-Chirp3-HD-Aoede',
   thai: 'th-TH-Chirp3-HD-Aoede',
   indonesian: 'id-ID-Chirp3-HD-Aoede',
   malay: 'ms-MY-Chirp3-HD-Aoede',
   hindi: 'hi-IN-Chirp3-HD-Aoede',
   tamil: 'ta-IN-Chirp3-HD-Aoede',
   bengali: 'bn-IN-Chirp3-HD-Aoede',

   // Middle Eastern languages
   arabic: 'ar-XA-Chirp3-HD-Aoede',
   turkish: 'tr-TR-Chirp3-HD-Aoede',
   hebrew: 'he-IL-Chirp3-HD-Aoede',
   persian: 'fa-IR-Chirp3-HD-Aoede',

   // Other languages
   russian: 'ru-RU-Chirp3-HD-Aoede',
   ukrainian: 'uk-UA-Chirp3-HD-Aoede',
   filipino: 'fil-PH-Chirp3-HD-Aoede',
   swahili: 'sw-KE-Chirp3-HD-Aoede',
  };

  // Convert to lowercase and remove any whitespace
  const normalizedLanguage = language.toLowerCase().trim();
  
  // Return the mapped code or default to English
  return languageMap[normalizedLanguage] || 'en-US-Chirp3-HD-Aoede';
};
</file>

<file path="src/utils/map-language-to-code.util.ts">
export const mapLanguageToCode = (language: string): string => {
  const languageMap: Record<string, string> = {
    'german': 'de-DE',
    'english': 'en-US',
    'french': 'fr-FR',
    'spanish': 'es-ES',
    'italian': 'it-IT',
    'chinese': 'zh-CN',
    'japanese': 'ja-JP',
    'korean': 'ko-KR',
    // Add more mappings as needed
  };

  // Convert to lowercase and remove any whitespace
  const normalizedLanguage = language.toLowerCase().trim();
  
  // Return the mapped code or default to English
  return languageMap[normalizedLanguage] || 'en-US';
};
</file>

<file path="src/utils/metadata.ts">
import { Metadata } from "next";
const rawBaseUrl = process.env.NEXT_PUBLIC_BASE_URL;
const baseUrl =
  rawBaseUrl && rawBaseUrl.startsWith("http")
    ? rawBaseUrl
    : "https://lessay-app.vercel.app";


export const siteMetadata: Metadata = {
  metadataBase: new URL(baseUrl),
  title: {
    default: "lessay - AI-Powered Language Learning Platform",
    template: "%s | lessay - Smart Language Learning"
  },
  description: "Transform your language learning journey with lessay's AI-powered platform. Personalized lessons, adaptive learning, and efficient progress tracking for faster fluency.",
  keywords: [
    "language learning app",
    "AI language tutor",
    "adaptive learning platform",
    "personalized language lessons",
    "efficient language learning",
    "smart language app",
    "language fluency tool",
    "AI education platform",
    "language learning software",
    "custom language courses"
  ],
  authors: [{ name: "lessay" }],
  creator: "lessay",
  publisher: "lessay",
  formatDetection: {
    email: false,
    address: false,
    telephone: false,
  },
  verification: {
    google: "4dBatA2Gt_G8fuxhTD9jhkv6T6FBmD1jDdu1c6IztxQ"
  },
  openGraph: {
    title: "lessay - Smart Language Learning",
    description: "Revolutionary AI-driven platform for efficient language mastery",
    url: baseUrl,
    siteName: "lessay",
    images: [
      {
        url: `${baseUrl}/og-image.webp`,
        width: 1200,
        height: 630,
      }
    ],
    locale: "en_US",
    type: "website",
  },
  twitter: {
    card: "summary_large_image",
    title: "lessay - Learn Languages Smarter",
    description: "AI-powered adaptive language learning platform",
    images: [`${baseUrl}/og-image.webp`],
    creator: "@lessay_app"
  },
  robots: {
    index: true,
    follow: true,
    googleBot: {
      index: true,
      follow: true,
      "max-video-preview": -1,
      "max-image-preview": "large",
      "max-snippet": -1,
    }
  },
  icons: {
    icon: "/favicons/favicon.ico",
    shortcut: "/favicons/favicon-16x16.png",
    apple: "/favicons/apple-touch-icon.png",
  }
};
</file>

<file path="src/utils/phoneme-audio.cacher.util.ts">
import logger from "./logger";


export const getCacheKey = (cleanIpa: string, lang: string) => 
  `audio-${cleanIpa}-${lang}`.replace(/[^a-zA-Z0-9-]/g, '_');

export const getCachedAudio = (cleanIpa: string, lang: string) => {
  const key = getCacheKey(cleanIpa, lang);
  const cached = localStorage.getItem(key);
  if (!cached) return null;
  
  try {
    const { timestamp, data } = JSON.parse(cached);
    // Cache valid for 7 days
    if (Date.now() - timestamp > 604800000) return null;
    return data;
  } catch (error) {
    logger.error('Cache parse error:', error);
    return null;
  }
};

export const cacheAudio = async (cleanIpa: string, lang: string, audioUrl: string) => {
  try {
    const key = getCacheKey(cleanIpa, lang);
    const audioBlob = await fetch(audioUrl).then(res => res.blob());
    const reader = new FileReader();
    
    reader.onloadend = () => {
      const base64data = reader.result;
      if (typeof base64data === 'string') {
        localStorage.setItem(
          key,
          JSON.stringify({
            timestamp: Date.now(),
            data: base64data.split(',')[1] // Store only the data part
          })
        );
      }
    };
    
    reader.readAsDataURL(audioBlob);
  } catch (error) {
    logger.error('Caching failed:', error);
  }
};
</file>

<file path="src/utils/phoneme-audio.handler.util.ts">
import logger from "./logger";


export const fetchPollyAudio = async (ipa: string, language: string) => {
  try {
    const request = createRequestBody(ipa, language);
    const response = await fetch('/api/tts', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(request)
    });

    if (!response.ok) throw new Error('Failed to fetch audio');
    
    const audioBlob = await response.blob();
    return URL.createObjectURL(audioBlob);
  } catch (error) {
    logger.error('Polly audio fetch error:', error);
    throw error;
  }
};


const createRequestBody = (ipa: string, language: string) => {
  const text = `<speak><phoneme alphabet="ipa" ph="${ipa}">${ipa}</phoneme></speak>`;
  return {
    text: text,
    language: language,
  };
};
</file>

<file path="src/utils/polly-voice.mapper.utli.ts">
// Neural voices only - Updated 2024-03-01
// Full list: https://docs.aws.amazon.com/polly/latest/dg/voicelist.html
export const getTtsVoiceId = (language: string) => {
  const neuralVoices: Record<string, string> = {
    // Arabic
    'ar-AE': 'Hala',        // Female - Modern Standard Arabic
    'ar-SA': 'Zeina',       // Female - Modern Standard Arabic
    
    // Chinese
    'cmn-CN': 'Zhiyu',      // Female - Mandarin
    'yue-CN': 'Hiujin',     // Female - Cantonese
    
    // Dutch
    'nl-NL': 'Laura',       // Female - Dutch
    
    // English
    'en-AU': 'Olivia',      // Female - Australian English
    'en-GB': 'Amy',         // Female - British English
    'en-IN': 'Kajal',       // Female - Indian English
    'en-US': 'Joanna',      // Female - US English
    
    // French
    'fr-CA': 'Léa',         // Female - Canadian French
    'fr-FR': 'Céline',      // Female - French
    
    // German
    'de-DE': 'Vicki',       // Female - German
    
    // Hebrew
    'he-IL': 'Hagit',       // Female - Hebrew
    
    // Hindi
    'hi-IN': 'Kajal',       // Female - Hindi
    
    // Italian
    'it-IT': 'Bianca',      // Female - Italian
    
    // Japanese
    'ja-JP': 'Takumi',      // Male - Japanese
    
    // Korean
    'ko-KR': 'Seoyeon',     // Female - Korean
    
    // Norwegian
    'nb-NO': 'Ida',         // Female - Norwegian
    
    // Polish
    'pl-PL': 'Ola',         // Female - Polish
    
    // Portuguese
    'pt-BR': 'Camila',      // Female - Brazilian Portuguese
    'pt-PT': 'Inês',        // Female - European Portuguese
    
    // Romanian
    'ro-RO': 'Carmen',      // Female - Romanian
    
    // Russian
    'ru-RU': 'Tatyana',     // Female - Russian
    
    // Spanish
    'es-ES': 'Lucia',       // Female - European Spanish
    'es-MX': 'Mia',         // Female - Mexican Spanish
    'es-US': 'Lupe',        // Female - US Spanish
    
    // Swedish
    'sv-SE': 'Elin',        // Female - Swedish
    
    // Turkish
    'tr-TR': 'Filiz',       // Female - Turkish
    
    // Welsh
    'cy-GB': 'Gwyneth',     // Female - Welsh
  };

  return neuralVoices[language] || 'Joanna'; // Fallback to Joanna (en-US)
};
</file>

<file path="src/utils/retryWithOperation.ts">
import logger from '@/utils/logger';
import axios from 'axios';

export const retryOperation = async <T>(operation: () => Promise<T>, attempts = 3, delayMs = 1000): Promise<T> => {
  let lastError: unknown;
  for (let attempt = 0; attempt < attempts; attempt++) {
      try {
        return await operation();
      } catch (error) {

          // If it's a 429 error, propagate immediately.
      if (axios.isAxiosError(error) && error?.response?.data?.error?.code === 429) {
        throw error;
      }
        
        lastError = error;
        logger.error(`RecordingService operation failed, attempt ${attempt + 1} of ${attempts}.`, error);
        if (attempt < attempts - 1) {
          await new Promise(resolve => setTimeout(resolve, delayMs * (attempt + 1)));
        }
      }
    }
    throw lastError;
  }
</file>

<file path="src/utils/vercel_blob-upload.ts">
import { put } from '@vercel/blob';
import logger from '@/utils/logger';

export const uploadFile = async (file: Buffer, filename: string, contentType: string): Promise<string> => {
  try {
    const blob = await put(filename, file, {
      access: 'public',
      contentType,
    });
    logger.log(`File uploaded successfully: ${blob.url}`);
    return blob.url;
  } catch (error) {
    logger.error('Error uploading file:', error);
    throw error;
  }
};
</file>

<file path="src/middleware.ts">
import { NextResponse, type NextRequest } from 'next/server'
import { createSupabaseServerClient } from '@/utils/supabase/server'

export async function middleware(request: NextRequest) {
  const response = NextResponse.next()
  const supabase = await createSupabaseServerClient(request)
  const { data: { user } } = await supabase.auth.getUser()
  const path = request.nextUrl.pathname

  // Allow access to login page for unauthenticated users
  if (path === '/app/login') {
    if (user) {
      return NextResponse.redirect(new URL('/app/lessons', request.url))
    }
    return response
  }

  // Protect all other app routes
  if (!user && path.startsWith('/app')) {
    return NextResponse.redirect(new URL('/app/login', request.url))
  }

  return response
}

export const config = {
  matcher: [
    '/app/:path*',
    '/api/auth/:path*'
  ]
}
</file>

<file path="tests/components/Recording.test.tsx">
import React, { act } from 'react';
import { renderHook } from '@testing-library/react';
import {
  useRecordingContext,
  RecordingProvider,
} from '@/context/recording-context';
import {
  SubscriptionProvider,
  useSubscription,
} from '@/context/subscription-context';
import { ErrorProvider, useError } from '@/hooks/useError';
import { ReactNode } from 'react';
import { mockDetailedResponse, mockResponse } from '@/models/AiResponse.model';

// Mock dependencies
jest.mock('@/context/subscription-context', () => ({
  useSubscription: jest.fn(),
  SubscriptionProvider: ({ children }: { children: ReactNode }) => children,
}));

// At the top of the file, define a global mock function for showError
const mockShowError = jest.fn();

jest.mock('@/hooks/useError', () => ({
  useError: () => ({
    showError: mockShowError,
  }),
  // A simple pass-through ErrorProvider:
  ErrorProvider: ({ children }: { children: React.ReactNode }) => children,
}));
jest.mock('posthog-js');
jest.mock('@supabase/supabase-js');

// Add this mock implementation above your beforeEach blocks
const mockAuth = {
  signInWithPassword: jest
    .fn()
    .mockResolvedValue({ data: { user: null }, error: null }),
  signOut: jest.fn().mockResolvedValue({ error: null }),
};

const mockSupabase = {
  auth: mockAuth,
  // Add other Supabase services as needed
};

require('@supabase/supabase-js').createClient = jest.fn(() => mockSupabase);

beforeAll(() => {
  // jest.clearAllMocks();
  global.URL.createObjectURL = jest.fn().mockReturnValue('mocked-url');
  global.URL.revokeObjectURL = jest.fn();
});

// ★ Stub out MediaRecorder if not already defined in the test environment
if (!global.MediaRecorder) {
  global.MediaRecorder = class {
    state = 'inactive';
    ondataavailable: ((event: any) => void) | null = null;
    onstop: (() => void) | null = null;
    constructor(public stream: any, public options: any) {}
    start() {
      this.state = 'recording';
      // Optionally: you could add a timeout to simulate data coming in.
    }
    stop() {
      // Simulate returning nonempty audio data (thus blob size will be nonzero)
      if (this.ondataavailable) {
        this.ondataavailable({
          data: new Blob(['dummyData'], { type: 'audio/webm' }),
        });
      }
      this.state = 'inactive';
      if (this.onstop) {
        this.onstop();
      }
    }
  } as any;
}
if (typeof MediaRecorder.isTypeSupported !== 'function') {
  MediaRecorder.isTypeSupported = (mimeType: string) =>
    mimeType === 'audio/webm';
}

// ★ Stub out navigator.mediaDevices
const fakeStream = {
  getTracks: () => [{ stop: jest.fn() }],
};
Object.defineProperty(navigator, 'mediaDevices', {
  configurable: true,
  writable: true,
  value: {
    getUserMedia: jest.fn().mockResolvedValue(fakeStream),
    enumerateDevices: jest.fn().mockResolvedValue([{ kind: 'audioinput' }]),
  },
});

const originalGetUserMedia = navigator.mediaDevices.getUserMedia;

// Set up the subscription hook mock
const mockUseSubscription = useSubscription as jest.MockedFunction<
  typeof useSubscription
>;
const mockUseError = useError as jest.MockedFunction<typeof useError>;

// Wrap your hook with all providers
const wrapper = ({ children }: { children: ReactNode }) => (
  <ErrorProvider>
    <RecordingProvider>
      <SubscriptionProvider>{children}</SubscriptionProvider>
    </RecordingProvider>
  </ErrorProvider>
);

beforeEach(() => {
  mockUseSubscription.mockReturnValue({
    isSubscribed: false,
    isSubscribedBannerShowed: false,
    setIsSubscribedBannerShowed: jest.fn(),
    setIsSubscribed: jest.fn(),
    checkSubscription: jest.fn(),
    handleSubmit: jest.fn(),
    status: 'idle',
    email: '',
    setEmail: jest.fn(),
    errorMessage: '',
    setErrorMessage: jest.fn(),
  });
  localStorage.clear();
  jest.clearAllMocks();

  process.env.NEXT_PUBLIC_ENVIRONMENT = 'test';
});

describe('RecordingContext', () => {
  afterEach(() => {
    // restore the original getUserMedia to avoid affecting other tests
    navigator.mediaDevices.getUserMedia = originalGetUserMedia;
  });


  test('provides a valid recording context', () => {
    const { result } = renderHook(() => useRecordingContext(), { wrapper });
    expect(result.current).not.toBeNull();
  });
  test('should start recording and update isRecording', async () => {
    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    await act(async () => {
      result.current.startRecording();
    });
    expect(result.current).not.toBeNull();
    expect(result.current.isRecording).toBe(true);
  });
  test('should stop recording and update isRecording', async () => {
    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    await act(async () => {
      await result.current.startRecording();
    });
    expect(result.current.isRecording).toBe(true);
    await act(async () => {
      await result.current.stopRecording();
    });
    expect(result.current.isRecording).toBe(false);
  });
  test('resets recording state correctly', async () => {
    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    await act(async () => {
      await result.current.startRecording();
      await result.current.stopRecording();
      result.current.resetRecording();
    });

    expect(result.current.audioURL).toBeNull();
    expect(result.current.aiResponse).toBeNull();
    expect(result.current.detailedAiResponse).toBeNull();
    expect(result.current.isProcessed).toBe(false);
  });
  test('prevents recording when exceeding max attempts', async () => {
    const originalEnv = process.env.NEXT_PUBLIC_ENVIRONMENT;
    process.env.NEXT_PUBLIC_ENVIRONMENT = 'production';

    const { result } = renderHook(() => useRecordingContext(), { wrapper });
    // Set attempts to max allowed + 1
    await act(async () => {
      result.current.setRecordingAttempts(
        result.current.maxRecordingAttempts + 1
      );
    });

    await act(async () => {
      await result.current.startRecording();
    });

    expect(result.current.isRecording).toBe(false);
    expect(mockShowError).toHaveBeenCalledWith(
      expect.stringContaining('maximum number of recording attempts'),
      'warning'
    );
    process.env.NEXT_PUBLIC_ENVIRONMENT = originalEnv;
  });

  test('allows unlimited attempts for subscribed users', async () => {
    // Mock subscription to return true
    mockUseSubscription.mockReturnValue({
      ...mockUseSubscription(),
      isSubscribed: true,
    });

    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    // Set attempts to high number
    act(() => {
      result.current.setRecordingAttempts(999);
    });

    await act(async () => {
      await result.current.startRecording();
    });

    expect(result.current.isRecording).toBe(true);
  });

  test('auto-stops recording after max time', async () => {
    // Use modern fake timers and set the initial system time to 0.
    jest.useFakeTimers('modern' as any);
    jest.setSystemTime(0);

    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    // Start the recording.
    await act(async () => {
      await result.current.startRecording();
    });

    // (Optional) Verify that recording has started.
    expect(result.current.isRecording).toBe(true);

    // Advance timers by 10 minutes plus 10 seconds.
    await act(async () => {
      jest.advanceTimersByTime(600000 + 10000);
      // Run any pending timer callbacks.
      jest.runOnlyPendingTimers();
      // Flush pending microtasks.
      await Promise.resolve();
    });

    // The auto-stop logic should have been triggered, setting isRecording to false.
    expect(result.current.isRecording).toBe(false);

    // Restore real timers.
    jest.useRealTimers();
  });

  test('handles microphone permission denied error', async () => {
    // Mock getUserMedia to throw permission error

    const { result } = renderHook(() => useRecordingContext(), { wrapper });

    const permissionError = new Error('Permission denied');
    permissionError.name = 'NotAllowedError';
    navigator.mediaDevices.getUserMedia = jest
      .fn()
      .mockRejectedValue(permissionError);

    await act(async () => {
      await result.current.startRecording();
    });

    expect(result.current.isRecording).toBe(false);
    expect(mockShowError).toHaveBeenCalledWith(
      expect.stringContaining('Microphone access denied.'),
      'error'
    );
  });
});

describe('fetching the ai response', () => {
  let hookResult: any;

  beforeEach(() => {
    // Clear all mocks and storage
    jest.clearAllMocks();
    localStorage.clear();

    // Single hook render
    const renderedHook = renderHook(() => useRecordingContext(), { wrapper });
    hookResult = renderedHook.result as any;

    // Reset to known state
    act(() => {
      hookResult.current.resetRecording();
      hookResult.current.setRecordingAttempts(0);
    });
  });

  afterEach(() => {
    // Clean up any intervals
    if (hookResult.current) {
      act(() => {
        hookResult.current.stopRecording();
      });
    }
    jest.clearAllTimers();
  });

  test('sets audioURL after stopping recording', async () => {
    // const { result } = renderHook(() => useRecordingContext(), { wrapper });

    await act(async () => {
      await (hookResult.current as any).startRecording();
      await (hookResult.current as any).stopRecording();
    });

    expect((hookResult.current as any).audioURL).toBe('mocked-url');
    expect(global.URL.createObjectURL).toHaveBeenCalled();
  });

  test('handles API response for deep analysis', async () => {
    const mockResponse = { aiResponse: mockDetailedResponse };

    // Mock fetch response
    global.fetch = jest.fn().mockResolvedValue({
      ok: true,
      json: () => Promise.resolve(mockResponse),
    });

    // const { result } = renderHook(() => useRecordingContext(), { wrapper });

    // First, update deep analysis flag and allow state update to flush
    await act(async () => {
      (hookResult.current as any).setIsDeepAnalysis(true);
    });

    // Then start/stop the recording
    await act(async () => {
      await hookResult.current.startRecording();
      await hookResult.current.stopRecording();
    });

    expect(hookResult.current.isDeepAnalysis).toBe(true);
    expect(hookResult.current.detailedAiResponse).not.toBeNull();
    expect(hookResult.current.detailedAiResponse).toEqual(
      mockResponse.aiResponse
    );
  });

  test('handles API response for standard analysis', async () => {
    process.env.NEXT_PUBLIC_ENVIRONMENT = 'testing';

    const mockBaseResponse = { aiResponse: mockResponse };

    // Mock fetch response
    global.fetch = jest.fn().mockResolvedValue({
      ok: true,
      json: () => Promise.resolve(mockBaseResponse),
    });

    // Then start/stop the recording and flush pending updates
    await act(async () => {
      await hookResult.current.startRecording();
      await hookResult.current.stopRecording();
      // Let any async state updates finish
      await new Promise((resolve) => setTimeout(resolve, 0));
    });

    // Now assert that aiResponse is populated
    expect(hookResult.current.aiResponse).not.toBeNull();
    expect(hookResult.current.aiResponse).toEqual(mockBaseResponse.aiResponse);
  });
});
</file>

<file path="tests/routes/main.test.ts">
import { NextRequest } from 'next/server';
import { POST as TTS_POST } from '@/app/api/tts/route';
import { POST as RECORDING_POST } from '@/app/api/recording/route';
import { POST as SUBSCRIBE_POST } from '@/app/api/subscribe/route';

// Mock the services so we can control behavior in tests.
jest.mock('@/services/tts.service', () => {
  return {
    TTS: jest.fn().mockImplementation(() => ({
      generateAudio: jest.fn().mockResolvedValue(Buffer.from('audio'))
    }))
  };
});

// Replace the current supabase mock with a chainable queryBuilder.
// Move the queryBuilder declaration inside the factory callback to avoid referencing out-of-scope variables.
jest.mock('@/repositories/supabase/supabase', () => {
  const queryBuilder = {
    select: jest.fn().mockReturnThis(),
    eq: jest.fn(), // we will override this in each test.
    insert: jest.fn(),
    // Make our chain thenable by defining a then function.
    then: function (resolve: (value: unknown) => void) {
      return resolve(this);
    },
  };

  return {
    supabase: {
      from: jest.fn(() => queryBuilder),
      // Expose the query builder so that tests can override its methods:
      __queryBuilder: queryBuilder,
    },
  };
});

jest.mock('@/services/polly.service', () => {
  return {
    PollyService: jest.fn().mockImplementation(() => ({}))
  };
});

// jest.mock('@supabase/supabase-js');

describe('TTS API POST route', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  test('should return 400 for missing required fields', async () => {
    // Missing the "language" field.
    const req = new NextRequest('http://localhost/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: 'Hello' })
    });
    
    const res = await TTS_POST(req);
    expect(res.status).toBe(400);
    const data = await res.json();
    expect(data.message).toMatch(/Missing required fields/);
  });

  test('should return an audio buffer when valid input is provided', async () => {
    const req = new NextRequest('http://localhost/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: 'Hello', language: 'en' })
    });
    
    const res = await TTS_POST(req);
    expect(res.status).toBe(200);
    expect(res.headers.get('Content-Type')).toBe('audio/mpeg');
    // Expect the audio buffer to be nonempty.
    const arrayBuffer = await res.arrayBuffer();
    expect(arrayBuffer.byteLength).toBeGreaterThan(0);
  });

  test('should return a 500 error when generateAudio throws', async () => {
    // Override the TTS mock so that generateAudio rejects.
    const { TTS } = require('@/services/tts.service');
    TTS.mockImplementationOnce(() => ({
      generateAudio: jest.fn().mockRejectedValue(new Error('Generation failed'))
    }));

    const req = new NextRequest('http://localhost/api/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: 'Hello', language: 'en' })
    });
    
    const res = await TTS_POST(req);
    expect(res.status).toBe(500);
    const data = await res.json();
    expect(data.message).toBe('Phoneme generation failed');
    expect(data.error).toBe('Generation failed');
  });
});

jest.mock('@/services/recording.service', () => ({
  RecordingService: jest.fn().mockImplementation(() => ({
    uploadFile: jest.fn().mockResolvedValue('mock-uri'),
    submitRecording: jest.fn().mockResolvedValue({ mock: 'response' })
  }))
}));

describe('Recording API', () => {
  // Helper to create a fake NextRequest with form data.
  const mockFormDataRequest = async (body: Buffer, headers: globalThis.Headers) => {
    const req = new NextRequest('http://localhost/api/recording', {
      method: 'POST',
      headers,
      body
    });
    
    // For formidable parsing, set the Content-Type header to multipart/form-data with a boundary.
    req.headers.set('Content-Type', 'multipart/form-data; boundary=test');
    return req;
  };

  test('should reject invalid form data', async () => {
    const req = await mockFormDataRequest(Buffer.from('invalid content'), new Headers());
    const res = await RECORDING_POST(req);
    expect(res.status).toBe(400);
  });
});

describe('Subscription API', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  test('should return 400 for invalid email address', async () => {
    const req = new NextRequest('http://localhost/api/subscribe', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ email: 'invalid-email' }),
    });

    const res = await SUBSCRIBE_POST(req);
    expect(res.status).toBe(400);
    const data = await res.json();
    expect(data.message).toBe('Invalid email address');
  });

  test('should return 200 for existing email address', async () => {
    // Get our mocked supabase.
    const { supabase } = require('@/repositories/supabase/supabase');

    // Override the chain for the email lookup.
    // Note that in the route, the chain is: supabase.from(...).select('*').eq('email', email)
    // Because our from() returns queryBuilder (the same object), we call .select() (which returns queryBuilder too)
    // and then override eq() to return a promise resolving with the desired value.
    supabase.from().eq.mockResolvedValue({ data: [{ email: 'test@example.com' }] });
    
    const req = new NextRequest('http://localhost/api/subscribe', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ email: 'test@example.com' }),
    });

    const res = await SUBSCRIBE_POST(req);
    expect(res.status).toBe(200);
    const data = await res.json();
    expect(data.message).toBe('Email already exists');
  });

  test('should return 200 for successful subscription', async () => {
      // Get the mocked supabase.
      const { supabase } = require('@/repositories/supabase/supabase');
      // Simulate no existing email.
      supabase.__queryBuilder.eq.mockResolvedValue({ data: [] });
      // Simulate a successful insertion.
      supabase.__queryBuilder.insert.mockResolvedValue({ error: null });
  
      const req = new NextRequest('http://localhost/api/subscribe', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ email: 'new@example.com' }),
      });
  
      const res = await SUBSCRIBE_POST(req);
      expect(res.status).toBe(200);
      const data = await res.json();
      expect(data.message).toBe('Subscription successful');
  });

  test('should return 500 for Supabase insertion error', async () => {
    // Mock Supabase to simulate an insertion error
    const { supabase } = require('@/repositories/supabase/supabase');
    supabase.__queryBuilder.eq.mockResolvedValue({ data: [] }); // No existing email
    supabase.__queryBuilder.insert.mockResolvedValue({ error: new Error('Supabase error') });

    const req = new NextRequest('http://localhost/api/subscribe', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ email: 'error@example.com' }),
    });

    const res = await SUBSCRIBE_POST(req);
    expect(res.status).toBe(500);
    const data = await res.json();
    expect(data.message).toBe('Supabase error');
  });
});
</file>

<file path="tests/servises/ai-service.test.ts">
import RecordingService from '@/services/recording.service';
import AIService from '@/services/ai.service';
import MessageGenerator from '@/services/generators/messageGenerator';
import MetricsService from '@/services/metrics.service';
import { mockDeep } from 'jest-mock-extended';

// Mock dependencies
jest.mock('@/services/ai.service');
jest.mock('@/services/generators/messageGenerator');
jest.mock('@/services/metrics.service');
// jest.mock('@/repositories/supabase/supabase');

jest.mock('@/repositories/supabase/supabase', () => {
  const queryBuilder = {
    select: jest.fn().mockReturnThis(),
    eq: jest.fn(), // we will override this in each test.
    insert: jest.fn(),
    // Make our chain thenable by defining a then function.
    then: function (resolve: (value: unknown) => void) {
      return resolve(this);
    },
  };

  return {
    supabase: {
      from: jest.fn(() => queryBuilder),
      // Expose the query builder so that tests can override its methods:
      __queryBuilder: queryBuilder,
    },
  };
});


describe('RecordingService', () => {
  let recordingService: RecordingService;
  let mockAIService: jest.Mocked<AIService>;
  let mockMessageGenerator: jest.Mocked<MessageGenerator>;
  let mockMetricsService: jest.Mocked<MetricsService>;

  beforeEach(() => {
    mockAIService = mockDeep<AIService>();
    mockMessageGenerator = mockDeep<MessageGenerator>();
    mockMetricsService = mockDeep<MetricsService>();

    (AIService as jest.Mock).mockImplementation(() => mockAIService);
    (MessageGenerator as jest.Mock).mockImplementation(() => mockMessageGenerator);
    (MetricsService as jest.Mock).mockImplementation(() => mockMetricsService);

    recordingService = new RecordingService();
  });

  afterEach(() => {
    jest.clearAllMocks();
  });

  describe('uploadFile', () => {
    it('should delegate to AIService uploadFile with correct parameters', async () => {
      const testBuffer = Buffer.from('test');
      const mockUri = 'gs://mock-file-uri';
      mockAIService.uploadFile.mockResolvedValue(mockUri);

      const result = await recordingService.uploadFile(testBuffer, 'audio/mpeg', 'test.mp3');

      expect(mockAIService.uploadFile).toHaveBeenCalledWith(
        testBuffer,
        'audio/mpeg',
        'test.mp3'
      );
      expect(result).toBe(mockUri);
    });
  });

  describe('submitRecording', () => {
    const mockFileUri = 'gs://mock-file-uri';
    const mockResponse = { analysis: 'test' };

    beforeEach(() => {
      mockAIService.generateContent.mockResolvedValue(mockResponse);
      mockMessageGenerator.generatePersonalizedPrompts.mockReturnValue({
        userPrompt: 'test user',
        systemPrompt: 'test system'
      });
      mockMessageGenerator.generateTargetLanguageDetectionPrompt.mockReturnValue({
        userPrompt: 'detect lang',
        systemPrompt: 'system lang'
      });
    });

    it('should complete full analysis flow successfully', async () => {
      const result = await recordingService.submitRecording(
        '192.168.0.1',
        mockFileUri,
        1000,
        1024,
        true
      );

      expect(mockAIService.generateContent).toHaveBeenCalled();
      expect(mockMetricsService.collectInteractionData).toHaveBeenCalledWith(
        '192.168.0.1',
        mockFileUri,
        mockResponse,
        1000,
        expect.any(Number),
        1024,
        expect.anything()
      );
      expect(result).toEqual(mockResponse);
    });

    it('should fallback to flash model when pro model fails', async () => {
      const error = new Error('Model overloaded');
      
      mockAIService.generateContent
        .mockRejectedValueOnce(error)
        .mockResolvedValueOnce(mockResponse);

      const result = await recordingService.submitRecording(
        '192.168.0.1',
        mockFileUri,
        1000,
        1024,
        true
      );

      expect(mockAIService.generateContent).toHaveBeenCalledTimes(3);
      expect(result).toEqual(mockResponse);
    });
  });

  describe('detectTargetLanguage', () => {
    it.only('should call AI service with language detection prompts', async () => {
      const mockResponse = { language: 'en' };
   
      mockMessageGenerator.generateTargetLanguageDetectionPrompt.mockReturnValue({
        userPrompt: 'detect lang',
        systemPrompt: 'system lang'
      });
      mockAIService.generateContent.mockResolvedValue(mockResponse);
      const result = await recordingService['detectTargetLanguage']('gs://test-uri');

      expect(mockMessageGenerator.generateTargetLanguageDetectionPrompt).toHaveBeenCalled();
      expect(mockAIService.generateContent).toHaveBeenCalledWith(
        'gs://test-uri',
        expect.any(String),
        expect.any(String),
        expect.any(String)
      );
      expect(result).toEqual(mockResponse);
    });
  });
});
</file>

<file path="tests/servises/auth-context.test.tsx">
// File: /tests/servises/auth-context.test.tsx

import React from 'react';
import { render, screen, act, waitFor } from '@testing-library/react';
import '@testing-library/jest-dom';
import { AuthProvider, useAuth } from '@/context/auth-context';
import * as AuthActions from '@/lib/server-actions/auth-actions';
import { useRouter } from 'next/navigation';
import { createClient } from '@/utils/supabase/client';
import { Session, User, AuthError } from '@supabase/supabase-js';

// --- Mocks ---

// Mock Next.js Router
jest.mock('next/navigation', () => ({
  useRouter: jest.fn(),
}));
const mockRouterPush = jest.fn();
const mockRouterReplace = jest.fn();
(useRouter as jest.Mock).mockReturnValue({
  push: mockRouterPush,
  replace: mockRouterReplace,
  prefetch: jest.fn(), // Add other methods if needed
  back: jest.fn(),
  forward: jest.fn(),
  refresh: jest.fn(),
  // Add any other properties/methods your component might use
});

// Mock Server Actions
jest.mock('@/lib/server-actions/auth-actions', () => ({
  getSessionAction: jest.fn(),
  loginAction: jest.fn(),
  registerAction: jest.fn(),
  loginWithGoogleAction: jest.fn(),
  logoutAction: jest.fn(),
}));

// Mock Supabase Client and Auth State Change
const mockUnsubscribe = jest.fn();
const mockOnAuthStateChange = jest.fn(() => ({
  data: { subscription: { unsubscribe: mockUnsubscribe } },
}));
const mockSupabaseClient = {
  auth: {
    onAuthStateChange: mockOnAuthStateChange,
  },
};
jest.mock('@/utils/supabase/client', () => ({
  createClient: jest.fn(() => mockSupabaseClient),
}));

// Mock UserProfileProvider (simple pass-through)
jest.mock('@/context/user-profile-context', () => ({
  UserProfileProvider: ({ children }: { children: React.ReactNode }) => <>{children}</>,
}));

// Mock Logger
jest.mock('@/utils/logger', () => ({
  log: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  info: jest.fn(),
}));

// --- Helper Components ---

// A simple component to display auth state for testing
const TestComponent = () => {
  const { user, session, loading, error, login, register, logout, loginWithGoogle, clearError } = useAuth();

  return (
    <div>
      <div data-testid="loading">{loading ? 'Loading...' : 'Loaded'}</div>
      <div data-testid="user">{user ? `User: ${user.id}` : 'No User'}</div>
      <div data-testid="session">{session ? `Session: ${session.access_token}` : 'No Session'}</div>
      <div data-testid="error">{error ? `Error: ${error}` : 'No Error'}</div>
      <button onClick={() => login('test@test.com', 'password')}>Login</button>
      <button onClick={() => register('new@test.com', 'password')}>Register</button>
      <button onClick={() => logout()}>Logout</button>
      <button onClick={() => loginWithGoogle()}>Login Google</button>
      <button onClick={() => clearError()}>Clear Error</button>
    </div>
  );
};

// --- Test Data ---
const mockUser: User = {
  id: 'user-123',
  app_metadata: {},
  user_metadata: {},
  aud: 'authenticated',
  created_at: new Date().toISOString(),
};

const mockSession: Session = {
  access_token: 'mock-access-token',
  refresh_token: 'mock-refresh-token',
  user: mockUser,
  expires_in: 3600,
  token_type: 'bearer',
};

const mockAuthError: AuthError = {
    name: 'AuthApiError',
    message: 'Invalid credentials',
    status: 400,
};


// --- Test Suite ---

describe('AuthProvider', () => {
  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();
    (useRouter as jest.Mock).mockReturnValue({ push: mockRouterPush, replace: mockRouterReplace });
    // Default mock implementations
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(null); // Start with no session
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({ data: { user: null, session: null }, error: null });
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({ data: { user: null, session: null }, error: null });
    (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: null });
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: null });
    mockOnAuthStateChange.mockImplementation((callback) => {
        // Store the callback to simulate events later if needed
        (mockOnAuthStateChange as any).callback = callback;
        return { data: { subscription: { unsubscribe: mockUnsubscribe } } };
    });
  });

  it('should initialize with loading state and fetch session', async () => {
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Initially loading
    expect(screen.getByTestId('loading')).toHaveTextContent('Loading...');
    expect(AuthActions.getSessionAction).toHaveBeenCalledTimes(1);

    // Wait for session to load
    await waitFor(() => {
      expect(screen.getByTestId('loading')).toHaveTextContent('Loaded');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle session fetch error', async () => {
    const sessionError = new Error('Failed to fetch session');
    (AuthActions.getSessionAction as jest.Mock).mockRejectedValue(sessionError);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => {
      expect(screen.getByTestId('loading')).toHaveTextContent('Loaded');
      expect(screen.getByTestId('user')).toHaveTextContent('No User');
      expect(screen.getByTestId('session')).toHaveTextContent('No Session');
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${sessionError.message}`);
    });
  });

  it('should handle successful login', async () => {
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({
      data: { user: mockUser, session: mockSession },
      error: null,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for initial load
    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Trigger login
    await act(async () => {
      screen.getByRole('button', { name: 'Login' }).click();
    });

    // Check state after login
    await waitFor(() => {
      expect(AuthActions.loginAction).toHaveBeenCalledWith('test@test.com', 'password');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
      expect(mockRouterPush).toHaveBeenCalledWith('/app/lessons');
    });
  });

  it('should handle failed login', async () => {
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({
        data: { user: null, session: null },
        error: mockAuthError,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Login' }).click();
    });

    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${mockAuthError.message}`);
    });
    expect(AuthActions.loginAction).toHaveBeenCalledWith('test@test.com', 'password');
    expect(screen.getByTestId('user')).toHaveTextContent('No User');
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
    expect(mockRouterPush).not.toHaveBeenCalled();

  });

  it('should handle successful registration', async () => {
    const newUser = { ...mockUser, id: 'new-user-456' };
    const newSession = { ...mockSession, user: newUser, access_token: 'new-access-token' };
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({
      data: { user: newUser, session: newSession },
      error: null,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Register' }).click();
    });

    await waitFor(() => {
      expect(AuthActions.registerAction).toHaveBeenCalledWith('new@test.com', 'password');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${newUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${newSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
      expect(mockRouterPush).toHaveBeenCalledWith('/app/onboarding'); // Check onboarding redirect
    });
  });

  it('should handle failed registration', async () => {
    // Arrange: Mock the action to return an error
    const registerError: AuthError = { name: 'AuthApiError', message: 'User already exists', status: 409 };
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({
        data: { user: null, session: null },
        error: registerError,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Act: Trigger the register action
    await act(async () => {
      screen.getByRole('button', { name: 'Register' }).click();
    });

    // Assert: Wait for the error message state update
    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${registerError.message}`);
    });

    // Assert: Check other state aspects
    expect(AuthActions.registerAction).toHaveBeenCalledWith('new@test.com', 'password');
    expect(screen.getByTestId('user')).toHaveTextContent('No User');
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
    expect(mockRouterPush).not.toHaveBeenCalled();
  });



  it('should handle successful logout', async () => {
    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: null });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for initial login state
    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    // Trigger logout
    await act(async () => {
      screen.getByRole('button', { name: 'Logout' }).click();
    });

    // Check state after logout
    await waitFor(() => {
      expect(AuthActions.logoutAction).toHaveBeenCalledTimes(1);
      expect(screen.getByTestId('user')).toHaveTextContent('No User');
      expect(screen.getByTestId('session')).toHaveTextContent('No Session');
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle failed logout', async () => {
    const logoutError: AuthError = { name: 'AuthApiError', message: 'Logout failed', status: 500 };
    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: logoutError });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    await act(async () => {
        screen.getByRole('button', { name: 'Logout' }).click();
    });

    await waitFor(() => {
      expect(AuthActions.logoutAction).toHaveBeenCalledTimes(1);
      // User/session might still be set if logout fails server-side but client doesn't clear
      // However, the provider *does* clear them optimistically before checking error in the `finally`
      // Let's check if the error is set
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${logoutError.message}`);
      // State might still be logged in if only error is set
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
    });
  });

  it('should call loginWithGoogle action', async () => {
     (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: null });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Login Google' }).click();
    });

    await waitFor(() => {
        expect(AuthActions.loginWithGoogleAction).toHaveBeenCalledTimes(1);
        // State shouldn't change immediately, relies on redirect and onAuthStateChange
        expect(screen.getByTestId('user')).toHaveTextContent('No User');
        expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle error from loginWithGoogle action', async () => {
    // Arrange: Mock the action to return an error
    const googleError: AuthError = { name: 'AuthApiError', message: 'Google Auth Failed', status: 500 };
    (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: googleError });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Act: Trigger the google login action
    await act(async () => {
      screen.getByRole('button', { name: 'Login Google' }).click();
    });

    // Assert: Wait for the error message state update
    await waitFor(() => {
        expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${googleError.message}`);
    });

    // Assert: Check other state aspects
    expect(AuthActions.loginWithGoogleAction).toHaveBeenCalledTimes(1);
    expect(screen.getByTestId('user')).toHaveTextContent('No User'); // State shouldn't change here
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
  });

  it('should clear error when clearError is called', async () => {
    const sessionError = new Error('Initial Error');
    (AuthActions.getSessionAction as jest.Mock).mockRejectedValue(sessionError);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for error to appear
    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${sessionError.message}`);
    });

    // Click clear error
    await act(async () => {
      screen.getByRole('button', { name: 'Clear Error' }).click();
    });

    // Check error is cleared
    expect(screen.getByTestId('error')).toHaveTextContent('No Error');
  });

  it('should update state on SIGNED_IN auth state change', async () => {
    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));
    expect(screen.getByTestId('user')).toHaveTextContent('No User');

    // Simulate Supabase firing the event
    await act(async () => {
      const callback = (mockOnAuthStateChange as any).callback;
      if (callback) {
        callback('SIGNED_IN', mockSession);
      }
    });

    await waitFor(() => {
        expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
        expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
    });
  });

  it('should update state and redirect on SIGNED_OUT auth state change when on /app', async () => {
     // Mock window.location
     const originalLocation = window.location;
     delete (window as any).location;
     window.location = { ...originalLocation, pathname: '/app/somepage' };

    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    // Simulate Supabase firing the event
    await act(async () => {
      const callback = (mockOnAuthStateChange as any).callback;
      if (callback) {
        callback('SIGNED_OUT', null);
      }
    });

    await waitFor(() => {
        expect(screen.getByTestId('user')).toHaveTextContent('No User');
        expect(screen.getByTestId('session')).toHaveTextContent('No Session');
        expect(mockRouterReplace).toHaveBeenCalledWith('/app/login');
    });

     // Restore window.location
     window.location = originalLocation;
  });

   it('should unsubscribe from auth state changes on unmount', () => {
    const { unmount } = render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    expect(mockOnAuthStateChange).toHaveBeenCalledTimes(1);
    expect(mockUnsubscribe).not.toHaveBeenCalled();

    unmount();

    expect(mockUnsubscribe).toHaveBeenCalledTimes(1);
  });

   it('useAuth should throw error when used outside AuthProvider', () => {
    // Hide console.error output for this specific test
    const consoleErrorSpy = jest.spyOn(console, 'error').mockImplementation(() => {});

    const ErrorComponent = () => {
        try {
            useAuth();
        } catch (e: any) {
            return <div>Error: {e.message}</div>;
        }
        return <div>No error</div>;
    };

    render(<ErrorComponent />);

    expect(screen.getByText('Error: useAuth must be used within an AuthProvider')).toBeInTheDocument();

    // Restore console.error
    consoleErrorSpy.mockRestore();
  });

});
</file>

<file path="tests/servises/auth-service.test.ts">
// File: /tests/lib/server-actions/auth-actions.test.ts

import {
  loginAction,
  registerAction,
  loginWithGoogleAction,
  logoutAction,
  getSessionAction,
} from '@/lib/server-actions/auth-actions';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import logger from '@/utils/logger';
import { Session, User, AuthError } from '@supabase/supabase-js';

// --- Mocks ---
jest.mock('@/utils/supabase/server', () => ({
  createSupabaseServerClient: jest.fn(),
}));

jest.mock('@/utils/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  log: jest.fn(),
}));

// Mock environment variables
const mockSiteUrl = 'http://localhost:3000';
process.env.NEXT_PUBLIC_SITE_URL = mockSiteUrl;

// --- Test Suite ---
describe('Auth Server Actions', () => {
  let mockSupabaseClient: any;
  let mockAuth: any;

  const mockUser = { id: 'user-123', email: 'test@example.com' } as User;
  const mockSession = {
    access_token: 'abc',
    refresh_token: 'def',
    user: mockUser,
    expires_in: 3600,
    token_type: 'bearer',
  } as Session;

  // Use plain objects for mock errors to avoid instanceof issues with mocked classes
  const mockAuthError = {
    name: 'AuthApiError', // Supabase errors often have this name
    message: 'Invalid credentials',
    status: 400,
  } as AuthError; // Cast for type checking

  const registerError = {
    name: 'AuthApiError',
    message: 'User already registered',
    status: 400,
  } as AuthError;

  const googleError = {
    name: 'AuthApiError',
    message: 'OAuth provider error',
    status: 500,
  } as AuthError;

  const logoutError = {
    name: 'AuthApiError',
    message: 'Logout failed',
    status: 500,
  } as AuthError;

  const sessionError = {
    name: 'AuthApiError',
    message: 'Failed to get session',
    status: 500,
  } as AuthError;

  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();

    // Setup the mock Supabase client and its auth methods
    mockAuth = {
      signInWithPassword: jest.fn(),
      signUp: jest.fn(),
      signInWithOAuth: jest.fn(),
      signOut: jest.fn(),
      getSession: jest.fn(),
    };
    mockSupabaseClient = {
      auth: mockAuth,
    };

    // Configure the mock factory to return our mock client
    (createSupabaseServerClient as jest.Mock).mockResolvedValue(mockSupabaseClient);
  });

  // --- loginAction ---
  describe('loginAction', () => {
    it('should call createSupabaseServerClient and supabase.auth.signInWithPassword', async () => {
      mockAuth.signInWithPassword.mockResolvedValueOnce({
        data: { user: mockUser, session: mockSession },
        error: null,
      });
      await loginAction('test@example.com', 'password123');
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockAuth.signInWithPassword).toHaveBeenCalledWith({
        email: 'test@example.com',
        password: 'password123',
      });
    });

    it('should return user and session data on successful login', async () => {
      const expectedData = { user: mockUser, session: mockSession };
      mockAuth.signInWithPassword.mockResolvedValueOnce({
        data: expectedData,
        error: null,
      });
      const result = await loginAction('test@example.com', 'password123');
      expect(result).toEqual({ data: expectedData, error: null });
    });

    it('should return error and log it if supabase login fails', async () => {
      mockAuth.signInWithPassword.mockResolvedValueOnce({
        data: { user: null, session: null },
        error: mockAuthError,
      });
      const result = await loginAction('test@example.com', 'password123');
      expect(result).toEqual({ data: { user: null, session: null }, error: mockAuthError });
      expect(logger.error).toHaveBeenCalledWith('Login error:', mockAuthError);
    });
  });

  // --- registerAction ---
  describe('registerAction', () => {
    it('should call createSupabaseServerClient and supabase.auth.signUp', async () => {
      mockAuth.signUp.mockResolvedValueOnce({
        data: { user: mockUser, session: mockSession },
        error: null,
      });
      await registerAction('new@example.com', 'newpassword');
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockAuth.signUp).toHaveBeenCalledWith({
        email: 'new@example.com',
        password: 'newpassword',
      });
    });

    it('should return user and session data on successful registration', async () => {
      const expectedData = { user: mockUser, session: mockSession };
      mockAuth.signUp.mockResolvedValueOnce({
        data: expectedData,
        error: null,
      });
      const result = await registerAction('new@example.com', 'newpassword');
      expect(result).toEqual({ data: expectedData, error: null });
    });

    it('should return error and log it if supabase registration fails', async () => {
      mockAuth.signUp.mockResolvedValueOnce({
        data: { user: null, session: null },
        error: registerError,
      });
      const result = await registerAction('new@example.com', 'newpassword');
      expect(result).toEqual({ data: { user: null, session: null }, error: registerError });
      expect(logger.error).toHaveBeenCalledWith('Registration error:', registerError);
    });
  });

  // --- loginWithGoogleAction ---
  describe('loginWithGoogleAction', () => {
    it('should call createSupabaseServerClient and supabase.auth.signInWithOAuth', async () => {
      mockAuth.signInWithOAuth.mockResolvedValueOnce({ data: {}, error: null });
      await loginWithGoogleAction();
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockAuth.signInWithOAuth).toHaveBeenCalledWith({
        provider: 'google',
        options: {
          redirectTo: `${mockSiteUrl}/app/lessons`,
        },
      });
    });

    it('should return { error: null } on successful initiation', async () => {
       mockAuth.signInWithOAuth.mockResolvedValueOnce({ data: {}, error: null });
       const result = await loginWithGoogleAction();
       expect(result).toEqual({ error: null });
    });


    it('should return error and log it if supabase Google login fails', async () => {
      mockAuth.signInWithOAuth.mockResolvedValueOnce({ data: {}, error: googleError });
      const result = await loginWithGoogleAction();
      expect(result).toEqual({ error: googleError });
      expect(logger.error).toHaveBeenCalledWith('Google login error:', googleError);
    });
  });

  // --- logoutAction ---
  describe('logoutAction', () => {
    it('should call createSupabaseServerClient and supabase.auth.signOut', async () => {
      mockAuth.signOut.mockResolvedValueOnce({ error: null });
      await logoutAction();
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockAuth.signOut).toHaveBeenCalledTimes(1);
    });

     it('should return { error: null } on successful logout', async () => {
       mockAuth.signOut.mockResolvedValueOnce({ error: null });
       const result = await logoutAction();
       expect(result).toEqual({ error: null });
    });

    it('should return error and log it if supabase logout fails', async () => {
      mockAuth.signOut.mockResolvedValueOnce({ error: logoutError });
      const result = await logoutAction();
      expect(result).toEqual({ error: logoutError });
      expect(logger.error).toHaveBeenCalledWith('Logout error:', logoutError);
    });
  });

  // --- getSessionAction ---
  describe('getSessionAction', () => {
    it('should call createSupabaseServerClient and supabase.auth.getSession', async () => {
      mockAuth.getSession.mockResolvedValueOnce({
        data: { session: mockSession },
        error: null,
      });
      await getSessionAction();
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockAuth.getSession).toHaveBeenCalledTimes(1);
    });

    it('should return the session on success', async () => {
      mockAuth.getSession.mockResolvedValueOnce({
        data: { session: mockSession },
        error: null,
      });
      const result = await getSessionAction();
      expect(result).toEqual(mockSession);
    });

    it('should return null if no session exists', async () => {
      mockAuth.getSession.mockResolvedValueOnce({
        data: { session: null },
        error: null,
      });
      const result = await getSessionAction();
      expect(result).toBeNull();
    });

    it('should return null and log error if supabase getSession fails', async () => {
      mockAuth.getSession.mockResolvedValueOnce({
        data: { session: null },
        error: sessionError,
      });
      const result = await getSessionAction();
      expect(result).toBeNull();
      expect(logger.error).toHaveBeenCalledWith('Get session error:', sessionError);
    });
  });
});
</file>

<file path="tests/servises/lesson-service.test.ts">
// File: tests/services/lesson.service.test.ts

import { mockDeep, MockProxy } from 'jest-mock-extended';
import LessonService from '@/services/lesson.service';
import {
  ILessonRepository,
  IOnboardingRepository,
} from '@/lib/interfaces/all-interfaces';
import { ILessonGeneratorService } from '@/services/lesson-generator.service';
import RecordingService from '@/services/recording.service';
import LearningProgressService from '@/services/learning-progress.service';
import { LearningProgressRepository } from '@/repositories/learning-progress.repository';
import {
  LessonModel,
  LessonStep,
  OnboardingModel,
  AudioMetrics,
  AssessmentLesson,
  LearningProgressModel,
  AdaptiveLessonGenerationRequest,
} from '@/models/AppAllModels.model';
import {
  ProficiencyLevel,
  LessonStepType,
  LearningTrajectory,
  MasteryLevel,
} from '@prisma/client';
import logger from '@/utils/logger';
import { mockAudioMetrics } from '@/__mocks__/generated-audio-metrics.mock'; // Assuming this mock exists

// --- Mock Dependencies ---
jest.mock('@/utils/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  debug: jest.fn(),
  log: jest.fn(),
}));

// Mock services/repositories instantiated internally or dependencies of internal services
jest.mock('@/services/recording.service');
jest.mock('@/services/learning-progress.service');
jest.mock('@/repositories/learning-progress.repository'); // Mock the repo used by LearningProgressService
jest.mock('@supabase/supabase-js');

const mockAuth = {
  signInWithPassword: jest
    .fn()
    .mockResolvedValue({ data: { user: null }, error: null }),
  signOut: jest.fn().mockResolvedValue({ error: null }),
};

const mockSupabase = {
  auth: mockAuth,
  // Add other Supabase services as needed
};

describe('LessonService', () => {
  let lessonService: LessonService;
  let mockLessonRepository: MockProxy<ILessonRepository>;
  let mockLessonGeneratorService: MockProxy<ILessonGeneratorService>;
  let mockOnboardingRepository: MockProxy<IOnboardingRepository>;
  let MockRecordingService: jest.MockedClass<typeof RecordingService>;
  let MockLearningProgressService: jest.MockedClass<
    typeof LearningProgressService
  >;
  let MockLearningProgressRepository: jest.MockedClass<
    typeof LearningProgressRepository
  >;
  let generateInitialLessonsSpy: jest.SpyInstance;

  // --- Mock Data ---
  const userId = 'test-user-id';
  const lessonId = 'lesson-123';
  const stepId = 'step-abc';
  const onboardingId = 'onboarding-xyz';

  const assessmentId = 'assessment-abc';

  const mockLessonStep: LessonStep = {
    id: stepId,
    lessonId: lessonId,
    stepNumber: 1,
    type: 'practice',
    content: 'Say Hello',
    translation: 'Sag Hallo',
    expectedAnswer: 'Hello',
    attempts: 0,
    maxAttempts: 3,
    correct: false,
    errorPatterns: [],
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  const mockLesson: LessonModel = {
    id: lessonId,
    userId: userId,
    lessonId: 'gen-lesson-1',
    focusArea: 'Greetings',
    targetSkills: ['Vocabulary', 'Pronunciation'],
    steps: [
      mockLessonStep,
      {
        ...mockLessonStep,
        id: 'step-def',
        stepNumber: 2,
        type: 'feedback',
        expectedAnswer: null,
      },
    ],
    performanceMetrics: null,
    audioMetrics: null,
    completed: false,
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  const mockCompletedLesson: LessonModel = {
    ...mockLesson,
    completed: true,
    performanceMetrics: {
      accuracy: 80,
      pronunciationScore: 75,
      grammarScore: 85,
      vocabularyScore: 88,
      overallScore: 82,
      strengths: ['basic vocab'],
      weaknesses: ['word order'],
      summary: 'Good progress',
      nextLessonSuggestions: ['Next Topic'],
      errorPatterns: ['word order issue'],
    },
  };

  const mockOnboarding: OnboardingModel = {
    id: onboardingId,
    userId: userId,
    steps: {},
    completed: true, // Assume onboarding is complete for most lesson actions
    learningPurpose: 'travel',
    nativeLanguage: 'English',
    targetLanguage: 'German',
    proficiencyLevel: ProficiencyLevel.beginner,
    initialAssessmentCompleted: false,
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  // Mock Assessment Lesson
  const mockAssessment: AssessmentLesson = {
    id: assessmentId,
    userId: userId,
    description: 'German Assessment',
    completed: true, // Assessment is complete
    sourceLanguage: 'English',
    targetLanguage: 'German',
    metrics: { accuracy: 70 },
    proposedTopics: ['Travel Vocabulary', 'Basic Grammar'],
    summary: 'Initial assessment summary.',
    createdAt: new Date(),
    updatedAt: new Date(),
    steps: [
      /* Add mock assessment steps if needed */
    ],
    // Add audioMetrics if testing scenarios involving them
    audioMetrics: null, // Default to null
  };

  const mockOnboardingAssessmentComplete: OnboardingModel = {
    ...mockOnboarding,
    initialAssessmentCompleted: true,
  };

  const mockLearningProgress: LearningProgressModel = {
    id: 'progress-1',
    userId: userId,
    estimatedProficiencyLevel: ProficiencyLevel.beginner,
    overallScore: 65,
    learningTrajectory: LearningTrajectory.steady,
    strengths: ['greetings'],
    weaknesses: ['articles'],
    createdAt: new Date(),
    updatedAt: new Date(),
    topics: [
      {
        id: 't1',
        learningProgressId: 'progress-1',
        topicName: 'Greetings',
        masteryLevel: MasteryLevel.Known,
        relatedLessonIds: [],
        relatedAssessmentIds: [],
        createdAt: new Date(),
        updatedAt: new Date(),
      },
      {
        id: 't2',
        learningProgressId: 'progress-1',
        topicName: 'Articles',
        masteryLevel: MasteryLevel.Learning,
        relatedLessonIds: [],
        relatedAssessmentIds: [],
        createdAt: new Date(),
        updatedAt: new Date(),
      },
    ],
    words: [],
  };

  const mockGeneratedCompletionResults = {
    metrics: {
      accuracy: 90,
      pronunciationScore: 85,
      grammarScore: 88,
      vocabularyScore: 92,
      overallScore: 89,
      strengths: ['Good vocab recall'],
      weaknesses: ['Verb ending'],
    },
    summary: 'Excellent work on this lesson!',
    nextLessonSuggestions: ['Verb Conjugation Practice'],
  };

  beforeEach(() => {
    // Clear logger mocks
    (logger.info as jest.Mock).mockClear();
    (logger.error as jest.Mock).mockClear();
    (logger.warn as jest.Mock).mockClear();
    (logger.log as jest.Mock).mockClear();

    // Create deep mocks for injected dependencies
    mockLessonRepository = mockDeep<ILessonRepository>();
    mockLessonGeneratorService = mockDeep<ILessonGeneratorService>();
    mockOnboardingRepository = mockDeep<IOnboardingRepository>();

    // --- Mock Internally Instantiated Services ---
    jest.clearAllMocks(); // Clear mocks for internally instantiated services too
    MockRecordingService = RecordingService as jest.MockedClass<
      typeof RecordingService
    >;
    MockLearningProgressService = LearningProgressService as jest.MockedClass<
      typeof LearningProgressService
    >;
    MockLearningProgressRepository =
      LearningProgressRepository as jest.MockedClass<
        typeof LearningProgressRepository
      >;

    // Mock the prototype methods *before* creating the LessonService instance
    MockRecordingService.prototype.uploadFile = jest.fn();
    MockRecordingService.prototype.submitLessonRecordingSession = jest.fn();
    MockLearningProgressService.prototype.updateProgressAfterLesson = jest.fn();
    MockLearningProgressService.prototype.getLearningProgressWithDetails = jest
      .fn()
      .mockResolvedValue(mockLearningProgress); // Default mock

    // Instantiate the service with mocked dependencies
    lessonService = new LessonService(
      mockLessonRepository,
      mockLessonGeneratorService,
      mockOnboardingRepository
    );

    // Store the spy in a variable accessible to tests
    generateInitialLessonsSpy = jest
      .spyOn(lessonService, 'generateInitialLessons')
      .mockResolvedValue([{ ...mockLesson, id: 'initial-lesson' }]);
  });

  afterEach(() => {
    // Restore the original implementation of the spied method after each test
    generateInitialLessonsSpy.mockRestore();
  });

  // --- Test Cases ---

  it('should be defined', () => {
    expect(lessonService).toBeDefined();
  });

  describe('getLessons', () => {
    it('should call repository getLessons and return the result if lessons exist', async () => {
      const lessons = [mockLesson];
      mockLessonRepository.getLessons.mockResolvedValue(lessons);

      const result = await lessonService.getLessons();

      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1);
      expect(mockOnboardingRepository.getOnboarding).not.toHaveBeenCalled();
      // Use the spy variable for assertion
      expect(generateInitialLessonsSpy).not.toHaveBeenCalled();
      expect(result).toEqual(lessons);
    });

    it('should throw error if no lessons found and initial assessment is not completed', async () => {
      mockLessonRepository.getLessons.mockResolvedValue([]); // No lessons
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding); // Assessment not complete

      await expect(lessonService.getLessons()).rejects.toThrow(
        'Initial assessment not completed'
      );

      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1);
      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      // Use the spy variable for assertion
      expect(generateInitialLessonsSpy).not.toHaveBeenCalled();
    });

    it('should call generateInitialLessons if no lessons found and initial assessment is completed', async () => {
      const initialLessons = [
        { ...mockLesson, id: 'initial-lesson-generated' },
      ];
      mockLessonRepository.getLessons.mockResolvedValue([]); // No lessons
      // Use the CORRECT variable name here
      mockOnboardingRepository.getOnboarding.mockResolvedValue(
        mockOnboardingAssessmentComplete
      ); // Assessment IS complete
      // Ensure the spy mock returns the desired value for this test
      generateInitialLessonsSpy.mockResolvedValue(initialLessons);

      const result = await lessonService.getLessons();

      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1);
      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      // Use the spy variable for assertion
      expect(generateInitialLessonsSpy).toHaveBeenCalledTimes(1);
      expect(result).toEqual(initialLessons); // Should return the generated lessons
    });

    it('should throw error if no lessons found and onboarding data is null', async () => {
      mockLessonRepository.getLessons.mockResolvedValue([]); // No lessons
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null); // No onboarding data

      await expect(lessonService.getLessons()).rejects.toThrow(
        'Initial assessment not completed'
      );

      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1);
      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      // Use the spy variable for assertion
      expect(generateInitialLessonsSpy).not.toHaveBeenCalled();
    });

    it('should re-throw error if repository fails', async () => {
      const error = new Error('DB Error');
      mockLessonRepository.getLessons.mockRejectedValue(error);
      await expect(lessonService.getLessons()).rejects.toThrow('DB Error');
      expect(mockOnboardingRepository.getOnboarding).not.toHaveBeenCalled();
      // Use the spy variable for assertion
      expect(generateInitialLessonsSpy).not.toHaveBeenCalled();
    });
  });

  describe('getLessonById', () => {
    it('should call repository getLessonById with correct ID', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue(mockLesson);
      await lessonService.getLessonById(lessonId);
      expect(mockLessonRepository.getLessonById).toHaveBeenCalledWith(lessonId);
    });

    it('should return the lesson and sort steps if found', async () => {
      const unsortedLesson = {
        ...mockLesson,
        steps: [mockLesson.steps[1], mockLesson.steps[0]],
      }; // Steps out of order
      mockLessonRepository.getLessonById.mockResolvedValue(unsortedLesson);
      const result = await lessonService.getLessonById(lessonId);
      expect(result).toBeDefined();
      expect(result?.steps[0].stepNumber).toBe(1);
      expect(result?.steps[1].stepNumber).toBe(2);
      expect(logger.info).toHaveBeenCalledWith('getLessonById', {
        lesson: result,
      });
    });

    it('should return null if repository returns null', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue(null);
      const result = await lessonService.getLessonById(lessonId);
      expect(result).toBeNull();
      expect(logger.info).toHaveBeenCalledWith('getLessonById', {
        lesson: null,
      });
    });
  });

  describe('createLesson', () => {
    it('should call repository createLesson with correct data and return the result', async () => {
      const lessonData = {
        focusArea: mockLesson.focusArea,
        targetSkills: mockLesson.targetSkills,
        steps: mockLesson.steps,
      };
      mockLessonRepository.createLesson.mockResolvedValue(mockLesson);

      const result = await lessonService.createLesson(lessonData);

      expect(mockLessonRepository.createLesson).toHaveBeenCalledWith(
        lessonData
      );
      expect(result).toEqual(mockLesson);
      expect(logger.info).toHaveBeenCalledWith(
        'Creating lesson',
        expect.any(Object)
      );
      expect(logger.info).toHaveBeenCalledWith(
        'Lesson created successfully',
        expect.any(Object)
      );
    });

    it('should log error and re-throw if repository fails', async () => {
      const lessonData = { focusArea: 'Test', targetSkills: [], steps: [] };
      const error = new Error('Create Failed');
      mockLessonRepository.createLesson.mockRejectedValue(error);

      await expect(lessonService.createLesson(lessonData)).rejects.toThrow(
        'Create Failed'
      );
      expect(logger.error).toHaveBeenCalledWith(
        'Error creating lesson',
        expect.objectContaining({ error: 'Create Failed' })
      );
    });
  });

  describe('updateLesson', () => {
    it('should call repository updateLesson with correct arguments', async () => {
      const updateData: Partial<LessonModel> = { focusArea: 'Updated Focus' };
      const updatedLesson = { ...mockLesson, focusArea: 'Updated Focus' };
      mockLessonRepository.updateLesson.mockResolvedValue(updatedLesson);

      const result = await lessonService.updateLesson(lessonId, updateData);

      expect(mockLessonRepository.updateLesson).toHaveBeenCalledWith(
        lessonId,
        updateData
      );
      expect(result).toEqual(updatedLesson);
    });
  });

  describe('completeLesson', () => {
    it('should throw error if lesson not found', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue(null);
      await expect(lessonService.completeLesson(lessonId)).rejects.toThrow(
        `Cannot complete lesson: Lesson with ID ${lessonId} not found`
      );
    });

    // Test AI path
    it('should use AI generator service if no metrics provided', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue(mockLesson);
      mockLessonGeneratorService.generateLessonCompletionResults.mockResolvedValue(
        mockGeneratedCompletionResults
      );
      mockLessonRepository.completeLesson.mockResolvedValue(
        mockCompletedLesson
      ); // Repo returns the final completed lesson
      MockLearningProgressService.prototype.updateProgressAfterLesson.mockResolvedValue(); // Mock progress update

      // Construct the expected 'fullMetrics' object that the service passes to the repo
      const expectedFullMetrics = {
        accuracy: mockGeneratedCompletionResults.metrics.accuracy,
        pronunciationScore:
          mockGeneratedCompletionResults.metrics.pronunciationScore,
        grammarScore: mockGeneratedCompletionResults.metrics.grammarScore,
        vocabularyScore: mockGeneratedCompletionResults.metrics.vocabularyScore,
        overallScore: mockGeneratedCompletionResults.metrics.overallScore,
        strengths: mockGeneratedCompletionResults.metrics.strengths,
        weaknesses: mockGeneratedCompletionResults.metrics.weaknesses,
        summary: mockGeneratedCompletionResults.summary,
        nextLessonSuggestions:
          mockGeneratedCompletionResults.nextLessonSuggestions,
      };

      const result = await lessonService.completeLesson(lessonId);

      expect(mockLessonRepository.getLessonById).toHaveBeenCalledWith(lessonId);
      expect(
        mockLessonGeneratorService.generateLessonCompletionResults
      ).toHaveBeenCalledWith(
        mockLesson,
        expect.any(Array) // Check the structure of userResponses if needed
      );

      expect(mockLessonRepository.completeLesson).toHaveBeenCalledWith(
        lessonId,
        expectedFullMetrics
      );

      expect(
        MockLearningProgressService.prototype.updateProgressAfterLesson
      ).toHaveBeenCalledWith(userId, mockCompletedLesson);
      expect(result).toEqual(mockCompletedLesson);
      expect(logger.info).toHaveBeenCalledWith('completing lesson', {
        lesson: mockLesson,
      });
      expect(logger.info).toHaveBeenCalledWith(
        'Lesson completion analysis generated',
        { completionResults: mockGeneratedCompletionResults }
      );
    });

    // Test Fallback path
    it('should use fallback metrics if AI generator fails', async () => {
      const aiError = new Error('AI failed');
      mockLessonRepository.getLessonById.mockResolvedValue(mockLesson);
      mockLessonGeneratorService.generateLessonCompletionResults.mockRejectedValue(
        aiError
      );
      mockLessonRepository.completeLesson.mockResolvedValue(
        mockCompletedLesson
      ); // Assume repo still completes with fallback

      const result = await lessonService.completeLesson(lessonId);

      expect(mockLessonRepository.getLessonById).toHaveBeenCalledWith(lessonId);
      expect(
        mockLessonGeneratorService.generateLessonCompletionResults
      ).toHaveBeenCalledTimes(1);
      expect(logger.error).toHaveBeenCalledWith(
        'Error completing lesson with AI analysis',
        { error: aiError }
      );
      expect(mockLessonRepository.completeLesson).toHaveBeenCalledWith(
        lessonId,
        expect.objectContaining({
          accuracy: expect.any(Number), // Check fallback structure
          pronunciationScore: expect.any(Number),
          summary: 'Lesson completed successfully.',
        })
      );
      // IMPORTANT: Progress update should NOT be called in the fallback path based on current code structure
      expect(
        MockLearningProgressService.prototype.updateProgressAfterLesson
      ).not.toHaveBeenCalled();
      expect(result).toEqual(mockCompletedLesson);
      expect(logger.info).toHaveBeenCalledWith(
        'Using fallback metrics for lesson completion',
        expect.any(Object)
      );
    });

    // Test direct metrics path (Added based on analysis)
    it('should use provided metrics and update progress if metrics are given directly', async () => {
      const providedMetrics = {
        accuracy: 95,
        pronunciationScore: 90,
        errorPatterns: ['test'],
      };
      const lessonWithProvidedMetricsCompleted = {
        ...mockCompletedLesson,
        performanceMetrics: providedMetrics,
      };

      mockLessonRepository.getLessonById.mockResolvedValue(mockLesson); // Still need to get lesson for userId
      mockLessonRepository.completeLesson.mockResolvedValue(
        lessonWithProvidedMetricsCompleted
      );

      const result = await lessonService.completeLesson(
        lessonId,
        providedMetrics
      );

      expect(mockLessonRepository.getLessonById).toHaveBeenCalledWith(lessonId);
      expect(
        mockLessonGeneratorService.generateLessonCompletionResults
      ).not.toHaveBeenCalled(); // Should not call AI
      expect(mockLessonRepository.completeLesson).toHaveBeenCalledWith(
        lessonId,
        providedMetrics
      );
      expect(
        MockLearningProgressService.prototype.updateProgressAfterLesson
      ).not.toHaveBeenCalled();

      expect(result).toEqual(lessonWithProvidedMetricsCompleted);
    });

    it('should log error if progress update fails after successful completion', async () => {
      const progressError = new Error('Progress update failed');
      mockLessonRepository.getLessonById.mockResolvedValue(mockLesson);
      mockLessonGeneratorService.generateLessonCompletionResults.mockResolvedValue(
        mockGeneratedCompletionResults
      );
      mockLessonRepository.completeLesson.mockResolvedValue(
        mockCompletedLesson
      );
      MockLearningProgressService.prototype.updateProgressAfterLesson.mockRejectedValue(
        progressError
      ); // Simulate failure

      await lessonService.completeLesson(lessonId); // Don't check return value here as error is logged async

      expect(mockLessonRepository.completeLesson).toHaveBeenCalled(); // Lesson completion still happens
      expect(
        MockLearningProgressService.prototype.updateProgressAfterLesson
      ).toHaveBeenCalledWith(userId, mockCompletedLesson);
      expect(logger.error).toHaveBeenCalledWith(
        'Failed to update learning progress after lesson completion',
        expect.objectContaining({ userId, lessonId, error: progressError })
      );
    });
  });

  describe('deleteLesson', () => {
    it('should call repository deleteLesson with correct ID', async () => {
      mockLessonRepository.deleteLesson.mockResolvedValue();
      await lessonService.deleteLesson(lessonId);
      expect(mockLessonRepository.deleteLesson).toHaveBeenCalledWith(lessonId);
    });
  });

  describe('generateInitialLessons', () => {
    const mockGeneratedLessonData = {
      focusArea: 'Topic 1',
      targetSkills: ['skill1'],
      steps: [{ stepNumber: 1, type: 'instruction', content: 'Hi' }],
    };
    const mockGeneratedLessonResult = { data: [mockGeneratedLessonData] };
    const mockCreatedLesson = {
      ...mockLesson,
      id: 'new-lesson-1',
      focusArea: 'Topic 1',
      steps: mockGeneratedLessonData.steps as LessonStep[],
    };

    beforeEach(() => {
      // Restore spy to allow testing the actual implementation
      generateInitialLessonsSpy.mockRestore();

      // Common mocks for generateInitialLessons tests
      mockOnboardingRepository.getOnboarding.mockResolvedValue(
        mockOnboardingAssessmentComplete
      );
      mockOnboardingRepository.getAssessmentLesson.mockResolvedValue(
        mockAssessment
      );
      mockLessonGeneratorService.generateLesson.mockResolvedValue(
        mockGeneratedLessonResult
      );
      mockLessonGeneratorService.generateAudioForSteps.mockImplementation(
        async (steps) =>
          steps.map((s) => ({ ...s, contentAudioUrl: 'audio.mp3' })) // Simulate adding audio
      );
      mockLessonRepository.createLesson.mockResolvedValue(mockCreatedLesson);
    });

    it('should throw error if onboarding data not found', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null);
      await expect(lessonService.generateInitialLessons()).rejects.toThrow(
        'User onboarding data not found'
      );
    });

    it('should throw error if initial assessment is not completed', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding); // Assessment not complete
      await expect(lessonService.generateInitialLessons()).rejects.toThrow(
        'Initial assessment not completed'
      );
    });

    it('should throw error if completed assessment data is not found', async () => {
      mockOnboardingRepository.getAssessmentLesson.mockResolvedValue(null);
      await expect(lessonService.generateInitialLessons()).rejects.toThrow(
        'Completed assessment not found'
      );
    });

    // --- Happy Path Test ---
    it('should generate lessons based on assessment topics (happy path)', async () => {
      const result = await lessonService.generateInitialLessons();

      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      expect(
        mockOnboardingRepository.getAssessmentLesson
      ).toHaveBeenCalledTimes(1);
      // Expect generateLesson to be called for selected topics
      // Based on mockAssessment.proposedTopics = ['Travel Vocabulary', 'Basic Grammar']
      // and beginner level adding 'Greetings', 'Introductions', 'Basic Phrases',
      // selectPrioritizedTopics should pick top 3, likely assessment + one basic.
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledTimes(
        3
      ); // Expecting 3 topics
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        'travel-vocabulary', // Normalized topic
        'German',
        'beginner',
        'English',
        expect.any(Object) // Adaptive request
      );
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        'basic-grammar', // Normalized topic
        'German',
        'beginner',
        'English',
        expect.any(Object) // Adaptive request
      );
      // The third topic depends on scoring, could be 'greetings', 'introductions', or 'basic-phrases'
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        expect.stringMatching(/^(greetings|introductions|basic-phrases)$/),
        'German',
        'beginner',
        'English',
        expect.any(Object) // Adaptive request
      );

      expect(
        mockLessonGeneratorService.generateAudioForSteps
      ).toHaveBeenCalledTimes(3); // Called for each generated lesson
      expect(mockLessonRepository.createLesson).toHaveBeenCalledTimes(3); // Called for each generated lesson
      expect(result).toHaveLength(3);
      expect(result[0]).toEqual(mockCreatedLesson); // Check structure of created lesson
    });

    // --- Verify topic prioritization logic ---
    it('should prioritize assessment topics over learning purpose topics', async () => {
      // Assessment topics: ['Travel Vocabulary', 'Basic Grammar'] score 2
      // Learning purpose ('travel'): ['Airport Navigation', 'Hotel Booking', 'Restaurant Ordering'] score 1
      // Beginner basics: ['Greetings', 'Introductions', 'Basic Phrases'] score 1.5
      // Expected order: Travel Vocabulary, Basic Grammar, (one of the basics)
      await lessonService.generateInitialLessons();

      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledTimes(
        3
      );
      const calls = mockLessonGeneratorService.generateLesson.mock.calls;
      const calledTopics = calls.map((call) => call[0]); // Get the first argument (topic) of each call

      expect(calledTopics).toContain('travel-vocabulary');
      expect(calledTopics).toContain('basic-grammar');
      expect(
        calledTopics.some((topic) =>
          ['greetings', 'introductions', 'basic-phrases'].includes(topic)
        )
      ).toBe(true);
    });

    // --- Test language configuration fallbacks ---
    it('should use default language config if onboarding fields are missing', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue({
        ...mockOnboardingAssessmentComplete,
        targetLanguage: undefined, // Missing target language
        proficiencyLevel: undefined,
        learningPurpose: undefined,
        nativeLanguage: undefined,
      });

      await lessonService.generateInitialLessons();

      // Expect generateLesson to be called with defaults
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        expect.any(String),
        'German', // Default target
        'beginner', // Default proficiency
        'English', // Default source
        expect.any(Object)
      );
      // Expect audio generation to use defaults too
      expect(
        mockLessonGeneratorService.generateAudioForSteps
      ).toHaveBeenCalledWith(
        expect.any(Array),
        'German', // Default target
        'English' // Default source
      );
    });
    // --- Handle empty lesson generation from AI service ---
    it('should handle empty lesson generation from AI service gracefully', async () => {
      mockLessonGeneratorService.generateLesson.mockResolvedValue({ data: [] }); // AI returns empty data

      const result = await lessonService.generateInitialLessons();

      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledTimes(
        3
      ); // Still attempts to generate for 3 topics
      expect(
        mockLessonGeneratorService.generateAudioForSteps
      ).not.toHaveBeenCalled(); // No steps to generate audio for
      expect(mockLessonRepository.createLesson).not.toHaveBeenCalled(); // No lessons to create
      expect(result).toEqual([]); // Should return an empty array
      expect(logger.error).toHaveBeenCalledWith(
        'Failed to generate lesson for topic',
        expect.any(Object)
      ); // Should log the error for each failed topic
    });

    it('should handle AI service failure for one topic but succeed for others', async () => {
      const errorTopic = 'basic-grammar';
      const successTopic1 = 'travel-vocabulary';
      const successTopic2 = 'greetings';

      // Mock AI to fail for one topic and succeed for others
      mockLessonGeneratorService.generateLesson.mockImplementation(
        async (topic) => {
          if (topic === errorTopic) {
            throw new Error(`AI failed for ${topic}`);
          }
          // Return standard success response for other topics
          return { data: [{ ...mockGeneratedLessonData, focusArea: topic }] };
        }
      );
      // Mock createLesson to reflect successful creation
      mockLessonRepository.createLesson.mockImplementation(async (data) => ({
        ...mockCreatedLesson,
        focusArea: data.focusArea,
        id: `created-${data.focusArea}`,
      }));

      const result = await lessonService.generateInitialLessons();

      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledTimes(
        3
      );
      expect(logger.error).toHaveBeenCalledWith(
        'Failed to generate lesson for topic',
        expect.objectContaining({ topic: errorTopic })
      );
      // Audio and create should only be called for successful generations
      expect(
        mockLessonGeneratorService.generateAudioForSteps
      ).toHaveBeenCalledTimes(2);
      expect(mockLessonRepository.createLesson).toHaveBeenCalledTimes(2);
      expect(result).toHaveLength(2); // Only two lessons should be created
      expect(result.some((l) => l.focusArea === successTopic1)).toBe(true);
      expect(result.some((l) => l.focusArea === successTopic2)).toBe(true);
    });

    it('should throw if all lesson generations fail critically', async () => {
      // Mock AI service to always throw an error
      const criticalError = new Error('Critical AI Error');
      mockLessonGeneratorService.generateLesson.mockRejectedValue(criticalError);

      // Call the function and expect it to resolve
      const result = await lessonService.generateInitialLessons();

      // Assertions:
      expect(result).toEqual([]); // Expect it to resolve to an empty array

      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledTimes(3); // It still tries for all topics

      // Check that the error was logged for each failed topic generation attempt
      expect(logger.error).toHaveBeenCalledTimes(3);
      expect(logger.error).toHaveBeenCalledWith(
          'Failed to generate lesson for topic',
          expect.objectContaining({ error: criticalError })
      );

      // Ensure the final "Critical error" log in generateInitialLessons's catch block was NOT called
      expect(logger.error).not.toHaveBeenCalledWith(
          'Critical error in lesson generation',
          expect.any(Object)
      );

      expect(mockLessonRepository.createLesson).not.toHaveBeenCalled(); // No lessons should be created
    });
  });

  describe('recordStepAttempt', () => {
    it('should throw error if lesson not found', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue(null);
      await expect(
        lessonService.recordStepAttempt(lessonId, stepId, 'response')
      ).rejects.toThrow('Assessment lesson not found'); // Error message seems wrong here, should be 'Lesson not found'
    });

    it('should throw error if step not found', async () => {
      mockLessonRepository.getLessonById.mockResolvedValue({
        ...mockLesson,
        steps: [],
      });
      await expect(
        lessonService.recordStepAttempt(lessonId, stepId, 'response')
      ).rejects.toThrow('Step not found');
    });

    it('should record attempt as correct (using expected answer) if max attempts reached', async () => {
      const stepAtMax = { ...mockLessonStep, attempts: 3 };
      mockLessonRepository.getLessonById.mockResolvedValue({
        ...mockLesson,
        steps: [stepAtMax],
      });
      mockLessonRepository.recordStepAttempt.mockResolvedValue({
        ...stepAtMax,
        attempts: 4,
      }); // Simulate repo response

      const result = await lessonService.recordStepAttempt(
        lessonId,
        stepId,
        'wrong answer'
      );

      expect(mockLessonRepository.recordStepAttempt).toHaveBeenCalledWith(
        lessonId,
        stepId,
        {
          userResponse: stepAtMax.expectedAnswer, // Uses expected answer
          correct: true, // Marked correct for UI flow
        }
      );
      expect(logger.info).toHaveBeenCalledWith(
        'Maximum attempts reached',
        expect.any(Object)
      );
      expect(result).toBeDefined();
    });

    it('should correctly identify correct answer (normalized match)', async () => {
      const step = { ...mockLessonStep, expectedAnswer: 'Expected Answer...' };
      mockLessonRepository.getLessonById.mockResolvedValue({
        ...mockLesson,
        steps: [step],
      });
      mockLessonRepository.recordStepAttempt.mockResolvedValue({
        ...step,
        correct: true,
        attempts: 1,
      });

      await lessonService.recordStepAttempt(
        lessonId,
        stepId,
        '  expected answer! '
      );

      expect(mockLessonRepository.recordStepAttempt).toHaveBeenCalledWith(
        lessonId,
        stepId,
        {
          userResponse: '  expected answer! ',
          correct: true,
        }
      );
    });

    it('should correctly identify incorrect answer', async () => {
      const step = { ...mockLessonStep, expectedAnswer: 'Correct Answer' };
      mockLessonRepository.getLessonById.mockResolvedValue({
        ...mockLesson,
        steps: [step],
      });
      mockLessonRepository.recordStepAttempt.mockResolvedValue({
        ...step,
        correct: false,
        attempts: 1,
      });

      await lessonService.recordStepAttempt(lessonId, stepId, 'Wrong Answer');

      expect(mockLessonRepository.recordStepAttempt).toHaveBeenCalledWith(
        lessonId,
        stepId,
        {
          userResponse: 'Wrong Answer',
          correct: false,
        }
      );
    });

    it('should mark instruction/feedback/summary steps as correct', async () => {
      const instructionStep = {
        ...mockLessonStep,
        type: LessonStepType.instruction,
        expectedAnswer: null,
      };
      mockLessonRepository.getLessonById.mockResolvedValue({
        ...mockLesson,
        steps: [instructionStep],
      });
      mockLessonRepository.recordStepAttempt.mockResolvedValue({
        ...instructionStep,
        correct: true,
        attempts: 1,
      });

      await lessonService.recordStepAttempt(lessonId, instructionStep.id, ''); // Empty response is ok

      expect(mockLessonRepository.recordStepAttempt).toHaveBeenCalledWith(
        lessonId,
        instructionStep.id,
        {
          userResponse: 'Acknowledged', // Default response
          correct: true,
        }
      );
    });
  });

  describe('checkAndGenerateNewLessons', () => {
    it('should throw if no lessons found', async () => {
      mockLessonRepository.getLessons.mockResolvedValue([]);
      // Ensure getLessons doesn't throw the onboarding error for this test
      mockOnboardingRepository.getOnboarding.mockResolvedValue(
        mockOnboardingAssessmentComplete
      );
      await expect(lessonService.checkAndGenerateNewLessons()).rejects.toThrow(
        'No lessons found'
      );
      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1); // Verify getLessons was called
    });

    it('should return empty array if not all lessons are complete', async () => {
      mockLessonRepository.getLessons.mockResolvedValue([
        mockLesson,
        { ...mockCompletedLesson, id: 'l2' },
      ]); // One incomplete
      const result = await lessonService.checkAndGenerateNewLessons();
      expect(result).toEqual([]);
      expect(logger.info).toHaveBeenCalledWith(
        'currentLessons',
        expect.any(Object)
      );
      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1); // Verify getLessons was called
    });

    it('should call generateNewLessonsBasedOnProgress if all lessons are complete', async () => {
      const newGeneratedLessons = [{ ...mockLesson, id: 'new1' }];
      const completedLessons = [
        { ...mockCompletedLesson, id: 'l1' },
        { ...mockCompletedLesson, id: 'l2' },
      ];

      mockLessonRepository.getLessons.mockResolvedValue(completedLessons);
      // Need to mock the call chain inside generateNewLessonsBasedOnProgress
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockLearningProgressService.prototype.getLearningProgressWithDetails.mockResolvedValue(
        mockLearningProgress
      );
      mockLessonGeneratorService.generateLesson.mockResolvedValue({
        data: [{ focusArea: 'New Topic', targetSkills: [], steps: [] }],
      });
      mockLessonGeneratorService.generateAudioForSteps.mockImplementation(
        async (steps) => steps
      );
      mockLessonRepository.createLesson.mockResolvedValue(
        newGeneratedLessons[0]
      );

      const result = await lessonService.checkAndGenerateNewLessons();

      expect(
        MockLearningProgressService.prototype.getLearningProgressWithDetails
      ).toHaveBeenCalledWith(userId);
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalled(); // Check specific args if needed
      expect(mockLessonRepository.createLesson).toHaveBeenCalled();
      expect(result).toEqual(newGeneratedLessons);
    });
  });

  describe('generateNewLessonsBasedOnProgress', () => {
    const mockCompletedLessonWithAudio: LessonModel = {
      ...mockCompletedLesson,
      audioMetrics: mockAudioMetrics as AudioMetrics, // Use the imported mock
    };
    const completedLessons = [
      {
        ...mockCompletedLessonWithAudio,
        id: 'l1',
        updatedAt: new Date(Date.now() - 10000),
      }, // Ensure different update times
      { ...mockCompletedLessonWithAudio, id: 'l2', updatedAt: new Date() }, // Most recent
    ];

    const newGeneratedLessonData = {
      focusArea: 'Weakness Area',
      targetSkills: ['skill'],
      steps: [],
    };
    const newGeneratedLessonResult = { data: [newGeneratedLessonData] };
    const newCreatedLesson = {
      ...mockLesson,
      id: 'new-gen-1',
      focusArea: 'Weakness Area',
    };

    beforeEach(() => {
      // Setup mocks for this block
      mockLessonRepository.getLessons.mockResolvedValue(completedLessons);
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockLearningProgressService.prototype.getLearningProgressWithDetails.mockResolvedValue(
        mockLearningProgress
      );
      mockLessonGeneratorService.generateLesson.mockResolvedValue(
        newGeneratedLessonResult
      );
      mockLessonGeneratorService.generateAudioForSteps.mockImplementation(
        async (steps) => steps
      );
      mockLessonRepository.createLesson.mockResolvedValue(newCreatedLesson);
    });

    it('should throw error if onboarding data not found', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null);
      await expect(
        lessonService.generateNewLessonsBasedOnProgress()
      ).rejects.toThrow('User onboarding data not found');
    });

    it('should throw error if no completed lessons found', async () => {
      mockLessonRepository.getLessons.mockResolvedValue([mockLesson]); // Only incomplete lessons
      await expect(
        lessonService.generateNewLessonsBasedOnProgress()
      ).rejects.toThrow('No completed lessons found to analyze');
    });

    it('should fetch progress, determine focus areas, generate, and create lessons', async () => {
      const result = await lessonService.generateNewLessonsBasedOnProgress();

      expect(mockLessonRepository.getLessons).toHaveBeenCalledTimes(1);
      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      expect(
        MockLearningProgressService.prototype.getLearningProgressWithDetails
      ).toHaveBeenCalledWith(userId);
      // Check that generateLesson is called, potentially multiple times based on focus areas
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalled();
      // Verify adaptive request structure passed to generator
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        expect.any(String), // Focus Area determined by logic
        mockOnboarding.targetLanguage,
        mockLearningProgress.estimatedProficiencyLevel, // Use progress proficiency
        mockOnboarding.nativeLanguage,
        expect.objectContaining({
          // Adaptive Request
          userInfo: expect.objectContaining({
            proficiencyLevel: mockLearningProgress.estimatedProficiencyLevel,
          }),
          overallProgress: expect.objectContaining({
            estimatedProficiencyLevel:
              mockLearningProgress.estimatedProficiencyLevel,
          }),
          performanceMetrics: expect.objectContaining({
            avgAccuracy: expect.any(Number),
          }),
          improvementAreas: expect.any(Object), // Should now be present
          learningRecommendations: expect.any(Object), // Should now be present
          learningStyle: expect.any(Object), // Should now be present
        })
      );
      expect(
        mockLessonGeneratorService.generateAudioForSteps
      ).toHaveBeenCalled();
      expect(mockLessonRepository.createLesson).toHaveBeenCalled();
      expect(result.length).toBeGreaterThan(0); // Should generate at least one lesson
      expect(result[0]).toEqual(newCreatedLesson);
    });

    it('should proceed without progress data if fetch fails', async () => {
      const progressError = new Error('Progress fetch failed');
      MockLearningProgressService.prototype.getLearningProgressWithDetails.mockRejectedValue(
        progressError
      );

      const result = await lessonService.generateNewLessonsBasedOnProgress();

      expect(logger.error).toHaveBeenCalledWith(
        'Failed to fetch learning progress, proceeding without it.',
        { userId, error: progressError }
      );
      // Ensure it still generates lessons, potentially with less context
      expect(mockLessonGeneratorService.generateLesson).toHaveBeenCalledWith(
        expect.any(String),
        mockOnboarding.targetLanguage,
        mockOnboarding.proficiencyLevel, // Fallback to onboarding proficiency
        mockOnboarding.nativeLanguage,
        expect.objectContaining({
          overallProgress: undefined, // No progress data
        })
      );
      expect(result.length).toBeGreaterThan(0);
    });
  });

  describe('processLessonRecording', () => {
    const mockAudioData = 'audio data';
    const mockBlob = new Blob([mockAudioData], { type: 'audio/webm' });
    (mockBlob as any).arrayBuffer = jest
      .fn()
      .mockResolvedValue(new TextEncoder().encode(mockAudioData).buffer);
    const recordingTime = 15;
    const recordingSize = 2048;
    const fileUri = 'uploaded/lesson-recording.webm';
    const mockAiResponse = mockAudioMetrics; // Use the imported mock
    const mockUpdatedLessonWithAudio = {
      ...mockLesson,
      audioMetrics: mockAudioMetrics as AudioMetrics,
    }; // Assume conversion works

    beforeEach(() => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockRecordingService.prototype.uploadFile.mockResolvedValue(fileUri);
      MockRecordingService.prototype.submitLessonRecordingSession.mockResolvedValue(
        mockAiResponse
      );
      mockLessonRepository.updateLesson.mockResolvedValue(
        mockUpdatedLessonWithAudio
      );
    });

    it('should process recording, get AI analysis, convert, and update lesson', async () => {
      const result = await lessonService.processLessonRecording(
        mockBlob,
        recordingTime,
        recordingSize,
        mockLesson
      );

      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      expect(MockRecordingService.prototype.uploadFile).toHaveBeenCalledWith(
        expect.any(Buffer),
        'audio/webm',
        expect.stringContaining(`lesson-${lessonId}-`)
      );
      expect(
        MockRecordingService.prototype.submitLessonRecordingSession
      ).toHaveBeenCalledWith(
        fileUri,
        recordingTime,
        recordingSize,
        {
          targetLanguage: mockOnboarding.targetLanguage,
          nativeLanguage: mockOnboarding.nativeLanguage,
        },
        mockLesson
      );
      expect(mockLessonRepository.updateLesson).toHaveBeenCalledWith(lessonId, {
        audioMetrics: expect.objectContaining({
          id: expect.any(String),
          overallPerformance: mockAiResponse.overallPerformance,
        }),
      });
      expect(result).toEqual(mockUpdatedLessonWithAudio);
      expect(logger.info).toHaveBeenCalledWith('Audio metrics generated', {
        audioMetrics: expect.any(Object),
      });
    });

    it('should throw error if onboarding data not found', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null);
      await expect(
        lessonService.processLessonRecording(
          mockBlob,
          recordingTime,
          recordingSize,
          mockLesson
        )
      ).rejects.toThrow('User onboarding data not found');
    });

    // Add tests for upload failure, AI submission failure similar to onboarding service tests if needed
  });
});
</file>

<file path="tests/servises/progress-service.test.ts">
// File: tests/services/learning-progress.service.test.ts

import LearningProgressService from '@/services/learning-progress.service';
import { ILearningProgressRepository } from '@/repositories/learning-progress.repository';
import { LearningProgressModel, LessonModel, AssessmentLesson, TopicProgressModel, WordProgressModel, AudioMetrics } from '@/models/AppAllModels.model';
import { MasteryLevel, ProficiencyLevel, LearningTrajectory } from '@prisma/client';
import { mockDeep, MockProxy } from 'jest-mock-extended';
import logger from '@/utils/logger';

// Mock the logger
jest.mock('@/utils/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  debug: jest.fn(),
}));

describe('LearningProgressService', () => {
  let progressService: LearningProgressService;
  let mockProgressRepository: MockProxy<ILearningProgressRepository>;

  const userId = 'test-user-id';
  const learningProgressId = 'test-progress-id';

  // --- Mock Data ---
  const mockExistingProgress: LearningProgressModel = {
    id: learningProgressId,
    userId: userId,
    estimatedProficiencyLevel: ProficiencyLevel.beginner,
    overallScore: 50,
    learningTrajectory: LearningTrajectory.steady,
    strengths: ['greeting'],
    weaknesses: ['past tense'],
    createdAt: new Date(),
    updatedAt: new Date(),
    topics: [],
    words: [],
  };

  const mockLesson: LessonModel = {
    id: 'lesson-1',
    userId: userId,
    lessonId: 'gen-lesson-1',
    focusArea: 'Travel Basics',
    targetSkills: ['asking directions', 'ordering food'],
    steps: [
      { id: 'step-1', lessonId: 'lesson-1', stepNumber: 1, type: 'instruction', content: '...', attempts: 0, maxAttempts: 1, correct: true, errorPatterns: [], createdAt: new Date(), updatedAt: new Date() },
      { id: 'step-2', lessonId: 'lesson-1', stepNumber: 2, type: 'new_word', content: 'Bahnhof', translation: 'train station', expectedAnswer: 'Bahnhof', attempts: 1, maxAttempts: 3, correct: true, errorPatterns: [], createdAt: new Date(), updatedAt: new Date() },
      { id: 'step-3', lessonId: 'lesson-1', stepNumber: 3, type: 'practice', content: 'Say: Wo ist der Bahnhof?', expectedAnswer: 'Wo ist der Bahnhof?', userResponse: 'Wo ist der Bahnhof?', attempts: 1, maxAttempts: 3, correct: true, errorPatterns: [], createdAt: new Date(), updatedAt: new Date() },
      { id: 'step-4', lessonId: 'lesson-1', stepNumber: 4, type: 'practice', content: 'Say: Ich möchte...', expectedAnswer: 'Ich möchte...', userResponse: 'Ich mochte...', attempts: 1, maxAttempts: 3, correct: false, errorPatterns: ['verb conjugation'], createdAt: new Date(), updatedAt: new Date() },
    ],
    performanceMetrics: {
      accuracy: 75,
      pronunciationScore: 80,
      grammarScore: 70,
      vocabularyScore: 85,
      overallScore: 78,
      strengths: ['basic vocab'],
      weaknesses: ['verb conjugation'],
    },
    audioMetrics: null, // Add mock audio metrics if needed
    completed: true,
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  const mockAssessment: AssessmentLesson = {
    id: 'assessment-1',
    userId: userId,
    description: 'Initial Assessment',
    completed: true,
    sourceLanguage: 'English',
    targetLanguage: 'German',
    metrics: {
      accuracy: 80,
      overallScore: 82,
      strengths: ['comprehension'],
      weaknesses: ['articles'],
    },
    audioMetrics: { // Example audio metrics
      id: 'audio-metrics-1',
      pronunciationScore: 85,
      fluencyScore: 75,
      grammarScore: 78,
      vocabularyScore: 88,
      overallPerformance: 81,
      proficiencyLevel: 'A2',
      learningTrajectory: LearningTrajectory.steady,
      pronunciationAssessment: { overall_score: 85, native_language_influence: { level: 'low', specific_features: [] }, phoneme_analysis: [], problematic_sounds: ['ch'], strengths: ['vowels'], areas_for_improvement: ['ch sound'] },
      fluencyAssessment: { overall_score: 75, speech_rate: { words_per_minute: 90, evaluation: 'appropriate' }, hesitation_patterns: { frequency: 'occasional', average_pause_duration: 0.5, typical_contexts: [] }, rhythm_and_intonation: { naturalness: 70, sentence_stress_accuracy: 75, intonation_pattern_accuracy: 80 } },
      grammarAssessment: { overall_score: 78, error_patterns: [{ category: 'articles', description: 'Incorrect article usage', examples: [], frequency: 'frequent', severity: 'medium' }], grammar_rules_to_review: [{ rule: 'Definite articles', priority: 'high', examples: [] }], grammar_strengths: ['basic word order'] },
      vocabularyAssessment: { overall_score: 88, range: 'adequate', appropriateness: 90, precision: 85, areas_for_expansion: [{ topic: 'Travel', suggested_vocabulary: ['Flugzeug', 'Ticket'] }] },
      exerciseCompletion: { overall_score: 80, exercises_analyzed: [], comprehension_level: 'good' },
      suggestedTopics: ['Travel', 'Food'],
      grammarFocusAreas: ['Articles'],
      vocabularyDomains: ['Common Verbs'],
      nextSkillTargets: ['Using definite articles correctly'],
      preferredPatterns: [],
      effectiveApproaches: [],
      createdAt: new Date(),
      updatedAt: new Date(),
    },
    proposedTopics: ['Travel Vocabulary', 'Basic Grammar'],
    summary: 'Good start, focus on articles.',
    createdAt: new Date(),
    updatedAt: new Date(),
    steps: [
      { id: 'a-step-1', assessmentId: 'assessment-1', stepNumber: 1, type: 'instruction', content: '...', attempts: 0, maxAttempts: 1, correct: true, createdAt: new Date(), updatedAt: new Date() },
      { id: 'a-step-2', assessmentId: 'assessment-1', stepNumber: 2, type: 'question', content: 'Der, die, or das Buch?', expectedAnswer: 'Das Buch', userResponse: 'Das Buch', attempts: 1, maxAttempts: 3, correct: true, createdAt: new Date(), updatedAt: new Date() },
      { id: 'a-step-3', assessmentId: 'assessment-1', stepNumber: 3, type: 'question', content: 'Translate: I am learning', expectedAnswer: 'Ich lerne', userResponse: 'Ich lernen', attempts: 1, maxAttempts: 3, correct: false, createdAt: new Date(), updatedAt: new Date() },
    ],
  };

  beforeEach(() => {
    // Create a deep mock of the repository
    mockProgressRepository = mockDeep<ILearningProgressRepository>();
    // Instantiate the service with the mock repository
    progressService = new LearningProgressService(mockProgressRepository);
  });

  afterEach(() => {
    jest.clearAllMocks();
  });

  // --- Test Cases ---

  it('should be defined', () => {
    expect(progressService).toBeDefined();
  });

  describe('getLearningProgress', () => {
    it('should call repository getLearningProgress with correct userId', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      await progressService.getLearningProgress(userId);
      expect(mockProgressRepository.getLearningProgress).toHaveBeenCalledWith(userId);
    });

    it('should return the progress model from repository', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      const result = await progressService.getLearningProgress(userId);
      expect(result).toEqual(mockExistingProgress);
    });

    it('should return null if repository returns null', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(null);
      const result = await progressService.getLearningProgress(userId);
      expect(result).toBeNull();
    });
  });

  describe('getLearningProgressWithDetails', () => {
    it('should call repository getLearningProgressWithDetails with correct userId', async () => {
      mockProgressRepository.getLearningProgressWithDetails.mockResolvedValue(mockExistingProgress);
      await progressService.getLearningProgressWithDetails(userId);
      expect(mockProgressRepository.getLearningProgressWithDetails).toHaveBeenCalledWith(userId);
    });

    it('should return the detailed progress model from repository', async () => {
      mockProgressRepository.getLearningProgressWithDetails.mockResolvedValue(mockExistingProgress);
      const result = await progressService.getLearningProgressWithDetails(userId);
      expect(result).toEqual(mockExistingProgress);
    });
  });

  describe('updateProgressAfterLesson', () => {
    it('should create new progress if none exists', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(null);
      mockProgressRepository.upsertLearningProgress.mockResolvedValueOnce({ ...mockExistingProgress, id: learningProgressId }); // Simulate creation returning progress
      mockProgressRepository.upsertLearningProgress.mockResolvedValueOnce(mockExistingProgress); // Simulate final update

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      // Expect creation call
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        userId: userId,
        estimatedProficiencyLevel: ProficiencyLevel.beginner, // Default
        learningTrajectory: LearningTrajectory.steady,
        strengths: [],
        weaknesses: [],
      }));
      // Expect final update call
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        lastLessonCompletedAt: expect.any(Date),
        // Check other calculated fields if needed
      }));
    });

    it('should update existing progress', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress); // Simulate final update

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      expect(mockProgressRepository.getLearningProgress).toHaveBeenCalledWith(userId);
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledTimes(1); // Only final update
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        lastLessonCompletedAt: expect.any(Date),
        overallScore: expect.any(Number), // Check calculated fields
        strengths: expect.any(Array),
        weaknesses: expect.any(Array),
      }));
    });

    it('should call updateTopicProgress for focusArea and targetSkills', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ topicName: mockLesson.focusArea })
      );
      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ topicName: mockLesson.targetSkills[0] })
      );
      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ topicName: mockLesson.targetSkills[1] })
      );
      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledTimes(1 + mockLesson.targetSkills.length);
    });

    it('should call updateWordProgress for relevant steps', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      // Step 2: new_word
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ word: 'Bahnhof', translation: 'train station' })
      );
      // Step 3: practice (correct)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ word: 'Wo ist der Bahnhof?' })
      );
      // Step 4: practice (incorrect)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ word: 'Ich möchte...' })
      );
      // Should be called 3 times (step 2, 3, 4)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledTimes(3);
    });

    it('should handle errors during update and log them', async () => {
      const testError = new Error('Database connection failed');
      mockProgressRepository.getLearningProgress.mockRejectedValue(testError);

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      expect(logger.error).toHaveBeenCalledWith(
        'Error updating learning progress after lesson:',
        expect.objectContaining({ userId, lessonId: mockLesson.id, error: testError })
      );
      // Ensure no further repository calls were made after the initial failure
      expect(mockProgressRepository.upsertTopicProgress).not.toHaveBeenCalled();
      expect(mockProgressRepository.upsertWordProgress).not.toHaveBeenCalled();
      expect(mockProgressRepository.upsertLearningProgress).not.toHaveBeenCalled();
    });

  });

  describe('updateProgressAfterAssessment', () => {
    it('should create new progress if none exists, using assessment proficiency', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(null);
      mockProgressRepository.upsertLearningProgress.mockResolvedValueOnce({ ...mockExistingProgress, id: learningProgressId }); // Creation
      mockProgressRepository.upsertLearningProgress.mockResolvedValueOnce(mockExistingProgress); // Final update

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      // Expect creation call with proficiency from audio metrics
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        userId: userId,
        estimatedProficiencyLevel: ProficiencyLevel.beginner, // A2 maps to beginner in the service logic
        learningTrajectory: LearningTrajectory.steady,
        strengths: [],
        weaknesses: [],
      }));
      // Expect final update call
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        lastAssessmentCompletedAt: expect.any(Date),
      }));
    });

    it('should update existing progress using assessment data', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress); // Final update

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      expect(mockProgressRepository.getLearningProgress).toHaveBeenCalledWith(userId);
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledTimes(1);
      expect(mockProgressRepository.upsertLearningProgress).toHaveBeenCalledWith(userId, expect.objectContaining({
        lastAssessmentCompletedAt: expect.any(Date),
        overallScore: expect.any(Number), // Check calculated fields
        estimatedProficiencyLevel: expect.any(String), // Should potentially update based on assessment
        learningTrajectory: LearningTrajectory.steady, // From audio metrics
        strengths: expect.arrayContaining(['greeting', 'comprehension', 'basic word order']), // Merged
        weaknesses: expect.arrayContaining(['past tense', 'articles', 'ch sound']), // Merged
      }));
    });

    it('should call updateTopicProgress for proposedTopics', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ topicName: mockAssessment.proposedTopics[0] })
      );
      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ topicName: mockAssessment.proposedTopics[1] })
      );
      expect(mockProgressRepository.upsertTopicProgress).toHaveBeenCalledTimes(mockAssessment.proposedTopics.length);
    });

    it('should call updateWordProgress for question steps', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      // Step 2: question (correct)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ word: 'Das Buch' }) // expectedAnswer from step 2
      );
      // Step 3: question (incorrect)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledWith(
        learningProgressId,
        expect.objectContaining({ word: 'Ich lerne' }) // expectedAnswer from step 3
      );
      // Should be called 2 times (step 2, 3)
      expect(mockProgressRepository.upsertWordProgress).toHaveBeenCalledTimes(2);
    });

    it('should handle errors during update and log them', async () => {
      const testError = new Error('Assessment update failed');
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress); // Assume progress exists
      mockProgressRepository.upsertTopicProgress.mockRejectedValue(testError); // Fail during topic update

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      expect(logger.error).toHaveBeenCalledWith(
        'Error updating learning progress after assessment:',
        expect.objectContaining({ userId, assessmentId: mockAssessment.id, error: testError })
      );
      // Ensure it didn't proceed to word update or final progress update
      expect(mockProgressRepository.upsertWordProgress).not.toHaveBeenCalled();
      expect(mockProgressRepository.upsertLearningProgress).not.toHaveBeenCalled();
    });
  });

  // --- Helper Method Tests (Optional - can be tested implicitly or explicitly) ---

  describe('calculateOverallProgress (Implicit Test)', () => {
    it('should update progress fields based on lesson metrics', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterLesson(userId, mockLesson);

      const finalUpdateCall = mockProgressRepository.upsertLearningProgress.mock.calls[0][1];

      // Example checks - refine based on actual calculation logic
      expect(finalUpdateCall.overallScore).toBeCloseTo((50 * 0.3) + (78 * 0.7), 0); // Weighted average
      expect(finalUpdateCall.strengths).toContain('greeting');
      expect(finalUpdateCall.strengths).toContain('basic vocab');
      expect(finalUpdateCall.weaknesses).toContain('past tense');
      expect(finalUpdateCall.weaknesses).toContain('verb conjugation');
      expect(finalUpdateCall.learningTrajectory).toBe(LearningTrajectory.accelerating); // Score increased significantly
    });

    it('should update progress fields based on assessment metrics including audio', async () => {
      mockProgressRepository.getLearningProgress.mockResolvedValue(mockExistingProgress);
      mockProgressRepository.upsertLearningProgress.mockResolvedValue(mockExistingProgress);

      await progressService.updateProgressAfterAssessment(userId, mockAssessment);

      const finalUpdateCall = mockProgressRepository.upsertLearningProgress.mock.calls[0][1];

      // Example checks
      expect(finalUpdateCall.overallScore).toBeCloseTo((50 * 0.3) + (81 * 0.7), 0); // Using audio overallPerformance
      expect(finalUpdateCall.estimatedProficiencyLevel).toBe(ProficiencyLevel.beginner); // A2 maps to beginner, not higher than existing
      expect(finalUpdateCall.learningTrajectory).toBe(LearningTrajectory.steady); // From audio metrics
      expect(finalUpdateCall.strengths).toEqual(expect.arrayContaining(['greeting', 'comprehension', 'basic word order']));
      expect(finalUpdateCall.weaknesses).toEqual(expect.arrayContaining(['past tense', 'articles', 'ch sound']));
    });
  });

  // Add tests for advanceMastery, regressMastery, mapCefrToProficiency if complex logic needs direct testing

});
</file>

<file path="tests/servises/user-context.test.tsx">
import React from 'react';
import { render, screen, act, waitFor } from '@testing-library/react';
import '@testing-library/jest-dom';
import { AuthProvider, useAuth } from '@/context/auth-context';
import * as AuthActions from '@/lib/server-actions/auth-actions';
import { useRouter } from 'next/navigation';
import { createClient } from '@/utils/supabase/client';
import { Session, User, AuthError } from '@supabase/supabase-js';

// --- Mocks ---

// Mock Next.js Router
jest.mock('next/navigation', () => ({
  useRouter: jest.fn(),
}));
const mockRouterPush = jest.fn();
const mockRouterReplace = jest.fn();
(useRouter as jest.Mock).mockReturnValue({
  push: mockRouterPush,
  replace: mockRouterReplace,
  prefetch: jest.fn(), // Add other methods if needed
  back: jest.fn(),
  forward: jest.fn(),
  refresh: jest.fn(),
  // Add any other properties/methods your component might use
});

// Mock Server Actions
jest.mock('@/lib/server-actions/auth-actions', () => ({
  getSessionAction: jest.fn(),
  loginAction: jest.fn(),
  registerAction: jest.fn(),
  loginWithGoogleAction: jest.fn(),
  logoutAction: jest.fn(),
}));

// Mock Supabase Client and Auth State Change
const mockUnsubscribe = jest.fn();
const mockOnAuthStateChange = jest.fn(() => ({
  data: { subscription: { unsubscribe: mockUnsubscribe } },
}));
const mockSupabaseClient = {
  auth: {
    onAuthStateChange: mockOnAuthStateChange,
  },
};
jest.mock('@/utils/supabase/client', () => ({
  createClient: jest.fn(() => mockSupabaseClient),
}));

// Mock UserProfileProvider (simple pass-through)
jest.mock('@/context/user-profile-context', () => ({
  UserProfileProvider: ({ children }: { children: React.ReactNode }) => <>{children}</>,
}));

// Mock Logger
jest.mock('@/utils/logger', () => ({
  log: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  info: jest.fn(),
}));

// --- Helper Components ---

// A simple component to display auth state for testing
const TestComponent = () => {
  const { user, session, loading, error, login, register, logout, loginWithGoogle, clearError } = useAuth();

  return (
    <div>
      <div data-testid="loading">{loading ? 'Loading...' : 'Loaded'}</div>
      <div data-testid="user">{user ? `User: ${user.id}` : 'No User'}</div>
      <div data-testid="session">{session ? `Session: ${session.access_token}` : 'No Session'}</div>
      <div data-testid="error">{error ? `Error: ${error}` : 'No Error'}</div>
      <button onClick={() => login('test@test.com', 'password')}>Login</button>
      <button onClick={() => register('new@test.com', 'password')}>Register</button>
      <button onClick={() => logout()}>Logout</button>
      <button onClick={() => loginWithGoogle()}>Login Google</button>
      <button onClick={() => clearError()}>Clear Error</button>
    </div>
  );
};

// --- Test Data ---
const mockUser: User = {
  id: 'user-123',
  app_metadata: {},
  user_metadata: {},
  aud: 'authenticated',
  created_at: new Date().toISOString(),
};

const mockSession: Session = {
  access_token: 'mock-access-token',
  refresh_token: 'mock-refresh-token',
  user: mockUser,
  expires_in: 3600,
  token_type: 'bearer',
};

const mockAuthError: AuthError = {
    name: 'AuthApiError',
    message: 'Invalid credentials',
    status: 400,
};


// --- Test Suite ---

describe('AuthProvider', () => {
  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();
    (useRouter as jest.Mock).mockReturnValue({ push: mockRouterPush, replace: mockRouterReplace });
    // Default mock implementations
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(null); // Start with no session
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({ data: { user: null, session: null }, error: null });
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({ data: { user: null, session: null }, error: null });
    (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: null });
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: null });
    mockOnAuthStateChange.mockImplementation((callback) => {
        // Store the callback to simulate events later if needed
        (mockOnAuthStateChange as any).callback = callback;
        return { data: { subscription: { unsubscribe: mockUnsubscribe } } };
    });
  });

  it('should initialize with loading state and fetch session', async () => {
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Initially loading
    expect(screen.getByTestId('loading')).toHaveTextContent('Loading...');
    expect(AuthActions.getSessionAction).toHaveBeenCalledTimes(1);

    // Wait for session to load
    await waitFor(() => {
      expect(screen.getByTestId('loading')).toHaveTextContent('Loaded');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle session fetch error', async () => {
    const sessionError = new Error('Failed to fetch session');
    (AuthActions.getSessionAction as jest.Mock).mockRejectedValue(sessionError);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => {
      expect(screen.getByTestId('loading')).toHaveTextContent('Loaded');
      expect(screen.getByTestId('user')).toHaveTextContent('No User');
      expect(screen.getByTestId('session')).toHaveTextContent('No Session');
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${sessionError.message}`);
    });
  });

  it('should handle successful login', async () => {
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({
      data: { user: mockUser, session: mockSession },
      error: null,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for initial load
    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Trigger login
    await act(async () => {
      screen.getByRole('button', { name: 'Login' }).click();
    });

    // Check state after login
    await waitFor(() => {
      expect(AuthActions.loginAction).toHaveBeenCalledWith('test@test.com', 'password');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
      expect(mockRouterPush).toHaveBeenCalledWith('/app/lessons');
    });
  });

  it('should handle failed login', async () => {
    (AuthActions.loginAction as jest.Mock).mockResolvedValue({
        data: { user: null, session: null },
        error: mockAuthError,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Login' }).click();
    });

    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${mockAuthError.message}`);
    });
    expect(AuthActions.loginAction).toHaveBeenCalledWith('test@test.com', 'password');
    expect(screen.getByTestId('user')).toHaveTextContent('No User');
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
    expect(mockRouterPush).not.toHaveBeenCalled();

  });

  it('should handle successful registration', async () => {
    const newUser = { ...mockUser, id: 'new-user-456' };
    const newSession = { ...mockSession, user: newUser, access_token: 'new-access-token' };
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({
      data: { user: newUser, session: newSession },
      error: null,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Register' }).click();
    });

    await waitFor(() => {
      expect(AuthActions.registerAction).toHaveBeenCalledWith('new@test.com', 'password');
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${newUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${newSession.access_token}`);
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
      expect(mockRouterPush).toHaveBeenCalledWith('/app/onboarding'); // Check onboarding redirect
    });
  });

  it('should handle failed registration', async () => {
    // Arrange: Mock the action to return an error
    const registerError: AuthError = { name: 'AuthApiError', message: 'User already exists', status: 409 };
    (AuthActions.registerAction as jest.Mock).mockResolvedValue({
        data: { user: null, session: null },
        error: registerError,
    });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Act: Trigger the register action
    await act(async () => {
      screen.getByRole('button', { name: 'Register' }).click();
    });

    // Assert: Wait for the error message state update
    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${registerError.message}`);
    });

    // Assert: Check other state aspects
    expect(AuthActions.registerAction).toHaveBeenCalledWith('new@test.com', 'password');
    expect(screen.getByTestId('user')).toHaveTextContent('No User');
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
    expect(mockRouterPush).not.toHaveBeenCalled();
  });



  it('should handle successful logout', async () => {
    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: null });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for initial login state
    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    // Trigger logout
    await act(async () => {
      screen.getByRole('button', { name: 'Logout' }).click();
    });

    // Check state after logout
    await waitFor(() => {
      expect(AuthActions.logoutAction).toHaveBeenCalledTimes(1);
      expect(screen.getByTestId('user')).toHaveTextContent('No User');
      expect(screen.getByTestId('session')).toHaveTextContent('No Session');
      expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle failed logout', async () => {
    const logoutError: AuthError = { name: 'AuthApiError', message: 'Logout failed', status: 500 };
    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);
    (AuthActions.logoutAction as jest.Mock).mockResolvedValue({ error: logoutError });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    await act(async () => {
        screen.getByRole('button', { name: 'Logout' }).click();
    });

    await waitFor(() => {
      expect(AuthActions.logoutAction).toHaveBeenCalledTimes(1);
      // User/session might still be set if logout fails server-side but client doesn't clear
      // However, the provider *does* clear them optimistically before checking error in the `finally`
      // Let's check if the error is set
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${logoutError.message}`);
      // State might still be logged in if only error is set
      expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
      expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
    });
  });

  it('should call loginWithGoogle action', async () => {
     (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: null });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    await act(async () => {
      screen.getByRole('button', { name: 'Login Google' }).click();
    });

    await waitFor(() => {
        expect(AuthActions.loginWithGoogleAction).toHaveBeenCalledTimes(1);
        // State shouldn't change immediately, relies on redirect and onAuthStateChange
        expect(screen.getByTestId('user')).toHaveTextContent('No User');
        expect(screen.getByTestId('error')).toHaveTextContent('No Error');
    });
  });

  it('should handle error from loginWithGoogle action', async () => {
    // Arrange: Mock the action to return an error
    const googleError: AuthError = { name: 'AuthApiError', message: 'Google Auth Failed', status: 500 };
    (AuthActions.loginWithGoogleAction as jest.Mock).mockResolvedValue({ error: googleError });

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));

    // Act: Trigger the google login action
    await act(async () => {
      screen.getByRole('button', { name: 'Login Google' }).click();
    });

    // Assert: Wait for the error message state update
    await waitFor(() => {
        expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${googleError.message}`);
    });

    // Assert: Check other state aspects
    expect(AuthActions.loginWithGoogleAction).toHaveBeenCalledTimes(1);
    expect(screen.getByTestId('user')).toHaveTextContent('No User'); // State shouldn't change here
    expect(screen.getByTestId('session')).toHaveTextContent('No Session');
  });

  it('should clear error when clearError is called', async () => {
    const sessionError = new Error('Initial Error');
    (AuthActions.getSessionAction as jest.Mock).mockRejectedValue(sessionError);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    // Wait for error to appear
    await waitFor(() => {
      expect(screen.getByTestId('error')).toHaveTextContent(`Error: ${sessionError.message}`);
    });

    // Click clear error
    await act(async () => {
      screen.getByRole('button', { name: 'Clear Error' }).click();
    });

    // Check error is cleared
    expect(screen.getByTestId('error')).toHaveTextContent('No Error');
  });

  it('should update state on SIGNED_IN auth state change', async () => {
    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('loading')).toHaveTextContent('Loaded'));
    expect(screen.getByTestId('user')).toHaveTextContent('No User');

    // Simulate Supabase firing the event
    await act(async () => {
      const callback = (mockOnAuthStateChange as any).callback;
      if (callback) {
        callback('SIGNED_IN', mockSession);
      }
    });

    await waitFor(() => {
        expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`);
        expect(screen.getByTestId('session')).toHaveTextContent(`Session: ${mockSession.access_token}`);
    });
  });

  it('should update state and redirect on SIGNED_OUT auth state change when on /app', async () => {
     // Mock window.location
     const originalLocation = window.location;
     delete (window as any).location;
     window.location = { ...originalLocation, pathname: '/app/somepage' };

    // Start logged in
    (AuthActions.getSessionAction as jest.Mock).mockResolvedValue(mockSession);

    render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    await waitFor(() => expect(screen.getByTestId('user')).toHaveTextContent(`User: ${mockUser.id}`));

    // Simulate Supabase firing the event
    await act(async () => {
      const callback = (mockOnAuthStateChange as any).callback;
      if (callback) {
        callback('SIGNED_OUT', null);
      }
    });

    await waitFor(() => {
        expect(screen.getByTestId('user')).toHaveTextContent('No User');
        expect(screen.getByTestId('session')).toHaveTextContent('No Session');
        expect(mockRouterReplace).toHaveBeenCalledWith('/app/login');
    });

     // Restore window.location
     window.location = originalLocation;
  });

   it('should unsubscribe from auth state changes on unmount', () => {
    const { unmount } = render(
      <AuthProvider>
        <TestComponent />
      </AuthProvider>
    );

    expect(mockOnAuthStateChange).toHaveBeenCalledTimes(1);
    expect(mockUnsubscribe).not.toHaveBeenCalled();

    unmount();

    expect(mockUnsubscribe).toHaveBeenCalledTimes(1);
  });

   it('useAuth should throw error when used outside AuthProvider', () => {
    // Hide console.error output for this specific test
    const consoleErrorSpy = jest.spyOn(console, 'error').mockImplementation(() => {});

    const ErrorComponent = () => {
        try {
            useAuth();
        } catch (e: any) {
            return <div>Error: {e.message}</div>;
        }
        return <div>No error</div>;
    };

    render(<ErrorComponent />);

    expect(screen.getByText('Error: useAuth must be used within an AuthProvider')).toBeInTheDocument();

    // Restore console.error
    consoleErrorSpy.mockRestore();
  });

});
</file>

<file path="tests/servises/user-repository.test.ts">
// File: /tests/repositories/user.repository.test.ts

import { UserRepository, IUserRepository } from '@/repositories/user.repository';
import prisma from '@/lib/prisma';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import logger from '@/utils/logger';
import { UserProfileModel } from '@/models/AppAllModels.model';
import { SubscriptionStatus, User as PrismaUser, Onboarding as PrismaOnboarding } from '@prisma/client';
import { SupabaseClient, Session, User as SupabaseUser } from '@supabase/supabase-js';

// --- Mocks ---

// Mock Prisma Client
jest.mock('@/lib/prisma', () => ({
  user: {
    findUnique: jest.fn(),
    create: jest.fn(),
    update: jest.fn(),
    delete: jest.fn(),
  },
  // Mock other models if needed by relations, though not strictly necessary for these tests
}));

// TODO: fix tests
// Mock Supabase Server Client
jest.mock('@/utils/supabase/server');
const mockGetSession = jest.fn();
const mockAuthAdminDeleteUser = jest.fn();
const mockSupabaseClient = {
  auth: {
    getSession: mockGetSession,
    admin: {
      deleteUser: mockAuthAdminDeleteUser,
    },
  },
} as unknown as SupabaseClient;
(createSupabaseServerClient as jest.Mock).mockResolvedValue(mockSupabaseClient);

// Mock Logger
jest.mock('@/utils/logger', () => ({
  debug: jest.fn(),
  info: jest.fn(),
  warn: jest.fn(),
  error: jest.fn(),
  log: jest.fn(),
}));

// --- Test Data ---
const mockUserId = 'auth-user-id-123';
const otherUserId = 'other-user-id-456';

const mockSupabaseUser: SupabaseUser = {
  id: mockUserId,
  app_metadata: {},
  user_metadata: {},
  aud: 'authenticated',
  created_at: new Date().toISOString(),
  email: 'test@example.com',
};

const mockSession: Session = {
  access_token: 'mock-access-token',
  refresh_token: 'mock-refresh-token',
  user: mockSupabaseUser,
  expires_in: 3600,
  token_type: 'bearer',
};

const mockPrismaOnboarding: PrismaOnboarding = {
    id: 'onboarding-id-1',
    userId: mockUserId,
    steps: {},
    completed: true,
    nativeLanguage: 'English',
    targetLanguage: 'German',
    proficiencyLevel: 'beginner',
    learningPurpose: 'general',
    initialAssessmentCompleted: true,
    createdAt: new Date(),
    updatedAt: new Date(),
};

const mockPrismaUser: PrismaUser & { onboarding: PrismaOnboarding | null } = {
  id: mockUserId,
  email: 'test@example.com',
  name: 'Test User',
  createdAt: new Date(),
  updatedAt: new Date(),
  subscriptionStatus: SubscriptionStatus.ACTIVE,
  subscriptionEndDate: new Date(Date.now() + 86400000), // Tomorrow
  onboarding: mockPrismaOnboarding,
};

const mockUserProfile: UserProfileModel = {
  id: mockUserId,
  userId: mockUserId,
  email: 'test@example.com',
  name: 'Test User',
  nativeLanguage: 'English',
  targetLanguage: 'German',
  proficiencyLevel: 'beginner',
  learningPurpose: 'general',
  onboardingCompleted: true,
  initialAssessmentCompleted: true,
  subscriptionStatus: SubscriptionStatus.ACTIVE,
  subscriptionEndDate: mockPrismaUser.subscriptionEndDate,
  createdAt: mockPrismaUser.createdAt,
  updatedAt: mockPrismaUser.updatedAt,
};

const mockUnauthorizedError = new Error('Unauthorized');
const mockUnauthorizedProfileError = new Error('Unauthorized to access this profile');
const mockUnauthorizedUpdateError = new Error('Unauthorized to update this profile');
const mockUnauthorizedCreateError = new Error('Unauthorized to create this profile');
const mockUnauthorizedDeleteError = new Error('Unauthorized: You can only delete your own profile.');
const mockNotFoundError = new Error('User profile not found'); // Or similar Prisma error
const mockMissingFieldsError = new Error('Missing required fields: userId and email are required');

// --- Test Suite ---
describe('UserRepository', () => {
  let userRepository: IUserRepository;

  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();

    // Default mock implementations
    mockGetSession.mockResolvedValue({ data: { session: mockSession }, error: null });
    (prisma.user.findUnique as jest.Mock).mockResolvedValue(mockPrismaUser);
    (prisma.user.create as jest.Mock).mockResolvedValue(mockPrismaUser);
    (prisma.user.update as jest.Mock).mockResolvedValue(mockPrismaUser);
    (prisma.user.delete as jest.Mock).mockResolvedValue(mockPrismaUser); // delete returns the deleted record
    mockAuthAdminDeleteUser.mockResolvedValue({ data: {}, error: null });

    // Instantiate the repository
    // Need to bypass constructor logic slightly as it checks typeof window
    userRepository = new UserRepository();
    // Manually assign the getSupabaseClient method for server-side simulation
    (userRepository as any).getSupabaseClient = async () => mockSupabaseClient;
  });

  // --- getSession (Internal Helper) ---
  describe('getSession (internal)', () => {
    it('should return session if Supabase client provides it', async () => {
      const session = await (userRepository as any).getSession();
      expect(session).toEqual(mockSession);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
    });

    it('should throw Unauthorized error if Supabase returns an error', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Connection failed') });
      await expect((userRepository as any).getSession()).rejects.toThrow(mockUnauthorizedError);
    });

    it('should throw Unauthorized error if Supabase returns null session', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: null });
      await expect((userRepository as any).getSession()).rejects.toThrow(mockUnauthorizedError);
    });

     it('should throw Unauthorized error if Supabase returns session without user', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: { ...mockSession, user: null } }, error: null });
      await expect((userRepository as any).getSession()).rejects.toThrow(mockUnauthorizedError);
    });
  });

  // --- getUserProfile ---
  describe('getUserProfile', () => {
    it('should get user profile successfully', async () => {
      const profile = await userRepository.getUserProfile(mockUserId);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.findUnique).toHaveBeenCalledWith({
        where: { id: mockUserId },
        include: { onboarding: true },
      });
      expect(profile).toEqual(mockUserProfile);
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should throw error if trying to get profile for a different user', async () => {
      await expect(userRepository.getUserProfile(otherUserId)).rejects.toThrow(mockUnauthorizedProfileError);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.findUnique).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith('Error fetching user profile:', mockUnauthorizedProfileError);
    });

    it('should return null if user is not found in prisma', async () => {
      (prisma.user.findUnique as jest.Mock).mockResolvedValueOnce(null);
      const profile = await userRepository.getUserProfile(mockUserId);
      expect(profile).toBeNull();
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.findUnique).toHaveBeenCalledWith({
        where: { id: mockUserId },
        include: { onboarding: true },
      });
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should re-throw error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Session fetch error') });
      await expect(userRepository.getUserProfile(mockUserId)).rejects.toThrow(mockUnauthorizedError);
      expect(logger.error).toHaveBeenCalledWith('Error fetching user profile:', mockUnauthorizedError);
    });

    it('should re-throw error if prisma query fails', async () => {
      const dbError = new Error('Database connection error');
      (prisma.user.findUnique as jest.Mock).mockRejectedValueOnce(dbError);
      await expect(userRepository.getUserProfile(mockUserId)).rejects.toThrow(dbError);
      expect(logger.error).toHaveBeenCalledWith('Error fetching user profile:', dbError);
    });
  });

  // --- createUserProfile ---
  describe('createUserProfile', () => {
    const createData: Partial<UserProfileModel> = {
      userId: mockUserId,
      email: 'new@example.com',
    };
    const expectedPrismaCreateData = {
        id: mockUserId,
        email: 'new@example.com',
        subscriptionStatus: SubscriptionStatus.NONE,
        subscriptionEndDate: null,
        onboarding: {
          create: {
            steps: {},
            completed: false,
          },
        },
    };
    const expectedReturnProfile: UserProfileModel = {
        id: mockUserId,
        userId: mockUserId,
        email: 'new@example.com',
        onboardingCompleted: false,
        initialAssessmentCompleted: false,
        createdAt: expect.any(Date),
        updatedAt: expect.any(Date),
        subscriptionStatus: SubscriptionStatus.NONE,
        subscriptionEndDate: null,
    };


    it('should create a user profile successfully if user does not exist', async () => {
      (prisma.user.findUnique as jest.Mock).mockResolvedValueOnce(null); // User doesn't exist
      const createdPrismaUser = {
          ...mockPrismaUser,
          email: createData.email,
          onboarding: { ...mockPrismaOnboarding, completed: false, initialAssessmentCompleted: false },
          subscriptionStatus: SubscriptionStatus.NONE,
          subscriptionEndDate: null,
      };
      (prisma.user.create as jest.Mock).mockResolvedValueOnce(createdPrismaUser);

      const profile = await userRepository.createUserProfile(createData);

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.findUnique).toHaveBeenCalledWith({ where: { id: mockUserId } });
      expect(prisma.user.create).toHaveBeenCalledWith({
        data: expectedPrismaCreateData,
        include: { onboarding: true },
      });
      expect(profile).toMatchObject(expectedReturnProfile); // Use partial match for dates
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should return existing profile if user already exists', async () => {
      (prisma.user.findUnique as jest.Mock).mockResolvedValueOnce(mockPrismaUser); // User exists
      // Mock findUnique again for the getUserProfile call within createUserProfile
      (prisma.user.findUnique as jest.Mock).mockResolvedValueOnce(mockPrismaUser);

      const profile = await userRepository.createUserProfile(createData);

      expect(mockGetSession).toHaveBeenCalledTimes(1); // Called once for the initial check
      expect(prisma.user.findUnique).toHaveBeenCalledTimes(2); // Called for exists check, then for getProfile
      expect(prisma.user.create).not.toHaveBeenCalled();
      expect(profile).toEqual(mockUserProfile); // Should return the full existing profile
    });

    it('should throw error if trying to create profile for a different user ID', async () => {
       const createDataOtherUser: Partial<UserProfileModel> = {
          userId: otherUserId, // Different user ID
          email: 'other@example.com',
       };
      await expect(userRepository.createUserProfile(createDataOtherUser)).rejects.toThrow(mockUnauthorizedCreateError);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.findUnique).not.toHaveBeenCalled();
      expect(prisma.user.create).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith('Error creating user profile:', mockUnauthorizedCreateError);
    });

    it('should throw error if required fields (userId, email) are missing', async () => {
      await expect(userRepository.createUserProfile({ userId: mockUserId })).rejects.toThrow(mockMissingFieldsError);
      await expect(userRepository.createUserProfile({ email: 'test@test.com' })).rejects.toThrow(mockMissingFieldsError);
      expect(mockGetSession).toHaveBeenCalledTimes(2); // Called for each attempt
      expect(prisma.user.findUnique).not.toHaveBeenCalled();
      expect(prisma.user.create).not.toHaveBeenCalled();
    });

    it('should re-throw error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Session fetch error') });
      await expect(userRepository.createUserProfile(createData)).rejects.toThrow(mockUnauthorizedError);
      expect(logger.error).toHaveBeenCalledWith('Error creating user profile:', mockUnauthorizedError);
    });

    it('should re-throw error if prisma query fails', async () => {
      const dbError = new Error('Database connection error');
      (prisma.user.findUnique as jest.Mock).mockRejectedValueOnce(dbError); // Fail the exists check
      await expect(userRepository.createUserProfile(createData)).rejects.toThrow(dbError);
      expect(logger.error).toHaveBeenCalledWith('Error creating user profile:', dbError);
    });
  });

  // --- updateUserProfile ---
  describe('updateUserProfile', () => {
    const updateData: Partial<UserProfileModel> = {
      name: 'Updated Name',
      nativeLanguage: 'Spanish',
      onboardingCompleted: true,
    };
    const expectedPrismaUpdateData = {
        name: 'Updated Name',
        onboarding: {
          upsert: {
            create: {
              nativeLanguage: 'Spanish',
              completed: true,
              steps: {},
            },
            update: {
              nativeLanguage: 'Spanish',
              completed: true,
            },
          },
        },
    };
    const updatedPrismaUser = {
        ...mockPrismaUser,
        name: 'Updated Name',
        onboarding: { ...mockPrismaOnboarding, nativeLanguage: 'Spanish', completed: true }
    };
    const expectedReturnProfile: UserProfileModel = {
        ...mockUserProfile,
        name: 'Updated Name',
        nativeLanguage: 'Spanish',
        onboardingCompleted: true,
    };

    it('should update user profile successfully', async () => {
      (prisma.user.update as jest.Mock).mockResolvedValueOnce(updatedPrismaUser);
      const profile = await userRepository.updateUserProfile(mockUserId, updateData);

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.update).toHaveBeenCalledWith({
        where: { id: mockUserId },
        data: expectedPrismaUpdateData,
        include: { onboarding: true },
      });
      expect(profile).toMatchObject(expectedReturnProfile);
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should throw error if trying to update profile for a different user', async () => {
      await expect(userRepository.updateUserProfile(otherUserId, updateData)).rejects.toThrow(mockUnauthorizedUpdateError);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.update).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith('Error updating user profile:', mockUnauthorizedUpdateError);
    });

    it('should re-throw error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Session fetch error') });
      await expect(userRepository.updateUserProfile(mockUserId, updateData)).rejects.toThrow(mockUnauthorizedError);
      expect(logger.error).toHaveBeenCalledWith('Error updating user profile:', mockUnauthorizedError);
    });

    it('should re-throw error if prisma query fails', async () => {
      const dbError = new Error('Database connection error');
      (prisma.user.update as jest.Mock).mockRejectedValueOnce(dbError);
      await expect(userRepository.updateUserProfile(mockUserId, updateData)).rejects.toThrow(dbError);
      expect(logger.error).toHaveBeenCalledWith('Error updating user profile:', dbError);
    });
  });

  // --- deleteUserProfile ---
  describe('deleteUserProfile', () => {
    it('should delete user profile and auth user successfully', async () => {
      await userRepository.deleteUserProfile(mockUserId);

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.delete).toHaveBeenCalledWith({ where: { id: mockUserId } });
      expect(mockAuthAdminDeleteUser).toHaveBeenCalledWith(mockUserId);
      expect(logger.error).not.toHaveBeenCalled();
      expect(logger.warn).toHaveBeenCalledWith(`Starting deletion for user: ${mockUserId}`);
      expect(logger.info).toHaveBeenCalledWith(`Deleting user data from DB: ${mockUserId}`);
      expect(logger.info).toHaveBeenCalledWith(`DB deletion complete: ${mockUserId}`);
      expect(logger.info).toHaveBeenCalledWith(`Auth user deleted: ${mockUserId}`);
      expect(logger.warn).toHaveBeenCalledWith(`Deletion completed for: ${mockUserId}`);
    });

    it('should throw error if trying to delete profile for a different user', async () => {
      await expect(userRepository.deleteUserProfile(otherUserId)).rejects.toThrow(mockUnauthorizedDeleteError);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.delete).not.toHaveBeenCalled();
      expect(mockAuthAdminDeleteUser).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(`Unauthorized delete attempt. Session user: ${mockUserId}, Target: ${otherUserId}`);
      expect(logger.error).toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.objectContaining({ message: mockUnauthorizedDeleteError.message }));
    });

    it('should re-throw error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Session fetch error') });
      await expect(userRepository.deleteUserProfile(mockUserId)).rejects.toThrow(mockUnauthorizedError);
      expect(logger.error).toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.objectContaining({ message: mockUnauthorizedError.message }));
    });

    it('should handle Prisma P2025 error (Record not found) gracefully', async () => {
      const p2025Error = { code: 'P2025', message: 'Record to delete not found.' };
      (prisma.user.delete as jest.Mock).mockRejectedValueOnce(p2025Error);

      // Should not throw, but log a warning and still attempt auth deletion
      await expect(userRepository.deleteUserProfile(mockUserId)).resolves.toBeUndefined();

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.delete).toHaveBeenCalledWith({ where: { id: mockUserId } });
      expect(logger.warn).toHaveBeenCalledWith(expect.stringContaining(`User profile not found in DB for deletion (userId: ${mockUserId})`));
      expect(logger.info).toHaveBeenCalledWith(expect.stringContaining(`Attempting Auth Provider deletion for potentially orphaned user: ${mockUserId}`));
      expect(mockAuthAdminDeleteUser).toHaveBeenCalledWith(mockUserId); // Still attempts auth deletion
      expect(logger.error).not.toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.anything()); // Should not log the main error
    });

     it('should log error if auth deletion fails after P2025 error', async () => {
      const p2025Error = { code: 'P2025', message: 'Record to delete not found.' };
      const authDeleteError = new Error('Auth service unavailable');
      (prisma.user.delete as jest.Mock).mockRejectedValueOnce(p2025Error);
      mockAuthAdminDeleteUser.mockResolvedValueOnce({ data: null, error: authDeleteError }); // Simulate auth error

      await expect(userRepository.deleteUserProfile(mockUserId)).resolves.toBeUndefined(); // Still resolves void

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.delete).toHaveBeenCalledWith({ where: { id: mockUserId } });
      expect(logger.warn).toHaveBeenCalledWith(expect.stringContaining(`User profile not found in DB for deletion (userId: ${mockUserId})`));
      expect(logger.info).toHaveBeenCalledWith(expect.stringContaining(`Attempting Auth Provider deletion for potentially orphaned user: ${mockUserId}`));
      expect(mockAuthAdminDeleteUser).toHaveBeenCalledWith(mockUserId);
      // Should log the auth deletion error specifically
      expect(logger.error).toHaveBeenCalledWith(expect.stringContaining(`Failed to delete potentially orphaned user ${mockUserId} from Auth Provider:`), authDeleteError.message);
      expect(logger.error).not.toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.anything()); // Should not log the main error
    });

    it('should re-throw other Prisma errors during deletion', async () => {
      const dbError = new Error('Database connection error');
      (prisma.user.delete as jest.Mock).mockRejectedValueOnce(dbError);
      await expect(userRepository.deleteUserProfile(mockUserId)).rejects.toThrow(`Failed to delete user profile: ${dbError.message}`);
      expect(logger.error).toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.objectContaining({ message: dbError.message }));
      expect(mockAuthAdminDeleteUser).not.toHaveBeenCalled(); // Should fail before auth deletion
    });

    it('should throw error if auth user deletion fails', async () => {
      const authError = new Error('Failed to delete auth user');
      mockAuthAdminDeleteUser.mockResolvedValueOnce({ data: null, error: authError });

      await expect(userRepository.deleteUserProfile(mockUserId)).rejects.toThrow(authError.message); // Action re-throws the specific auth error message

      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(prisma.user.delete).toHaveBeenCalledWith({ where: { id: mockUserId } });
      expect(mockAuthAdminDeleteUser).toHaveBeenCalledWith(mockUserId);
      expect(logger.error).toHaveBeenCalledWith(`Auth deletion failed: ${authError.message}`, { userId: mockUserId });
      expect(logger.error).toHaveBeenCalledWith(expect.stringContaining('Error during user profile deletion'), expect.objectContaining({ message: authError.message }));
    });
  });
});
</file>

<file path="tests/servises/user-service.test.ts">
// File: /tests/lib/server-actions/user-actions.test.ts

import {
  getUserProfileAction,
  createUserProfileAction,
  updateUserProfileAction,
  deleteUserProfileAction,
} from '@/lib/server-actions/user-actions';
import UserService from '@/services/user.service';
// No longer need to mock UserRepository directly here if we mock UserService
// import { UserRepository } from '@/repositories/user.repository';
import { UserProfileModel } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { revalidatePath } from 'next/cache';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import { SubscriptionStatus } from '@prisma/client';
import { SupabaseClient, Session, User } from '@supabase/supabase-js';

// --- Mocks ---

// Mock UserService and its prototype methods
jest.mock('@/services/user.service');
const mockGetUserProfile = jest.fn();
const mockCreateUserProfile = jest.fn();
const mockUpdateUserProfile = jest.fn();
const mockDeleteUserProfile = jest.fn();
UserService.prototype.getUserProfile = mockGetUserProfile;
UserService.prototype.createUserProfile = mockCreateUserProfile;
UserService.prototype.updateUserProfile = mockUpdateUserProfile;
UserService.prototype.deleteUserProfile = mockDeleteUserProfile;

// Mock Supabase Server Client and Auth methods
jest.mock('@/utils/supabase/server');
const mockGetSession = jest.fn();
// const mockAuthAdminDeleteUser = jest.fn(); // Keep if needed by service/repo mock, but likely not needed here
const mockSupabaseClient = {
  auth: {
    getSession: mockGetSession,
    // admin: { // Mock admin interface if used by repository
    //   deleteUser: mockAuthAdminDeleteUser,
    // }
  },
} as unknown as SupabaseClient; // Cast to avoid full type implementation
(createSupabaseServerClient as jest.Mock).mockResolvedValue(mockSupabaseClient);

// Mock Next.js Cache
jest.mock('next/cache', () => ({
  revalidatePath: jest.fn(),
}));

// Mock Logger
jest.mock('@/utils/logger', () => ({
  debug: jest.fn(),
  info: jest.fn(),
  warn: jest.fn(),
  error: jest.fn(),
  log: jest.fn(), // Add log if used
}));

// --- Test Data ---
const mockUserId = 'user-test-123';
const otherUserId = 'user-other-456';

const mockUserProfile: UserProfileModel = {
  id: mockUserId,
  userId: mockUserId,
  email: 'test@example.com',
  name: 'Test User',
  nativeLanguage: 'English',
  targetLanguage: 'German',
  proficiencyLevel: 'beginner',
  learningPurpose: 'general',
  onboardingCompleted: true,
  initialAssessmentCompleted: true,
  subscriptionStatus: SubscriptionStatus.ACTIVE,
  subscriptionEndDate: new Date(Date.now() + 86400000), // Tomorrow
  createdAt: new Date(),
  updatedAt: new Date(),
};

const mockUser: User = {
  id: mockUserId,
  app_metadata: {},
  user_metadata: {},
  aud: 'authenticated',
  created_at: new Date().toISOString(),
  email: 'test@example.com',
};

const mockSession: Session = {
  access_token: 'mock-access-token',
  refresh_token: 'mock-refresh-token',
  user: mockUser,
  expires_in: 3600,
  token_type: 'bearer',
};

// Use specific error messages matching the implementation
const mockAuthError = new Error('Authentication required.');
const mockUnauthorizedError = new Error('Unauthorized');
const mockNotFoundError = new Error('User profile not found');
const mockDeleteError = new Error('Failed to delete profile');
const mockDeleteAuthRequiredErrorMsg = 'Authentication required. Please log in again.';
const mockDeleteUnauthorizedErrorMsg = 'Unauthorized to perform this action.';
const mockDeleteGenericErrorMsg = 'Failed to delete profile due to an unexpected error.';


// --- Test Suite ---
describe('User Server Actions', () => {
  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();

    // Default mock implementations for UserService methods
    mockGetUserProfile.mockResolvedValue(mockUserProfile);
    mockCreateUserProfile.mockResolvedValue(mockUserProfile);
    mockUpdateUserProfile.mockResolvedValue(mockUserProfile);
    mockDeleteUserProfile.mockResolvedValue(undefined); // Resolves void on success

    // Default mock implementation for Supabase getSession
    mockGetSession.mockResolvedValue({ data: { session: mockSession }, error: null });
  });

  // --- getUserProfileAction ---
  describe('getUserProfileAction', () => {
    it('should get the user profile for the currently logged-in user', async () => {
      const profile = await getUserProfileAction(mockUserId);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      // Check that the mocked service method was called
      expect(mockGetUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(profile).toEqual(mockUserProfile);
      expect(logger.warn).not.toHaveBeenCalled();
    });

    it('should throw Unauthorized error when trying to get another user profile', async () => {
      await expect(getUserProfileAction(otherUserId)).rejects.toThrow(mockUnauthorizedError.message);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(logger.warn).toHaveBeenCalledWith(
        `Unauthorized attempt to get profile. Logged in user: ${mockUserId}, Requested user: ${otherUserId}`
      );
      // Service method should not be called if authorization fails
      expect(mockGetUserProfile).not.toHaveBeenCalled();
    });

    it('should throw Authentication error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Supabase connection error') }); // Simulate Supabase error

      await expect(getUserProfileAction(mockUserId)).rejects.toThrow(mockAuthError.message);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(mockGetUserProfile).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        'Error in getUserProfileAction:',
        expect.objectContaining({ error: mockAuthError.message }) // Check the error thrown by the action
      );
    });

     it('should throw Authentication error if session is null', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: null });

      await expect(getUserProfileAction(mockUserId)).rejects.toThrow(mockAuthError.message);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(mockGetUserProfile).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        'Error in getUserProfileAction:',
        expect.objectContaining({ error: mockAuthError.message })
      );
    });

    it('should return null if user profile is not found by the service', async () => {
      // Configure the mocked service method to return null
      mockGetUserProfile.mockResolvedValueOnce(null);

      const profile = await getUserProfileAction(mockUserId);

      expect(profile).toBeNull(); // Action should return null now
      expect(mockGetUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(logger.error).not.toHaveBeenCalled(); // Action handles null return gracefully
    });

    it('should return null and log error for general service errors', async () => {
      const serviceError = new Error('Database connection failed');
      // Configure the mocked service method to reject
      mockGetUserProfile.mockRejectedValueOnce(serviceError);

      const profile = await getUserProfileAction(mockUserId);

      expect(profile).toBeNull(); // Action should catch, log, and return null
      expect(mockGetUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(logger.error).toHaveBeenCalledWith(
        'Error in getUserProfileAction:',
        expect.objectContaining({ error: serviceError.message })
      );
    });
  });

  // --- createUserProfileAction ---
  describe('createUserProfileAction', () => {
    const newProfileData: Partial<UserProfileModel> = {
      userId: mockUserId, // Important: Usually userId comes from auth, ensure it's passed
      email: 'new@example.com',
      onboardingCompleted: false,
    };

    it('should create a user profile successfully', async () => {
      const createdProfile = { ...mockUserProfile, ...newProfileData, id: mockUserId };
      mockCreateUserProfile.mockResolvedValueOnce(createdProfile);

      const profile = await createUserProfileAction(newProfileData);

      // Check that the mocked service method was called
      expect(mockCreateUserProfile).toHaveBeenCalledWith(newProfileData);
      expect(profile).toEqual(createdProfile);
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should throw and log error if service creation fails', async () => {
      const serviceError = new Error('Failed to insert user');
      mockCreateUserProfile.mockRejectedValueOnce(serviceError);

      // Action should re-throw the error
      await expect(createUserProfileAction(newProfileData)).rejects.toThrow(serviceError);

      expect(mockCreateUserProfile).toHaveBeenCalledWith(newProfileData);
      expect(logger.error).toHaveBeenCalledWith(
        'Error in createUserProfileAction:',
        serviceError
      );
    });
  });

  // --- updateUserProfileAction ---
  describe('updateUserProfileAction', () => {
    const updateData: Partial<UserProfileModel> = {
      name: 'Updated Name',
      learningPurpose: 'business',
    };
    const updatedProfile = { ...mockUserProfile, ...updateData };

    it('should update the user profile for the currently logged-in user', async () => {
      mockUpdateUserProfile.mockResolvedValueOnce(updatedProfile);

      const profile = await updateUserProfileAction(mockUserId, updateData);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      // Check that the mocked service method was called
      expect(mockUpdateUserProfile).toHaveBeenCalledWith(mockUserId, updateData);
      expect(profile).toEqual(updatedProfile);
      expect(logger.warn).not.toHaveBeenCalled();
    });

    it('should throw Unauthorized error when trying to update another user profile', async () => {
      await expect(updateUserProfileAction(otherUserId, updateData)).rejects.toThrow(mockUnauthorizedError.message);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(logger.warn).toHaveBeenCalledWith(
        `Unauthorized attempt to update profile. Logged in user: ${mockUserId}, Target user: ${otherUserId}`
      );
      expect(mockUpdateUserProfile).not.toHaveBeenCalled();
    });

    it('should throw Authentication error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Supabase error') });

      await expect(updateUserProfileAction(mockUserId, updateData)).rejects.toThrow(mockAuthError.message);

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(mockUpdateUserProfile).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        'Error in updateUserProfileAction:',
        expect.objectContaining({ error: mockAuthError.message })
      );
    });

    it('should throw and log error if service update fails', async () => {
      const serviceError = new Error('Database update failed');
      mockUpdateUserProfile.mockRejectedValueOnce(serviceError);

      // Action should re-throw the error
      await expect(updateUserProfileAction(mockUserId, updateData)).rejects.toThrow(serviceError);

      expect(mockUpdateUserProfile).toHaveBeenCalledWith(mockUserId, updateData);
      expect(logger.error).toHaveBeenCalledWith(
        'Error in updateUserProfileAction:',
        expect.objectContaining({ error: serviceError.message })
      );
    });
  });

  // --- deleteUserProfileAction ---
  describe('deleteUserProfileAction', () => {
    it('should delete the user profile for the currently logged-in user', async () => {
      const result = await deleteUserProfileAction();

      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      // Check that the mocked service method was called
      expect(mockDeleteUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(revalidatePath).toHaveBeenCalledWith('/');
      expect(revalidatePath).toHaveBeenCalledWith('/app');
      expect(result).toEqual({ success: true });
      expect(logger.warn).toHaveBeenCalledWith(`deleteUserProfileAction: Initiating profile deletion for user: ${mockUserId}`);
      expect(logger.warn).toHaveBeenCalledWith(`deleteUserProfileAction: Successfully completed profile deletion for user: ${mockUserId}`);
      expect(logger.error).not.toHaveBeenCalled();
    });

    it('should return error if session fetch fails', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: new Error('Supabase error') });

      const result = await deleteUserProfileAction();

      // Check the specific error message from the action's catch block
      expect(result).toEqual({ success: false, error: mockDeleteAuthRequiredErrorMsg });
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(mockDeleteUserProfile).not.toHaveBeenCalled();
      expect(revalidatePath).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        `Error in deleteUserProfileAction for user UNKNOWN:`, // User ID is unknown before session check
        expect.objectContaining({ message: mockAuthError.message }) // The original error causing the failure
      );
    });

     it('should return error if session is null', async () => {
      mockGetSession.mockResolvedValueOnce({ data: { session: null }, error: null });

      const result = await deleteUserProfileAction();

      // Check the specific error message
      expect(result).toEqual({ success: false, error: mockDeleteAuthRequiredErrorMsg });
      expect(createSupabaseServerClient).toHaveBeenCalledTimes(1);
      expect(mockGetSession).toHaveBeenCalledTimes(1);
      expect(mockDeleteUserProfile).not.toHaveBeenCalled();
      expect(revalidatePath).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        `Error in deleteUserProfileAction for user UNKNOWN:`,
        expect.objectContaining({ message: mockAuthError.message }) // The original error
      );
    });


    it('should return error and log if service deletion fails', async () => {
      mockDeleteUserProfile.mockRejectedValueOnce(mockDeleteError);

      const result = await deleteUserProfileAction();

      // Check the specific error message
      expect(result).toEqual({ success: false, error: mockDeleteGenericErrorMsg });
      expect(mockDeleteUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(revalidatePath).not.toHaveBeenCalled();
      expect(logger.error).toHaveBeenCalledWith(
        `Error in deleteUserProfileAction for user ${mockUserId}:`,
        expect.objectContaining({ message: mockDeleteError.message })
      );
    });

     it('should return specific error message for Unauthorized error during deletion', async () => {
      const unauthorizedServiceError = new Error('Unauthorized'); // Simulate service throwing this
      mockDeleteUserProfile.mockRejectedValueOnce(unauthorizedServiceError);

      const result = await deleteUserProfileAction();

      // Check the specific error message
      expect(result).toEqual({ success: false, error: mockDeleteUnauthorizedErrorMsg });
      expect(mockDeleteUserProfile).toHaveBeenCalledWith(mockUserId);
      expect(logger.error).toHaveBeenCalledWith(
        `Error in deleteUserProfileAction for user ${mockUserId}:`,
        expect.objectContaining({ message: unauthorizedServiceError.message })
      );
    });
  });
});
</file>

<file path=".env.example">
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
NEXT_PUBLIC_POSTHOG_KEY=
NEXT_PUBLIC_POSTHOG_HOST=


NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
NEXT_PUBLIC_BASE_URL=
NODE_ENV=development
VERCEL_URL=
AI_API_KEY=

AI_API_KEY_1=
AI_API_KEY_2=
AI_API_KEY_3=
AI_API_KEY_4=

HTTP_PROXY=
HTTPS_PROXY=

NEXT_PUBLIC_ENVIRONMENT=development
MOCK_AI_RESPONSE=false

NEXT_PUBLIC_POSTHOG_KEY=
NEXT_PUBLIC_POSTHOG_HOST=


AWS_POLLY_REGION=
AWS_POLLY_ACCESS_KEY=
AWS_POLLY_SECRET_KEY= 

# Update the DATABASE_URL to match the docker-compose configuration
DATABASE_URL="postgresql://myuser:mypassword@localhost:5433/mydb"
</file>

<file path=".prettierrc">
{
  "semi": true,
  "singleQuote": true,
  "printWidth": 80,
  "tabWidth": 2,
  "trailingComma": "es5"
}
</file>

<file path="babel.test.babelrc">
{
  "presets": [
    "@babel/preset-env",
    "@babel/preset-react",
    "@babel/preset-typescript"
  ],
  "plugins": [
    ["module-resolver", {
      "root": ["./src"],
      "alias": {
        "@": "./src"
      }
    }]
  ]
}
</file>

<file path="docker-compose.mac.prod.yml">
version: '3.3'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.mac
    ports:
      - '3000:3000'
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://postgres.tdzryocudlllmufiiaki:KentHD720pgans2vlad@aws-0-us-west-1.pooler.supabase.com:5432/postgres
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
      - NODE_ENV=development
      - CHOKIDAR_INTERVAL=300
    # depends_on:
    #   - db
    volumes:
      - ./src:/app/src # Mount src directory for hot reload
      - ./public:/app/public # Mount public directory for hot reload
      - ./package.json:/app/package.json # Mount package.json
      - ./package-lock.json:/app/package-lock.json # Mount package-lock.json
      - ./tailwind.config.ts:/app/tailwind.config.ts # Mount tailwind.config.ts
      - ./src/app/globals.css:/app/src/app/globals.css # Mount globals.css
      - ./tsconfig.json:/app/tsconfig.json # Mount tsconfig.json
      - ./prisma:/app/prisma # Mount prisma
      - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  # db:
  #   image: postgres:17
  #   environment:
  #     POSTGRES_USER: myuser
  #     POSTGRES_PASSWORD: mypassword
  #     POSTGRES_DB: mydb
  #   ports:
  #     - '5433:5432'
  #   volumes:
  #     - postgres-data:/var/lib/postgresql/data
  #   networks:
  #     - web-network

networks:
  web-network:
    driver: bridge

# volumes:
#   postgres-data:
</file>

<file path="docker-compose.mac.yml">
version: '3.3'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.mac
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://myuser:mypassword@db:5432/mydb
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
      - NODE_ENV=development
      - CHOKIDAR_INTERVAL=300
    depends_on:
      - db
    volumes:
      - ./src:/app/src  # Mount src directory for hot reload
      - ./public:/app/public  # Mount public directory for hot reload
      - ./package.json:/app/package.json  # Mount package.json
      - ./package-lock.json:/app/package-lock.json  # Mount package-lock.json
      - ./tailwind.config.ts:/app/tailwind.config.ts  # Mount tailwind.config.ts
      - ./src/app/globals.css:/app/src/app/globals.css  # Mount globals.css
      - ./tsconfig.json:/app/tsconfig.json  # Mount tsconfig.json
      - ./prisma:/app/prisma  # Mount prisma
      - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  db:
    image: postgres:17
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5433:5432" 
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - web-network


networks:
  web-network:
    driver: bridge

volumes:
  postgres-data:
</file>

<file path="Dockerfile.proxy">
FROM node:20.11-bullseye
ARG HTTP_PROXY
ARG HTTPS_PROXY

ENV HTTP_PROXY=${HTTP_PROXY}
ENV HTTPS_PROXY=${HTTPS_PROXY}

ENV http_proxy=${HTTP_PROXY}
ENV https_proxy=${HTTPS_PROXY}

ENV NO_PROXY=localhost,127.0.0.1,.docker.internal,supabase.com,dl-cdn.alpinelinux.org
WORKDIR /app

RUN if [ -n "${HTTP_PROXY}" ]; then \
      npm config set proxy ${HTTP_PROXY} && \
      npm config set https-proxy ${HTTPS_PROXY} && \
      { echo "proxy=${HTTP_PROXY}"; \
        echo "http-proxy=${HTTP_PROXY}"; \
        echo "https-proxy=${HTTPS_PROXY}"; } > /root/.curlrc; \
    fi

RUN if [ -z "${HTTP_PROXY}" ]; then \
      apt-get update && apt-get install -y curl ca-certificates; \
    else \
      http_proxy=${HTTP_PROXY} https_proxy=${HTTPS_PROXY} \
      apt-get update && apt-get install -y curl ca-certificates; \
    fi

RUN echo "precedence ::ffff:0:0/96 100" > /etc/gai.conf

COPY package*.json ./

# Install dependencies with proxy support
RUN if [ -n "${HTTP_PROXY}" ]; then \
      npm config set proxy ${HTTP_PROXY} && \
      npm config set https-proxy ${HTTPS_PROXY} && \
      npm config set strict-ssl false; \
    fi && \
    npm install --verbose

COPY . .

RUN npx prisma generate

EXPOSE 3000

CMD ["npm", "run", "dev"]
</file>

<file path="eslint.config.mjs">
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
  {
    rules: {
      "no-unused-vars": "off",
      "@typescript-eslint/no-unused-vars": "off",
      "no-console": "off",
      "no-undef": "off",
      "no-empty": "off",
      "no-extra-semi": "off",
      "no-mixed-spaces-and-tabs": "off",
      "no-redeclare": "off",
      "no-unreachable": "off",
      "no-unsafe-finally": "off",
      "no-unsafe-negation": "off",
      "no-useless-escape": "off",
      "no-var": "off",
      "prefer-const": "off",
      "quotes": "off",
      "semi": "off",
      "@typescript-eslint/no-explicit-any": "off",
      "@typescript-eslint/no-misused-new": "off",
      "@typescript-eslint/ban-ts-comment": "off",
      "@typescript-eslint/ban-types": "off",
      "react-hooks/exhaustive-deps": "off",
      "react/display-name": "off",
      "no-warning-comments": "off"
    },
    ignores: []
  }
];

export default eslintConfig;
</file>

<file path="exported-data.json">
[
  {
    "id": "cm91dx28m0001lh1176u9k5qd",
    "userId": "mock-user-id",
    "description": "Comprehensive German language assessment",
    "completed": false,
    "sourceLanguage": "English",
    "targetLanguage": "German",
    "metrics": {
      "accuracy": 0,
      "strengths": [],
      "weaknesses": [],
      "grammarScore": 0,
      "overallScore": 0,
      "vocabularyScore": 0,
      "pronunciationScore": 0
    },
    "proposedTopics": [],
    "summary": null,
    "createdAt": "2025-04-03T13:21:34.870Z",
    "updatedAt": "2025-04-03T13:21:34.870Z",
    "sessionRecordingUrl": null,
    "steps": [
      {
        "id": "cm91dx29e0003lh11uflo309z",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 2,
        "type": "question",
        "content": "Choose the correct German translation for 'Hello'.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686482848-content_step_2.mp3",
        "translation": null,
        "expectedAnswer": "Hallo",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686483482-answer_step_2.mp3",
        "maxAttempts": 3,
        "userResponse": "Hallo",
        "attempts": 2,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:29.937Z",
        "feedback": "Correct! 'Hallo' is the most common way to say 'Hello' in German. Other options include 'Guten Tag' (Good day) and 'Guten Morgen' (Good morning).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:29.939Z"
      },
      {
        "id": "cm91dx2a10008lh1170jfw7kt",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 6,
        "type": "question",
        "content": "Choose the correct article for 'Tisch' (table).",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686489957-content_step_6.mp3",
        "translation": null,
        "expectedAnswer": "der",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686490561-answer_step_6.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "The correct article is 'der'. Therefore, it is 'der Tisch'. Remember that German nouns have genders (masculine, feminine, or neuter) which determine the article.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx2a4000elh113tt2ahgu",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 7,
        "type": "question",
        "content": "What is the past participle of the verb 'essen' (to eat)?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686491655-content_step_7.mp3",
        "translation": null,
        "expectedAnswer": "gegessen",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686492409-answer_step_7.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "The correct past participle is 'gegessen'. This is used to form the perfect tense (e.g., Ich habe gegessen - I have eaten).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx2a3000alh11cch5c4m4",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 4,
        "type": "question",
        "content": "Complete the sentence: Ich _____ ein Buch.",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686486272-content_step_4.mp3",
        "translation": "I _____ a book.",
        "expectedAnswer": "lese",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686486956-answer_step_4.mp3",
        "maxAttempts": 3,
        "userResponse": "This is a mock response different from the expected",
        "attempts": 8,
        "correct": false,
        "lastAttemptAt": "2025-04-03T13:25:33.501Z",
        "feedback": "The correct answer is 'lese'. The verb 'lesen' (to read) is conjugated to 'lese' in the first person singular (ich).",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:25:33.502Z"
      },
      {
        "id": "cm91dx2a3000clh11zhfgy3hk",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 8,
        "type": "summary",
        "content": "Thank you for completing the assessment! Based on your responses, we have a better understanding of your German language skills. We're excited to help you on your language learning journey, no matter your level. Let's get started!",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686494861-content_step_8.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": null,
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      },
      {
        "id": "cm91dx29s0005lh113q4tud6e",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 1,
        "type": "instruction",
        "content": "Welcome to our German language assessment! This short quiz will help us determine your current German proficiency level. Please answer each question to the best of your ability. Don't worry if you don't know all the answers – this is just to help us personalize your learning experience. Viel Glück! (Good luck!)",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686481755-content_step_1.mp3",
        "translation": null,
        "expectedAnswer": null,
        "expectedAnswerAudioUrl": null,
        "maxAttempts": 1,
        "userResponse": "Acknowledged",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:16.551Z",
        "feedback": null,
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:16.552Z"
      },
      {
        "id": "cm91dx2a6000glh11ezdyqlwf",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 3,
        "type": "question",
        "content": "What is the German word for 'thank you'?",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686484428-content_step_3.mp3",
        "translation": null,
        "expectedAnswer": "Danke",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686485129-answer_step_3.mp3",
        "maxAttempts": 3,
        "userResponse": "Danke",
        "attempts": 1,
        "correct": true,
        "lastAttemptAt": "2025-04-03T13:22:36.332Z",
        "feedback": "'Danke' is correct! You can also say 'Vielen Dank' for 'Thank you very much'.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:22:36.333Z"
      },
      {
        "id": "cm91dx2a7000hlh111peyaxaj",
        "assessmentId": "cm91dx28m0001lh1176u9k5qd",
        "stepNumber": 5,
        "type": "question",
        "content": "Translate the following sentence into German: 'My name is John.'",
        "contentAudioUrl": "/lessay/assessmentStep/audio/1743686488193-content_step_5.mp3",
        "translation": null,
        "expectedAnswer": "Ich heiße John",
        "expectedAnswerAudioUrl": "/lessay/assessmentStep/audio/1743686488904-answer_step_5.mp3",
        "maxAttempts": 3,
        "userResponse": null,
        "attempts": 0,
        "correct": false,
        "lastAttemptAt": null,
        "feedback": "Correct! 'Ich heiße John' is the most common way to say 'My name is John'. Another option is 'Mein Name ist John'.",
        "createdAt": "2025-04-03T13:21:34.898Z",
        "updatedAt": "2025-04-03T13:21:34.898Z"
      }
    ]
  }
]
</file>

<file path="google9439ee28c89af9a5 (1).html">
google-site-verification: google9439ee28c89af9a5.html
</file>

<file path="jest.setup.mjs">
import fetch, { Request, Response, Headers } from 'node-fetch';
import '@testing-library/jest-dom';
import { TextEncoder, TextDecoder } from 'util';
import '@testing-library/jest-dom';


// Polyfill TextEncoder and TextDecoder for Next.js request parsing in Node.
globalThis.TextEncoder = TextEncoder;
globalThis.TextDecoder = TextDecoder;
globalThis.Headers = Headers;
globalThis.Request = Request;
globalThis.Response = Response;
globalThis.fetch = fetch;

process.env.NEXT_PUBLIC_SUPABASE_URL = 'mock-url';
process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY = 'mock-key';

globalThis.IS_REACT_ACT_ENVIRONMENT = true;

if (!globalThis.Request) {
  globalThis.Request = Request;
  globalThis.Response = Response;
  globalThis.Headers = Headers;
  globalThis.fetch = fetch;
}
</file>

<file path="postcss.config.mjs">
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;
</file>

<file path="README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path="sitemap-config.mjs">
const siteUrl = process.env.NEXT_PUBLIC_BASE_URL || 'https://lessay-app.vercel.app';

const config = {
  siteUrl: siteUrl,
  generateRobotsTxt: true,
  exclude: ['/api/*', '/404'],
  robotsTxtOptions: {
    policies: [
      {
        userAgent: '*',
        allow: '/',
        disallow: ['/api/*'],
      },
    ],
    additionalSitemaps: [
      `${siteUrl}/server-sitemap.xml`,
    ],
  },
  transform: async (config, path) => {
    return {
      loc: path,
      changefreq: 'daily',
      priority: config.priority,
      lastmod: new Date().toISOString(),
    };
  },
};

export default config;
</file>

<file path="tailwind.config.ts">
import type { Config } from "tailwindcss";

export default {
  content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
    extend: {
      fontFamily: {
        sans: ['Segoe UI', 'system-ui', 'sans-serif'],
      },
      colors: {
        // Neutral Colors (1-12)
        neutral: {
          1: 'var(--neutral-1)',
          2: 'var(--neutral-2)',
          3: 'var(--neutral-3)',
          4: 'var(--neutral-4)',
          5: 'var(--neutral-5)',
          6: 'var(--neutral-6)',
          7: 'var(--neutral-7)',
          8: 'var(--neutral-8)',
          9: 'var(--neutral-9)',
          10: 'var(--neutral-10)',
          11: 'var(--neutral-11)',
          12: 'var(--neutral-12)',
        },
        // Accent Colors (1-10)
        accent: {
          1: 'var(--accent-1)',
          2: 'var(--accent-2)',
          3: 'var(--accent-3)',
          4: 'var(--accent-4)',
          5: 'var(--accent-5)',
          6: 'var(--accent-6)',
          7: 'var(--accent-7)',
          8: 'var(--accent-8)',
          9: 'var(--accent-9)',
          10: 'var(--accent-10)',
        },
        // Semantic Colors
        background: 'var(--background)',
        foreground: 'var(--foreground)',
        primary: 'var(--primary)',
        secondary: 'var(--secondary)',
        success: 'var(--success)',
        warning: 'var(--warning)',
        error: 'var(--error)',
      },
      borderRadius: {
        none: '0',
        sm: '2px',
        DEFAULT: '4px',
        md: '6px',
        lg: '8px',
        full: '9999px',
      },
      boxShadow: {
        sm: '0 1px 2px 0 rgb(0 0 0 / 0.05)',
        DEFAULT: '0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1)',
        md: '0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1)',
        lg: '0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1)',
        xl: '0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1)',
        '2xl': '0 25px 50px -12px rgb(0 0 0 / 0.25)',
        inner: 'inset 0 2px 4px 0 rgb(0 0 0 / 0.05)',
        none: 'none',
      },
      spacing: {
        px: '1px',
        0: '0',
        0.5: '2px',
        1: '4px',
        1.5: '6px',
        2: '8px',
        2.5: '10px',
        3: '12px',
        3.5: '14px',
        4: '16px',
        5: '20px',
        6: '24px',
        7: '28px',
        8: '32px',
        9: '36px',
        10: '40px',
        11: '44px',
        12: '48px',
        14: '56px',
        16: '64px',
        20: '80px',
        24: '96px',
        28: '112px',
        32: '128px',
        36: '144px',
        40: '160px',
        44: '176px',
        48: '192px',
        52: '208px',
        56: '224px',
        60: '240px',
        64: '256px',
        72: '288px',
        80: '320px',
        96: '384px',
      },
      fontSize: {
        xs: ['12px', { lineHeight: '16px' }],
        sm: ['14px', { lineHeight: '20px' }],
        base: ['16px', { lineHeight: '24px' }],
        lg: ['18px', { lineHeight: '28px' }],
        xl: ['20px', { lineHeight: '28px' }],
        '2xl': ['24px', { lineHeight: '32px' }],
        '3xl': ['30px', { lineHeight: '36px' }],
        '4xl': ['36px', { lineHeight: '40px' }],
        '5xl': ['48px', { lineHeight: '48px' }],
        '6xl': ['60px', { lineHeight: '60px' }],
        '7xl': ['72px', { lineHeight: '72px' }],
        '8xl': ['96px', { lineHeight: '96px' }],
        '9xl': ['128px', { lineHeight: '128px' }],
      },
    },
  },
  plugins: [],
} satisfies Config;
</file>

<file path="tsconfig-seed.json">
{
  "extends": "./tsconfig.json",
  "compilerOptions": {
    "module": "NodeNext",
    "moduleResolution": "NodeNext",
    "allowSyntheticDefaultImports": true,
    "esModuleInterop": true,
    "noEmit": true
  },
  "ts-node": {
    "esm": true,
    "experimentalSpecifierResolution": "node"
  },
  "include": ["prisma/**/*.ts", "src/lib/**/*.ts"]
}
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    "target": "esnext",
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "commonjs",
    // "moduleResolution": "NodeNext",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": [
        "src/*"
      ]
    },
    "baseUrl": "./",
    "moduleResolution": "node"
  },
  "include": [
    "next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    ".next/types/**/*.ts",
    "src"
, "scripts/export-data.js"  ],
  "exclude": [
    "node_modules"
  ]
}
</file>

<file path="documentation/flutter_integration.md">
This is a new phase, focusing on modifying the **existing Flutter application** to communicate with the Next.js backend APIs we've previously outlined in the documentation.

---

**Flutter Frontend Integration: TODO #1**
Objective: Configure the Flutter application's API client to communicate with the Next.js backend and handle authentication.

---

1.  **Acknowledge & Understand:**
    *   I understand this task involves making foundational changes to the provided Flutter application. The goal is to enable its `ApiClient` to correctly target the Next.js backend and to include Supabase JWTs for authenticated requests. This also involves ensuring the Supabase Flutter SDK is set up for fetching these JWTs.

2.  **Breakdown (if necessary):**
    *   Verify/Update server URL configuration in `lib/config/config.dart`.
    *   Modify `lib/core/http/api_client.dart` to inject JWT into headers and enhance error handling.
    *   Ensure/Implement Supabase Flutter SDK setup for JWT retrieval, potentially by creating a new auth helper service.
    *   Review existing Flutter auth state management (`lib/core/user/user_provider.dart`, `lib/core/user/user_service.dart`) in light of direct Supabase SDK usage for JWTs.

3.  **Identify Affected Components (Flutter Codebase):**
    *   `lib/config/config.dart`: For backend server URL.
    *   `lib/core/http/api_client.dart`: For HTTP request logic, header modification, and error handling.
    *   `lib/main.dart` (or equivalent): For Supabase Flutter SDK initialization.
    *   Potentially new file: `lib/core/auth/supabase_auth_service.dart` (or similar) for Supabase Flutter SDK interactions and JWT retrieval.
    *   `pubspec.yaml`: To ensure `supabase_flutter` dependency is present.
    *   `lib/core/user/user_service.dart` and `lib/core/user/user_provider.dart`: While full auth logic rewrite is out of scope for *this* TODO, the mechanism for obtaining the JWT will affect how these might eventually interact with auth state.

4.  **Outline Implementation Approach:**

    *   **A. Update Server URL Configuration:**
        *   **File:** `lib/config/config.dart`
        *   **Action:** Modify the `Config.initialize()` method (or where `_serverUrl` is set). It currently loads `SERVER_URL` from `.env`.
        *   **Instruction for User/Orchestrator:** The `.env` file in the Flutter project must be updated with `SERVER_URL=<your_deployed_lessay_nextjs_backend_url>`.
        *   **Code Change:** No direct code change needed in `config.dart` if it correctly loads from `.env`, but ensure it's robust.

    *   **B. Supabase Flutter SDK Setup & JWT Retrieval:**
        *   **Dependency Check (`pubspec.yaml`):**
            *   Verify if `supabase_flutter` is listed as a dependency. If not, add it: `flutter pub add supabase_flutter`.
        *   **Initialization (`lib/main.dart`):**
            *   Ensure `Supabase.initialize()` is called with the *same* Supabase URL and Anon Key used by the Next.js backend. This is crucial for a unified auth system.
                ```dart
                // In main.dart
                await Supabase.initialize(
                  url: '<YOUR_SUPABASE_URL>', // From Next.js project's .env
                  anonKey: '<YOUR_SUPABASE_ANON_KEY>', // From Next.js project's .env
                );
                ```
        *   **Create Supabase Auth Helper (New File Recommended):**
            *   **File:** `lib/core/auth/supabase_auth_helper.dart` (or similar existing auth service if adaptable)
            *   **Content:**
                ```dart
                import 'package:supabase_flutter/supabase_flutter.dart';

                class SupabaseAuthHelper {
                  final SupabaseClient _client = Supabase.instance.client;

                  Future<String?> getCurrentSessionToken() async {
                    final session = _client.auth.currentSession;
                    return session?.accessToken;
                  }

                  Stream<AuthState> get onAuthStateChange => _client.auth.onAuthStateChange;

                  User? get currentUser => _client.auth.currentUser;

                  // Add other Supabase auth methods (login, logout, signup) here later
                  // For now, focus is on token retrieval for ApiClient
                }
                ```
            *   **Provider (Optional but Recommended):** Expose `SupabaseAuthHelper` via a Riverpod provider if it's to be used in multiple places.

    *   **C. Modify `ApiClient` for JWT and Enhanced Error Handling:**
        *   **File:** `lib/core/http/api_client.dart`
        *   **Import:** `import 'package:lessay_translate/core/auth/supabase_auth_helper.dart';` (or path to your helper)
        *   **Instantiate Helper (or get from provider):**
            ```dart
            // Inside ApiClient class or passed via constructor
            final SupabaseAuthHelper _authHelper = SupabaseAuthHelper(); // Or inject via provider
            ```
        *   **Modify `post`, `get` (and other HTTP methods):**
            *   Before `http.post` or `http.get`:
                ```dart
                final String? token = await _authHelper.getCurrentSessionToken();
                final Map<String, String> requestHeaders = {
                  'Content-Type': 'application/json',
                  if (token != null) 'Authorization': 'Bearer $token',
                  ...(headers ?? {}), // Merge existing headers
                };
                // Use requestHeaders in http.post/get
                ```
            *   Ensure `baseUrl` (now pointing to Next.js backend) is correctly used.
            *   **Error Handling Enhancement:**
                *   In the `catch (e)` block, and after checking `response.statusCode`:
                    *   Attempt to parse `response.body` as JSON if it's an error response.
                    *   Check for a structured error message from the Next.js backend (e.g., `jsonResponse['error']` or `jsonResponse['message']`).
                    *   Throw a more specific `AppException` (from `lib/core/exceptions/app_exception.dart`) with the message and status code.
                    *   The existing `ErrorHandlerService` (`lib/core/services/error_handler_service.dart`) can then be used in UI layers to display user-friendly messages based on these exceptions.
                ```dart
                // Example enhanced error handling in ApiClient post/get
                // ... inside try block after http call
                if (response.statusCode >= 200 && response.statusCode < 300) {
                  if (response.body.isEmpty) return {}; // Handle empty success response
                  final jsonResponse = jsonDecode(response.body);
                  if (jsonResponse['error'] != null) { // Assuming Next.js might send error in body even with 2xx
                    throw AppException(jsonResponse['error'].toString(), response.statusCode);
                  }
                  return jsonResponse;
                } else {
                  String errorMessage = 'Request failed with status: ${response.statusCode}';
                  try {
                    final jsonError = jsonDecode(response.body);
                    errorMessage = jsonError['error']?.toString() ?? jsonError['message']?.toString() ?? errorMessage;
                  } catch (_) {
                    // Failed to parse JSON error, use default message
                  }
                  logger.e('API Error: $errorMessage, Status: ${response.statusCode}, Body: ${response.body.substring(0, (response.body.length > 200) ? 200 : response.body.length)}');
                  throw AppException(errorMessage, response.statusCode);
                }
                // ... in catch (e)
                } catch (e) {
                  logger.e('ApiClient Error ($endpoint): $e');
                  if (e is AppException) rethrow;
                  throw AppException('Network error or unexpected issue occurred.', null);
                }
                ```

    *   **D. Review Existing Flutter Auth State Management:**
        *   **Files:** `lib/core/user/user_service.dart`, `lib/core/user/user_provider.dart`.
        *   **Note:** The current `UserService.dart` is a mock (`return UserModel.local()`). A full refactor to use `SupabaseAuthHelper` for login, signup, logout, and user state changes via `onAuthStateChange` will be a *separate, subsequent TODO*.
        *   For *this* TODO, the critical part is that `SupabaseAuthHelper` can provide the JWT. The existing `UserProvider` might need to be updated to reflect the user state from `Supabase.instance.client.auth.currentUser` and `onAuthStateChange`.

5.  **Identify Potential Challenges/Dependencies:**
    *   **Supabase Flutter SDK:** Ensuring `supabase_flutter` is correctly added and initialized.
    *   **JWT Availability:** The logic to retrieve the JWT must be robust.
    *   **Next.js Backend Deployment:** The Flutter app needs a deployed Next.js backend URL to target.
    *   **CORS:** The Next.js backend must be configured to accept requests from the Flutter app's origin (though for mobile apps, CORS is typically less of an issue than for web-to-web, server-side configuration for allowed origins might still be relevant depending on deployment).
    *   **Error Structure Alignment:** The Flutter app's error handling needs to anticipate the error structure returned by the Next.js APIs.

6.  **Consider Edge Cases/Testing (Briefly):**
    *   **No JWT:** `ApiClient` should handle cases where no JWT is available (user not logged in). For protected routes, it should probably not make the call or the backend should return a 401.
    *   **Expired JWT:** Supabase Flutter SDK should handle refreshes. If a refresh fails and an expired token is sent, the Next.js backend should return 401. `ApiClient` should handle this.
    *   **Testing:**
        *   Unit test `SupabaseAuthHelper` (if created) to ensure it correctly interacts with a mocked Supabase client.
        *   Unit test `ApiClient` methods to verify:
            *   JWT is added to headers correctly.
            *   Requests are made to the correct base URL + endpoint.
            *   Successful responses are parsed.
            *   Error responses from Next.js (e.g., 401, 403, 500 with JSON body) are handled and result in appropriate `AppException`s.

7.  **(Optional) Estimate Relative Effort:**
    *   **Medium.** This involves touching several core parts of the Flutter app (config, HTTP client, auth utilities) and requires careful setup of Supabase SDK.

---
This completes the plan for Flutter Frontend Integration: TODO #1. I await your confirmation to proceed or if you have further instructions.
</file>

<file path="prisma/migrations/20250416133011_add_subscription_fields/migration.sql">
/*
  Warnings:

  - A unique constraint covering the columns `[stripeCustomerId]` on the table `User` will be added. If there are existing duplicate values, this will fail.

*/
-- AlterTable
ALTER TABLE "User" ADD COLUMN     "cancelAtPeriodEnd" BOOLEAN NOT NULL DEFAULT false,
ADD COLUMN     "stripeCustomerId" TEXT;

-- CreateIndex
CREATE UNIQUE INDEX "User_stripeCustomerId_key" ON "User"("stripeCustomerId");
</file>

<file path="prisma/migrations/20250416134335_add_subscription_field/migration.sql">
-- AlterTable
ALTER TABLE "payments" ALTER COLUMN "stripePaymentIntentId" DROP NOT NULL;
</file>

<file path="prisma/seed.ts">
import { ProficiencyLevel, LessonStepType, AssessmentStepType } from '@prisma/client'
// import prisma from '../src/lib/prisma.ts'
import prisma from '../src/lib/prisma.js';
import { assessmentMockDataJson } from '../src/__mocks__/assessment-data.mock';

async function main() {
  // Clear existing data in the correct order
  await prisma.lessonStep.deleteMany({}); // Delete lesson steps first
  await prisma.lesson.deleteMany({}); // Then delete lessons
  await prisma.assessmentStep.deleteMany({}); // Delete assessment steps
  await prisma.assessmentLesson.deleteMany({}); // Then delete assessment lessons
  await prisma.onboarding.deleteMany({}); // Then delete onboarding
  await prisma.user.deleteMany({}); // Finally delete users

  // Create test user (matching the mock auth service)
  const user = await prisma.user.create({
    data: {
      id: 'mock-user-id', // Use the same ID as in your mock auth service
      email: 'mock@example.com',
      name: 'Mock User',
    },
  })

  const onboarding = await prisma.onboarding.create({
    data: {
      userId: user.id,
      steps: {
        welcome: true,
        purpose: true,
        languages: true,
        proficiency: true
      },
      completed: false,
      learningPurpose: 'Relocation',
      nativeLanguage: 'English',
      targetLanguage: 'German',
      proficiencyLevel: ProficiencyLevel.beginner,
      initialAssessmentCompleted: false,
    },
  })

  for (const assessmentData of assessmentMockDataJson) {
    const assessmentLesson = await prisma.assessmentLesson.create({
      data: {
        id: assessmentData.id,
        userId: user.id,
        description: assessmentData.description,
        completed: false,
        sourceLanguage: assessmentData.sourceLanguage,
        targetLanguage: assessmentData.targetLanguage,
        metrics: assessmentData.metrics,
        proposedTopics: assessmentData.proposedTopics,
        summary: assessmentData.summary,
        createdAt: new Date(assessmentData.createdAt),
        updatedAt: new Date(assessmentData.updatedAt),
        sessionRecordingUrl: assessmentData.sessionRecordingUrl,
        steps: {
          create: assessmentData.steps.map(step => ({
            id: step.id,
            stepNumber: step.stepNumber,
            type: step.type as AssessmentStepType,
            content: step.content,
            contentAudioUrl: step.contentAudioUrl,
            translation: step.translation,
            expectedAnswer: step.expectedAnswer,
            expectedAnswerAudioUrl: step.expectedAnswerAudioUrl,
            maxAttempts: step.maxAttempts,
            userResponse: null,
            attempts: 0,
            correct: false,
            lastAttemptAt: null,
            feedback: null,
            createdAt: new Date(step.createdAt),
            updatedAt: new Date(step.updatedAt)
          }))
        }
      },
    });

    console.log(`Created assessment lesson: ${assessmentLesson.id} with ${assessmentData.steps.length} steps`);
  }

  // Create regular lessons - Lesson 1: Greetings and Introductions
  // const lesson1 = await prisma.lesson.create({
  //   data: {
  //     userId: user.id,
  //     lessonId: 'greetings-intro',
  //     focusArea: 'Greetings and Introductions',
  //     targetSkills: ['Basic Greetings', 'Self-Introduction', 'Polite Phrases'],
  //     performanceMetrics: {
  //       accuracy: 0,
  //       pronunciationScore: 0,
  //       errorPatterns: []
  //     },
  //     steps: {
  //       create: [
  //         {
  //           stepNumber: 1,
  //           type: LessonStepType.instruction,
  //           content: "Welcome to the 'Basic Greetings' lesson! In this lesson, you'll learn common German greetings and introductions.",
  //           contentAudioUrl: 'https://example.com/audio/german/hallo.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 2,
  //           type: LessonStepType.new_word,
  //           content: 'Hallo',
  //           contentAudioUrl: 'https://example.com/audio/german/hallo.mp3',
  //           translation: 'Hello',
  //           expectedAnswer: 'Hallo',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/hallo.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 3,
  //           type: LessonStepType.new_word,
  //           content: 'Guten Tag',
  //           contentAudioUrl: 'https://example.com/audio/german/guten_tag.mp3',
  //           translation: 'Good day',
  //           expectedAnswer: 'Guten Tag',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/guten_tag.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 4,
  //           type: LessonStepType.new_word,
  //           content: 'Auf Wiedersehen',
  //           contentAudioUrl: 'https://example.com/audio/german/auf_wiedersehen.mp3',
  //           translation: 'Goodbye',
  //           expectedAnswer: 'Auf Wiedersehen',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/auf_wiedersehen.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 5,
  //           type: LessonStepType.practice,
  //           content: 'How do you introduce yourself in German saying "My name is John"?',
  //           contentAudioUrl: null,
  //           translation: 'Ich heiße John',
  //           expectedAnswer: 'Ich heiße John',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/ich_heisse_john.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 6,
  //           type: LessonStepType.model_answer,
  //           content: 'Great job! Now let\'s learn how to ask someone\'s name.',
  //           contentAudioUrl: null,
  //           translation: null,
  //           expectedAnswer: null,
  //           expectedAnswerAudioUrl: null,
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 7,
  //           type: LessonStepType.new_word,
  //           content: 'Wie heißt du?',
  //           contentAudioUrl: 'https://example.com/audio/german/wie_heisst_du.mp3',
  //           translation: 'What is your name?',
  //           expectedAnswer: 'Wie heißt du',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/wie_heisst_du.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 8,
  //           type: LessonStepType.summary,
  //           content: "Congratulations! You've completed the Basic Greetings lesson. You now know how to greet people and introduce yourself in German!",
  //           contentAudioUrl: 'https://example.com/audio/german/congratulations.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         }
  //       ]
  //     },
  //     completed: false
  //   },
  //   include: {
  //     steps: true
  //   }
  // })

  // Lesson 2: Restaurant Phrases
  // const lesson2 = await prisma.lesson.create({
  //   data: {
  //     userId: user.id,
  //     lessonId: 'restaurant-basics',
  //     focusArea: 'Restaurant Vocabulary',
  //     targetSkills: ['Ordering Food', 'Table Requests', 'Payment Phrases'],
  //     performanceMetrics: {
  //       accuracy: 0,
  //       pronunciationScore: 0,
  //       errorPatterns: []
  //     },
  //     steps: {
  //       create: [
  //         {
  //           stepNumber: 1,
  //           type: LessonStepType.instruction,
  //           content: "Welcome to the 'Restaurant Phrases' lesson! In this lesson, you'll learn essential phrases for ordering food and drinks in German restaurants.",
  //           contentAudioUrl: 'https://example.com/audio/german/congratulations.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 2,
  //           type: LessonStepType.new_word,
  //           content: 'Speisekarte',
  //           contentAudioUrl: 'https://example.com/audio/german/speisekarte.mp3',
  //           translation: 'Menu',
  //           expectedAnswer: 'Speisekarte',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/speisekarte.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 3,
  //           type: LessonStepType.prompt,
  //           content: 'How do you ask "Can I have the menu, please?" in German?',
  //           contentAudioUrl: null,
  //           translation: 'Kann ich bitte die Speisekarte haben?',
  //           expectedAnswer: 'Kann ich bitte die Speisekarte haben',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/kann_ich_bitte_speisekarte.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 4,
  //           type: LessonStepType.new_word,
  //           content: 'Ich möchte bestellen',
  //           contentAudioUrl: 'https://example.com/audio/german/ich_moechte_bestellen.mp3',
  //           translation: 'I would like to order',
  //           expectedAnswer: 'Ich möchte bestellen',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/ich_moechte_bestellen.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 5,
  //           type: LessonStepType.practice,
  //           content: 'How would you say "The check, please" in German?',
  //           contentAudioUrl: null,
  //           translation: 'Die Rechnung, bitte',
  //           expectedAnswer: 'Die Rechnung, bitte',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/die_rechnung_bitte.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 6,
  //           type: LessonStepType.model_answer,
  //           content: 'Excellent! Now try ordering a specific item.',
  //           contentAudioUrl: null,
  //           translation: null,
  //           expectedAnswer: null,
  //           expectedAnswerAudioUrl: null,
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 7,
  //           type: LessonStepType.new_word,
  //           content: 'Ein Wasser, bitte',
  //           contentAudioUrl: 'https://example.com/audio/german/ein_wasser_bitte.mp3',
  //           translation: 'A water, please',
  //           expectedAnswer: 'Ein Wasser, bitte',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/ein_wasser_bitte.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 8,
  //           type: LessonStepType.summary,
  //           content: "Great job! You've completed the Restaurant Phrases lesson. You're now ready to order food and drinks in German restaurants with confidence!",
  //           contentAudioUrl: 'https://example.com/audio/german/congratulations.mp3',
  //           attempts: 1,
  //           correct: false,
  //           errorPatterns: []
  //         }
  //       ]
  //     },
  //     completed: false
  //   },
  //   include: {
  //     steps: true
  //   }
  // })

  // Lesson 3: Travel Basics
  // const lesson3 = await prisma.lesson.create({
  //   data: {
  //     userId: user.id,
  //     lessonId: 'travel-basics',
  //     focusArea: 'Travel Essentials',
  //     targetSkills: ['Asking for Directions', 'Public Transport', 'Booking Accommodation'],
  //     performanceMetrics: {
  //       accuracy: 0,
  //       pronunciationScore: 0,
  //       errorPatterns: []
  //     },
  //     steps: {
  //       create: [
  //         {
  //           stepNumber: 1,
  //           type: LessonStepType.instruction,
  //           content: "Welcome to the 'Travel Essentials' lesson! In this lesson, you'll learn key phrases for navigating public transportation and asking for directions in German.",
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 2,
  //           type: LessonStepType.new_word,
  //           content: 'Wo ist...?',
  //           contentAudioUrl: 'https://example.com/audio/german/wo_ist.mp3',
  //           translation: 'Where is...?',
  //           expectedAnswer: 'Wo ist',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/wo_ist.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 3,
  //           type: LessonStepType.practice,
  //           content: 'How do you ask "How do I get to the train station?" in German?',
  //           contentAudioUrl: null,
  //           translation: 'Wie komme ich zum Bahnhof?',
  //           expectedAnswer: 'Wie komme ich zum Bahnhof',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/wie_komme_ich_zum_bahnhof.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 4,
  //           type: LessonStepType.new_word,
  //           content: 'Der Zug',
  //           contentAudioUrl: 'https://example.com/audio/german/der_zug.mp3',
  //           translation: 'The train',
  //           expectedAnswer: 'Der Zug',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/der_zug.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 5,
  //           type: LessonStepType.practice,
  //           content: 'How would you ask "When does the next bus come?" in German?',
  //           contentAudioUrl: null,
  //           translation: 'Wann kommt der nächste Bus?',
  //           expectedAnswer: 'Wann kommt der nächste Bus',
  //           expectedAnswerAudioUrl: 'https://example.com/audio/german/wann_kommt_der_naechste_bus.mp3',
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         },
  //         {
  //           stepNumber: 6,
  //           type: LessonStepType.summary,
  //           content: "Well done! You've completed the Travel Essentials lesson. You're now prepared to navigate German cities and use public transportation with ease!",
  //           attempts: 0,
  //           correct: false,
  //           errorPatterns: []
  //         }
  //       ]
  //     },
  //     completed: false
  //   },
  //   include: {
  //     steps: true
  //   }
  // })

  // console.log(`Created user: ${user.email}`)
  // console.log(`Created onboarding for user: ${onboarding.id}`)
  // console.log(`Created assessment lesson with ${assessmentLesson.steps.length} steps`)
  // console.log(`Created lesson 1: ${lesson1.focusArea} with ${lesson1.steps.length} steps`)
  // console.log(`Created lesson 2: ${lesson2.focusArea} with ${lesson2.steps.length} steps`)
  // console.log(`Created lesson 3: ${lesson3.focusArea} with ${lesson3.steps.length} steps`)
}

main()
  .catch((e) => {
    console.error(e)
    process.exit(1)
  })
  .finally(async () => {
    await prisma.$disconnect()
  })
</file>

<file path="public/sitemap-0.xml">
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:news="http://www.google.com/schemas/sitemap-news/0.9" xmlns:xhtml="http://www.w3.org/1999/xhtml" xmlns:mobile="http://www.google.com/schemas/sitemap-mobile/1.0" xmlns:image="http://www.google.com/schemas/sitemap-image/1.1" xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">
<url><loc>https://lessay-app.vercel.app</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/about</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/privacy</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/terms</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/app/lessons</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/app/onboarding</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/app/login</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/app/profile</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
<url><loc>https://lessay-app.vercel.app/app</loc><lastmod>2025-04-23T13:49:04.405Z</lastmod><changefreq>daily</changefreq><priority>0.7</priority></url>
</urlset>
</file>

<file path="src/__mocks__/generated-lessons.mock.ts">
import logger from "@/utils/logger";
import { LessonStepType } from "@prisma/client"

// Helper function outside the object
function getRandomTopic(lessons: Record<string, any>): string {
  const topics = Object.keys(lessons);
  const randomIndex = Math.floor(Math.random() * topics.length);
  return topics[randomIndex];
}

export const MockLessonGeneratorService = {

  generateAudioForStep: async function(
    content: string,
    language: string = "English"
  ) {
    logger.info(`Generating audio for step and language: ${content} ${language}`);
    // 1-second silent audio in base64 WAV format
    const base64Audio = 'UklGRiwAAABXQVZFZm10IBAAAAABAAEARKwAAIhUAAABAAgAZGF0YRIwAAAC';
    return base64Audio
  },
  generateLesson: async function(topic: string, targetLanguage: string, difficultyLevel: string) {
    // Combined list of all lessons (initial + advanced)
    const allLessonTemplates: Record<string, any> = {
      // Initial lessons
      'Vocabulary Building': {
        focusArea: 'Travel',
        targetSkills: ['Vocabulary', 'Asking for Directions'],
        steps: [
          {
            stepNumber: 1,
            type: LessonStepType.instruction,
            content: 'Welcome to the Travel Vocabulary lesson! In this lesson, you\'ll learn essential words and phrases for navigating airports and asking for directions.',
            translation: 'Willkommen zur Reisevokabular-Lektion! In dieser Lektion lernen Sie wichtige Wörter und Sätze, um sich auf Flughäfen zurechtzufinden und nach dem Weg zu fragen.',
            maxAttempts: 1
          },
          {
            stepNumber: 2,
            type: LessonStepType.prompt,
            content: 'How to say "where is" in German?',
            translation: 'wo ist',
            maxAttempts: 3,
            expectedAnswer: 'wo ist'
          },
          {
            stepNumber: 3,
            type: LessonStepType.feedback,
            content: 'Great job!',
            translation: 'Gut gemacht!'
          },
          {
            stepNumber: 4,
            type: LessonStepType.prompt,
            content: 'How to say "the airport" in German?',
            expectedAnswer: 'der Flughafen',
            maxAttempts: 3,
          },
          {
            stepNumber: 5,
            type: LessonStepType.feedback,
            content: 'Excellent pronunciation! Now, let\'s learn how to ask for directions.',
            translation: 'Ausgezeichnete Aussprache! Lassen Sie uns nun lernen, wie man nach dem Weg fragt.'
          },
          {
            stepNumber: 6,
            type: LessonStepType.prompt,
            content: 'How do you ask "Where is the airport?" in German?',
            expectedAnswer: 'wo ist der Flughafen',
            maxAttempts: 3,
            translation: 'Wie fragt man "Wo ist der Flughafen?" auf Deutsch?'
          },
          {
            stepNumber: 7,
            type: LessonStepType.feedback,
            content: 'Lets add some more words to our vocabulary',
            translation: ''
          },
          {
            stepNumber: 8,
            type: LessonStepType.new_word,
            content: 'Das Gate',
            maxAttempts: 3,
            translation: 'das Gate'
          },
          {
            stepNumber: 9,
            type: LessonStepType.summary,
            content: 'Great job! You\'ve completed the Travel Vocabulary lesson. You\'ve learned how to ask for directions and use key airport terminology in German.',
            translation: 'Gut gemacht! Sie haben die Reisevokabular-Lektion abgeschlossen. Sie haben gelernt, wie man nach dem Weg fragt und wichtige Flughafenterminologie auf Deutsch verwendet.'
          }
        ]
      },
      
      // Example of another template - Hotel Booking with proper model_answer usage
      'Hotel Booking': {
        focusArea: 'Travel Accommodation',
        targetSkills: ['Booking', 'Requests'],
        steps: [
          {
            stepNumber: 1,
            type: LessonStepType.instruction,
            content: 'Welcome to the Hotel Booking lesson! In this lesson, you\'ll learn essential phrases for making hotel reservations and requesting services.',
            translation: 'Willkommen zur Hotelbuchungslektion! In dieser Lektion lernen Sie wichtige Sätze für Hotelbuchungen und das Anfordern von Dienstleistungen.',
            maxAttempts: 1
          },
          {
            stepNumber: 2,
            type: LessonStepType.new_word,
            content: 'das Hotel',
            translation: 'the hotel',
            maxAttempts: 3,
            expectedAnswer: 'das Hotel'
          },
          {
            stepNumber: 3,
            type: LessonStepType.feedback,
            content: 'Very good! "das Hotel" is "the hotel" in German. Now let\'s practice this word.',
            translation: 'Sehr gut! "das Hotel" ist "the hotel" auf Deutsch. Lassen Sie uns jetzt dieses Wort üben.'
          },
          {
            stepNumber: 4,
            type: LessonStepType.practice,
            content: 'Repeat the word for hotel: das Hotel',
            expectedAnswer: 'das Hotel',
            maxAttempts: 3
          },
          {
            stepNumber: 5,
              type: LessonStepType.feedback,
            content: 'Well done! Now, let\'s learn how to make a reservation.',
            translation: 'Gut gemacht! Jetzt lernen wir, wie man eine Reservierung macht.',
            maxAttempts: 1
          },
          {
            stepNumber: 6,
            type: LessonStepType.prompt,
            content: 'How do you say "I have a reservation" in German?',
            expectedAnswer: 'Ich habe eine Reservierung',
            translation: 'Wie sagt man "Ich habe eine Reservierung" auf Deutsch?',
            maxAttempts: 3
          },
          {
            stepNumber: 7,
            type: LessonStepType.feedback,
            content: 'To say "I have a reservation" in German, you say "Ich habe eine Reservierung"',
            translation: 'Um "I have a reservation" auf Deutsch zu sagen, sagt man "Ich habe eine Reservierung"'
          },
          {
            stepNumber: 8,
            type: LessonStepType.summary,
            content: 'Great job! You\'ve completed the Hotel Booking lesson. You can now make reservations and request services in German hotels.',
            translation: 'Gut gemacht! Sie haben die Hotel-Buchungslektion abgeschlossen. Sie können jetzt Reservierungen vornehmen und Dienstleistungen in deutschen Hotels anfordern.'
          }
        ]
      },
      // Advanced lessons
      'Pronunciation Practice': {
        focusArea: 'Pronunciation Improvement',
        targetSkills: ['Sound Recognition', 'Accent Reduction'],
        steps: [
          {
            stepNumber: 1,
            type: LessonStepType.instruction,
            content: 'Welcome to the Pronunciation Practice lesson! In this lesson, you\'ll work on perfecting your German pronunciation and reducing your accent.',
            translation: 'Willkommen zur Ausspracheübungslektion! In dieser Lektion werden Sie an der Verbesserung Ihrer deutschen Aussprache arbeiten und Ihren Akzent reduzieren.',
            maxAttempts: 1
          },
          {
            stepNumber: 2,
            type: LessonStepType.prompt,
            content: 'To start, say "ready to practice pronunciation"',
            translation: 'Um zu beginnen, sagen Sie "bereit für die Ausspracheübung"',
            maxAttempts: 3
          },
          {
            stepNumber: 3,
            type: LessonStepType.new_word,
            content: 'die Aussprache',
            translation: 'the pronunciation',
            expectedAnswer: 'die Aussprache',
            maxAttempts: 3
          },
          {
            stepNumber: 4,
            type: LessonStepType.practice,
            content: 'die Aussprache',
            expectedAnswer: 'die Aussprache',
            maxAttempts: 3
          },
          {
            stepNumber: 5,
            type: LessonStepType.new_word,
            content: 'schwierig',
            translation: 'difficult',
            expectedAnswer: 'schwierig',
            maxAttempts: 3
          },
          {
            stepNumber: 6,
            type: LessonStepType.feedback,
            content: 'Die Aussprache ist manchmal schwierig',
            translation: 'The pronunciation is sometimes difficult',
            expectedAnswer: 'Die Aussprache ist manchmal schwierig'
          },
          {
            stepNumber: 7,
            type: LessonStepType.summary,
            content: 'Excellent work! You\'ve completed the Pronunciation Practice lesson. Your German pronunciation has improved, and you\'re on your way to speaking more naturally.',
            translation: 'Ausgezeichnete Arbeit! Sie haben die Ausspracheübungslektion abgeschlossen. Ihre deutsche Aussprache hat sich verbessert und Sie sind auf dem Weg, natürlicher zu sprechen.'
          }
        ]
      },
      'Grammar Rules': {
        focusArea: 'Grammar Fundamentals',
        targetSkills: ['Sentence Structure', 'Verb Conjugation'],
        steps: [
          {
            stepNumber: 1,
            type: LessonStepType.instruction,
            content: 'Welcome to the Grammar Fundamentals lesson! In this lesson, you\'ll learn basic German sentence structure and verb conjugation patterns.',
            translation: 'Willkommen zur Lektion über Grammatik-Grundlagen! In dieser Lektion lernen Sie die grundlegende deutsche Satzstruktur und Verbkonjugationsmuster.',
            maxAttempts: 1
          },
          {
            stepNumber: 2,
            type: LessonStepType.prompt,
            content: 'To start, say "I am ready to learn grammar"',
            translation: 'Um zu beginnen, sagen Sie "Ich bin bereit, Grammatik zu lernen"',
            maxAttempts: 3
          },
          {
            stepNumber: 3,
            type: LessonStepType.new_word,
            content: 'die Grammatik',
            translation: 'the grammar',
            expectedAnswer: 'die Grammatik',
            maxAttempts: 3
          },
          {
            stepNumber: 4,
            type: LessonStepType.practice,
            content: 'die Grammatik',
            expectedAnswer: 'die Grammatik',
            maxAttempts: 3
          },
          {
            stepNumber: 5,
            type: LessonStepType.prompt,
            content: 'How do you say "I learn grammar"?',
            translation: 'Wie sagt man "Ich lerne Grammatik"?',
            maxAttempts: 3
          },
          {
            stepNumber: 6,
            type: LessonStepType.feedback,
            content: 'Ich lerne Grammatik',
            translation: 'I learn grammar',
            expectedAnswer: 'Ich lerne Grammatik',
            maxAttempts: 3
          },
          {
            stepNumber: 7,
            type: LessonStepType.summary,
            content: 'Congratulations! You\'ve completed the Grammar Fundamentals lesson. You now understand basic German sentence structures and can form simple sentences with proper verb conjugation.',
            translation: 'Herzlichen Glückwunsch! Sie haben die Lektion zu den Grammatik-Grundlagen abgeschlossen. Sie verstehen jetzt die grundlegenden deutschen Satzstrukturen und können einfache Sätze mit korrekter Verbkonjugation bilden.'
          }
        ]
      }
    };
    // TODO: AUTH USER CREATES THE USER PROFILE 
    // TODO: USER SKILL PROGRESSION 

    // If topic is not specified, pick a random one
    const selectedTopic = topic || getRandomTopic(allLessonTemplates);
    
    // Get lesson data for the selected topic
    const lessonData = allLessonTemplates[selectedTopic] || {
      focusArea: 'General Conversation',
      targetSkills: ['Vocabulary', 'Basic Phrases'],
      steps: [
        {
          stepNumber: 1,
          type: LessonStepType.instruction,
          content: 'Welcome to the General Conversation lesson! In this lesson, you\'ll learn basic phrases for everyday conversations in your target language.',
          translation: 'Willkommen zur Lektion über allgemeine Konversation! In dieser Lektion lernen Sie grundlegende Sätze für alltägliche Gespräche in Ihrer Zielsprache.'
        },
        {
          stepNumber: 2,
          type: LessonStepType.new_word,
          content: 'Hallo',
          translation: 'Hello',
          expectedAnswer: 'Hallo',
          maxAttempts: 3
        },
        {
          stepNumber: 3,
          type: LessonStepType.feedback,
          content: 'Excellent! Now let\'s practice saying "Hallo".',
          translation: 'Ausgezeichnet! Jetzt üben wir, "Hallo" zu sagen.'
        },
        {
          stepNumber: 4,
          type: LessonStepType.practice,
          content: 'Repeat: Hallo',
          expectedAnswer: 'Hallo',
          maxAttempts: 3
        },
        {
          stepNumber: 5,
          type: LessonStepType.feedback,
          content: 'Perfect pronunciation! You\'re making great progress.',
          translation: 'Perfekte Aussprache! Sie machen große Fortschritte.'
        },
        {
          stepNumber: 6,
          type: LessonStepType.summary,
          content: 'Great job! You\'ve completed the General Conversation lesson. You can now use basic phrases for everyday interactions.',
          translation: 'Gut gemacht! Sie haben die Lektion zur allgemeinen Konversation abgeschlossen. Sie können jetzt grundlegende Sätze für alltägliche Interaktionen verwenden.'
        }
      ]
    };

    // Log the generated lesson data
    console.log('Generated lesson data:', { 
      topic: selectedTopic, 
      targetLanguage, 
      difficultyLevel, 
      lessonData 
    });

    // Return the lesson data wrapped in an object with a 'data' property
    return { data: [lessonData] };
  },

  // Helper method to get a random topic
  getRandomTopic(lessons: Record<string, any>): string {
    const topics = Object.keys(lessons);
    const randomIndex = Math.floor(Math.random() * topics.length);
    return topics[randomIndex];
  }
}
</file>

<file path="src/app/app/lessons/[id]/page.tsx">
'use client';

import { useState, useEffect } from 'react';
import { useRouter, useParams } from 'next/navigation';
import { useLesson } from '@/context/lesson-context';
import { useOnboarding } from '@/context/onboarding-context';
import {
  AssessmentStep as AssessmentStepModel,
  LessonModel,
  LessonStep,
  isPerformanceMetrics,
} from '@/models/AppAllModels.model';
import LessonChat from '@/components/lessons/lessonChat';
import logger from '@/utils/logger';
import { AudioMetrics } from '@/models/AppAllModels.model';
import { toast } from 'react-hot-toast';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import { useAuth } from '@/context/auth-context';
import HeaderWithProfile from '@/components/HeaderWithProfile';

export default function LessonDetailPage() {
  const router = useRouter();
  const { id } = useParams();
  const { user } = useAuth();

  const { onboarding } = useOnboarding();
  const {
    getLessonById,
    completeLesson,
    recordStepAttempt,
    loading,
    processLessonRecording,
    checkAndGenerateNewLessons
  } = useLesson();
  const [lesson, setLesson] = useState<LessonModel | null>(null);
  const [results, setResults] = useState<LessonModel | null>(null);
  const [pronunciationResults, setPronunciationResults] =
    useState<AudioMetrics | null>(null);
  const [pronunciationResultsLoading, setPronunciationResultsLoading] =
    useState<boolean>(false);
  const [sessionRecording, setSessionRecording] = useState<RecordingBlob | null>(null);

  useEffect(() => {
    const init = async () => {
      logger.info('init', { id });
      if(!user) return;
      const fetchedLesson = await getLessonById(id as string);
      setLesson(fetchedLesson);
      logger.info('fetchedLesson', { fetchedLesson });
    };
    init();
  }, [id, user]);

  useEffect(() => {
    const processPronunciation = async () => {
      logger.info('processPronunciation', { sessionRecording, lesson });
      if (sessionRecording && lesson) {
        if (!sessionRecording.lastModified || !sessionRecording.size) {
          return
        }
        try {
          logger.info('Processing pronunciation recording', { sessionRecording, lesson });
          const recordingTime = sessionRecording.recordingTime || 10000;
          const recordingSize = sessionRecording.size;

          logger.info('recordingTime', { recordingTime });
        
          const lessonWithAudioMetrics = await processLessonRecording(
            sessionRecording,
            lesson,
            recordingTime,
            recordingSize
          );
          logger.info('Lesson with audio metrics', { lessonWithAudioMetrics });
          if (!lessonWithAudioMetrics.audioMetrics) {
            throw new Error('No audio metrics found');
          }
          setPronunciationResults(lessonWithAudioMetrics.audioMetrics);
           await checkAndGenerateNewLessons();

        } catch (error) {
          logger.error('Failed to process pronunciation:', error);
        } finally {
          setPronunciationResultsLoading(false);
        }
      }
    };
    processPronunciation();

  }, [sessionRecording, lesson]);

  const handleStepComplete = async (
    step: LessonStep | AssessmentStepModel,
    userResponse: string
  ): Promise<LessonStep | AssessmentStepModel> => {
    logger.info('handleStepComplete', { step, userResponse });

    try {
      if (!lesson) {
        throw new Error('Lesson is not loaded');
      }
      return await recordStepAttempt(lesson.id, step.id, userResponse);
    } catch (error) {
      logger.error('Failed to record step attempt:', error);
      throw error;
    }
  };

  // onComplete from children lessonChat call is here 
  const handleLessonComplete = async (sessionRecording: Blob | null) => {
    if (lesson) {
      setSessionRecording(sessionRecording);
      const results = await completeLesson(lesson.id, sessionRecording);
      logger.info('lesson complete results', { results });
      setResults(results);
    }
  };

  if (!lesson && loading) {
    return (
      <div className="min-h-screen flex flex-col items-center justify-center">
        <div className="animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-black mb-4"></div>
        <p className="text-xl">Loading lesson...</p>
      </div>
    );
  }

  // Show results if available
  if (results) {
    return (
      <div className="container mx-auto py-8 px-4">
        <HeaderWithProfile />
        <div className="bg-white shadow-md rounded-lg overflow-hidden">
          <div className="p-6 bg-black text-white">
            <h2 className="text-2xl font-bold">
              Lesson Results: {results.focusArea}
            </h2>
          </div>

          <div className="p-6">
            {/* Basic Performance Summary */}
            <div className="mb-8">
              <h3 className="text-xl font-semibold mb-4">
                Performance Summary
              </h3>

              {results.performanceMetrics &&
              isPerformanceMetrics(results.performanceMetrics) ? (
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                  {/* Accuracy */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">
                        Accuracy
                      </span>
                      <span className="text-xl font-bold">
                        {results.performanceMetrics.accuracy || 0}%
                      </span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-blue-600 h-2.5 rounded-full"
                        style={{
                          width: `${results.performanceMetrics.accuracy || 0}%`,
                        }}
                      ></div>
                    </div>
                  </div>

                  {/* Pronunciation Score */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">
                        Pronunciation
                      </span>
                      <span className="text-xl font-bold">
                        {results.performanceMetrics.pronunciationScore || 0}%
                      </span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-green-600 h-2.5 rounded-full"
                        style={{
                          width: `${
                            results.performanceMetrics.pronunciationScore || 0
                          }%`,
                        }}
                      ></div>
                    </div>
                  </div>
                  
                  {/* Grammar Score */}
                  {results.performanceMetrics.grammarScore !== undefined && (
                    <div className="bg-gray-50 p-4 rounded-lg">
                      <div className="flex items-center justify-between mb-2">
                        <span className="font-medium text-gray-700">
                          Grammar
                        </span>
                        <span className="text-xl font-bold">
                          {results.performanceMetrics.grammarScore}%
                        </span>
                      </div>
                      <div className="w-full bg-gray-200 rounded-full h-2.5">
                        <div
                          className="bg-purple-600 h-2.5 rounded-full"
                          style={{
                            width: `${results.performanceMetrics.grammarScore}%`,
                          }}
                        ></div>
                      </div>
                    </div>
                  )}
                  
                  {/* Vocabulary Score */}
                  {results.performanceMetrics.vocabularyScore !== undefined && (
                    <div className="bg-gray-50 p-4 rounded-lg">
                      <div className="flex items-center justify-between mb-2">
                        <span className="font-medium text-gray-700">
                          Vocabulary
                        </span>
                        <span className="text-xl font-bold">
                          {results.performanceMetrics.vocabularyScore}%
                        </span>
                      </div>
                      <div className="w-full bg-gray-200 rounded-full h-2.5">
                        <div
                          className="bg-yellow-600 h-2.5 rounded-full"
                          style={{
                            width: `${results.performanceMetrics.vocabularyScore}%`,
                          }}
                        ></div>
                      </div>
                    </div>
                  )}
                  
                  {/* Overall Score */}
                  {results.performanceMetrics.overallScore !== undefined && (
                    <div className="bg-gray-50 p-4 rounded-lg col-span-1 md:col-span-2">
                      <div className="flex items-center justify-between mb-2">
                        <span className="font-medium text-gray-700">
                          Overall Performance
                        </span>
                        <span className="text-xl font-bold">
                          {results.performanceMetrics.overallScore}%
                        </span>
                      </div>
                      <div className="w-full bg-gray-200 rounded-full h-2.5">
                        <div
                          className="bg-indigo-600 h-2.5 rounded-full"
                          style={{
                            width: `${results.performanceMetrics.overallScore}%`,
                          }}
                        ></div>
                      </div>
                    </div>
                  )}
                </div>
              ) : (
                <p className="text-gray-500">
                  No performance metrics available.
                </p>
              )}
            </div>

            {/* Lesson Summary Section */}
            {results.performanceMetrics && 
            isPerformanceMetrics(results.performanceMetrics) && 
            results.performanceMetrics.summary && (
              <div className="mb-8">
                <h3 className="text-xl font-semibold mb-4">
                  Lesson Summary
                </h3>
                <div className="bg-gray-50 p-4 rounded-lg">
                  <p className="text-gray-700">
                    {results.performanceMetrics.summary}
                  </p>
                </div>
              </div>
            )}

            {/* Strengths and Weaknesses */}
            {results.performanceMetrics && 
            isPerformanceMetrics(results.performanceMetrics) && 
            (results.performanceMetrics.strengths && results.performanceMetrics.strengths.length > 0 || 
             results.performanceMetrics.weaknesses && results.performanceMetrics.weaknesses.length > 0) && (
              <div className="mb-8">
                <h3 className="text-xl font-semibold mb-4">
                  Strengths and Areas for Improvement
                </h3>
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
                  {/* Strengths */}
                  {results.performanceMetrics.strengths && 
                  results.performanceMetrics.strengths.length > 0 && (
                    <div className="bg-green-50 p-4 rounded-lg border border-green-200">
                      <h4 className="font-semibold mb-3 text-green-800">Strengths</h4>
                      <ul className="list-disc pl-5 space-y-1">
                        {results.performanceMetrics.strengths.map((strength, index) => (
                          <li key={index} className="text-gray-700">
                            {strength}
                          </li>
                        ))}
                      </ul>
                    </div>
                  )}
                  
                  {/* Weaknesses */}
                  {results.performanceMetrics.weaknesses && 
                  results.performanceMetrics.weaknesses.length > 0 && (
                    <div className="bg-orange-50 p-4 rounded-lg border border-orange-200">
                      <h4 className="font-semibold mb-3 text-orange-800">Areas to Focus On</h4>
                      <ul className="list-disc pl-5 space-y-1">
                        {results.performanceMetrics.weaknesses.map((weakness, index) => (
                          <li key={index} className="text-gray-700">
                            {weakness}
                          </li>
                        ))}
                      </ul>
                    </div>
                  )}
                </div>
              </div>
            )}

            {/* Next Lesson Suggestions */}
            {results.performanceMetrics && 
            isPerformanceMetrics(results.performanceMetrics) && 
            results.performanceMetrics.nextLessonSuggestions && 
            results.performanceMetrics.nextLessonSuggestions.length > 0 && (
              <div className="mb-8">
                <h3 className="text-xl font-semibold mb-4">
                  Recommended Next Steps
                </h3>
                <div className="bg-blue-50 p-4 rounded-lg border border-blue-200">
                  <div className="flex flex-wrap gap-2">
                    {results.performanceMetrics.nextLessonSuggestions.map((suggestion, index) => (
                      <span key={index} className="px-3 py-1 bg-blue-100 text-blue-700 rounded-full text-sm">
                        {suggestion}
                      </span>
                    ))}
                  </div>
                </div>
              </div>
            )}

            {/* Detailed Pronunciation Results Section */}
            {pronunciationResults && (
              <div className="mb-8 border-t pt-8">
                <h3 className="text-xl font-semibold mb-4">
                  Detailed Language Analysis
                </h3>
                
                {/* Proficiency Level and Trajectory */}
                <div className="bg-gray-50 p-4 rounded-lg mb-6">
                  <div className="flex justify-between items-center mb-4">
                    <span className="font-medium text-gray-700">CEFR Level</span>
                    <span className="text-lg font-bold bg-black text-white px-3 py-1 rounded">
                      {pronunciationResults.proficiencyLevel}
                    </span>
                  </div>
                  <div className="flex justify-between items-center">
                    <span className="font-medium text-gray-700">Learning Trajectory</span>
                    <span className={`text-lg font-medium ${
                      pronunciationResults.learningTrajectory === 'accelerating' ? 'text-green-600' :
                      pronunciationResults.learningTrajectory === 'steady' ? 'text-blue-600' : 'text-yellow-600'
                    }`}>
                      {pronunciationResults.learningTrajectory.toLowerCase().replace('_', ' ')}
                    </span>
                  </div>
                </div>
                
                {/* Skill Scores */}
                <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
                  {/* Pronunciation Score */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">Pronunciation</span>
                      <span className="text-xl font-bold">{pronunciationResults.pronunciationScore}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-purple-600 h-2.5 rounded-full"
                        style={{ width: `${pronunciationResults.pronunciationScore}%` }}
                      ></div>
                    </div>
                  </div>
                  
                  {/* Fluency Score */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">Fluency</span>
                      <span className="text-xl font-bold">{pronunciationResults.fluencyScore}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-blue-600 h-2.5 rounded-full"
                        style={{ width: `${pronunciationResults.fluencyScore}%` }}
                      ></div>
                    </div>
                  </div>
                  
                  {/* Grammar Score */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">Grammar</span>
                      <span className="text-xl font-bold">{pronunciationResults.grammarScore}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-green-600 h-2.5 rounded-full"
                        style={{ width: `${pronunciationResults.grammarScore}%` }}
                      ></div>
                    </div>
                  </div>
                  
                  {/* Vocabulary Score */}
                  <div className="bg-gray-50 p-4 rounded-lg">
                    <div className="flex items-center justify-between mb-2">
                      <span className="font-medium text-gray-700">Vocabulary</span>
                      <span className="text-xl font-bold">{pronunciationResults.vocabularyScore}%</span>
                    </div>
                    <div className="w-full bg-gray-200 rounded-full h-2.5">
                      <div
                        className="bg-yellow-600 h-2.5 rounded-full"
                        style={{ width: `${pronunciationResults.vocabularyScore}%` }}
                      ></div>
                    </div>
                  </div>
                </div>
                
                {/* Pronunciation Details */}
                <div className="bg-gray-50 p-4 rounded-lg mb-6">
                  <h4 className="font-semibold mb-3 text-lg">Pronunciation Details</h4>
                  
                  {/* Problematic Sounds */}
                  {pronunciationResults.pronunciationAssessment.problematic_sounds.length > 0 && (
                    <div className="mb-4">
                      <h5 className="font-medium text-gray-700 mb-2">Problematic Sounds</h5>
                      <div className="flex flex-wrap gap-2">
                        {pronunciationResults.pronunciationAssessment.problematic_sounds.map((sound, idx) => (
                          <span key={idx} className="px-3 py-1 bg-red-100 text-red-700 rounded-full text-sm">
                            {sound}
                          </span>
                        ))}
                      </div>
                    </div>
                  )}
                  
                  {/* Areas for Improvement */}
                  <div className="mb-2">
                    <h5 className="font-medium text-gray-700 mb-2">Areas for Improvement</h5>
                    <ul className="list-disc pl-5 space-y-1">
                      {pronunciationResults.pronunciationAssessment.areas_for_improvement.map((area, idx) => (
                        <li key={idx} className="text-gray-700">{area}</li>
                      ))}
                    </ul>
                  </div>
                  
                  {/* Strengths */}
                  <div>
                    <h5 className="font-medium text-gray-700 mb-2">Strengths</h5>
                    <ul className="list-disc pl-5 space-y-1">
                      {pronunciationResults.pronunciationAssessment.strengths.map((strength, idx) => (
                        <li key={idx} className="text-gray-700">{strength}</li>
                      ))}
                    </ul>
                  </div>
                </div>
                
                {/* Grammar Focus Areas */}
                <div className="bg-gray-50 p-4 rounded-lg mb-6">
                  <h4 className="font-semibold mb-3 text-lg">Suggested Focus Areas</h4>
                  <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <div>
                      <h5 className="font-medium text-gray-700 mb-2">Grammar Focus</h5>
                      <ul className="list-disc pl-5 space-y-1">
                        {pronunciationResults.grammarFocusAreas.map((area, idx) => (
                          <li key={idx} className="text-gray-700">{area}</li>
                        ))}
                      </ul>
                    </div>
                    <div>
                      <h5 className="font-medium text-gray-700 mb-2">Next Skill Targets</h5>
                      <ul className="list-disc pl-5 space-y-1">
                        {pronunciationResults.nextSkillTargets.map((skill, idx) => (
                          <li key={idx} className="text-gray-700">{skill}</li>
                        ))}
                      </ul>
                    </div>
                  </div>
                </div>
                
                {/* Suggested Topics */}
                <div className="bg-gray-50 p-4 rounded-lg">
                  <h4 className="font-semibold mb-3 text-lg">Suggested Topics for Next Lessons</h4>
                  <div className="flex flex-wrap gap-2">
                    {pronunciationResults.suggestedTopics.map((topic, idx) => (
                      <span key={idx} className="px-3 py-1 bg-blue-100 text-blue-700 rounded-full text-sm">
                        {topic}
                      </span>
                    ))}
                  </div>
                </div>
              </div>
            )}
            
            {/* Loading State for Pronunciation Results */}
            {pronunciationResultsLoading && !pronunciationResults && (
              <div className="mb-8 text-center py-6">
                <div className="animate-spin rounded-full h-10 w-10 border-t-2 border-b-2 border-black mx-auto mb-4"></div>
                <p className="text-lg">Analyzing your pronunciation and language skills...</p>
              </div>
            )}

            {/* Error Patterns */}
            <div className="mb-8">
              <h3 className="text-xl font-semibold mb-4">
                Common Errors
              </h3>
              {results.performanceMetrics &&
              isPerformanceMetrics(results.performanceMetrics) &&
              results.performanceMetrics.errorPatterns &&
              results.performanceMetrics.errorPatterns.length > 0 ? (
                <ul className="list-disc pl-5 space-y-2">
                  {results.performanceMetrics.errorPatterns.map(
                    (error, index) => (
                      <li key={index} className="text-gray-700">
                        {error}
                      </li>
                    )
                  )}
                </ul>
              ) : (
                <p className="text-gray-500">
                  No specific error patterns detected.
                </p>
              )}
            </div>

            {/* Steps Review */}
            <div className="mb-8">
              <h3 className="text-xl font-semibold mb-4">
                Step-by-Step Review
              </h3>
              <div className="space-y-4">
                {results.steps.map((step, index) => (
                  <div
                    key={index}
                    className={`p-4 rounded-lg border ${
                      step.correct
                        ? 'border-green-200 bg-green-50'
                        : 'border-red-200 bg-red-50'
                    }`}
                  >
                    <p className="font-medium">{step.content}</p>
                    {step.userResponse && (
                      <div className="mt-2">
                        <span className="text-gray-700 text-sm">
                          Your response:
                        </span>
                        <p
                          className={`font-medium ${
                            step.correct ? 'text-green-600' : 'text-red-600'
                          }`}
                        >
                          {step.userResponse}
                        </p>
                      </div>
                    )}
                    {!step.correct && step.expectedAnswer && (
                      <div className="mt-2">
                        <span className="text-gray-700 text-sm">Expected:</span>
                        <p className="font-medium text-gray-700">
                          {step.expectedAnswer}
                        </p>
                      </div>
                    )}
                    {/* Show max attempts notice */}
                    {!step.correct && step.attempts >= step.maxAttempts && (
                      <div className="mt-2 text-sm text-orange-600">
                        Maximum attempts reached ({step.attempts}/{step.maxAttempts})
                      </div>
                    )}
                  </div>
                ))}
              </div>
            </div>

            <div className="flex justify-end">
              <button
                onClick={() => router.push('/app/lessons')}
                className="px-6 py-2 bg-black text-white rounded-md hover:bg-gray-800 transition-colors"
              >
                Return to Lessons
              </button>
            </div>
          </div>
        </div>
      </div>
    );
  }

  return (
    lesson && (
      <div className="container mx-auto h-screen flex flex-col py-4 px-4 overflow-hidden">
        <HeaderWithProfile />
        <div className="flex-1 min-h-0">
          <LessonChat
            lesson={lesson as LessonModel}
            onComplete={handleLessonComplete}
            onStepComplete={handleStepComplete}
            loading={loading}
            targetLanguage={onboarding?.targetLanguage || 'English'}
          />
        </div>
      </div>
    )
  );
}
</file>

<file path="src/app/app/page.tsx">
import Footer from "@/components/Footer";



export default function AppPage() {

  return (
    <div className="flex flex-col items-center justify-items-center   pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
  
  <h1>App Page</h1>

      <Footer />
    </div>
  );
}
</file>

<file path="src/components/onboarding/LearningPurposeStep.tsx">
import React from 'react'

interface LearningPurposeStepProps {
  onNext: (data: { learningPurpose: string }) => void
  formData: {
    nativeLanguage: string
    targetLanguage: string
    learningPurpose: string
    proficiencyLevel: string
  }
  loading: boolean
}

export default function LearningPurposeStep({ 
  onNext, 
  formData, 
  loading 
}: LearningPurposeStepProps) {
  const [learningPurpose, setLearningPurpose] = React.useState(formData.learningPurpose || '')

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault()
    onNext({ learningPurpose })
  }

  const purposes = [
    'Travel', 'Business', 'Academic', 'Cultural Exchange', 
    'Relocation', 'Personal Interest', 'Other'
  ]

  return (
    <div className="animate-fade-in px-4">
      <h2 className="text-3xl font-semibold text-foreground">
        Why Are You Learning {formData.targetLanguage}?
      </h2>
      <form className="mt-6 space-y-6" onSubmit={handleSubmit}>
        <div>
          <label className="block text-sm font-medium text-neutral-9 mb-3">
            Select Your Learning Purpose
          </label>
          <div className="space-y-2">
            {purposes.map(purpose => (
              <div 
                key={purpose} 
                className={`flex items-center px-4 py-3 rounded-md border transition-colors cursor-pointer
                          ${learningPurpose === purpose 
                            ? 'border-accent-6 bg-accent-1' 
                            : 'border-neutral-5 hover:bg-neutral-2'}`}
                onClick={() => setLearningPurpose(purpose)}
              >
                <div className="flex items-center h-5">
                  <input
                    id={purpose}
                    name="learningPurpose"
                    type="radio"
                    className="h-4 w-4 text-accent-6 focus:ring-accent-6 border-neutral-5"
                    value={purpose}
                    checked={learningPurpose === purpose}
                    onChange={() => setLearningPurpose(purpose)}
                    disabled={loading}
                  />
                </div>
                <label htmlFor={purpose} className="ml-3 block text-sm font-medium text-foreground">
                  {purpose}
                </label>
              </div>
            ))}
          </div>
        </div>
        <div className="pt-2">
          <button
            type="submit"
            disabled={loading || !learningPurpose}
            className="w-full py-2.5 px-4 bg-primary hover:bg-accent-7 text-neutral-1 rounded-md transition-colors 
                     focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                     font-medium text-sm flex items-center justify-center"
          >
            {loading ? (
              <span className="flex items-center">
                <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                  <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                  <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                Saving...
              </span>
            ) : 'Continue'}
          </button>
        </div>
      </form>
    </div>
  )
}
</file>

<file path="src/components/onboarding/ProficiencyStep.tsx">
import React from 'react'

interface ProficiencyStepProps {
  onNext: (data: { proficiencyLevel: string }) => Promise<void>
  onAssessmentGeneration: () => void
  formData: {
    nativeLanguage: string
    targetLanguage: string
    learningPurpose: string
    proficiencyLevel: string
  }
  loading: boolean
}

export default function ProficiencyStep({ 
  onNext, 
  onAssessmentGeneration,
  formData, 
  loading 
}: ProficiencyStepProps) {
  const [proficiencyLevel, setProficiencyLevel] = React.useState(formData.proficiencyLevel || '')

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault()
    await onNext({ proficiencyLevel })
    onAssessmentGeneration()
  }

  const levels = [
    { id: 'beginner', name: 'Beginner', description: 'Little to no prior knowledge' },
    { id: 'intermediate', name: 'Intermediate', description: 'Basic conversations and reading' },
    { id: 'advanced', name: 'Advanced', description: 'Comfortable in most situations' }
  ]

  return (
    <div className="animate-fade-in px-4">
      <h2 className="text-3xl font-semibold text-foreground">
        Your {formData.targetLanguage} Proficiency Level
      </h2>
      <p className="mt-2 text-neutral-8">
        How would you rate your current level?
      </p>
      <form className="mt-6 space-y-6" onSubmit={handleSubmit}>
        <div className="space-y-3">
          {levels.map(level => (
            <div 
              key={level.id}
              className={`border rounded-lg p-4 cursor-pointer transition-all ${
                proficiencyLevel === level.id 
                  ? 'border-accent-6 bg-accent-1 shadow-sm' 
                  : 'border-neutral-5 hover:bg-neutral-2'
              }`}
              onClick={() => setProficiencyLevel(level.id)}
            >
              <div className="flex items-center">
                <input
                  id={level.id}
                  name="proficiencyLevel"
                  type="radio"
                  className="h-4 w-4 text-accent-6 focus:ring-accent-6 border-neutral-5"
                  value={level.id}
                  checked={proficiencyLevel === level.id}
                  onChange={() => setProficiencyLevel(level.id)}
                  disabled={loading}
                />
                <label htmlFor={level.id} className="ml-3 block text-sm font-medium text-foreground">
                  {level.name}
                </label>
              </div>
              <p className="mt-1 ml-7 text-sm text-neutral-8">{level.description}</p>
            </div>
          ))}
        </div>
        <div className="pt-2">
          <button
            type="submit"
            disabled={loading || !proficiencyLevel}
            className="w-full py-2.5 px-4 bg-primary hover:bg-accent-7 text-neutral-1 rounded-md transition-colors 
                     focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                     font-medium text-sm flex items-center justify-center"
          >
            {loading ? (
              <span className="flex items-center">
                <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                  <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                  <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                Saving...
              </span>
            ) : 'Continue to Assessment'}
          </button>
        </div>
      </form>
    </div>
  )
}
</file>

<file path="src/components/onboarding/WelcomeStep.tsx">
import React from 'react'

interface WelcomeStepProps {
  onNext: () => void
  loading: boolean
}

export default function WelcomeStep({ onNext, loading }: WelcomeStepProps) {
  console.log('tts quality', process.env.NEXT_PUBLIC_MOCK_TTS_QUALITY);
  return (
    <div className="text-center animate-fade-in px-4">
      <h2 className="text-3xl font-semibold text-foreground">
        Welcome to Language Learning
      </h2>
      <p className="mt-2 text-neutral-8">
        Let&apos;s get started with your personalized language learning journey
      </p>
      <div className="mt-8">
        <button
          onClick={onNext}
          disabled={loading}
          className="w-full py-2.5 px-4 bg-primary hover:bg-accent-7 text-neutral-1 rounded-md transition-colors 
                     focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                     font-medium text-sm flex items-center justify-center"
        >
          {loading ? (
            <span className="flex items-center">
              <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
              Loading...
            </span>
          ) : 'Get Started'}
        </button>
      </div>
    </div>
  )
}
</file>

<file path="src/components/AppLoadingIndicator.tsx">
// File: src/components/AppLoadingIndicator.tsx
export default function AppLoadingIndicator() {
  return (
    <div className="fixed inset-0 z-[9999] flex flex-col items-center justify-center bg-neutral-1 bg-opacity-90 backdrop-blur-sm">
      <div className="animate-spin h-12 w-12 border-4 border-neutral-3 border-t-accent-6 rounded-full mb-4" />
      <p className="text-lg font-medium text-neutral-12">Initializing App...</p>
      <p className="text-sm text-neutral-8">Please wait a moment.</p>
    </div>
  );
}
</file>

<file path="src/lib/interfaces/all-interfaces.ts">
import { AssessmentLesson, AssessmentStep, OnboardingModel } from "@/models/AppAllModels.model"
import { LessonModel, GeneratedLesson, LessonStep } from '@/models/AppAllModels.model'

export  interface IOnboardingRepository {
  getOnboarding(): Promise<OnboardingModel | null>
  createOnboarding(): Promise<OnboardingModel>
  updateOnboarding(step: string, formData: any): Promise<OnboardingModel>
  completeOnboarding(): Promise<OnboardingModel>
  deleteOnboarding(): Promise<void>
  getStatus(): Promise<boolean>
  getAssessmentLesson(): Promise<AssessmentLesson | null>
  getAssessmentLessonById(lessonId: string): Promise<AssessmentLesson | null>
  completeAssessmentLesson(assessment: AssessmentLesson, data: {
    summary: string;
    metrics: any;
    proposedTopics: string[];
  }): Promise<AssessmentLesson>
  createAssessmentLesson(userId: string, assessment: Omit<AssessmentLesson, 'id' | 'createdAt' | 'updatedAt'>): Promise<AssessmentLesson>
  recordStepAttempt(lessonId: string, stepId: string, data:{userResponse: string, correct: boolean}): Promise<AssessmentStep>
  updateOnboardingAssessmentLesson(lessonId: string, lessonData: Partial<AssessmentLesson>): Promise<AssessmentLesson>
}

export interface ILessonRepository {
  getLessons: () => Promise<LessonModel[]>
  getLessonById: (lessonId: string) => Promise<LessonModel | null>
  createLesson: (lessonData: { 
    focusArea: string
    targetSkills: string[]
    steps: LessonStep[]
  }) => Promise<LessonModel>
  updateLesson: (lessonId: string, lessonData: Partial<LessonModel>) => Promise<LessonModel>
  completeLesson: (lessonId: string, performanceMetrics?: {
    accuracy?: number
    pronunciationScore?: number
    errorPatterns?: string[]
  }) => Promise<LessonModel>
  deleteLesson: (lessonId: string) => Promise<void>
  recordStepAttempt: (lessonId: string, stepId: string, data: {
    userResponse: string
    correct: boolean
  }) => Promise<LessonStep>
  getStepHistory: (lessonId: string, stepId: string) => Promise<LessonStep[]>
}



export interface RecordingBlob extends Blob {
  recordingTime?: number;
  recordingSize?: number;
  lastModified?: number;
}



// Add these interfaces (adjust types like number/string/array as needed based on AI response)
export interface AiPerformanceMetrics {
  pronunciation_score?: number;
  fluency_score?: number;
  grammar_accuracy?: number; // Note the different name
  vocabulary_score?: number;
  overall_performance?: number;
  strengths?: string[];
  weaknesses?: string[];
}

export interface AiProgressTracking {
  improvement_since_last_assessment?: any; // Type appropriately if used
  learning_trajectory?: string;
  estimated_proficiency_level?: string;
  time_to_next_level_estimate?: string;
}

export interface AiAdaptiveSuggestions {
  suggested_topics?: string[];
  grammar_focus_areas?: string[];
  vocabulary_domains?: string[];
  next_skill_targets?: string[];
  learning_style_observations?: {
    preferred_patterns?: string[];
    effective_approaches?: string[];
  };
  // Add preferred_patterns and effective_approaches directly if they are top-level in suggestions
  preferred_patterns?: string[];
  effective_approaches?: string[];
}

// You might also want a top-level interface for the whole AI response
export interface AiLessonAnalysisResponse {
  pronunciation_assessment?: any; // Use more specific type if defined
  fluency_assessment?: any;
  grammar_assessment?: any;
  vocabulary_assessment?: any;
  exercise_completion?: any;
  performance_metrics?: AiPerformanceMetrics;
  adaptive_learning_suggestions?: AiAdaptiveSuggestions;
  progress_tracking?: AiProgressTracking;
  // Add other potential top-level fields if necessary
  audioRecordingUrl?: string;
  recordingDuration?: number;
}
</file>

<file path="src/lib/server-actions/_withErrorHandling.ts">
// src/lib/server-actions/_withErrorHandling.ts
import logger from '@/utils/logger'

export type Result<T> = { data?: T; error?: string }

export async function withServerErrorHandling<T>(
  fn: () => Promise<T>
): Promise<Result<T>> {
  try {
    const data = await fn()
    return { data }
  } catch (err: any) {
    const message = err instanceof Error ? err.message : 'Unknown error'
    logger.error('ServerAction error:', message)
    return { error: message }
  }
}
</file>

<file path="src/lib/server-actions/onboarding-actions.ts">
'use server';

import OnboardingService from '@/services/onboarding.service';
import { OnboardingRepository } from '@/repositories/onboarding.repository';
import LessonService from '@/services/lesson.service';
import { LessonRepository } from '@/repositories/lesson.repository';
import AIService from '@/services/ai.service';
import AssessmentGeneratorService from '@/services/assessment-generator.service';
import { GoogleTTS } from '@/services/google-tts.service';
import LessonGeneratorService from '@/services/lesson-generator.service';
import { AssessmentLesson, AssessmentStep, OnboardingModel } from '@/models/AppAllModels.model';
import { uploadFile } from '@/utils/vercel_blob-upload';
import logger from '@/utils/logger';
import { withServerErrorHandling, Result } from './_withErrorHandling';

function createOnboardingService() {
  const repo = new OnboardingRepository();
  const lessonRepo = new LessonRepository();
  return new OnboardingService(
    repo,
    new LessonService(
      lessonRepo,
      new LessonGeneratorService(new AIService(), new GoogleTTS(), uploadFile),
      repo
    ),
    new AssessmentGeneratorService(new AIService(), new GoogleTTS(), uploadFile)
  );
}

// Create
export async function createOnboardingAction(): Promise<Result<OnboardingModel>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.createOnboarding();
  });
}

// Read
export async function getOnboardingAction(): Promise<Result<OnboardingModel | null>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.getOnboarding();
  });
}

// Update a single step
export async function updateOnboardingAction(
  step: string,
  formData: any
): Promise<Result<OnboardingModel>> {
  return withServerErrorHandling(async () => {
    if (!step) throw new Error('Step is required');
    const svc = createOnboardingService();
    const updated = await svc.updateOnboarding(step, formData);
    logger.log('updated onboarding:', updated);
    return updated;
  });
}

// Delete
export async function deleteOnboardingAction(): Promise<Result<void>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    const deleted = await svc.deleteOnboarding();
    logger.log('deleted onboarding:', deleted);
    return deleted;
  });
}

// Mark complete + generate lessons
export async function markOnboardingCompleteAndGenerateInitialLessonsAction(): Promise<Result<OnboardingModel>> {
  return withServerErrorHandling(async () => {
    logger.info('marking onboarding complete and generating initial lessons');
    const svc = createOnboardingService();
    const completed = await svc.markOnboardingAsCompleteAndGenerateLessons();
    logger.info('completed onboarding:', completed);
    return completed;
  });
}

// Status flag
export async function getStatusAction(): Promise<Result<boolean>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.getStatus();
  });
}

// Assessment lesson fetch/complete/record/etc.
export async function getAssessmentLessonAction(): Promise<Result<AssessmentLesson>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.getAssessmentLesson();
  });
}

export async function completeAssessmentLessonAction(
  lessonId: string,
  userResponse: string
): Promise<Result<AssessmentLesson>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.completeAssessmentLesson(lessonId, userResponse);
  });
}

export async function recordAssessmentStepAttemptAction(
  lessonId: string,
  stepId: string,
  userResponse: string
): Promise<Result<AssessmentStep>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.recordStepAttempt(lessonId, stepId, userResponse);
  });
}

export async function updateOnboardingLessonAction(
  lessonId: string,
  lessonData: Partial<AssessmentLesson>
): Promise<Result<AssessmentLesson>> {
  return withServerErrorHandling(async () => {
    const svc = createOnboardingService();
    return await svc.updateOnboardingAssessmentLesson(lessonId, lessonData);
  });
}

export async function processAssessmentLessonRecordingAction(
  sessionRecording: Blob,
  lesson: AssessmentLesson,
  recordingTime: number,
  recordingSize: number
): Promise<Result<AssessmentLesson>> {
  return withServerErrorHandling(async () => {
    if (!sessionRecording)   throw new Error('No session recording provided');
    if (!lesson)             throw new Error('No assessment lesson provided');
    if (!recordingTime)      throw new Error('No recording time provided');
    if (!recordingSize)      throw new Error('No recording size provided');

    const svc = createOnboardingService();
    return await svc.processAssessmentLessonRecording(
      sessionRecording,
      lesson,
      recordingTime,
      recordingSize
    );
  });
}
</file>

<file path="src/lib/server-actions/stt-actions.ts">
'use server';

import { createSupabaseServerClient } from '@/utils/supabase/server'; // Import the server client creator
import logger from '@/utils/logger'; // Import logger
import { GoogleSttService, SttRequestConfig } from '@/services/stt.service';

const sttService = new GoogleSttService();

interface TranscribeResult {
  transcript?: string;
  error?: string;
}

export async function transcribeAudio(formData: FormData): Promise<TranscribeResult> {
  try {
    // 1. Get Supabase client and validate user session
    const supabase = await createSupabaseServerClient();
    const { data: { session }, error: sessionError } = await supabase.auth.getSession();

    if (sessionError) {
      console.error('STT Action: Error getting session:', sessionError);
      return { error: 'Failed to retrieve session' };
    }

    if (!session?.user?.id) {
      console.error('STT Action: Unauthorized access attempt.');
      return { error: 'Unauthorized' };
    }
    const userId = session.user.id;

    // 2. Parse FormData
    const audioBlob = formData.get('audio') as Blob | null;
    const languageCode = formData.get('languageCode') as string | null; // e.g., 'en-US'
    const sampleRateHertzStr = formData.get('sampleRateHertz') as string | null; // e.g., '48000'
    const encodingStr = formData.get('encoding') as string | null; // e.g., 'WEBM_OPUS', 'LINEAR16'

    if (!audioBlob || !languageCode || !sampleRateHertzStr || !encodingStr) {
      console.error('STT Action: Missing required form data.', { audioBlob: !!audioBlob, languageCode, sampleRateHertzStr, encodingStr });
      return { error: 'Missing required form data: audio, languageCode, sampleRateHertz, encoding' };
    }

    const sampleRateHertz = parseInt(sampleRateHertzStr, 10);
    if (isNaN(sampleRateHertz)) {
        console.error('STT Action: Invalid sampleRateHertz.', { sampleRateHertzStr });
        return { error: 'Invalid sampleRateHertz' };
    }

    // TODO: Validate encoding against allowed types (e.g., 'WEBM_OPUS', 'LINEAR16')

    // 3. Convert Blob to Buffer/Base64 for Google API
    const audioBytes = await audioBlob.arrayBuffer();
    const audioBuffer = Buffer.from(audioBytes);

    const sttRequestConfig: SttRequestConfig = {
      audioBytes: audioBuffer,
      encoding: encodingStr, // As validated earlier
      sampleRateHertz: sampleRateHertz,
      languageCode: languageCode,
    };

    try {
      console.log(`STT Action: Sending request to GoogleSttService for user ${userId}, lang: ${languageCode}, rate: ${sampleRateHertz}, encoding: ${encodingStr}, size: ${audioBlob.size}`);
      const sttResponse = await sttService.transcribe(sttRequestConfig);

      if (!sttResponse.transcript) {
        console.warn('STT Action: GoogleSttService returned no transcription.');
        return { transcript: '' };
      }

      console.log(`STT Action: Successfully transcribed audio for user ${userId}. Transcript: "${sttResponse.transcript}"`);
      return { transcript: sttResponse.transcript };

    } catch (error) {
      console.error('STT Action: Error calling GoogleSttService:', error);
      return { error: `STT service error: ${error instanceof Error ? error.message : String(error)}` };
    }

  } catch (error) {
    console.error('STT Action: Error processing request:', error);
    if (error instanceof Error) {
      return { error: `Internal Server Error: ${error.message}` };
    }
    return { error: 'Internal Server Error' };
  }
}
</file>

<file path="src/services/recording.service.ts">
import logger from '@/utils/logger';
import AIService, { models } from './ai.service';
import MessageGenerator from './generators/messageGenerator';
import MetricsService from './metrics.service';
import { retryOperation } from '@/utils/retryWithOperation';
import { LanguageDetectionResponse } from '@/models/Language-detection.model';
import { IUploadableAIService } from '@/interfaces/ai-service.interface';
import { DetailedAIResponse } from '@/models/AiResponse.model';
import {
  AssessmentLesson,
  AudioMetrics,
  LessonModel,
} from '@/models/AppAllModels.model';

class RecordingService {
  private aiService: IUploadableAIService;
  private messageGenerator: MessageGenerator;
  private metricsService: MetricsService;

  constructor() {
    this.aiService = new AIService();
    this.messageGenerator = new MessageGenerator();
    this.metricsService = new MetricsService();
  }

  async uploadFile(
    audioBuffer: Buffer,
    mimeType: string,
    fileName: string
  ): Promise<string> {
    // The retries for uploadFile are already handled in AIService.uploadFile.
    return await this.aiService.uploadFile(audioBuffer, mimeType, fileName);
  }

  async submitRecording(
    userIP: string,
    fileUri: string, // File URI returned from the upload
    recordingTime: number,
    recordingSize: number,
    isDeepAnalysis: boolean
  ): Promise<Record<string, unknown>> {
    try {
      // Generate content using AI service with retry logic.
      const startTime = Date.now();

      const detectedTargetLanguage = await retryOperation(() =>
        this.detectTargetLanguage(fileUri)
      );

      logger.log('Detected Target Language:', detectedTargetLanguage);

      const personalizedPrompts =
        this.messageGenerator.generatePersonalizedPrompts(
          detectedTargetLanguage,
          isDeepAnalysis
        );

      logger.log('Personalized Prompts:', personalizedPrompts);

      let aiResponse: Record<string, unknown>;
      try {
        aiResponse = await retryOperation(() =>
          this.aiService.generateContent(
            fileUri,
            personalizedPrompts.userPrompt,
            personalizedPrompts.systemPrompt,
            models.gemini_2_5_pro_exp
          )
        );
        logger.log('AI Response:', aiResponse);
      } catch (error) {
        logger.error('Error generating content with the error:', error);
        aiResponse = await retryOperation(() =>
          this.aiService.generateContent(
            fileUri,
            personalizedPrompts.userPrompt,
            personalizedPrompts.systemPrompt,
            models.gemini_2_0_flash
          )
        );
      }

      const endTime = Date.now();
      const responseTime = endTime - startTime;

      // Collect interaction data with retry logic.
      await retryOperation(() =>
        this.metricsService.collectInteractionData(
          userIP,
          fileUri,
          aiResponse,
          recordingTime,
          responseTime,
          recordingSize,
          detectedTargetLanguage
        )
      );

      return aiResponse;
    } catch (error) {
      logger.error('Error submitting recording:', error);
      throw error;
    }
  }

  async submitLessonRecordingSession(
    fileUri: string,
    recordingTime: number,
    recordingSize: number,
    languages: { targetLanguage: string; nativeLanguage: string },
    lessonData: LessonModel | AssessmentLesson
  ): Promise<Record<string, unknown>> {
    try {
      // Generate content using AI service with retry logic.
      const startTime = Date.now();

      // detailed analysis
      const personalizedPrompts =
        this.messageGenerator.generateLessonRecordingAnalysisPrompts(
          languages.targetLanguage,
          languages.nativeLanguage,
          lessonData
        );

      logger.log('Personalized Prompts:', personalizedPrompts);

      let aiResponse: Record<string, unknown>;
      try {
        aiResponse = await retryOperation(() =>
          this.aiService.generateContent(
            fileUri,
            personalizedPrompts.userPrompt,
            personalizedPrompts.systemPrompt,
            models.gemini_2_0_flash
          )
        );
        logger.log(
          'AI Response in submitLessonRecordingSession:',
          JSON.stringify(aiResponse)
        );
      } catch (error) {
        logger.error('Error generating content with the error:', error);
        aiResponse = await retryOperation(() =>
          this.aiService.generateContent(
            fileUri,
            personalizedPrompts.userPrompt,
            personalizedPrompts.systemPrompt,
            models.gemini_2_0_flash
          )
        );
      }

      return aiResponse;
    } catch (error) {
      logger.error('Error submitting recording:', error);
      throw error;
    }
  }

  private async detectTargetLanguage(
    fileUri: string
  ): Promise<LanguageDetectionResponse> {
    const { userPrompt, systemPrompt } =
      this.messageGenerator.generateTargetLanguageDetectionPrompt();
    const response = await this.aiService.generateContent(
      fileUri,
      userPrompt,
      systemPrompt,
      models.gemini_2_0_flash
    );
    return response as unknown as LanguageDetectionResponse;
  }
}
export default RecordingService;
</file>

<file path="src/services/stt.service.ts">
import { SpeechClient } from '@google-cloud/speech';
import { google } from '@google-cloud/speech/build/protos/protos'; // For types
import logger from '@/utils/logger';

// Ensure GOOGLE_APPLICATION_CREDENTIALS is set in your environment for this to work
let speechClient: SpeechClient | null = null;
try {
    speechClient = new SpeechClient();
    logger.info('Google SpeechClient initialized successfully.');
} catch (error) {
    logger.error('Failed to initialize Google SpeechClient:', error);
    // Depending on requirements, you might want to throw here or handle initialization failure downstream
}

export interface SttRequestConfig {
    audioBytes: Buffer; // Raw audio data
    encoding: 'WEBM_OPUS' | 'LINEAR16' | string; // Allow string for flexibility, but define common ones
    sampleRateHertz: number;
    languageCode: string; // e.g., 'en-US'
    enableAutomaticPunctuation?: boolean;
    model?: string; // e.g., 'telephony_short', 'latest_long'
    // Add other relevant RecognitionConfig fields as needed
}

export interface SttResponse {
    transcript: string;
    // Add other relevant fields from the response if needed (e.g., confidence, word timings)
}

export interface ISttService {
    transcribe(config: SttRequestConfig): Promise<SttResponse>;
}

export class GoogleSttService implements ISttService {
    async transcribe(config: SttRequestConfig): Promise<SttResponse> {
        if (!speechClient) {
            throw new Error('Google SpeechClient is not initialized. Check credentials and logs.');
        }

        const {
            audioBytes,
            encoding,
            sampleRateHertz,
            languageCode,
            enableAutomaticPunctuation = true, // Default to true
            model = 'default', // Default model, consider 'telephony_short' or others based on use case
        } = config;

        const recognitionConfig: google.cloud.speech.v1.IRecognitionConfig = {
            encoding: encoding as unknown as google.cloud.speech.v1.RecognitionConfig.AudioEncoding, // Cast needed
            sampleRateHertz: sampleRateHertz,
            languageCode: languageCode,
            enableAutomaticPunctuation: enableAutomaticPunctuation,
            model: model,
            // Add other config options here if passed in SttRequestConfig
            // e.g., enableWordTimeOffsets: config.enableWordTimeOffsets,
        };

        const audio = {
            content: audioBytes.toString('base64'), // API expects base64 encoded string
        };

        const requestPayload: google.cloud.speech.v1.IRecognizeRequest = {
            config: recognitionConfig,
            audio: audio,
        };

        try {
            logger.info(`Sending STT request to Google Cloud for language: ${languageCode}, encoding: ${encoding}, rate: ${sampleRateHertz}`);
            const [response] = await speechClient.recognize(requestPayload);
            logger.debug('Received STT response from Google Cloud:', response);

            // Process the response to extract the most likely transcript
            const transcription = response.results
                ?.map(result => result.alternatives?.[0]?.transcript)
                .filter(transcript => transcript !== undefined) // Filter out undefined transcripts
                .join('\n') ?? ''; // Join results and provide empty string if null/undefined

            if (!transcription && response.results && response.results.length > 0) {
                logger.warn('Google STT API returned results but no valid transcriptions found.');
            } else if (!response.results || !response.results.length) {
                logger.warn('Google STT API returned no results.');
            }

            return { transcript: transcription };

        } catch (error) {
            logger.error('Error calling Google Cloud STT API:', error);
            // Re-throw or handle specific Google API errors
            throw new Error(`Google STT API request failed: ${error instanceof Error ? error.message : String(error)}`);
        }
    }
}

// Optional: Factory function (similar to auth service)
// export function getSttService(): ISttService {
//     // Add logic here to potentially return a mock service based on environment variables
//     return new GoogleSttService();
// }
</file>

<file path="src/services/user.service.ts">
import { IUserRepository } from '@/repositories/user.repository'
import { UserProfileModel } from '@/models/AppAllModels.model'
import logger from '@/utils/logger'

export default class UserService {
  private userRepository: IUserRepository

  constructor(userRepository: IUserRepository) {
    this.userRepository = userRepository
  }

  async getUserProfile(userId: string): Promise<UserProfileModel | null> {
    logger.debug(`UserService: Getting profile for user ${userId}`);
    try {
      const profile = await this.userRepository.getUserProfile(userId);
      logger.debug(`UserService: Got profile for user ${userId}`, { profileFound: !!profile });
      return profile;
    } catch (error) {
      logger.error(`Error in UserService.getUserProfile for user ${userId}:`, error);
      // Re-throw to allow controller/action to handle specific error types if needed
      throw error;
    }
  }

  async createUserProfile(profile: Partial<UserProfileModel>): Promise<UserProfileModel> {
    // Validate that essential fields are present
    if (!profile.userId || !profile.email) {
      const missingFields = [];
      if (!profile.userId) missingFields.push('userId');
      if (!profile.email) missingFields.push('email');
      const errorMessage = `UserService.createUserProfile: Missing required fields: ${missingFields.join(', ')}`;
      logger.error(errorMessage, { profile });
      throw new Error(errorMessage);
    }

    try {
      // Now we know userId and email are strings
      const profileData = {
        userId: profile.userId,
        email: profile.email,
      };
      return await this.userRepository.createUserProfile(profileData);
    } catch (error) {
      logger.error('Error in UserService.createUserProfile:', error);
      throw error;
    }
  }

  async updateUserProfile(userId: string, profile: Partial<UserProfileModel>): Promise<UserProfileModel> {
    try {
      return await this.userRepository.updateUserProfile(userId, profile)
    } catch (error) {
      logger.error('Error in UserService.updateUserProfile:', error)
      throw error
    }
  }

  /**
  * Deletes a user's profile and all associated data.
  * @param userId The ID of the user whose profile should be deleted.
  */
  async deleteUserProfile(userId: string): Promise<void> {
    logger.info(`UserService: Attempting to delete profile and auth user for ${userId}`);
    try {
      // The repository method now handles both DB and Auth deletion
      await this.userRepository.deleteUserProfile(userId);
      logger.info(`UserService: Successfully completed deletion process for user ${userId}`);
    } catch (error) {
      logger.error(`Error in UserService.deleteUserProfile for user ${userId}:`, error);
      // Re-throw the error so the calling layer (e.g., server action) knows it failed
      throw error;
    }
  }
}
</file>

<file path="src/utils/supabase/admin.ts">
// src/utils/supabase/admin.ts
import { createClient } from '@supabase/supabase-js'
import logger from '../logger'

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const serviceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY

if (!supabaseUrl || !serviceRoleKey) {
  logger.error('Supabase URL or Service Role Key is missing for Admin Client.')
  // Throw an error during initialization if keys are missing server-side
  // This prevents the application from starting in an invalid state.
  throw new Error('Supabase Admin Client cannot be initialized: Missing URL or Service Role Key.')
}

// Create a singleton instance of the Supabase client for admin tasks
// This is safe because the service role key doesn't depend on user sessions/cookies
const supabaseAdmin = createClient(supabaseUrl, serviceRoleKey, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  },
   // Add global fetch options for timeout if needed, especially for serverless
   global: {
    fetch: (input, init) => {
      return fetch(input, {
        ...init,
        signal: AbortSignal.timeout(30000), // 30-second timeout
      });
    },
  },
})

logger.info('Supabase Admin client initialized successfully.')

export default supabaseAdmin
</file>

<file path="tests/servises/onboarding-service.test.ts">
import { mockDeep, MockProxy, mockReset } from 'jest-mock-extended';
import OnboardingService from '@/services/onboarding.service';
import LessonService from '@/services/lesson.service';
import { IAssessmentGeneratorService } from '@/services/assessment-generator.service';
import RecordingService from '@/services/recording.service';
import LearningProgressService from '@/services/learning-progress.service';
import { IOnboardingRepository } from '@/lib/interfaces/all-interfaces';
import {
  AssessmentLesson,
  AssessmentStep,
  OnboardingModel,
  AudioMetrics,
} from '@/models/AppAllModels.model';
import { ProficiencyLevel, AssessmentStepType } from '@prisma/client';
import logger from '@/utils/logger';
import { assessmentMockData2 } from '@/__mocks__/assessment-data.mock'; // Import mock data

// --- Mock Dependencies ---
jest.mock('@/utils/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  debug: jest.fn(),
  log: jest.fn(), // Add log if used
}));

// Mock services instantiated internally
jest.mock('@/services/recording.service');
jest.mock('@/services/learning-progress.service');
jest.mock('@supabase/supabase-js');
// Mock repository used by LearningProgressService if needed, assuming it's implicitly handled by mocking LearningProgressService itself
// jest.mock('@/repositories/learning-progress.repository');
//
const mockAuth = {
  signInWithPassword: jest
    .fn()
    .mockResolvedValue({ data: { user: null }, error: null }),
  signOut: jest.fn().mockResolvedValue({ error: null }),
};

const mockSupabase = {
  auth: mockAuth,
  // Add other Supabase services as needed
};

describe('OnboardingService', () => {
  let onboardingService: OnboardingService;
  let mockOnboardingRepository: MockProxy<IOnboardingRepository>;
  let mockLessonService: MockProxy<LessonService>;
  let mockAssessmentGeneratorService: MockProxy<IAssessmentGeneratorService>;
  let MockRecordingService: jest.MockedClass<typeof RecordingService>;
  let MockLearningProgressService: jest.MockedClass<
    typeof LearningProgressService
  >;

  // --- Mock Data ---
  const userId = 'test-user-id';
  const onboardingId = 'onboarding-1';
  const assessmentLessonId = 'assessment-lesson-1';
  const stepId = 'step-123';

  const mockOnboarding: OnboardingModel = {
    id: onboardingId,
    userId: userId,
    steps: {},
    completed: false,
    learningPurpose: 'travel',
    nativeLanguage: 'English',
    targetLanguage: 'German',
    proficiencyLevel: ProficiencyLevel.beginner,
    initialAssessmentCompleted: false,
    createdAt: new Date(),
    updatedAt: new Date(),
  };

  const mockAssessmentLesson: AssessmentLesson = {
    // Use imported mock data structure, ensure it matches AssessmentLesson type
    ...(assessmentMockData2[0] as unknown as AssessmentLesson), // Cast carefully
    id: assessmentLessonId,
    userId: userId,
    completed: false,
    // Override specific fields if necessary
  };

  const mockCompleteAssessmentLesson: AssessmentLesson = {
    ...mockAssessmentLesson,
    completed: true,
    metrics: {
      accuracy: 85,
      overallScore: 80,
      strengths: ['vocab'],
      weaknesses: ['grammar'],
    },
    summary: 'Good job!',
    proposedTopics: ['Travel', 'Food'],
    audioMetrics: null, // Add mock audio metrics if testing processAssessmentLessonRecording
  };

  const mockAssessmentStep: AssessmentStep = {
    id: stepId,
    assessmentId: assessmentLessonId,
    stepNumber: 1,
    type: 'question',
    content: 'Question content',
    maxAttempts: 3,
    attempts: 0,
    correct: false,
    createdAt: new Date(),
    updatedAt: new Date(),
    expectedAnswer: 'Expected Answer',
  };

  beforeEach(() => {
    (logger.info as jest.Mock).mockClear();
    (logger.error as jest.Mock).mockClear();
    (logger.warn as jest.Mock).mockClear();
    (logger.log as jest.Mock).mockClear();

    // Create deep mocks for injected dependencies
    mockOnboardingRepository = mockDeep<IOnboardingRepository>();
    mockLessonService = mockDeep<LessonService>();
    mockAssessmentGeneratorService = mockDeep<IAssessmentGeneratorService>();

    // --- Mock Internally Instantiated Services ---
    // Clear mocks and setup instances for RecordingService
    jest.clearAllMocks(); // Clear mocks for internally instantiated services too
    MockRecordingService = RecordingService as jest.MockedClass<
      typeof RecordingService
    >;
    MockLearningProgressService = LearningProgressService as jest.MockedClass<
      typeof LearningProgressService
    >;

    // Mock the methods of the instances that will be created
    MockRecordingService.prototype.uploadFile = jest.fn();
    MockRecordingService.prototype.submitLessonRecordingSession = jest.fn();
    MockLearningProgressService.prototype.updateProgressAfterAssessment =
      jest.fn();
    // Add mocks for other LearningProgressService methods if called by OnboardingService

    // Instantiate the service with mocked dependencies
    onboardingService = new OnboardingService(
      mockOnboardingRepository,
      mockLessonService,
      mockAssessmentGeneratorService
    );
  });

  // --- Test Cases ---

  it('should be defined', () => {
    expect(onboardingService).toBeDefined();
  });

  describe('getOnboarding', () => {
    it('should call repository getOnboarding and return the result', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      const result = await onboardingService.getOnboarding();
      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      expect(result).toEqual(mockOnboarding);
      expect(logger.info).toHaveBeenCalledWith('Onboarding:', mockOnboarding);
    });

    it('should return null if repository returns null', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null);
      const result = await onboardingService.getOnboarding();
      expect(result).toBeNull();
      expect(logger.info).toHaveBeenCalledWith('Onboarding:', null);
    });
  });

  describe('createOnboarding', () => {
    it('should call repository createOnboarding and return the result', async () => {
      mockOnboardingRepository.createOnboarding.mockResolvedValue(
        mockOnboarding
      );
      const result = await onboardingService.createOnboarding();
      expect(mockOnboardingRepository.createOnboarding).toHaveBeenCalledTimes(
        1
      );
      expect(result).toEqual(mockOnboarding);
    });
  });

  describe('updateOnboarding', () => {
    it('should call repository updateOnboarding with correct arguments', async () => {
      const step = 'language_select';
      const formData = { nativeLanguage: 'French' };
      const updatedOnboarding = { ...mockOnboarding, nativeLanguage: 'French' };
      mockOnboardingRepository.updateOnboarding.mockResolvedValue(
        updatedOnboarding
      );

      const result = await onboardingService.updateOnboarding(step, formData);

      expect(mockOnboardingRepository.updateOnboarding).toHaveBeenCalledWith(
        step,
        formData
      );
      expect(result).toEqual(updatedOnboarding);
    });
  });

  describe('markOnboardingAsCompleteAndGenerateLessons', () => {
    it('should complete onboarding and trigger initial lesson generation', async () => {
      const completedOnboarding = { ...mockOnboarding, completed: true };
      mockOnboardingRepository.completeOnboarding.mockResolvedValue(
        completedOnboarding
      );
      mockLessonService.generateInitialLessons.mockResolvedValue([]); // Assuming returns array of lessons

      const result =
        await onboardingService.markOnboardingAsCompleteAndGenerateLessons();

      expect(mockOnboardingRepository.completeOnboarding).toHaveBeenCalledTimes(
        1
      );
      expect(mockLessonService.generateInitialLessons).toHaveBeenCalledTimes(1);
      expect(result).toEqual(completedOnboarding);
    });
  });

  describe('deleteOnboarding', () => {
    it('should call repository deleteOnboarding', async () => {
      mockOnboardingRepository.deleteOnboarding.mockResolvedValue();
      await onboardingService.deleteOnboarding();
      expect(mockOnboardingRepository.deleteOnboarding).toHaveBeenCalledTimes(
        1
      );
    });
  });

  describe('getStatus', () => {
    it('should call repository getStatus and return the result', async () => {
      mockOnboardingRepository.getStatus.mockResolvedValue(true);
      const result = await onboardingService.getStatus();
      expect(mockOnboardingRepository.getStatus).toHaveBeenCalledTimes(1);
      expect(result).toBe(true);
    });
  });

  describe('getAssessmentLesson', () => {
    it('should return existing assessment lesson if found', async () => {
      mockOnboardingRepository.getAssessmentLesson.mockResolvedValue(
        mockAssessmentLesson
      );
      // CHANGE THIS LINE: Remove userId from the call
      // const result = await onboardingService.getAssessmentLesson(userId);
      const result = await onboardingService.getAssessmentLesson(); // No argument

      // CHANGE THIS LINE: Expect call without arguments
      // expect(mockOnboardingRepository.getAssessmentLesson).toHaveBeenCalledWith(userId);
      expect(
        mockOnboardingRepository.getAssessmentLesson
      ).toHaveBeenCalledTimes(1); // Or .toHaveBeenCalled()

      expect(result).toEqual(mockAssessmentLesson);
      expect(
        mockAssessmentGeneratorService.generateAssessmentSteps
      ).not.toHaveBeenCalled();
      expect(
        mockOnboardingRepository.createAssessmentLesson
      ).not.toHaveBeenCalled();
    });

    it('should generate and create a new assessment if none exists', async () => {
      const generatedSteps = [
        {
          stepNumber: 1,
          type: AssessmentStepType.instruction,
          content: '...',
          maxAttempts: 1,
        },
      ];
      const stepsWithAudio = [
        { ...generatedSteps[0], contentAudioUrl: 'audio.mp3' },
      ];

      mockOnboardingRepository.getAssessmentLesson.mockResolvedValue(null);
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding); // Assuming getOnboarding also doesn't need userId here
      mockAssessmentGeneratorService.generateAssessmentSteps.mockResolvedValue(
        generatedSteps as any
      );
      mockAssessmentGeneratorService.generateAudioForSteps.mockResolvedValue(
        stepsWithAudio as any
      );
      mockOnboardingRepository.createAssessmentLesson.mockResolvedValue(
        mockAssessmentLesson
      ); // Return the created lesson

      const result = await onboardingService.getAssessmentLesson(); // No argument

      expect(
        mockOnboardingRepository.getAssessmentLesson
      ).toHaveBeenCalledTimes(1); // Or .toHaveBeenCalled()

      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1); // This likely still needs to be called
      expect(
        mockAssessmentGeneratorService.generateAssessmentSteps
      ).toHaveBeenCalledWith(
        mockOnboarding.targetLanguage,
        mockOnboarding.nativeLanguage,
        mockOnboarding.proficiencyLevel
      );
      expect(
        mockAssessmentGeneratorService.generateAudioForSteps
      ).toHaveBeenCalledWith(
        generatedSteps,
        mockOnboarding.targetLanguage,
        mockOnboarding.nativeLanguage
      );
      expect(
        mockOnboardingRepository.createAssessmentLesson
      ).toHaveBeenCalledWith(
        userId,
        expect.objectContaining({
          // Keep userId here if create needs it
          userId: userId,
          sourceLanguage: mockOnboarding.nativeLanguage,
          targetLanguage: mockOnboarding.targetLanguage,
          steps: stepsWithAudio,
        })
      );
      expect(result).toEqual(mockAssessmentLesson);
    });

    it('should throw error if onboarding data is missing for generation', async () => {
      mockOnboardingRepository.getAssessmentLesson.mockResolvedValue(null);
      mockOnboardingRepository.getOnboarding.mockResolvedValue({
        ...mockOnboarding,
        targetLanguage: null,
      }); // Missing target language

      await expect(onboardingService.getAssessmentLesson()).rejects.toThrow(
        'Missing required parameters'
      );
    });
  });

  describe('completeAssessmentLesson', () => {
    it('should get lesson, generate results, complete lesson, update progress, and complete onboarding', async () => {
      const assessmentResult = {
        metrics: {
          accuracy: 85,
          overallScore: 80,
          strengths: ['vocab'],
          weaknesses: ['grammar'],
        },
        summary: 'Good job!',
        proposedTopics: ['Travel', 'Food'],
      };
      const completedOnboarding = {
        ...mockOnboarding,
        completed: true,
        initialAssessmentCompleted: true,
      };

      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue(
        mockAssessmentLesson
      );
      mockAssessmentGeneratorService.generateAssessmentResult.mockResolvedValue(
        assessmentResult
      );
      mockOnboardingRepository.completeAssessmentLesson.mockResolvedValue(
        mockCompleteAssessmentLesson
      );
      // Mock the LearningProgressService call (assuming it resolves successfully)
      MockLearningProgressService.prototype.updateProgressAfterAssessment.mockResolvedValue();
      mockOnboardingRepository.completeOnboarding.mockResolvedValue(
        completedOnboarding
      );

      const result = await onboardingService.completeAssessmentLesson(
        assessmentLessonId,
        'some response'
      ); // userResponse seems unused here?

      expect(
        mockOnboardingRepository.getAssessmentLessonById
      ).toHaveBeenCalledWith(assessmentLessonId);
      expect(
        mockAssessmentGeneratorService.generateAssessmentResult
      ).toHaveBeenCalledWith(mockAssessmentLesson);
      expect(
        mockOnboardingRepository.completeAssessmentLesson
      ).toHaveBeenCalledWith(
        expect.objectContaining({ id: assessmentLessonId }), // Pass the updated lesson object
        assessmentResult
      );
      expect(
        MockLearningProgressService.prototype.updateProgressAfterAssessment
      ).toHaveBeenCalledWith(userId, mockCompleteAssessmentLesson);
      expect(mockOnboardingRepository.completeOnboarding).toHaveBeenCalledTimes(
        1
      );
      expect(result).toEqual(mockCompleteAssessmentLesson);
    });

    it('should log error if updating learning progress fails', async () => {
      const assessmentResult = {
        metrics: {
          accuracy: 85,
          overallScore: 80,
          strengths: ['vocab'],
          weaknesses: ['grammar'],
        },
        summary: 'Good job!',
        proposedTopics: ['Travel', 'Food'],
      };
      const progressError = new Error('Failed to update progress');

      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue(
        mockAssessmentLesson
      );
      mockAssessmentGeneratorService.generateAssessmentResult.mockResolvedValue(
        assessmentResult
      );
      mockOnboardingRepository.completeAssessmentLesson.mockResolvedValue(
        mockCompleteAssessmentLesson
      );
      MockLearningProgressService.prototype.updateProgressAfterAssessment.mockRejectedValue(
        progressError
      ); // Simulate failure
      mockOnboardingRepository.completeOnboarding.mockResolvedValue({
        ...mockOnboarding,
        completed: true,
      });

      await onboardingService.completeAssessmentLesson(
        assessmentLessonId,
        'some response'
      );

      expect(
        MockLearningProgressService.prototype.updateProgressAfterAssessment
      ).toHaveBeenCalledWith(userId, mockCompleteAssessmentLesson);
      expect(logger.error).toHaveBeenCalledWith(
        'Failed to update learning progress after assessment completion',
        expect.objectContaining({
          userId,
          assessmentId: assessmentLessonId,
          error: progressError,
        })
      );
      // Ensure onboarding completion still happens
      expect(mockOnboardingRepository.completeOnboarding).toHaveBeenCalledTimes(
        1
      );
    });

    it('should throw error if assessment lesson not found', async () => {
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue(null);
      await expect(
        onboardingService.completeAssessmentLesson(
          assessmentLessonId,
          'response'
        )
      ).rejects.toThrow('Assessment lesson not found');
    });
  });

  describe('recordStepAttempt', () => {
    it('should throw error if lesson not found', async () => {
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue(null);
      await expect(
        onboardingService.recordStepAttempt(
          assessmentLessonId,
          stepId,
          'response'
        )
      ).rejects.toThrow('Assessment lesson not found');
    });

    it('should throw error if step not found in lesson', async () => {
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [],
      }); // Lesson without the step
      await expect(
        onboardingService.recordStepAttempt(
          assessmentLessonId,
          stepId,
          'response'
        )
      ).rejects.toThrow('Step not found');
    });

    it('should record attempt as correct (but use expected answer) if max attempts reached', async () => {
      const stepAtMaxAttempts = { ...mockAssessmentStep, attempts: 3 }; // attempts >= maxAttempts
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [stepAtMaxAttempts],
      });
      mockOnboardingRepository.recordStepAttempt.mockResolvedValue({
        ...stepAtMaxAttempts,
        attempts: 4,
      }); // Simulate repo response

      const result = await onboardingService.recordStepAttempt(
        assessmentLessonId,
        stepId,
        'wrong answer'
      );

      expect(mockOnboardingRepository.recordStepAttempt).toHaveBeenCalledWith(
        assessmentLessonId,
        stepId,
        {
          userResponse: mockAssessmentStep.expectedAnswer, // Should use expected answer
          correct: true, // Mark as correct to proceed UI
        }
      );
      expect(logger.info).toHaveBeenCalledWith(
        'Maximum attempts reached',
        expect.anything()
      );
      expect(result).toBeDefined();
    });

    it('should correctly identify a correct answer for a question step (exact match)', async () => {
      const step = { ...mockAssessmentStep, expectedAnswer: 'Exact Answer' };
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [step],
      });
      mockOnboardingRepository.recordStepAttempt.mockResolvedValue({
        ...step,
        correct: true,
        attempts: 1,
      });

      await onboardingService.recordStepAttempt(
        assessmentLessonId,
        stepId,
        'Exact Answer'
      );

      expect(mockOnboardingRepository.recordStepAttempt).toHaveBeenCalledWith(
        assessmentLessonId,
        stepId,
        {
          userResponse: 'Exact Answer',
          correct: true,
        }
      );
    });

    it('should correctly identify a correct answer for a question step (normalized match)', async () => {
      const step = {
        ...mockAssessmentStep,
        expectedAnswer: 'Expected Answer...',
      };
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [step],
      });
      mockOnboardingRepository.recordStepAttempt.mockResolvedValue({
        ...step,
        correct: true,
        attempts: 1,
      });

      await onboardingService.recordStepAttempt(
        assessmentLessonId,
        stepId,
        '  expected answer! '
      ); // With extra space, punctuation, case difference

      expect(mockOnboardingRepository.recordStepAttempt).toHaveBeenCalledWith(
        assessmentLessonId,
        stepId,
        {
          userResponse: '  expected answer! ',
          correct: true, // Normalization should handle this
        }
      );
    });

    it('should correctly identify an incorrect answer for a question step', async () => {
      const step = { ...mockAssessmentStep, expectedAnswer: 'Correct Answer' };
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [step],
      });
      mockOnboardingRepository.recordStepAttempt.mockResolvedValue({
        ...step,
        correct: false,
        attempts: 1,
      });

      await onboardingService.recordStepAttempt(
        assessmentLessonId,
        stepId,
        'Wrong Answer'
      );

      expect(mockOnboardingRepository.recordStepAttempt).toHaveBeenCalledWith(
        assessmentLessonId,
        stepId,
        {
          userResponse: 'Wrong Answer',
          correct: false,
        }
      );
    });

    it('should mark instruction/feedback/summary steps as correct', async () => {
      const instructionStep = {
        ...mockAssessmentStep,
        type: AssessmentStepType.instruction,
        expectedAnswer: null,
      };
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [instructionStep],
      });
      mockOnboardingRepository.recordStepAttempt.mockResolvedValue({
        ...instructionStep,
        correct: true,
        attempts: 1,
      });

      await onboardingService.recordStepAttempt(
        assessmentLessonId,
        stepId,
        'Acknowledged'
      ); // Or empty string

      expect(mockOnboardingRepository.recordStepAttempt).toHaveBeenCalledWith(
        assessmentLessonId,
        stepId,
        {
          userResponse: 'Acknowledged',
          correct: true,
        }
      );
    });

    it('should handle errors during recording and log them', async () => {
      const dbError = new Error('DB write failed');
      const step = { ...mockAssessmentStep, expectedAnswer: 'Answer' };
      mockOnboardingRepository.getAssessmentLessonById.mockResolvedValue({
        ...mockAssessmentLesson,
        steps: [step],
      });
      mockOnboardingRepository.recordStepAttempt.mockRejectedValue(dbError);

      await expect(
        onboardingService.recordStepAttempt(
          assessmentLessonId,
          stepId,
          'Answer'
        )
      ).rejects.toThrow('DB write failed');
      expect(logger.error).toHaveBeenCalledWith(
        'Error recording step attempt:',
        dbError
      );
    });
  });

  describe('updateOnboardingAssessmentLesson', () => {
    it('should call repository updateOnboardingAssessmentLesson with correct arguments', async () => {
      const updateData: Partial<AssessmentLesson> = {
        summary: 'Updated summary',
      };
      const updatedLesson = {
        ...mockAssessmentLesson,
        summary: 'Updated summary',
      };
      mockOnboardingRepository.updateOnboardingAssessmentLesson.mockResolvedValue(
        updatedLesson
      );

      const result = await onboardingService.updateOnboardingAssessmentLesson(
        assessmentLessonId,
        updateData
      );

      expect(
        mockOnboardingRepository.updateOnboardingAssessmentLesson
      ).toHaveBeenCalledWith(assessmentLessonId, updateData);
      expect(result).toEqual(updatedLesson);
    });

    it('should throw error if lessonId is missing', async () => {
      await expect(
        onboardingService.updateOnboardingAssessmentLesson('', {
          summary: 'test',
        })
      ).rejects.toThrow('Lesson ID is required');
      expect(
        mockOnboardingRepository.updateOnboardingAssessmentLesson
      ).not.toHaveBeenCalled();
    });
  });

  describe('processAssessmentLessonRecording', () => {
    const mockAudioData = 'audio data';
    const mockBlob = new Blob([mockAudioData], { type: 'audio/webm' });

    (mockBlob as any).arrayBuffer = jest.fn().mockResolvedValue(
      new TextEncoder().encode(mockAudioData).buffer // Simulate returning an ArrayBuffer
    );
    const recordingTime = 10;
    const recordingSize = 1024;
    const fileUri = 'mock/path/to/recording.webm';
    const mockAiResponse = {
      /* structure based on convertAiResponseToAudioMetrics input */
      pronunciationScore: 80,
      fluencyScore: 70,
      grammarScore: 75,
      vocabularyScore: 85,
      overallPerformance: 78,
      proficiencyLevel: 'B1',
      learningTrajectory: 'steady',
      pronunciationAssessment: {
        overall_score: 80,
        native_language_influence: {},
        phoneme_analysis: [],
        problematic_sounds: [],
        strengths: [],
        areas_for_improvement: [],
      },
      fluencyAssessment: {
        overall_score: 70,
        speech_rate: {},
        hesitation_patterns: {},
        rhythm_and_intonation: {},
      },
      grammarAssessment: {
        overall_score: 75,
        error_patterns: [],
        grammar_rules_to_review: [],
        grammar_strengths: [],
      },
      vocabularyAssessment: {
        overall_score: 85,
        range: 'good',
        appropriateness: 0,
        precision: 0,
        areas_for_expansion: [],
      },
      exerciseCompletion: {
        overall_score: 0,
        exercises_analyzed: [],
        comprehension_level: 'good',
      },
      suggestedTopics: [],
      grammarFocusAreas: [],
      vocabularyDomains: [],
      nextSkillTargets: [],
      preferredPatterns: [],
      effectiveApproaches: [],
    };
    const mockConvertedAudioMetrics: AudioMetrics = {
      /* structure matching AudioMetrics */
      id: expect.any(String), // crypto.randomUUID()
      pronunciationScore: 80,
      fluencyScore: 70,
      grammarScore: 75,
      vocabularyScore: 85,
      overallPerformance: 78,
      proficiencyLevel: 'B1',
      learningTrajectory: 'steady',
      // ... other fields populated from mockAiResponse or defaults
      pronunciationAssessment: expect.any(Object),
      fluencyAssessment: expect.any(Object),
      grammarAssessment: expect.any(Object),
      vocabularyAssessment: expect.any(Object),
      exerciseCompletion: expect.any(Object),
      suggestedTopics: [],
      grammarFocusAreas: [],
      vocabularyDomains: [],
      nextSkillTargets: [],
      preferredPatterns: [],
      effectiveApproaches: [],
      createdAt: expect.any(Date),
      updatedAt: expect.any(Date),
    };

    it('should process recording, get AI analysis, convert, and update lesson', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockRecordingService.prototype.uploadFile.mockResolvedValue(fileUri);
      MockRecordingService.prototype.submitLessonRecordingSession.mockResolvedValue(
        mockAiResponse
      );
      // The conversion happens internally, assume it works for this test focus
      mockOnboardingRepository.updateOnboardingAssessmentLesson.mockResolvedValue(
        {
          ...mockAssessmentLesson,
          audioMetrics: mockConvertedAudioMetrics, // Simulate the update result
        }
      );

      const result = await onboardingService.processAssessmentLessonRecording(
        mockBlob,
        mockAssessmentLesson,
        recordingTime,
        recordingSize
      );

      expect(mockOnboardingRepository.getOnboarding).toHaveBeenCalledTimes(1);
      expect(MockRecordingService.prototype.uploadFile).toHaveBeenCalledWith(
        expect.any(Buffer), // Buffer.from(await mockBlob.arrayBuffer())
        'audio/webm',
        expect.stringContaining(`lesson-${assessmentLessonId}-`) // Filename pattern
      );
      expect(
        MockRecordingService.prototype.submitLessonRecordingSession
      ).toHaveBeenCalledWith(
        fileUri,
        recordingTime,
        recordingSize,
        {
          targetLanguage: mockOnboarding.targetLanguage,
          nativeLanguage: mockOnboarding.nativeLanguage,
        },
        mockAssessmentLesson
      );
      expect(
        mockOnboardingRepository.updateOnboardingAssessmentLesson
      ).toHaveBeenCalledWith(
        assessmentLessonId,
        { audioMetrics: expect.objectContaining({ pronunciationScore: 80 }) } // Check if conversion result is passed
      );
      expect(result.audioMetrics).toBeDefined();
      expect(result.audioMetrics?.pronunciationScore).toBe(80);
    });

    it('should throw error if onboarding data not found', async () => {
      mockOnboardingRepository.getOnboarding.mockResolvedValue(null);
      await expect(
        onboardingService.processAssessmentLessonRecording(
          mockBlob,
          mockAssessmentLesson,
          recordingTime,
          recordingSize
        )
      ).rejects.toThrow('User onboarding data not found');
    });

    it('should handle error during file upload', async () => {
      const uploadError = new Error('S3 Upload Failed');
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockRecordingService.prototype.uploadFile.mockRejectedValue(uploadError);

      await expect(
        onboardingService.processAssessmentLessonRecording(
          mockBlob,
          mockAssessmentLesson,
          recordingTime,
          recordingSize
        )
      ).rejects.toThrow('S3 Upload Failed'); // Or whatever error uploadFile throws
      expect(
        MockRecordingService.prototype.submitLessonRecordingSession
      ).not.toHaveBeenCalled();
      expect(
        mockOnboardingRepository.updateOnboardingAssessmentLesson
      ).not.toHaveBeenCalled();
    });

    it('should handle error during AI submission', async () => {
      const aiError = new Error('AI Service Unavailable');
      mockOnboardingRepository.getOnboarding.mockResolvedValue(mockOnboarding);
      MockRecordingService.prototype.uploadFile.mockResolvedValue(fileUri);
      MockRecordingService.prototype.submitLessonRecordingSession.mockRejectedValue(
        aiError
      );

      await expect(
        onboardingService.processAssessmentLessonRecording(
          mockBlob,
          mockAssessmentLesson,
          recordingTime,
          recordingSize
        )
      ).rejects.toThrow('AI Service Unavailable');
      expect(
        mockOnboardingRepository.updateOnboardingAssessmentLesson
      ).not.toHaveBeenCalled();
    });
  });
});
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*
!.env.example

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts
# Google Cloud Credentials
config/google-credentials.json

project_snapshot.txt
</file>

<file path="docker-compose.proxy.prod.yml">
version: '3.3'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.proxy
      args:
        - HTTP_PROXY=http://172.16.2.254:3128
        - HTTPS_PROXY=http://172.16.2.254:3128
    ports:
      - '3000:3000'
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql://postgres.tdzryocudlllmufiiaki:KentHD720pgans2vlad@aws-0-us-west-1.pooler.supabase.com:5432/postgres
      - HTTP_PROXY=http://172.16.2.254:3128
      - HTTPS_PROXY=http://172.16.2.254:3128
      - NO_PROXY=localhost,127.0.0.1,.docker.internal
      - NODE_TLS_REJECT_UNAUTHORIZED=0
      - CHOKIDAR_INTERVAL=300
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
    # depends_on:
    #   - db
    volumes:
      - ./src:/app/src # Mount src directory for hot reload
      - ./public:/app/public # Mount public directory for hot reload
      - ./package.json:/app/package.json # Mount package.json
      - ./package-lock.json:/app/package-lock.json # Mount package-lock.json
      - ./tailwind.config.ts:/app/tailwind.config.ts # Mount tailwind.config.ts
      - ./src/app/globals.css:/app/src/app/globals.css # Mount globals.css
      - ./tsconfig.json:/app/tsconfig.json # Mount tsconfig.json
      - ./prisma:/app/prisma # Mount prisma
      # - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    restart: unless-stopped
    networks:
      - web-network
    command: sh -c "npm rebuild && npm run dev"

  # db:
  #   image: postgres:17
  #   environment:
  #     POSTGRES_USER: myuser
  #     POSTGRES_PASSWORD: mypassword
  #     POSTGRES_DB: mydb
  #   ports:
  #     - '5433:5432'
  #   volumes:
  #     - postgres-data:/var/lib/postgresql/data
  #   networks:
  #     - web-network

networks:
  web-network:
    driver: bridge

# volumes:
#   postgres-data:
</file>

<file path="docker-compose.proxy.yml">
version: '3.3'

services:
  web:
    build:
      context: .
      dockerfile: Dockerfile.proxy
      args:
        - HTTP_PROXY=http://172.16.2.254:3128
        - HTTPS_PROXY=http://172.16.2.254:3128
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - HTTP_PROXY=http://172.16.2.254:3128
      - HTTPS_PROXY=http://172.16.2.254:3128
      - DATABASE_URL=postgresql://myuser:mypassword@db:5432/mydb
      - CHOKIDAR_INTERVAL=300
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - FAST_REFRESH=false
    depends_on:
      - db
    volumes:
      - ./src:/app/src  # Mount src directory for hot reload
      - ./public:/app/public  # Mount public directory for hot reload
      - ./package.json:/app/package.json  # Mount package.json
      - ./package-lock.json:/app/package-lock.json  # Mount package-lock.json
      - ./tailwind.config.ts:/app/tailwind.config.ts  # Mount tailwind.config.ts
      - ./src/app/globals.css:/app/src/app/globals.css  # Mount globals.css
      - ./tsconfig.json:/app/tsconfig.json  # Mount tsconfig.json
      - ./prisma:/app/prisma  # Mount prisma
      - ./node_modules:/app/node_modules
      - ./.env:/app/.env
    networks:
      - web-network

  db:
    image: postgres:17
    environment:
      POSTGRES_USER: myuser
      POSTGRES_PASSWORD: mypassword
      POSTGRES_DB: mydb
    ports:
      - "5433:5432" 
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - web-network


networks:
  web-network:
    driver: bridge

volumes:
  postgres-data:
</file>

<file path="Dockerfile.mac">
# Dockerfile.mac
FROM node:20.11-alpine3.19

# 1) Install psql (PostgreSQL client)
RUN apk add --no-cache postgresql-client

# 2) Set workdir and install app deps
WORKDIR /app
COPY package*.json ./
RUN npm install

# 3) Copy the rest of your code and generate Prisma client
COPY . .
RUN npx prisma generate

EXPOSE 3000
CMD ["npm", "run", "dev"]
</file>

<file path="jest.config.mjs">
export default {
  preset: 'ts-jest',
  testEnvironment: 'jest-environment-jsdom',
  // Make sure Jest transforms .mjs as well by adding it to the regex
  transform: {
    '^.+\\.(js|jsx|ts|tsx|mjs)$': [
      'babel-jest',
      { configFile: './babel.test.babelrc' }
    ]
  },
  setupFilesAfterEnv: ['<rootDir>/jest.setup.mjs'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/$1'
  },
  // Updated transformIgnorePatterns to include "node-fetch" in the exception
  transformIgnorePatterns: [
    '/node_modules/(?!(posthog-js|node-fetch|data-uri-to-buffer|fetch-blob|formdata-polyfill|lucide-react)/)'
  ],
  // This tells Jest to treat these extensions as ESM files
  globals: {
    'ts-jest': {
      useESM: true
    }
  }
};
</file>

<file path="next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  serverActions: {
    bodySizeLimit: '5mb', // Increase the limit (e.g., to 5MB or adjust as needed)
  },
  env: {
    // Properly configure base URL for all environments
    NEXT_PUBLIC_BASE_URL: process.env.VERCEL_URL
      ? `https://${process.env.VERCEL_URL}`
      : process.env.NEXT_PUBLIC_BASE_URL || 'https://lessay-app.vercel.app',
  },
  experimental: {
    // Performance optimizations
    turbo: {
      rules: {
        "*.png": ["file-loader"],
        "*.jpg": ["file-loader"],
        "*.svg": ["file-loader"],
      },
      resolveAlias: {
        // Add module aliases for better tree-shaking
        '@': './src',
      },
    },
    // Enable optimizations
    optimizePackageImports: ['@/components'],
    // Enable next-sitemap integration
    nextScriptWorkers: true,
  },
 
  reactStrictMode: true,
  compress: true,        // Enable compression
  poweredByHeader: false, // Remove X-Powered-By header
  generateEtags: true,   // Generate ETags for caching
  productionBrowserSourceMaps: false, // Disable source maps in production
  
  // Cache and performance
  onDemandEntries: {
    maxInactiveAge: 60 * 60 * 1000, // 1 hour
    pagesBufferLength: 5,
  },
  
  // Asset optimization
  images: {
    domains: [
      new URL(process.env.NEXT_PUBLIC_BASE_URL || 'https://lessay-app.vercel.app').hostname
    ],
    deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
    imageSizes: [16, 32, 48, 64, 96, 128, 256, 384],
    minimumCacheTTL: 60,
  },
  
  // Output optimization
  output: 'standalone',
};

export default nextConfig;
</file>

<file path="package.json">
{
  "name": "lessay-subscribe",
  "version": "0.2.0",
  "private": true,
  "type": "module",
  "scripts": {
    "dev": "next dev",
    "build": "prisma generate && next build",
    "postbuild": "next-sitemap --config sitemap-config.mjs",
    "start": "WATCHPACK_POLLING=true next start",
    "lint": "next lint",
    "test": "npx jest",
    "docker:mac:run": "docker-compose -f docker-compose.mac.yml up",
    "docker:mac:build": "docker-compose -f docker-compose.mac.yml build",
    "docker:proxy:run": "docker compose -f docker-compose.proxy.yml up",
    "docker:proxy:build": "docker compose -f docker-compose.proxy.yml build",
    "db:seed": "TS_NODE_PROJECT=tsconfig-seed.json node --loader ts-node/esm --require tsconfig-paths/register prisma/seed.ts",
    "prisma:migrate": "npx prisma migrate dev",
    "prisma:reset": "npx prisma migrate reset",
    "tunnel": "ngrok http 3000"
  },
  "dependencies": {
    "@aws-sdk/client-polly": "^3.750.0",
    "@aws-sdk/node-http-handler": "^3.374.0",
    "@google-cloud/speech": "^7.0.1",
    "@prisma/client": "^6.5.0",
    "@radix-ui/react-slot": "^1.2.0",
    "@stripe/react-stripe-js": "^3.6.0",
    "@stripe/stripe-js": "^7.0.0",
    "@supabase/ssr": "^0.6.1",
    "@supabase/supabase-js": "^2.48.1",
    "@types/formidable": "^3.4.5",
    "@vercel/analytics": "^1.5.0",
    "@vercel/blob": "^0.27.3",
    "@vercel/speed-insights": "^1.1.0",
    "axios": "^1.7.9",
    "class-variance-authority": "^0.7.1",
    "formidable": "^3.5.2",
    "google-auth-library": "^9.15.1",
    "https-proxy-agent": "^5.0.1",
    "lucide-react": "^0.475.0",
    "micro": "^10.0.1",
    "next": "15.1.6",
    "posthog-js": "^1.223.4",
    "proxy-agent": "^6.5.0",
    "radix-ui": "^1.2.0",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-hot-toast": "^2.5.1",
    "stripe": "^18.0.0",
    "supabase": "^2.20.12",
    "tailwind-merge": "^3.2.0"
  },
  "devDependencies": {
    "@babel/core": "^7.24.5",
    "@babel/preset-env": "^7.24.5",
    "@babel/preset-react": "^7.24.1",
    "@babel/preset-typescript": "^7.24.1",
    "@builder.io/partytown": "^0.10.3",
    "@eslint/eslintrc": "^3",
    "@testing-library/jest-dom": "^6.6.3",
    "@testing-library/react": "^16.3.0",
    "@testing-library/user-event": "^14.6.1",
    "@types/jest": "^29.5.14",
    "@types/node": "^20",
    "@types/react": "^19.0.10",
    "@types/react-dom": "^19",
    "babel-jest": "^29.7.0",
    "babel-plugin-module-resolver": "^5.0.2",
    "eslint": "^9",
    "eslint-config-next": "15.1.6",
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^29.7.0",
    "jest-mock-extended": "^4.0.0-beta1",
    "next-sitemap": "^4.2.3",
    "node-fetch": "^3.3.2",
    "postcss": "^8",
    "prisma": "^6.5.0",
    "tailwindcss": "^3.4.1",
    "ts-jest": "^29.2.6",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.8.2"
  },
  "prisma": {
    "seed": "TS_NODE_PROJECT=tsconfig-seed.json node --loader ts-node/esm --require tsconfig-paths/register prisma/seed.ts"
  }
}
</file>

<file path="prisma/schema.prisma">
// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

// Looking for ways to speed up your queries, or scale easily with your serverless or edge functions?
// Try Prisma Accelerate: https://pris.ly/cli/accelerate-init

generator client {
  provider      = "prisma-client-js"
  binaryTargets = ["native", "linux-musl-openssl-3.0.x"]
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Onboarding {
  id                      String   @id @default(cuid())
  userId                  String   @unique
  user                    User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  steps                   Json
  completed               Boolean  @default(false)
  learningPurpose         String?
  nativeLanguage          String?
  targetLanguage          String?
  proficiencyLevel        ProficiencyLevel?
  initialAssessmentCompleted Boolean @default(false)
  createdAt               DateTime @default(now())
  updatedAt               DateTime @updatedAt

  @@map("onboarding")
}

model User {
  id        String   @id @default(cuid())
  email     String   @unique
  name      String?
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt
  onboarding Onboarding?
  assessmentLessons AssessmentLesson[]
  lessons Lesson[]
  payments          Payment[]
  learningProgress  LearningProgress? 
  subscriptionStatus SubscriptionStatus @default(NONE)
  subscriptionId    String?            @unique
  subscriptionEndDate DateTime?
  subscriptionPlan  String?
  trialStartDate    DateTime?
  trialEndDate      DateTime?
  subscriptionStartDate DateTime?
  billingCycle      String?
  paymentMethodId   String?
  stripeCustomerId  String?            @unique
  cancelAtPeriodEnd Boolean            @default(false)
}

enum ProficiencyLevel {
  beginner
  intermediate
  advanced
}

enum LessonGenerationStatus {
  pending
  completed
  failed
}

enum AssessmentStepType {
  question        // Assessment question
  feedback        // Feedback on user's answer
  instruction     // Instructions for the assessment
  summary         // Assessment summary/results
}
enum LessonStepType {
  prompt
  feedback // messages like 'great job'
  new_word
  practice
  instruction 
  summary    
}

enum MasteryLevel {
  NotStarted
  Seen         // Introduced but not practiced much
  Learning     // Actively being practiced
  Practiced    // Practiced multiple times, showing some retention
  Known        // Generally recalled correctly
  Mastered     // Consistently recalled correctly over time
}



model AssessmentLesson {
  id                String   @id @default(cuid())
  userId            String   @unique // Only one assessment per user
  user              User     @relation(fields: [userId], references: [id], onDelete: Cascade)
  description       String?  // Brief description if needed
  completed         Boolean  @default(false)
  sourceLanguage    String   // User's native language
  targetLanguage    String   // User's target language
  // Assessment metrics
  metrics           Json?    // Store assessment metrics like accuracy, pronunciation scores, etc.
  proposedTopics    String[] // Topics suggested based on assessment performance
  summary           String?  // Overall assessment summary
  createdAt         DateTime @default(now())
  updatedAt         DateTime @updatedAt
  steps             AssessmentStep[]
  audioMetrics      AudioMetrics?
  sessionRecordingUrl String?
  @@map("assessment_lessons")
}

model AssessmentStep {
  id                String           @id @default(cuid())
  assessmentId      String
  assessment        AssessmentLesson @relation(fields: [assessmentId], references: [id], onDelete: Cascade)
  stepNumber        Int
  type              AssessmentStepType
  content           String
  contentAudioUrl   String?
  translation       String?
  expectedAnswer    String?
  expectedAnswerAudioUrl String?
  maxAttempts       Int              @default(3)  // Maximum attempts before showing correct answer
  userResponse      String?
  userResponseHistory Json?
  attempts          Int              @default(0)
  correct           Boolean          @default(false)
  lastAttemptAt     DateTime?
  feedback          String?          // Feedback specific to this step
  createdAt         DateTime         @default(now())
  updatedAt         DateTime         @updatedAt

  @@map("assessment_steps")
}

model Lesson {
  id                  String    @id @default(cuid())
  userId              String
  user                User      @relation(fields: [userId], references: [id], onDelete: Cascade)
  lessonId            String
  focusArea           String
  targetSkills        String[]
  performanceMetrics  Json?
  completed           Boolean   @default(false)
  createdAt           DateTime  @default(now())
  updatedAt           DateTime  @updatedAt
  steps               LessonStep[]
  audioMetrics        AudioMetrics?
  sessionRecordingUrl String?

  @@map("lessons")
}


model LessonStep {
  id              String   @id @default(cuid())
  lessonId        String
  lesson          Lesson   @relation(fields: [lessonId], references: [id])
  stepNumber      Int
  type            LessonStepType
  content         String
  contentAudioUrl String?
  translation     String?
  expectedAnswer  String?
  expectedAnswerAudioUrl String?
  userResponse    String?
  userResponseHistory Json?
  attempts        Int      @default(0)
  maxAttempts     Int      @default(3)  // Maximum attempts before showing correct answer
  correct         Boolean  @default(false)
  lastAttemptAt   DateTime?
  errorPatterns   String[]
  createdAt       DateTime @default(now())
  updatedAt       DateTime @updatedAt

  @@map("lesson_steps")
}

enum LearningTrajectory {
  steady
  accelerating
  plateauing
}

enum LanguageInfluenceLevel {
  minimal
  moderate
  strong
}

enum SpeechRateEvaluation {
  slow
  appropriate
  fast
}

enum HesitationFrequency {
  rare
  occasional
  frequent
}

enum PriorityLevel {
  low
  medium
  high
}

enum SeverityLevel {
  minor
  moderate
  major
}

enum VocabularyRange {
  limited
  adequate
  extensive
}

enum ComprehensionLevel {
  poor
  fair
  good
  excellent
}

model AudioMetrics {
  id                    String   @id @default(cuid())
  // Relationships
  lessonId              String?  @unique
  lesson                Lesson?  @relation(fields: [lessonId], references: [id])
  assessmentLessonId    String?  @unique
  assessmentLesson      AssessmentLesson? @relation(fields: [assessmentLessonId], references: [id])
  
  // Top-level metrics for easy querying
  pronunciationScore    Float
  fluencyScore          Float
  grammarScore          Float
  vocabularyScore       Float
  overallPerformance    Float
  
  // CEFR level and trajectory
  proficiencyLevel      String    // CEFR level: A1-C2 (keeping as String for flexibility)
  learningTrajectory    LearningTrajectory
  
  // Detailed analysis sections as JSON
  pronunciationAssessment Json    // Full pronunciation analysis
  fluencyAssessment      Json    // Full fluency analysis
  grammarAssessment      Json    // Full grammar analysis
  vocabularyAssessment   Json    // Full vocabulary analysis
  exerciseCompletion     Json    // Exercise-specific analysis
  
  // Learning recommendations
  suggestedTopics       String[]
  grammarFocusAreas     String[]
  vocabularyDomains     String[]
  nextSkillTargets      String[]
  
  // Learning style observations
  preferredPatterns     String[]
  effectiveApproaches   String[]
  
  // Metadata
  audioRecordingUrl     String?  // Optional URL to the audio file
  recordingDuration     Float?   // Optional duration in seconds
  createdAt             DateTime @default(now())
  updatedAt             DateTime @updatedAt

  @@map("audio_metrics")
}


model LearningProgress {
  id                        String           @id @default(cuid())
  userId                    String           @unique
  user                      User             @relation(fields: [userId], references: [id], onDelete: Cascade)
  estimatedProficiencyLevel ProficiencyLevel @default(beginner) // Overall estimated level
  overallScore              Float?           // Calculated score (e.g., 0-100) based on recent performance
  learningTrajectory        LearningTrajectory @default(steady) // How is the user progressing?
  strengths                 String[]         // Areas where the user excels (e.g., "Verb Conjugation", "Travel Vocabulary")
  weaknesses                String[]         // Areas needing improvement (e.g., "Pronunciation of 'ü'", "Dative Case")
  lastLessonCompletedAt     DateTime?
  lastAssessmentCompletedAt DateTime?
  createdAt                 DateTime         @default(now())
  updatedAt                 DateTime         @updatedAt

  topics                    TopicProgress[]  // Relation to topics studied
  words                     WordProgress[]   // Relation to words encountered

  @@map("learning_progress")
}

model TopicProgress {
  id                 String         @id @default(cuid())
  learningProgressId String
  learningProgress   LearningProgress @relation(fields: [learningProgressId], references: [id], onDelete: Cascade)
  topicName          String         // e.g., "Greetings", "Ordering Food", "Past Tense"
  masteryLevel       MasteryLevel   @default(NotStarted)
  lastStudiedAt      DateTime?
  relatedLessonIds   String[]       // IDs of lessons covering this topic
  relatedAssessmentIds String[]     // IDs of assessments covering this topic
  score              Float?         // Optional score specific to this topic based on related lessons/steps

  createdAt          DateTime       @default(now())
  updatedAt          DateTime       @updatedAt

  @@unique([learningProgressId, topicName]) // Ensure unique topic per user progress
  @@map("topic_progress")
}

model WordProgress {
  id                  String         @id @default(cuid())
  learningProgressId  String
  learningProgress    LearningProgress @relation(fields: [learningProgressId], references: [id], onDelete: Cascade)
  word                String         // The word or phrase in the target language
  translation         String?        // Translation in the user's native language
  masteryLevel        MasteryLevel   @default(Seen)
  timesCorrect        Int            @default(0)
  timesIncorrect      Int            @default(0)
  firstSeenAt         DateTime       @default(now())
  lastReviewedAt      DateTime?
  relatedLessonStepIds String[]       // IDs of lesson steps where this word appeared
  relatedAssessmentStepIds String[] // IDs of assessment steps where this word appeared

  // Optional fields for Spaced Repetition System (SRS) - future enhancement
  // nextReviewDate    DateTime?
  // interval          Int?           // Interval in days
  // easeFactor        Float?         // Factor influencing next interval

  createdAt           DateTime       @default(now())
  updatedAt           DateTime       @updatedAt

  @@unique([learningProgressId, word]) // Ensure unique word per user progress
  @@index([learningProgressId, masteryLevel]) // Index for querying words by mastery
  @@map("word_progress")
}


model Payment {
  id                    String    @id @default(cuid())
  userId                String
  user                  User      @relation(fields: [userId], references: [id], onDelete: Cascade)

  stripePaymentIntentId String?    @unique // Changed to optional
  status                PaymentStatus @default(PENDING)
  amount                Int       // Amount in smallest currency unit (e.g., cents for USD)
  currency              String    // e.g., "usd"

  // Link to what was purchased (adapt as needed)
  productId             String?   // e.g., a specific course ID, subscription plan ID
  productType           String?   // e.g., "course", "subscription", "credits"

  errorMessage          String?   // Store error message if payment failed
  metadata              Json?     // Store any additional metadata if needed

  subscriptionPlan      String?
  isRecurring           Boolean? @default(false)
  relatedSubscriptionId String?

  createdAt             DateTime  @default(now())
  updatedAt             DateTime  @updatedAt

  @@index([userId])
  @@map("payments")
}

enum PaymentStatus {
  PENDING    // Initial status when intent is created
  PROCESSING // Payment is being processed (optional intermediate state)
  SUCCEEDED  // Payment successful
  FAILED     // Payment failed
  REQUIRES_ACTION // Needs further user action (e.g., 3D Secure)
  CANCELED   // Payment was canceled
}


enum SubscriptionStatus {
  NONE
  TRIAL
  ACTIVE
  CANCELED
  PAST_DUE
  EXPIRED
}
</file>

<file path="src/components/onboarding/LanguageSelectionStep.tsx">
import React from 'react'

interface LanguageSelectionStepProps {
  onNext: (data: { nativeLanguage: string; targetLanguage: string }) => void
  formData: {
    nativeLanguage: string
    targetLanguage: string
    learningPurpose: string
    proficiencyLevel: string
  }
  loading: boolean
}

export default function LanguageSelectionStep({ 
  onNext, 
  formData, 
  loading 
}: LanguageSelectionStepProps) {
  const [nativeLanguage, setNativeLanguage] = React.useState(formData.nativeLanguage || '')
  const [targetLanguage, setTargetLanguage] = React.useState(formData.targetLanguage || '')

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault()
    onNext({ nativeLanguage, targetLanguage })
  }

  const languages = [
    'English', 'Spanish', 'French', 'German', 'Italian', 
    'Portuguese', 'Russian', 'Chinese', 'Japanese', 'Korean', 'Polish'
  ]

  return (
    <div className="animate-fade-in px-4">
      <h2 className="text-3xl font-semibold text-foreground">
        Select Your Languages
      </h2>
      <form className="mt-6 space-y-6" onSubmit={handleSubmit}>
        <div className="space-y-2">
          <label htmlFor="nativeLanguage" className="block text-sm font-medium text-neutral-9">
            Your Native Language
          </label>
          <div className="relative">
            <select
              id="nativeLanguage"
              required
              className="block w-full rounded-md border border-neutral-5 bg-neutral-1 px-3 py-2.5 text-foreground shadow-sm
                        focus:border-accent-6 focus:ring-2 focus:ring-accent-6 focus:outline-none
                        disabled:bg-neutral-3 disabled:text-neutral-6 disabled:cursor-not-allowed"
              value={nativeLanguage}
              onChange={(e) => setNativeLanguage(e.target.value)}
              disabled={loading}
            >
              <option value="">Select your native language</option>
              {languages.map(lang => (
                <option key={lang} value={lang}>{lang}</option>
              ))}
            </select>
         
          </div>
        </div>
        
        <div className="space-y-2">
          <label htmlFor="targetLanguage" className="block text-sm font-medium text-neutral-9">
            Language You Want to Learn
          </label>
          <div className="relative">
            <select
              id="targetLanguage"
              required
              className="block w-full rounded-md border border-neutral-5 bg-neutral-1 px-3 py-2.5 text-foreground shadow-sm
                        focus:border-accent-6 focus:ring-2 focus:ring-accent-6 focus:outline-none
                        disabled:bg-neutral-3 disabled:text-neutral-6 disabled:cursor-not-allowed"
              value={targetLanguage}
              onChange={(e) => setTargetLanguage(e.target.value)}
              disabled={loading}
            >
              <option value="">Select a language to learn</option>
              {languages.map(lang => (
                <option key={lang} value={lang}>{lang}</option>
              ))}
            </select>
          </div>
        </div>
        
        <div className="pt-2">
          <button
            type="submit"
            disabled={loading || !nativeLanguage || !targetLanguage}
            className="w-full py-2.5 px-4 bg-primary hover:bg-accent-7 text-neutral-1 rounded-md transition-colors 
                     focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                     font-medium text-sm flex items-center justify-center"
          >
            {loading ? (
              <span className="flex items-center">
                <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                  <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                  <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                Saving...
              </span>
            ) : 'Continue'}
          </button>
        </div>
      </form>
    </div>
  )
}
</file>

<file path="src/lib/server-actions/payment-actions.ts">
// // src/actions/payment.actions.ts

// 'use server'; // Mark this file as containing Server Actions

// import { PaymentService } from '@/services/payment.service';
// import logger from '@/utils/logger';
// import { createSupabaseServerClient } from '@/utils/supabase/server';

// import { PaymentRepository } from '@/repositories/payment.repository';


// export interface SubscriptionProductDetails {
//   id: string; // Your internal product ID (e.g., 'premium_monthly', 'premium_yearly')
//   stripePriceId: string; // The ID of the Price object in Stripe (e.g., price_123...)
//   type: 'subscription';
//   name: string; // e.g., "Premium Monthly Plan"
// }


// // Helper to get current user ID securely within the action
// async function getCurrentUserId(): Promise<string> {
//   const supabase = await createSupabaseServerClient();
//   const { data: { session }, error } = await supabase.auth.getSession();
//   if (error) {
//     logger.error('Get session error:', error);
//     throw new Error('Failed to get session.');
//   }
//   if (!session?.user?.id) {
//     throw new Error('Authentication required.');
//   }
//   return session.user.id;
// }


// function createPaymentService(): PaymentService {
//   const paymentRepository = new PaymentRepository(); // Instantiate repository
//   return new PaymentService(paymentRepository); // Pass repository to service
// }





// /**
//  * Server Action to create a Stripe Checkout Session for subscriptions.
//  * @param product - Details of the subscription product including Stripe Price ID.
//  * @returns An object containing the sessionId or an error message.
//  */
// export async function createCheckoutSessionAction(
//   product: SubscriptionProductDetails
// ): Promise<{ sessionId: string | null; error: string | null }> {
//   try {
//     // 1. Authenticate the user
//     const userId = await getCurrentUserId();
//     logger.info(`createCheckoutSessionAction: Initiated by user ${userId} for price ${product.stripePriceId}`);

//     // 2. Validate input
//     if (!product || !product.id || !product.stripePriceId || product.type !== 'subscription') {
//       throw new Error('Invalid or missing subscription product details.');
//     }

//     // 3. Instantiate the Payment Service
//     const paymentService = createPaymentService();

//     // 4. Call the service method to create the checkout session
//     const sessionId = await paymentService.createCheckoutSession(userId, product);

//     logger.info(`createCheckoutSessionAction: Successfully created session ${sessionId} for user ${userId}`);
//     return { sessionId: sessionId, error: null };

//   } catch (error: any) {
//     logger.error('Error in createCheckoutSessionAction:', {
//       errorMessage: error.message,
//       product: product,
//       userId: 'hidden', // Avoid logging userId directly in error if possible
//     });

//     let userErrorMessage = 'Failed to start subscription process. Please try again.';
//     if (error.message.includes('Authentication required')) {
//       userErrorMessage = 'Authentication required. Please log in.';
//     } else if (error.message.includes('User not found')) {
//       userErrorMessage = 'User account not found.';
//     } else if (error.message.includes('Invalid product type')) {
//       userErrorMessage = 'Invalid product selected for subscription.';
//     }

//     return { sessionId: null, error: userErrorMessage };
//   }
// }
</file>

<file path="src/lib/server-actions/user-actions.ts">
'use server';

import { withServerErrorHandling, Result } from './_withErrorHandling'
import UserService from '@/services/user.service';
import { UserRepository } from '@/repositories/user.repository';
import { UserProfileModel } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { revalidatePath } from 'next/cache';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import { Prisma } from '@prisma/client';

function createUserService() {
  const repository = new UserRepository();
  return new UserService(repository);
}

async function getCurrentUserId(): Promise<string> {
  const supabase = await createSupabaseServerClient();
  const { data: { session }, error } = await supabase.auth.getSession();
  if (error || !session?.user?.id) {
    throw new Error('Authentication required.');
  }
  return session.user.id;
}

// GET PROFILE
export async function getUserProfileAction(userId: string): Promise<Result<UserProfileModel | null>> {
  return withServerErrorHandling(async () => {
    const currentUserId = await getCurrentUserId();
    if (userId !== currentUserId) throw new Error('Unauthorized');
    const svc = createUserService();
    return await svc.getUserProfile(userId);
  })
}

// CREATE PROFILE
export async function createUserProfileAction(profile: Partial<UserProfileModel>): Promise<Result<UserProfileModel>> {
  return withServerErrorHandling(async () => {
    const svc = createUserService();
    try {
      return await svc.createUserProfile(profile as any);
    } catch (error: any) {
      // On unique‐constraint error, return existing
      if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === 'P2002') {
        logger.warn('Duplicate email, fetching existing profile');
        return (await getUserProfileAction(profile.userId!)).data!
      }
      throw error;
    }
  })
}

// UPDATE PROFILE
export async function updateUserProfileAction(userId: string, profile: Partial<UserProfileModel>): Promise<Result<UserProfileModel>> {
  return withServerErrorHandling(async () => {
    const currentUserId = await getCurrentUserId();
    if (userId !== currentUserId) throw new Error('Unauthorized');
    const svc = createUserService();
    return await svc.updateUserProfile(userId, profile);
  })
}

// DELETE PROFILE
export async function deleteUserProfileAction(): Promise<Result<null>> {
  return withServerErrorHandling(async () => {
    const userId = await getCurrentUserId();
    const svc = createUserService();
    await svc.deleteUserProfile(userId);
    // revalidate pages if you like
    revalidatePath('/');
    revalidatePath('/app');
    return null;
  })
}
</file>

<file path="src/models/AppAllModels.model.ts">
import { ProficiencyLevel, LearningTrajectory, LanguageInfluenceLevel, SpeechRateEvaluation, HesitationFrequency, PriorityLevel, SeverityLevel, VocabularyRange, ComprehensionLevel, MasteryLevel, SubscriptionStatus } from '@prisma/client'
import type { JsonValue } from '@prisma/client/runtime/library'
import { PaymentStatus } from '@prisma/client'; // Make sure PaymentStatus is imported

export interface OnboardingModel {
  id: string;
  userId: string;
  steps: JsonValue;
  completed: boolean;
  learningPurpose?: string | null;
  nativeLanguage?: string | null;
  targetLanguage?: string | null;
  proficiencyLevel?: ProficiencyLevel | null;
  initialAssessmentCompleted?: boolean;
  createdAt: Date;
  updatedAt: Date;
}

export interface AssessmentLesson {
  id: string;
  userId: string;
  description?: string | null;
  completed: boolean;
  sourceLanguage: string;
  targetLanguage: string;
  metrics?: JsonValue | null | {
    accuracy?: number;
    pronunciationScore?: number;
    grammarScore?: number;
    vocabularyScore?: number;
    overallScore?: number;
    strengths?: string[];
    weaknesses?: string[];
  };
  audioMetrics?: AudioMetrics | null;
  sessionRecordingUrl?: string | null;
  proposedTopics: string[];
  summary?: string | null;
  createdAt: Date;
  updatedAt: Date;
  steps: AssessmentStep[];
}

export interface AssessmentStep {
  id: string;
  assessmentId: string;
  stepNumber: number;
  type: 'question' | 'feedback' | 'instruction' | 'summary';
  content: string;
  contentAudioUrl?: string | null;
  translation?: string | null;
  expectedAnswer?: string | null;
  expectedAnswerAudioUrl?: string | null;
  maxAttempts: number;
  userResponse?: string | null;
  userResponseHistory?: JsonValue | null;
  attempts: number;
  correct: boolean;
  lastAttemptAt?: Date | null;
  feedback?: string | null;
  createdAt: Date;
  updatedAt: Date;
}

export interface GeneratedLesson {
  id: string;
  userId: string;
  lessonId: string;
  focusArea: string;
  targetSkills: string[];
  steps: LessonStep[];
  completed: boolean;
  createdAt: Date;
  updatedAt: Date;
}

export interface LessonModel {
  id: string;
  userId: string;
  lessonId: string;
  focusArea: string;
  targetSkills: string[];
  steps: LessonStep[];
  performanceMetrics?: JsonValue | null | {
    accuracy?: number;
    pronunciationScore?: number;
    grammarScore?: number;
    vocabularyScore?: number;
    overallScore?: number;
    strengths?: string[];
    weaknesses?: string[];
    summary?: string;
    nextLessonSuggestions?: string[];
    errorPatterns?: string[];
  };
  audioMetrics?: AudioMetrics | null;
  sessionRecordingUrl?: string | null;
  completed: boolean;
  createdAt: Date;
  updatedAt: Date;
}

export interface LessonStep {
  id: string;
  lessonId: string;
  stepNumber: number;
  type: 'prompt' | 'feedback' | 'new_word' | 'practice' | 'instruction' | 'summary';
  content: string;
  contentAudioUrl?: string | null;
  translation?: string | null;
  expectedAnswer?: string | null;
  expectedAnswerAudioUrl?: string | null;
  userResponse?: string | null;
  userResponseHistory?: JsonValue | null;
  attempts: number;
  maxAttempts: number;
  correct: boolean;
  lastAttemptAt?: Date | null;
  errorPatterns: string[];
  createdAt: Date;
  updatedAt: Date;
}

// Add other models as needed
export interface UserProfileModel {
  id: string;
  userId: string;
  email: string;
  name?: string;
  nativeLanguage?: string;
  targetLanguage?: string;
  proficiencyLevel?: 'beginner' | 'intermediate' | 'advanced';
  learningPurpose?: string;
  onboardingCompleted: boolean;
  createdAt: Date;
  initialAssessmentCompleted: boolean;
  updatedAt: Date;
  learningProgressSummary?: {
    estimatedProficiencyLevel: ProficiencyLevel;
    overallScore?: number | null;
    learningTrajectory: LearningTrajectory;
  }
  subscriptionStatus: SubscriptionStatus;
  subscriptionId?: string | null;
  subscriptionPlan?: string | null;
  trialStartDate?: Date | null;
  trialEndDate?: Date | null;
  subscriptionStartDate?: Date | null;
  subscriptionEndDate?: Date | null;
  billingCycle?: string | null;
  paymentMethodId?: string | null;
  stripeCustomerId?: string | null;
  cancelAtPeriodEnd?: boolean;
}

// Add a type guard for assessment metrics
export function isAssessmentMetrics(obj: JsonValue): obj is {
  accuracy?: number;
  pronunciationScore?: number;
  grammarScore?: number;
  vocabularyScore?: number;
  overallScore?: number;
  strengths?: string[];
  weaknesses?: string[];
} {
  return typeof obj === 'object' && obj !== null && !Array.isArray(obj);
}

// Add a type guard for lesson performance metrics
export function isPerformanceMetrics(obj: JsonValue): obj is {
  accuracy?: number;
  pronunciationScore?: number;
  grammarScore?: number;
  vocabularyScore?: number;
  overallScore?: number;
  strengths?: string[];
  weaknesses?: string[];
  summary?: string;
  nextLessonSuggestions?: string[];
  errorPatterns?: string[];
} {
  return typeof obj === 'object' && obj !== null && !Array.isArray(obj);
}

// Detailed assessment types for the JSON fields
export interface PronunciationAssessment {
  overall_score: number;
  native_language_influence: {
    level: LanguageInfluenceLevel;
    specific_features: string[];
  };
  phoneme_analysis: Array<{
    phoneme: string; // IPA symbol
    target_realization: string; // IPA for standard target language
    user_realization: string; // IPA for user's pronunciation
    accuracy: number; // 0-100
    examples: string[]; // words/phrases from recording
  }>;
  problematic_sounds: string[]; // IPA symbols
  strengths: string[];
  areas_for_improvement: string[];
}

export interface FluencyAssessment {
  overall_score: number;
  speech_rate: {
    words_per_minute: number;
    evaluation: SpeechRateEvaluation;
  };
  hesitation_patterns: {
    frequency: HesitationFrequency;
    average_pause_duration: number; // seconds
    typical_contexts: string[];
  };
  rhythm_and_intonation: {
    naturalness: number; // 0-100
    sentence_stress_accuracy: number; // 0-100
    intonation_pattern_accuracy: number; // 0-100
  };
}

export interface GrammarAssessment {
  overall_score: number;
  error_patterns: Array<{
    category: string; // e.g., verb tense, word order
    description: string;
    examples: string[];
    frequency: HesitationFrequency;
    severity: SeverityLevel;
  }>;
  grammar_rules_to_review: Array<{
    rule: string;
    priority: PriorityLevel;
    examples: string[];
  }>;
  grammar_strengths: string[];
}

export interface VocabularyAssessment {
  overall_score: number;
  range: VocabularyRange;
  appropriateness: number; // 0-100
  precision: number; // 0-100
  areas_for_expansion: Array<{
    topic: string;
    suggested_vocabulary: string[];
  }>;
}

export interface ExerciseCompletion {
  overall_score: number;
  exercises_analyzed: Array<{
    prompt: string;
    expected_answer: string;
    user_response: string;
    accuracy: number; // 0-100
    error_analysis?: string;
  }>;
  comprehension_level: ComprehensionLevel;
}

// Main AudioMetrics interface
export interface AudioMetrics {
  id: string;
  // Relationships
  lessonId?: string | null;
  assessmentLessonId?: string | null;

  // Top-level metrics
  pronunciationScore: number; // 0-100
  fluencyScore: number; // 0-100
  grammarScore: number; // 0-100
  vocabularyScore: number; // 0-100
  overallPerformance: number; // 0-100

  // CEFR level and trajectory
  proficiencyLevel: string; // CEFR level: A1-C2
  learningTrajectory: LearningTrajectory;

  // Detailed analysis sections
  pronunciationAssessment: PronunciationAssessment;
  fluencyAssessment: FluencyAssessment;
  grammarAssessment: GrammarAssessment;
  vocabularyAssessment: VocabularyAssessment;
  exerciseCompletion: ExerciseCompletion;

  // Learning recommendations
  suggestedTopics: string[];
  grammarFocusAreas: string[];
  vocabularyDomains: string[];
  nextSkillTargets: string[];

  // Learning style observations
  preferredPatterns: string[];
  effectiveApproaches: string[];

  // Metadata
  audioRecordingUrl?: string | null;
  recordingDuration?: number | null; // seconds
  createdAt: Date;
  updatedAt: Date;
}

// Type guards for JSON fields with proper compatibility with JsonValue
export function isPronunciationAssessment(obj: JsonValue): obj is JsonValue {
  return typeof obj === 'object' && obj !== null && 'overall_score' in obj && 'phoneme_analysis' in obj;
}

export function isFluencyAssessment(obj: JsonValue): obj is JsonValue {
  return typeof obj === 'object' && obj !== null && 'overall_score' in obj && 'speech_rate' in obj;
}

export function isGrammarAssessment(obj: JsonValue): obj is JsonValue {
  return typeof obj === 'object' && obj !== null && 'overall_score' in obj && 'error_patterns' in obj;
}

export function isVocabularyAssessment(obj: JsonValue): obj is JsonValue {
  return typeof obj === 'object' && obj !== null && 'overall_score' in obj && 'areas_for_expansion' in obj;
}

export function isExerciseCompletion(obj: JsonValue): obj is JsonValue {
  return typeof obj === 'object' && obj !== null && 'overall_score' in obj && 'exercises_analyzed' in obj;
}

// Helper functions for safely accessing the data after type checking
export function getPronunciationAssessment(obj: JsonValue): PronunciationAssessment | null {
  if (isPronunciationAssessment(obj)) {
    return obj as unknown as PronunciationAssessment;
  }
  return null;
}

export function getFluencyAssessment(obj: JsonValue): FluencyAssessment | null {
  if (isFluencyAssessment(obj)) {
    return obj as unknown as FluencyAssessment;
  }
  return null;
}

export function getGrammarAssessment(obj: JsonValue): GrammarAssessment | null {
  if (isGrammarAssessment(obj)) {
    return obj as unknown as GrammarAssessment;
  }
  return null;
}

export function getVocabularyAssessment(obj: JsonValue): VocabularyAssessment | null {
  if (isVocabularyAssessment(obj)) {
    return obj as unknown as VocabularyAssessment;
  }
  return null;
}

export function getExerciseCompletion(obj: JsonValue): ExerciseCompletion | null {
  if (isExerciseCompletion(obj)) {
    return obj as unknown as ExerciseCompletion;
  }
  return null;
}

// Structure for sending to lesson generation
export interface AdaptiveLessonGenerationRequest {
  userInfo: {
    nativeLanguage: string;
    targetLanguage: string;
    proficiencyLevel: string;
    learningPurpose?: string;
  };
  focusTopic: string;

  // New overall progress section
  overallProgress?: {
    estimatedProficiencyLevel: ProficiencyLevel;
    overallScore?: number | null;
    learningTrajectory: LearningTrajectory;
    persistentStrengths: string[];
    persistentWeaknesses: string[];
    lowMasteryTopics?: string[];
    lowMasteryWordsCount?: number;
  };

  performanceMetrics: {
    avgAccuracy?: number;
    avgPronunciationScore?: number;
    avgFluencyScore?: number;
    avgGrammarScore?: number;
    avgVocabularyScore?: number;
    strengths: string[];
    weaknesses: string[];
  };

  detailedAudioAnalysis?: {
    pronunciationScore: number;
    fluencyScore: number;
    grammarScore: number;
    vocabularyScore: number;
    overallPerformance: number;
    problematicSounds: string[];
    grammarRulesToReview: Array<{ rule: string; priority: string }>;
    commonGrammarErrors: Array<{ category: string; description: string }>;
    vocabularyAreasForExpansion: Array<{ topic: string; suggestedVocabulary: string[] }>;
    suggestedTopics: string[];
    grammarFocusAreas: string[];
    nextSkillTargets: string[];
    effectiveApproaches: string[];
    preferredPatterns: string[];
  };

  previousLesson?: {
    id: string;
    focusArea: string;
    targetSkills: string[];
  };
}


export interface LearningProgressModel {
  id: string;
  userId: string;
  estimatedProficiencyLevel: ProficiencyLevel;
  overallScore?: number | null;
  learningTrajectory: LearningTrajectory;
  strengths: string[];
  weaknesses: string[];
  lastLessonCompletedAt?: Date | null;
  lastAssessmentCompletedAt?: Date | null;
  createdAt: Date;
  updatedAt: Date;
  // Optional: Include related topics/words if fetched
  topics?: TopicProgressModel[];
  words?: WordProgressModel[];
}

export interface TopicProgressModel {
  id: string;
  learningProgressId: string;
  topicName: string;
  masteryLevel: MasteryLevel;
  lastStudiedAt?: Date | null;
  relatedLessonIds: string[];
  relatedAssessmentIds: string[];
  score?: number | null;
  createdAt: Date;
  updatedAt: Date;
}

export interface WordProgressModel {
  id: string;
  learningProgressId: string;
  word: string;
  translation?: string | null;
  masteryLevel: MasteryLevel;
  timesCorrect: number;
  timesIncorrect: number;
  firstSeenAt: Date;
  lastReviewedAt?: Date | null;
  relatedLessonStepIds: string[];
  relatedAssessmentStepIds: string[];
  createdAt: Date;
  updatedAt: Date;
}



export interface PaymentModel {
  id: string;
  userId: string;
  stripePaymentIntentId?: string | null;
  status: PaymentStatus;
  amount: number; // Amount in smallest currency unit
  currency: string;
  productId?: string | null;
  productType?: string | null;
  errorMessage?: string | null;
  metadata?: JsonValue | null;
  subscriptionPlan?: string | null;
  isRecurring?: boolean | null;
  relatedSubscriptionId?: string | null;
  createdAt: Date;
  updatedAt: Date;
}
</file>

<file path="src/services/assessment-generator.service.ts">
import { IAIService } from '@/interfaces/ai-service.interface';
import { models } from './ai.service';
import logger from '@/utils/logger';
import { retryOperation } from '@/utils/retryWithOperation';
// import { IAssessmentGeneratorService } from '@/lib/interfaces/all-interfaces';
import { MockAssessmentGeneratorService } from '@/__mocks__/generated-assessment-lessons.mock';
import {
  AssessmentStep,
  AssessmentStepType,
  ProficiencyLevel,
} from '@prisma/client';
import { AssessmentLesson } from '@/models/AppAllModels.model';
import { ITTS } from '@/interfaces/tts.interface';
import * as fs from 'fs';
import * as path from 'path';

export interface IAssessmentGeneratorService {
  generateAssessmentSteps: (
    targetLanguage: string,
    sourceLanguage: string,
    proficiencyLevel: string
  ) => Promise<AssessmentStep[]>;
  generateAssessmentResult: (
    assessmentLesson: AssessmentLesson,
  ) => Promise<AiAssessmentResultResponse>;
  generateAudioForSteps: (
    steps: AssessmentStep[],
    language: string,
    sourceLanguage: string
  ) => Promise<AssessmentStep[]>;
}

export interface AiAssessmentResultResponse {
  metrics: {
    accuracy: number;
    pronunciationScore: number;
    grammarScore: number;
    vocabularyScore: number;
    overallScore: number;
    strengths: string[];
    weaknesses: string[];
  };
  proposedTopics: string[];
  summary: string;
}

class AssessmentGeneratorService implements IAssessmentGeneratorService {
  private aiService: IAIService;
  private useMock: boolean;
  private useAudioGeneratorMock: boolean;
  private useAudioUploadMock: boolean;
  private ttsService: ITTS;
  private uploadFunction: (file: Buffer, filename: string, contentType: string) => Promise<string>;

  constructor(
    aiService: IAIService,
    ttsService: ITTS,
    uploadFunction: (file: Buffer, filename: string, contentType: string) => Promise<string>
  ) {
    this.aiService = aiService;
    this.useMock = process.env.NEXT_PUBLIC_MOCK_ASSESSMENT_GENERATOR ===
      'true';
    this.useAudioGeneratorMock = process.env.NEXT_PUBLIC_MOCK_AUDIO_GENERATOR ===
      'true';

    this.useAudioUploadMock = process.env.NEXT_PUBLIC_USE_AUDIO_UPLOAD_MOCK ===
      'true';
    // this.useAudioUploadMock = false;
    this.ttsService = ttsService;
    this.uploadFunction = uploadFunction;

    logger.info('AssessmentGeneratorService initialized', {
      useMock: this.useMock,
      useAudioGeneratorMock: this.useAudioGeneratorMock,
      useAudioUploadMock: this.useAudioUploadMock
    });
  }

  async generateAssessmentSteps(
    targetLanguage: string,
    sourceLanguage: string,
    proficiencyLevel: string
  ): Promise<any> {
    logger.info('Generating assessment lesson', {
      targetLanguage,
      sourceLanguage,
      proficiencyLevel,
    });

    if (!targetLanguage || !sourceLanguage || !proficiencyLevel) {
      throw new Error('Missing required parameters');
    }

    let aiResponse: Record<string, unknown> | Record<string, unknown>[] = [];
    try {
      if (this.useMock) {
        logger.info('Using mock assessment generator');
        const mockLesson =
          await MockAssessmentGeneratorService.generateAssessmentLesson(
            sourceLanguage,
            targetLanguage
          );
        logger.info('Mock assessment generated', { mockLesson });
        aiResponse = mockLesson;
      } else {
        const prompts = this.generateAssessmentPrompts(
          targetLanguage,
          sourceLanguage,
          proficiencyLevel
        );

        logger.info('Generated prompts for assessment', { prompts });

        // aiResponse = await retryOperation(() =>
        aiResponse = await this.aiService.generateContent(
          '', // No file URI needed
          prompts.userPrompt,
          prompts.systemPrompt,
          models.gemini_2_0_flash
        )
        // );
      }
      // TODO: add validation and try again if it fails

      logger.info('AI response received', { aiResponse });

      return this.formatAssessmentResponse(aiResponse);
    } catch (error) {
      logger.error('Error generating assessment:', {
        targetLanguage,
        sourceLanguage,
        proficiencyLevel,
        error,
      });
      throw error;
    }
  }

  private getUserResponses(assessmentLesson: AssessmentLesson): { stepId: string; response: string; allResponses: string[] }[] {
    try {
      // Collect all user responses from the steps

      const userResponses = assessmentLesson.steps
        .filter(step => step.attempts > 0)
        .map(step => {

          let responseHistory: string[] = [];
          const historyValue = step.userResponseHistory; // This is the JsonValue from Prisma

          if (historyValue !== null && historyValue !== undefined) {
            if (Array.isArray(historyValue) && historyValue.every(item => typeof item === 'string')) {
              // It's already a string array, which is the ideal case
              responseHistory = historyValue;
            } else if (typeof historyValue === 'string') {
              // It's a plain string, wrap it in an array
              responseHistory = [historyValue];
              logger.warn('userResponseHistory was a plain string, treating as single-item history', { history: historyValue });
            } else {
              // It's some other unexpected type (object, number, boolean), treat as empty
              logger.error('userResponseHistory was an unexpected type', { type: typeof historyValue, history: historyValue });
              responseHistory = [];
            }
          }

          // Use the most recent response (either from history or the single field)
          const latestResponse = responseHistory.length > 0
            ? responseHistory[responseHistory.length - 1]
            : (step.userResponse || '');

          return {
            stepId: step.id,
            response: latestResponse,
            // Optionally include full history if needed by analysis
            allResponses: responseHistory.length > 0 ? responseHistory : (step.userResponse ? [step.userResponse] : [])
          };
        });

      logger.info('Collected user responses for analysis', {
        responseCount: userResponses.length
      });
      return userResponses;
    } catch (error) {
      logger.error('Error collecting user responses for analysis', { error });
      throw error;
    }
  }

  public async generateAssessmentResult(
    assessmentLesson: AssessmentLesson,
  ): Promise<AiAssessmentResultResponse> {
    try {
      if (this.useMock) {
        logger.info('Using mock assessment generator');
        let userResponse = 'test';
        return MockAssessmentGeneratorService.generateAssessmentResult(
          assessmentLesson,
          userResponse
        );
      }
      // getting user responses
      const userResponses = this.getUserResponses(assessmentLesson);



      const prompts = this.generateOnboardingAssessmentEvaluationPrompts(
        assessmentLesson.steps as AssessmentStep[],
        userResponses
      );

      logger.info('Generated assessment prompts ', { prompts });

      const aiResponse = await retryOperation(() =>
        this.aiService.generateContent(
          '', // No file URI needed
          prompts.userPrompt,
          prompts.systemPrompt,
          models.gemini_2_0_flash
        )
      );

      logger.info('AI response received', { aiResponse });

      return this.constructAiAssessmentResultResponse(aiResponse);
    } catch (error) {
      logger.error('Error generating assessment:', {
        error,
      });
      throw error;
    }
  }

  public async generateAudioForSteps(
    steps: AssessmentStep[],
    language: string,
    sourceLanguage: string
  ): Promise<AssessmentStep[]> {
    logger.info('Generating audio for assessment lesson', {
      steps,
    });

    try {
      logger.info('useAudioGeneratorMock', this.useAudioGeneratorMock);
      if (this.useAudioGeneratorMock) {
        logger.info('Using mock audio generator because useAudioGeneratorMock is true', this.useAudioGeneratorMock);

        for (const step of steps) {
          const audioBase64 =
            await MockAssessmentGeneratorService.generateAudioForStep(
              step.content,
              language
            );
          // Convert base64 string to Buffer
          const audioBuffer = Buffer.from(audioBase64, 'base64');

          if (this.useAudioUploadMock) {
            const audioFile = this.createAudioFile(audioBuffer, `content_step_${step.stepNumber}.mp3`);
            step.contentAudioUrl = await this.saveAudioLocally(audioFile, 'lessay/assessmentStep/audio');
          } else {
            step.contentAudioUrl = await this.uploadAudioFile(audioBuffer, 'lessay/assessmentStep/audio');
          }

          if (step.expectedAnswer) {
            const answerAudioBase64 =
              await MockAssessmentGeneratorService.generateAudioForStep(
                step.expectedAnswer!,
                language
              );
            const answerAudioBuffer = Buffer.from(answerAudioBase64, 'base64');

            if (this.useAudioUploadMock) {
              const audioFile = this.createAudioFile(answerAudioBuffer, `answer_step_${step.stepNumber}.mp3`);
              step.expectedAnswerAudioUrl = await this.saveAudioLocally(audioFile, 'lessay/assessmentStep/audio');
            } else {
              step.expectedAnswerAudioUrl = await this.uploadAudioFile(answerAudioBuffer, 'lessay/assessmentStep/audio');
            }
          }
        }
        logger.info('Mock assessment generated', { steps });
      } else {
        // Real implementation
        let voice: string;

        for (const step of steps) {
          // generate step content in native language
          voice = this.ttsService.getVoice(sourceLanguage, 'basic');
          logger.info('voice for source language content', voice);

          const audioBase64 = await retryOperation(() =>
            this.ttsService.synthesizeSpeech(step.content, sourceLanguage, voice)
          );

          // Convert base64 string to Buffer
          const audioBuffer = Buffer.from(audioBase64, 'base64');

          let contentAudioUrl: string;

          // Check if we should save locally or upload to Vercel Blob
          if (this.useAudioUploadMock) {
            const audioFile = this.createAudioFile(audioBuffer, `content_step_${step.stepNumber}.mp3`);
            contentAudioUrl = await this.saveAudioLocally(audioFile, 'lessay/assessmentStep/audio');
          } else {
            contentAudioUrl = await this.uploadAudioFile(audioBuffer, 'lessay/assessmentStep/audio');
          }

          logger.info('audio for content saved/uploaded', contentAudioUrl);
          step.contentAudioUrl = contentAudioUrl;

          // generate expected answer in target language
          if (step.expectedAnswer) {
            const voice = this.ttsService.getVoice(language, 'basic');
            const answerAudioBase64 = await retryOperation(() =>
              this.ttsService.synthesizeSpeech(
                step.expectedAnswer!,
                language,
                voice
              )
            );

            // Convert base64 string to Buffer
            const answerAudioBuffer = Buffer.from(answerAudioBase64, 'base64');

            let answerAudioUrl: string;

            // Check if we should save locally or upload to Vercel Blob
            if (this.useAudioUploadMock) {
              const audioFile = this.createAudioFile(answerAudioBuffer, `answer_step_${step.stepNumber}.mp3`);
              answerAudioUrl = await this.saveAudioLocally(audioFile, 'lessay/assessmentStep/audio');
            } else {
              answerAudioUrl = await this.uploadAudioFile(answerAudioBuffer, 'lessay/assessmentStep/audio');
            }

            logger.info('audio for expectedAnswer saved/uploaded', answerAudioUrl);
            step.expectedAnswerAudioUrl = answerAudioUrl;
          }
        }
      }

      return steps;
    } catch (error) {
      logger.error('Error generating audio for assessment:', {
        error,
      });
      throw error;
    }
  }

  // Helper method to save files locally in public folder
  private async saveAudioLocally(file: File, pathPrefix: string): Promise<string> {
    try {
      // Create the directory structure if it doesn't exist
      const publicDir = path.join(process.cwd(), 'public');
      const targetDir = path.join(publicDir, pathPrefix);

      if (!fs.existsSync(targetDir)) {
        fs.mkdirSync(targetDir, { recursive: true });
      }

      // Generate a unique filename with timestamp
      const timestamp = Date.now();
      const filename = `${timestamp}-${file.name}`;
      const filePath = path.join(targetDir, filename);

      // Convert File to Buffer and save
      const arrayBuffer = await file.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      fs.writeFileSync(filePath, buffer);

      // Return the URL path that can be used in browser
      return `/${pathPrefix}/${filename}`;
    } catch (error) {
      logger.error('Error saving audio file locally', { error });
      throw error;
    }
  }

  // Helper method to create a File from audio buffer
  private createAudioFile(
    audioBuffer: string | Buffer | ArrayBuffer, // Updated to also accept Buffer
    filename: string
  ): File {
    let blob: Blob;

    // If the audioBuffer is a Node.js Buffer, convert it to an ArrayBuffer before proceeding.
    if (typeof audioBuffer !== 'string' && Buffer.isBuffer(audioBuffer)) {
      audioBuffer = audioBuffer.buffer.slice(
        audioBuffer.byteOffset,
        audioBuffer.byteOffset + audioBuffer.byteLength
      ) as ArrayBuffer;
    }

    logger.info(
      'audioBuffer',
      typeof audioBuffer === 'string'
        ? audioBuffer.slice(0, 100)
        : 'ArrayBuffer received'
    );

    if (typeof audioBuffer === 'string') {
      // If it's a base64 string, convert it to a Blob using Buffer
      const base64Data = audioBuffer.includes(',')
        ? audioBuffer.split(',')[1] // Extract from data URL if necessary
        : audioBuffer;
      const buffer = Buffer.from(base64Data, 'base64');
      blob = new Blob([buffer], { type: 'audio/mp3' });
    } else {
      // If it's already an ArrayBuffer
      blob = new Blob([audioBuffer], { type: 'audio/mp3' });
    }

    return new File([blob], filename, { type: 'audio/mp3' });
  }

  private constructAiAssessmentResultResponse(
    aiResponse: any
  ): AiAssessmentResultResponse {
    return {
      metrics: {
        accuracy: aiResponse.metrics.accuracy,
        pronunciationScore: aiResponse.metrics.pronunciationScore,
        grammarScore: aiResponse.metrics.grammarScore,
        vocabularyScore: aiResponse.metrics.vocabularyScore,
        overallScore: aiResponse.metrics.overallScore,
        strengths: aiResponse.metrics.strengths,
        weaknesses: aiResponse.metrics.weaknesses,
      },
      proposedTopics: aiResponse.proposedTopics,
      summary: aiResponse.summary,
    };
  }

  private formatAssessmentResponse(aiResponse: any): any[] {
    // Extract the steps array from the AI response
    // If we can't find it, return an empty array
    try {
      const data = aiResponse.data || aiResponse;
      const steps = data.steps || [];

      // Ensure all steps have required properties
      return steps.map((step: any, index: number) => ({
        stepNumber: step.stepNumber || index + 1,
        type: step.type || AssessmentStepType.question,
        content: step.content || 'No content provided',
        contentAudioUrl: step.contentAudioUrl || null,
        translation: step.translation || null,
        expectedAnswer: step.expectedAnswer || null,
        expectedAnswerAudioUrl: step.expectedAnswerAudioUrl || null,
        maxAttempts: step.maxAttempts || 3,
        attempts: 0,
        correct: false,
        feedback: step.feedback || null,
      }));
    } catch (error) {
      logger.error('Error formatting assessment response', {
        error,
        aiResponse,
      });
      return [];
    }
  }




  private generateAssessmentPrompts(
    targetLanguage: string,
    sourceLanguage: string,
    proficiencyLevel: string
  ): { userPrompt: string; systemPrompt: string } {

    const systemPrompt = `## ROLE: Language Assessment Designer (Onboarding & Voice-Focused)

You are an expert language assessment designer specializing in creating **initial onboarding assessments** to evaluate proficiency in **${targetLanguage}** for learners whose native language is **${sourceLanguage}**.

## CORE OBJECTIVE:

Generate a structured language assessment designed to accurately determine a new user's **initial proficiency level (beginner, intermediate, or advanced)**. The assessment must be suitable for **voice-only interaction** (responses captured via Speech-to-Text).

## GUIDING PRINCIPLES & CONSTRAINTS:

1.  **Diagnostic Purpose:** The primary goal is to gauge the user's current abilities across core skills (vocabulary, basic grammar, comprehension, simple production) to inform personalized learning plans.
2.  **Progressive Difficulty:** The assessment must start with very basic questions (A1 level) and progressively increase in difficulty (towards A2, B1, and potentially higher depending on performance) to effectively identify the user's ceiling. Use the provided \`proficiencyLevel\` input parameter (\`${proficiencyLevel}\`) as a hint for the *expected range* but ensure the assessment covers a spectrum.
3.  **Voice-Input Compatibility:**
    *   All questions must be clearly answerable **verbally**.
    *   Phrasing should be concise and unambiguous for STT interpretation.
    *   Favor question types like: "How do you say X?", "Translate Y", "Repeat Z", "What is the word for...?", simple sentence completion.
    *   Avoid tasks requiring written input, visual selection from multiple complex options, or subtle distinctions hard to express verbally.
4.  **Structure & Flow:**
    *   Follow the standard assessment flow: Introduction -> Questions (interspersed with brief feedback) -> Summary.
    *   Include 6-8 core questions.
    *   Use \`instruction\` steps for welcoming/explaining.
    *   Use \`question\` steps for assessment items.
    *   Use \`feedback\` steps *briefly* after *some* questions for encouragement or clarification (as seen in mocks), but keep them concise.
    *   Use a \`summary\` step for conclusion.
5.  **Content & Language:**
    *   Instructions, feedback, and summary \`content\` should primarily be in **${sourceLanguage}** for clarity.
    *   Question \`content\` should generally be in **${sourceLanguage}** asking for a response in **${targetLanguage}**.
    *   \`expectedAnswer\` must be in **${targetLanguage}**.
    *   \`translation\` field should contain the **${targetLanguage}** translation of the question \`content\` where applicable (or null otherwise).
6.  **Tone:** Maintain a welcoming, encouraging, and non-intimidating tone throughout.
7.  **Output Format:** Strictly adhere to the specified JSON output format. Ensure all required fields are present for each step type.`;

    const userPrompt = `## TASK: Generate Onboarding Language Assessment Steps

Create a welcoming onboarding language assessment for a new user learning **${targetLanguage}** whose native language is **${sourceLanguage}**. The goal is to determine their initial proficiency level. Consider the estimated starting level is potentially around **${proficiencyLevel}**, but design the assessment to test a range from beginner upwards.

**Assessment Requirements:**

1.  **Introduction:** Start with a friendly \`instruction\` step in **${sourceLanguage}** explaining the assessment's purpose (to gauge current level for personalized learning) and mention it's voice-based.
2.  **Questions (6-8 total):**
    *   Create \`question\` steps that progressively increase in difficulty.
    *   Start with A1-level basics (e.g., greetings, simple nouns, basic verbs).
    *   Gradually introduce slightly more complex vocabulary, grammar (e.g., simple sentence structure, common verb conjugations, articles if easily spoken), and phrasing suitable for A2/B1 levels.
    *   Ensure questions are clear, concise, and easily answerable by **speaking** the answer in **${targetLanguage}**.
    *   Question \`content\` should be in **${sourceLanguage}**.
    *   Provide the \`expectedAnswer\` in **${targetLanguage}**.
    *   Provide the \`translation\` of the question \`content\` into **${targetLanguage}** where relevant.
    *   Set \`maxAttempts\` (usually 3 for questions).
3.  **Feedback:** Include brief, encouraging \`feedback\` steps (in **${sourceLanguage}**) after some (not necessarily all) questions, confirming correctness or providing the right answer concisely if needed (similar to mocks). Set \`maxAttempts\` to 1 for feedback/instruction/summary.
4.  **Conclusion:** End with a \`summary\` step in **${sourceLanguage}** offering encouragement and stating that the results will inform their learning plan.
5.  **Voice Focus:** Prioritize testing spoken vocabulary recall, basic sentence formation, and comprehension of simple spoken prompts.

**Output Format (JSON):**

Generate a single JSON object containing a \`steps\` array. Each object in the array must follow this structure precisely:

\`\`\`json
{
  "steps": [
    {
      "stepNumber": 1,
      "type": "instruction", // Types: instruction, question, feedback, summary
      "content": "Welcome message in ${sourceLanguage}...",
      "translation": null,
      "expectedAnswer": null,
      "maxAttempts": 1,
      "feedback": null
    },
    {
      "stepNumber": 2,
      "type": "question",
      "content": "Basic question in ${sourceLanguage} (e.g., 'How do you say...')...",
      "translation": "Question content translated to ${targetLanguage}",
      "expectedAnswer": "Expected answer in ${targetLanguage}",
      "maxAttempts": 3,
      "feedback": "Optional brief feedback hint/explanation in ${sourceLanguage}" // Can be null
    },
    // ... more question steps with increasing difficulty ...
    {
       "stepNumber": 3, // Example feedback step
       "type": "feedback",
       "content": "Brief positive feedback in ${sourceLanguage}...",
       "translation": null,
       "expectedAnswer": null,
       "maxAttempts": 1,
       "feedback": null
    },
    // ... more question steps ...
    {
      "stepNumber": 8, // Example final step
      "type": "summary",
      "content": "Concluding encouraging message in ${sourceLanguage}...",
      "translation": null,
      "expectedAnswer": null,
      "maxAttempts": 1,
      "feedback": null
    }
    // Ensure stepNumbers are sequential and correct
  ]
}
\`\`\``;

    return {
      systemPrompt,
      userPrompt
    };
  }

  // You can add this method to evaluate the onboarding assessment results
  private generateOnboardingAssessmentEvaluationPrompts(
    assessmentSteps: AssessmentStep[],
    userResponses: { stepId: string; response: string; allResponses: string[] }[]
  ): { userPrompt: string; systemPrompt: string } {
    return {
      systemPrompt: `You are an expert language assessment evaluator specializing in determining a user's 
        proficiency level and learning needs based on their responses to an onboarding assessment.
        
        Analyze the user's responses to determine:
        1. Their overall proficiency level (beginner, intermediate, or advanced)
        2. Their strengths and weaknesses
        3. Recommended learning topics based on their performance
        4. A supportive summary of their current abilities`,

      userPrompt: `Evaluate the following onboarding assessment responses and determine the user's proficiency level.
        
        Assessment steps:
        ${JSON.stringify(assessmentSteps, null, 2)}
        
        User responses:
        ${JSON.stringify(userResponses, null, 2)}
        
        Provide your evaluation in the following JSON format:
        {
          "metrics": {
            "accuracy": number,           // Overall percentage of correct answers
            "pronunciationScore": number, // Estimated pronunciation score based on complexity of responses
            "grammarScore": number,       // Grammar accuracy score
            "vocabularyScore": number,    // Vocabulary knowledge score
            "overallScore": number,       // Overall proficiency score
            "strengths": ["string"],      // List of identified strengths
            "weaknesses": ["string"]      // List of identified areas for improvement
          },
          "proficiencyLevel": "beginner|intermediate|advanced", // Determined level
          "proposedTopics": ["string"],   // 3-5 recommended topics for initial learning
          "summary": "string"             // Encouraging summary of results
        }
        
        Be supportive and encouraging in your assessment, focusing on the user's potential for growth
        while still providing an accurate proficiency assessment.`
    };
  }

  private async uploadAudioFile(audioBuffer: Buffer, pathPrefix: string): Promise<string> {
    if (this.useAudioUploadMock) {
      return `mock://${pathPrefix}/${Date.now()}.mp3`;
    }
    if (!this.uploadFunction) {
      throw new Error('Upload function not provided');
    }
    const filename = `${pathPrefix}/${Date.now()}.mp3`;
    return this.uploadFunction(audioBuffer, filename, 'audio/mpeg');
  }
}

export default AssessmentGeneratorService;
</file>

<file path="src/services/payment.service.ts">
// // File: src/services/payment.service.ts
// import Stripe from 'stripe';
// import logger from '@/utils/logger';
// import { PaymentStatus, SubscriptionStatus, User } from '@prisma/client'; // Import necessary enums/types
// import { PaymentModel } from '@/models/AppAllModels.model'; // Keep if you still log payments for record-keeping
// import prisma from '@/lib/prisma'; // Needed for updating User subscription status
// import { IPaymentRepository } from '@/repositories/payment.repository';
// import { SubscriptionProductDetails } from '@/lib/server-actions/payment-actions';

// // Initialize Stripe (ensure keys are loaded from environment variables)
// const stripeSecretKey = process.env.STRIPE_SECRET_KEY;
// if (!stripeSecretKey) {
//   logger.error('FATAL: Stripe secret key is not defined in environment variables.');
//   // Throw error to prevent service instantiation without a key
//   throw new Error('Stripe secret key is not defined.');
// }
// const stripe = new Stripe(stripeSecretKey, {
//   apiVersion: '2024-04-10', // Use your desired API version
//   typescript: true,
// });


// export class PaymentService {
//   private paymentRepository: IPaymentRepository;

//   constructor(paymentRepository: IPaymentRepository) {
//     this.paymentRepository = paymentRepository;
//     // Stripe initialization check is handled above
//   }
//   /**
//     * Creates a Stripe Checkout Session for initiating a subscription.
//     * Assumes the trial period (e.g., 7 days) is configured on the Stripe Price object.
//     * @param userId - The ID of the user subscribing.
//     * @param product - Details including the Stripe Price ID.
//     * @returns The session ID for redirecting the user to Stripe Checkout.
//     */
//   async createCheckoutSession(userId: string, product: SubscriptionProductDetails): Promise<string> {
//     logger.info(`Creating checkout session for user ${userId}, price ${product.stripePriceId}`);

//     if (!userId || !product || !product.stripePriceId || product.type !== 'subscription') {
//       throw new Error('Invalid or missing subscription product details.');
//     }

//     const user = await prisma.user.findUnique({ where: { id: userId } });
//     if (!user) {
//       throw new Error(`User not found: ${userId}`);
//     }

//     // Check if user already hasn active subscription or trial
//     if (user.subscriptionStatus === SubscriptionStatus.ACTIVE || user.subscriptionStatus === SubscriptionStatus.TRIAL) {
//       // Check if the subscription end date is in the future
//       const now = new Date();
//       if (!user.subscriptionEndDate || user.subscriptionEndDate > now) {
//         logger.warn(`User ${userId} already has an active or trial subscription.`);
//         // Option 1: Prevent creating a new session
//         throw new Error('You already have an active subscription or trial.');
//         // Option 2: Redirect to a billing portal (more complex setup)
//         // Option 3: Allow session creation (might lead to multiple subscriptions if not handled carefully)
//       }
//     }


//     const successUrl = `${process.env.NEXT_PUBLIC_BASE_URL}/app/settings?subscription=success&session_id={CHECKOUT_SESSION_ID}`;
//     const cancelUrl = `${process.env.NEXT_PUBLIC_BASE_URL}/app/settings?subscription=canceled`;

//     try {
//       const sessionParams: Stripe.Checkout.SessionCreateParams = {
//         payment_method_types: ['card'],
//         mode: 'subscription',
//         line_items: [
//           {
//             price: product.stripePriceId,
//             quantity: 1,
//           },
//         ],
//         customer_email: user.email,
//         client_reference_id: userId,
//         success_url: successUrl,
//         cancel_url: cancelUrl,
//         // --- Trial Period Handling ---
//         // Use the trial period configured on the Stripe Price object itself.
//         // This is generally the recommended approach.
//         subscription_data: {
//           trial_from_plan: true,
//           // Optionally add metadata to the subscription itself
//           metadata: {
//             userId: userId,
//             internalProductId: product.id,
//           }
//         },
//         // --- End Trial Period Handling ---
//         metadata: { // Metadata for the Checkout Session (useful in checkout.session.completed)
//           userId: userId,
//           productId: product.id, // Your internal ID
//           stripePriceId: product.stripePriceId,
//         }
//       };

//       const session = await stripe.checkout.sessions.create(sessionParams);
//       logger.info(`Stripe Checkout Session created: ${session.id} for user ${userId}`);

//       if (!session.id) {
//         throw new Error('Failed to create Stripe Checkout Session: No session ID returned.');
//       }
//       return session.id;

//     } catch (error: any) {
//       logger.error('Error creating Stripe Checkout Session:', { error: error.message, userId, product });
//       throw new Error(`Failed to create Stripe Checkout Session: ${error.message}`);
//     }
//   }

//   /**
//    * Handles incoming Stripe webhooks related to subscriptions.
//    * @param payload - The raw request body from Stripe.
//    * @param signature - The value of the 'stripe-signature' header.
//    * @returns True if handled successfully, throws error otherwise.
//    */
//   async handleWebhook(payload: Buffer | string, signature: string | string[] | undefined): Promise<boolean> {
//     const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;
//     if (!webhookSecret) {
//       logger.error('Stripe webhook secret is not configured.');
//       throw new Error('Webhook secret not configured.');
//     }
//     if (!signature) {
//       logger.error('Stripe webhook signature missing.');
//       throw new Error('Webhook signature missing.');
//     }

//     let event: Stripe.Event;

//     try {
//       event = stripe.webhooks.constructEvent(payload, signature, webhookSecret);
//       logger.info(`Received Stripe webhook event: ${event.type} (ID: ${event.id})`);
//     } catch (err: any) {
//       logger.error('Error verifying Stripe webhook signature:', { error: err.message });
//       throw new Error(`Webhook signature verification failed: ${err.message}`);
//     }

//     // --- Checkout Session Completed (Subscription Initiated/Trial Started) ---
//     if (event.type === 'checkout.session.completed') {
//       const session = event.data.object as Stripe.Checkout.Session;
//       const userId = session.client_reference_id;
//       const subscriptionId = session.subscription;

//       if (session.mode !== 'subscription' || !userId || !subscriptionId || typeof subscriptionId !== 'string') {
//         logger.warn(`Ignoring checkout.session.completed: Invalid mode, missing userId, or subscriptionId.`, { sessionId: session.id });
//         return true; // Acknowledge but don't process invalid data
//       }

//       logger.info(`Checkout session completed for user ${userId}, subscription ${subscriptionId}, payment status ${session.payment_status}`);

//       try {
//         const subscription = await stripe.subscriptions.retrieve(subscriptionId);
//         await this.updateUserSubscriptionStatus(
//           userId,
//           subscriptionId,
//           subscription.status, // Will be 'trialing' or 'active'
//           subscription.current_period_end ? new Date(subscription.current_period_end * 1000) : null
//         );

//         // Optional: Create Payment record for initial setup/payment if applicable
//         if (session.payment_status === 'paid' && session.payment_intent && typeof session.payment_intent === 'string') {
//           const paymentIntent = await stripe.paymentIntents.retrieve(session.payment_intent);
//           await this.paymentRepository.createPayment({
//             userId: userId,
//             stripePaymentIntentId: paymentIntent.id,
//             status: PaymentStatus.SUCCEEDED,
//             amount: paymentIntent.amount_received,
//             currency: paymentIntent.currency,
//             productId: session.metadata?.productId || null,
//             productType: 'subscription_initial', // Mark as initial payment/setup
//           });
//           logger.info(`Created initial payment record for subscription ${subscriptionId}`);
//         }


//       } catch (error) {
//         logger.error(`Error processing checkout.session.completed for sub ${subscriptionId}:`, error);
//         return true; // Acknowledge to avoid retries for potentially persistent issues
//       }
//       return true;
//     }

//     // --- Invoice Paid (Subscription Renewal or Trial Conversion) ---
//     if (event.type === 'invoice.payment_succeeded') {
//       const invoice = event.data.object as Stripe.Invoice;
//       const subscriptionId = invoice.subscription;
//       const userId = await this.getUserIdFromInvoice(invoice);

//       if (!subscriptionId || typeof subscriptionId !== 'string' || !userId) {
//         logger.warn('Webhook invoice.payment_succeeded missing subscription ID or userId', { invoiceId: invoice.id });
//         return true;
//       }

//       // Check billing reason: 'subscription_cycle' (renewal) or 'subscription_create' (initial payment)
//       // or 'subscription_update' or 'subscription_threshold'
//       // If it's the first invoice after a trial, billing_reason might be 'subscription_cycle' or 'subscription_update'
//       const billingReason = invoice.billing_reason;
//       logger.info(`Invoice payment succeeded for subscription ${subscriptionId}, user ${userId}, reason: ${billingReason}`);

//       try {
//         const subscription = await stripe.subscriptions.retrieve(subscriptionId);
//         await this.updateUserSubscriptionStatus(
//           userId,
//           subscriptionId,
//           subscription.status, // Should be 'active'
//           subscription.current_period_end ? new Date(subscription.current_period_end * 1000) : null
//         );

//         // Optional: Create Payment record for this recurring payment
//         if (invoice.payment_intent && typeof invoice.payment_intent === 'string') {
//           const paymentIntent = await stripe.paymentIntents.retrieve(invoice.payment_intent);
//           await this.paymentRepository.createPayment({
//             userId: userId,
//             stripePaymentIntentId: paymentIntent.id,
//             status: PaymentStatus.SUCCEEDED,
//             amount: invoice.amount_paid, // Use amount_paid from invoice
//             currency: invoice.currency,
//             productId: subscription.metadata?.internalProductId || invoice.metadata?.productId || null,
//             productType: 'subscription_renewal', // Mark as renewal
//           });
//           logger.info(`Created renewal payment record for subscription ${subscriptionId}`);
//         }


//       } catch (error) {
//         logger.error(`Error processing invoice.payment_succeeded for sub ${subscriptionId}:`, error);
//         return true; // Acknowledge
//       }
//       return true;
//     }

//     // --- Invoice Payment Failed (Renewal Failed) ---
//     if (event.type === 'invoice.payment_failed') {
//       const invoice = event.data.object as Stripe.Invoice;
//       const subscriptionId = invoice.subscription;
//       const userId = await this.getUserIdFromInvoice(invoice);

//       if (!subscriptionId || typeof subscriptionId !== 'string' || !userId) {
//         logger.warn('Webhook invoice.payment_failed missing subscription ID or userId', { invoiceId: invoice.id });
//         return true;
//       }

//       logger.warn(`Invoice payment failed for subscription ${subscriptionId}, user ${userId}`);
//       try {
//         const subscription = await stripe.subscriptions.retrieve(subscriptionId);
//         // Update status based on Stripe's status (could be 'past_due', 'canceled', 'unpaid')
//         await this.updateUserSubscriptionStatus(
//           userId,
//           subscriptionId,
//           subscription.status,
//           subscription.current_period_end ? new Date(subscription.current_period_end * 1000) : null // Keep end date for potential reactivation
//         );
//         // Optionally create a FAILED payment record
//         if (invoice.payment_intent && typeof invoice.payment_intent === 'string') {
//           await this.paymentRepository.createPayment({
//             userId: userId,
//             stripePaymentIntentId: invoice.payment_intent,
//             status: PaymentStatus.FAILED,
//             amount: invoice.amount_due,
//             currency: invoice.currency,
//             productId: subscription.metadata?.internalProductId || invoice.metadata?.productId || null,
//             productType: 'subscription_renewal_failed',
//             errorMessage: invoice.last_payment_error?.message || 'Payment failed.',
//           });
//         }
//       } catch (error) {
//         logger.error(`Error processing invoice.payment_failed for sub ${subscriptionId}:`, error);
//         return true; // Acknowledge
//       }
//       return true;
//     }

//     // --- Subscription Status Changes (canceled, trial ended without payment, etc.) ---
//     if (event.type === 'customer.subscription.updated' || event.type === 'customer.subscription.deleted') {
//       const subscription = event.data.object as Stripe.Subscription;
//       const userId = await this.getUserIdFromSubscription(subscription);

//       if (!userId) {
//         logger.warn(`Webhook ${event.type} could not determine userId`, { subscriptionId: subscription.id });
//         return true;
//       }

//       logger.info(`Subscription ${event.type} event for user ${userId}, subscription ${subscription.id}, status: ${subscription.status}`);
//       try {
//         const stripeStatus = event.type === 'customer.subscription.deleted' ? 'deleted' : subscription.status;
//         // Use canceled_at if available and it's a cancellation event
//         const endDate = (stripeStatus === 'canceled' || stripeStatus === 'deleted') && subscription.canceled_at
//           ? new Date(subscription.canceled_at * 1000)
//           : (subscription.current_period_end ? new Date(subscription.current_period_end * 1000) : null); // Otherwise use period end

//         await this.updateUserSubscriptionStatus(userId, subscription.id, stripeStatus, endDate);
//       } catch (error) {
//         logger.error(`Error processing ${event.type} for sub ${subscription.id}:`, error);
//         return true; // Acknowledge
//       }
//       return true;
//     }

//     // --- Trial Will End (Optional: Send Reminder Email) ---
//     if (event.type === 'customer.subscription.trial_will_end') {
//       const subscription = event.data.object as Stripe.Subscription;
//       const userId = await this.getUserIdFromSubscription(subscription);
//       // Send reminder email to user userId
//       logger.info(`Trial ending soon for user ${userId}, subscription ${subscription.id}`);
//       // Add your email sending logic here
//       return true; // Acknowledge
//     }


//     logger.warn(`Unhandled Stripe event type received: ${event.type} (ID: ${event.id})`);
//     return true; // Acknowledge receipt of unhandled events
//   }

//   // --- Helper Functions (getUserIdFromInvoice, getUserIdFromSubscription) remain the same ---
//   private async getUserIdFromInvoice(invoice: Stripe.Invoice): Promise<string | null> {
//     // 1. Check Invoice metadata first (most reliable if you set it)
//     if (invoice.metadata?.userId) return invoice.metadata.userId;

//     // 2. Check Subscription metadata (if invoice is linked to a subscription)
//     if (invoice.subscription && typeof invoice.subscription === 'string') {
//       try {
//         const subscription = await stripe.subscriptions.retrieve(invoice.subscription, { expand: ['metadata'] });
//         if (subscription.metadata?.userId) {
//           return subscription.metadata.userId;
//         }
//       } catch (error) {
//         logger.warn(`Could not retrieve subscription ${invoice.subscription} during userId lookup for invoice ${invoice.id}`, error);
//       }
//     }

//     // 3. Check Customer metadata (fallback)
//     if (invoice.customer && typeof invoice.customer === 'string') {
//       try {
//         const customer = await stripe.customers.retrieve(invoice.customer, { expand: ['metadata'] });
//         if (!customer.deleted && customer.metadata?.userId) {
//           return customer.metadata.userId;
//         }
//       } catch (error) {
//         logger.warn(`Could not retrieve customer ${invoice.customer} during userId lookup for invoice ${invoice.id}`, error);
//       }
//     }

//     logger.warn(`Could not determine userId for invoice ${invoice.id}`);
//     return null;
//   }

//   private async getUserIdFromSubscription(subscription: Stripe.Subscription): Promise<string | null> {
//     // 1. Check Subscription metadata first
//     if (subscription.metadata?.userId) return subscription.metadata.userId;

//     // 2. Check Customer metadata (fallback)
//     if (subscription.customer && typeof subscription.customer === 'string') {
//       try {
//         const customer = await stripe.customers.retrieve(subscription.customer, { expand: ['metadata'] });
//         if (!customer.deleted && customer.metadata?.userId) {
//           return customer.metadata.userId;
//         }
//       } catch (error) {
//         logger.warn(`Could not retrieve customer ${subscription.customer} during userId lookup for subscription ${subscription.id}`, error);
//       }
//     }
//     logger.warn(`Could not determine userId for subscription ${subscription.id}`);
//     return null;
//   }


//   /**
//    * Updates the user's subscription details in the database based on Stripe status.
//    */
//   private async updateUserSubscriptionStatus(
//     userId: string,
//     stripeSubscriptionId: string,
//     stripeStatus: Stripe.Subscription.Status | 'deleted',
//     periodEndDate?: Date | null
//   ): Promise<void> {
//     logger.info(`Updating subscription status for user ${userId}, sub ${stripeSubscriptionId} to Stripe status ${stripeStatus}`);

//     let appStatus: SubscriptionStatus;
//     let finalEndDate: Date | null = periodEndDate || null;
//     let finalSubscriptionId: string | null = stripeSubscriptionId;

//     switch (stripeStatus) {
//       case 'active':
//         appStatus = SubscriptionStatus.ACTIVE;
//         break;
//       case 'trialing':
//         appStatus = SubscriptionStatus.TRIAL;
//         break;
//       case 'past_due':
//         appStatus = SubscriptionStatus.PAST_DUE;
//         break;
//       case 'canceled': // User explicitly canceled, but might still be active until periodEndDate
//         appStatus = SubscriptionStatus.CANCELED;
//         // Keep finalEndDate as periodEndDate unless canceled_at is present and earlier
//         break;
//       case 'unpaid': // Often leads to cancellation, treat as PAST_DUE or CANCELED
//         appStatus = SubscriptionStatus.PAST_DUE; // Or CANCELED depending on Stripe settings/grace period
//         break;
//       case 'incomplete': // Payment setup not finished
//       case 'incomplete_expired': // Setup expired
//         appStatus = SubscriptionStatus.NONE; // Treat as if no subscription exists
//         finalEndDate = null;
//         finalSubscriptionId = null;
//         break;
//       case 'deleted': // Subscription removed entirely in Stripe
//         appStatus = SubscriptionStatus.NONE; // Or CANCELED if you prefer
//         finalEndDate = null;
//         finalSubscriptionId = null;
//         break;
//       default:
//         logger.warn(`Unknown Stripe subscription status encountered: ${stripeStatus}. Setting status to NONE.`);
//         appStatus = SubscriptionStatus.NONE;
//         finalEndDate = null;
//         finalSubscriptionId = null;
//     }

//     // If status indicates termination, ensure end date is cleared
//     if (appStatus === SubscriptionStatus.NONE || appStatus === SubscriptionStatus.CANCELED && !finalEndDate) {
//       finalEndDate = null;
//     }
//     // If status indicates termination, ensure subscription ID is cleared
//     if (appStatus === SubscriptionStatus.NONE) {
//       finalSubscriptionId = null;
//     }


//     try {
//       await prisma.user.update({
//         where: { id: userId },
//         data: {
//           subscriptionStatus: appStatus,
//           subscriptionId: finalSubscriptionId, // Use potentially nulled ID
//           subscriptionEndDate: finalEndDate,
//         },
//       });
//       logger.info(`Successfully updated user ${userId} subscription status in DB to ${appStatus}, EndDate: ${finalEndDate}, SubId: ${finalSubscriptionId}`);
//     } catch (error) {
//       logger.error(`Failed to update user subscription status in DB for user ${userId}`, { error });
//     }
//   }
// }
</file>

<file path="src/utils/supabase/server.ts">
import { createServerClient, type CookieOptions } from '@supabase/ssr';
import { cookies } from 'next/headers';
import type { NextRequest } from 'next/server';
import logger from '../logger';
import { Session, SignInWithOAuthCredentials, SignInWithPasswordCredentials, SignUpWithPasswordCredentials, User } from '@supabase/supabase-js';

const MOCK_USER_ID = 'mock-user-id';
const MOCK_USER_EMAIL = 'dev@example.com';
const mockUser: User = {
  id: MOCK_USER_ID,
  email: MOCK_USER_EMAIL,
  aud: 'authenticated',
  role: 'authenticated',
  app_metadata: { provider: 'email' },
  user_metadata: { name: 'Dev User' },
  created_at: new Date().toISOString(),
  updated_at: new Date().toISOString(),
};

const mockSession: Session = {
  access_token: 'mock-access-token',
  refresh_token: 'mock-refresh-token',
  token_type: 'bearer',
  expires_in: 3600,
  expires_at: Math.floor(Date.now() / 1000) + 3600,
  user: mockUser,
};
// --- END: MOCK AUTH DATA --- END: MOCK AUTH DATA ---

async function createRealSupabaseServerClient(request?: NextRequest) {
  try {
    if (request) {
      // Middleware usage
      return createServerClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
        {
          cookies: {
            get(name: string) {
              return request.cookies.get(name)?.value;
            },
            set(name: string, value: string, options: CookieOptions) {
              request.cookies.set({ name, value, ...options });
            },
            remove(name: string, options: CookieOptions) {
              request.cookies.set({ name, value: '', ...options });
            },
          },
          // Add global fetch options for timeout
          global: {
            fetch: (input, init) => {
              return fetch(input, {
                ...init,
                // Increase timeout to 30 seconds for proxy environments
                signal: AbortSignal.timeout(30000),
              });
            },
          },
        }
      );
    }

    // Server Component usage - now with await
    const cookieStore = await cookies();
    return createServerClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!,
      {
        cookies: {
          get(name: string) {
            return cookieStore.get(name)?.value;
          },
          set(name: string, value: string, options: CookieOptions) {
            cookieStore.set({ name, value, ...options });
          },
          remove(name: string, options: CookieOptions) {
            cookieStore.set({ name, value: '', ...options });
          },
        },
        // Add global fetch options for timeout
        global: {
          fetch: (input, init) => {
            return fetch(input, {
              ...init,
              // Increase timeout to 30 seconds for proxy environments
              signal: AbortSignal.timeout(30000),
            });
          },
        },
      }
    );
  } catch (error) {
    logger.error('Error in createRealSupabaseServerClient:', {
      error: (error as Error).message,
    });
    throw error;
  }
}

export async function createSupabaseServerClient(request?: NextRequest) {
  const isMockAuth = process.env.NEXT_PUBLIC_MOCK_AUTH === 'true';

  // If mock auth is enabled, return a modified client immediately
  if (isMockAuth && typeof window === 'undefined') { // Ensure this runs server-side only for this block
    logger.warn('MOCK AUTH ENABLED: Returning mock Supabase client for server.');

    // We still need a real client for non-auth operations (like database queries)
    // Create a real client instance but we will override its auth methods
    const realSupabaseClient = await createRealSupabaseServerClient(request);

    return {
      ...realSupabaseClient, // Spread the real client's methods
      auth: { // Override the auth object
        ...realSupabaseClient.auth, // Keep other auth methods if needed
        getUser: async () => {
          logger.debug('MOCK AUTH: getUser() called');
          return { data: { user: mockUser }, error: null };
        },
        getSession: async () => {
          logger.debug('MOCK AUTH: getSession() called');
          return { data: { session: mockSession }, error: null };
        },
       // Mock implementations for other used auth methods
       signInWithPassword: async (credentials: SignInWithPasswordCredentials) => {
         logger.debug('MOCK AUTH: signInWithPassword() called', credentials);
         // Simulate successful login for the mock user
         return { data: { user: mockUser, session: mockSession }, error: null };
       },
       signUp: async (credentials: SignUpWithPasswordCredentials) => {
         logger.debug('MOCK AUTH: signUp() called', credentials);
         // Simulate successful sign up (user exists, maybe no session yet depending on email confirm)
         // For simplicity, return the mock user but null session like a real signup without auto-confirm
         return { data: { user: mockUser, session: null }, error: null };
         // Or simulate auto-confirm:
         // return { data: { user: mockUser, session: mockSession }, error: null };
       },
       signInWithOAuth: async (credentials: SignInWithOAuthCredentials) => {
         logger.debug('MOCK AUTH: signInWithOAuth() called', credentials);
         // Cannot redirect, just simulate success
         return { data: { provider: credentials.provider, url: 'mock-oauth-url' }, error: null };
       },
       signOut: async () => {
         logger.debug('MOCK AUTH: signOut() called');
         // Simulate successful sign out
         return { error: null };
       },
       // Add mock admin deleteUser to support deletion
       admin: {
         deleteUser: async (userId: string) => {
           logger.debug('MOCK AUTH: admin.deleteUser() called', { userId });
           if (userId === MOCK_USER_ID) {
             return { data: null, error: null };
           }
           return { data: null, error: { message: 'User not found' } };
         }
       },
        // Optionally mock other auth methods if they cause issues
        // signOut: async () => { return { error: null }; },
      },
    };
  }

  // If mock auth is disabled or running in a context where it shouldn't apply (e.g., client), create the real client
  return createRealSupabaseServerClient(request);
}
</file>

<file path="src/utils/logger.ts">
import { supabase } from "@/repositories/supabase/supabase";

class Logger {
  private isProduction: boolean;

  constructor() {
    this.isProduction = process.env.NODE_ENV === 'production';
  }

  error(message: string, ...args: unknown[]): void {
    // if (!this.isProduction) {
      console.error(message, ...args);
    // } else {
      // Prepare comprehensive error details
      // const errorDetails = args.map(arg => {
      //   if (arg instanceof Error) {
      //     return {
      //       name: arg.name,
      //       message: arg.message,
      //       stack: arg.stack,
      //     };
      //   }
      //   return arg;
      // });
      // const errorData = {
      //   message,
      //   details: errorDetails,
      //   timestamp: new Date().toISOString(),
      // };

      // Log error to Supabase without blocking the execution flow
      // (async () => {
      //   const { error: supabaseError } = await supabase
      //     .from('error_logs')
      //     .insert([errorData]);
      //   if (supabaseError) {
      //     // If logging to Supabase fails in production, fallback to a basic console output.
      //     console.log("Failed to log error to Supabase:", supabaseError);
      //   }
      // })();
    // }
  }

  debug(message: string, ...args: unknown[]): void {
    // if (!this.isProduction) {
      console.debug(message, ...args);
    // } else {
      // Optionally, warnings can also be logged to Supabase in a similar fashion if needed.
      console.log(`DEBUG : ${message}`, ...args);
    // }
  }

  info(message: string, ...args: unknown[]): void {
    // if (!this.isProduction) {
    console.log(message, ...args);
    // }
  }

  warn(message: string, ...args: unknown[]): void {
    // if (!this.isProduction) {
      console.warn(message, ...args);
    // } else {
      // Optionally, warnings can also be logged to Supabase in a similar fashion if needed.
      console.log(`Warning: ${message}`, ...args);
    // }
  }

  log(message: string, ...args: unknown[]): void {
    // if (!this.isProduction) {
    console.log(message, ...args);
    // } else {
    // In production, standard logs can be suppressed, or adjust as needed.
    // }
  }
}

const logger = new Logger();
export default logger;
</file>

<file path="document.md">
# Lessay: Project and Application Documentation

## 1. Introduction

This document provides a detailed description of the 'lessay' project, covering its purpose, architecture, key features, and technical details. It will also address how the backend can serve external clients (like a Flutter app) and considerations for building a Flutter frontend.

## 2. Project Overview

### Project Name

The project name is 'lessay'.

### Purpose

lessay is an AI-powered language learning platform focused on accent and pronunciation analysis. It aims to help users improve their spoken language skills by providing personalized lessons, detailed feedback on pronunciation, accent characteristics, and overall speech patterns.

### Target Audience

The platform targets language learners of various levels who wish to refine their pronunciation, understand their accent, and improve their overall spoken fluency and clarity in a new language.

### Core Technologies

*   **Framework & Frontend:** Next.js (App Router), React, TypeScript
*   **Styling:** Tailwind CSS
*   **Backend Logic:** Next.js (API Routes, Server Actions), Node.js
*   **Database:** PostgreSQL
*   **ORM:** Prisma
*   **Authentication:** Supabase
*   **AI Services:**
    *   Language Model (LLM): Google Gemini (e.g., `gemini-2.5-pro-exp`, `gemini-2.0-flash`)
    *   Text-to-Speech (TTS): Google Cloud TTS, AWS Polly
    *   Speech-to-Text (STT): Google Cloud Speech-to-Text
*   **File Storage:** Vercel Blob
*   **Payments (Integrated/Planned):** Stripe
*   **Deployment & Hosting:** Vercel
*   **Analytics & Monitoring:** PostHog, Vercel Speed Insights, Vercel Analytics



## 3. System Architecture

### 3.1. Overall Architecture

The "lessay" project is structured as a **Monolithic Repository (Monorepo)** housing a **Next.js Full-Stack Application**. This architecture allows for a unified codebase for both frontend and backend development, streamlining the development process.

It follows a **Client-Server model**:
*   The **Next.js application** serves as the core, delivering both the frontend user interface (built with React components) and the backend logic (through API routes and Server Actions).
*   The primary **client** is a web browser, which interacts with the frontend served by Next.js.

The project's directory structure reflects this full-stack approach:
*   `src/app/`: Contains the Next.js App Router implementation, including frontend pages (e.g., `page.tsx` files) and backend API routes (e.g., under `src/app/api/`).
*   `src/components/`: Houses reusable React UI components used across the frontend.
*   `src/services/`: Encapsulates backend business logic and integrations with external services.
*   `src/lib/server-actions/`: Contains server-side functions callable directly from client components (RPC-style).
*   `src/repositories/`: Implements the data access layer, abstracting database interactions.
*   `prisma/`: Manages the database schema (`schema.prisma`) and migrations for PostgreSQL.

### 3.2. Frontend Architecture

*   **Framework:** React with Next.js (App Router).
    *   Pages are defined by `page.tsx` files within the `src/app/` directory structure (e.g., `src/app/app/lessons/page.tsx`, `src/app/app/onboarding/page.tsx`).
    *   The root layout is defined in `src/app/layout.tsx`, with nested layouts like `src/app/app/layout.tsx`.
*   **Language:** TypeScript (evident from `.ts` and `.tsx` file extensions, and the `tsconfig.json` file).
*   **UI Components:**
    *   Custom reusable components are located in `src/components/` (e.g., `Recording.tsx`, `Footer.tsx`, `lessons/lessonChat.tsx`).
    *   Standardized UI primitives (buttons, dialogs) are found in `src/components/ui/` (e.g., `alert-dialog.tsx`, `button.tsx`), suggesting the use or inspiration of a UI library like Radix UI, wrapped for consistent styling.
*   **Styling:** Tailwind CSS is used for styling, configured in `tailwind.config.ts` and with global styles in `src/app/globals.css`. The `cn` utility (`src/utils/cn.ts`) is used for conditional class merging.
*   **State Management:** Primarily utilizes React Context API. This is inferred from the `src/context/` directory, which contains various context providers like `auth-context.tsx`, `lesson-context.tsx`, `onboarding-context.tsx`, `recording-context.tsx`, `user-profile-context.tsx`, and `app-initializer-context.tsx`.
*   **Client-Side Routing:** Handled by the Next.js App Router.
*   **Key Frontend Responsibilities:**
    *   Rendering the user interface and managing user interactions.
    *   Collecting user input, including text (forms) and voice (microphone access for recordings).
    *   Making asynchronous requests to the Next.js backend (API Routes or Server Actions) to fetch data, submit information, and trigger business logic.
    *   Displaying data, feedback, lessons, and assessment results received from the backend.
    *   Managing client-side user authentication state and redirecting users based on auth status or onboarding progress.
    *   Providing interactive learning experiences like the lesson chat interface.

### 3.3. Backend Architecture

*   **Framework/Environment:** Node.js, as leveraged by the Next.js full-stack capabilities.
*   **API Layer:**
    *   **Next.js API Routes:** RESTful or GraphQL endpoints are defined under `src/app/api/` (e.g., `src/app/api/recording/route.ts` for audio uploads, `src/app/api/tts/route.ts` for text-to-speech, `src/app/api/subscribe/route.ts` for waitlist).
    *   **Next.js Server Actions:** Functions defined in `src/lib/server-actions/` (e.g., `auth-actions.ts`, `lesson-actions.ts`, `onboarding-actions.ts`) allow client components to directly call server-side logic with type safety.
*   **Service Layer:**
    *   Business logic is modularized into services located in `src/services/` (e.g., `AiService.ts`, `LessonService.ts`, `OnboardingService.ts`, `RecordingService.ts`, `TtsService.ts`, `UserService.ts`). These services handle core operations and orchestrate interactions between the API layer, data access layer, and external services.
    *   Generator services like `AssessmentGeneratorService.ts` and `LessonGeneratorService.ts` are responsible for dynamically creating learning content.
*   **Data Access Layer (DAL)/Repository Layer:**
    *   Database interactions are abstracted through repositories defined in `src/repositories/` (e.g., `LessonRepository.ts`, `UserRepository.ts`, `OnboardingRepository.ts`, `LearningProgressRepository.ts`).
    *   These repositories use Prisma as the ORM to communicate with the PostgreSQL database.
*   **Authentication & Authorization:**
    *   User authentication is managed via Supabase Auth, as indicated by `src/utils/supabase/` utilities and server actions in `src/lib/server-actions/auth-actions.ts`.
    *   Route protection and session validation are handled by Next.js middleware (`src/middleware.ts`), which integrates with Supabase for checking user sessions. Server Actions and API Routes also perform session validation.
*   **Key Backend Responsibilities:**
    *   Handling HTTP requests from the frontend via API Routes and Server Actions.
    *   Managing user authentication, registration, and session lifecycle with Supabase.
    *   Performing CRUD operations on the PostgreSQL database through Prisma and the repository layer.
    *   Integrating with various external AI services for:
        *   Language model interactions (Google Gemini).
        *   Text-to-Speech (Google TTS, AWS Polly).
        *   Speech-to-Text (Google Cloud STT).
    *   Processing and storing audio recordings, potentially using Vercel Blob for file storage.
    *   Executing core business logic related to generating lessons and assessments, tracking user progress, and providing feedback.
    *   Potentially handling payment processing and subscription management via Stripe webhooks (inferred from schema and commented-out code).

### 3.4. Database

*   **Type:** PostgreSQL. This is confirmed by the `provider = "postgresql"` line in `prisma/schema.prisma` and the `provider = "postgresql"` in `prisma/migrations/migration_lock.toml`.
*   **ORM:** Prisma. Indicated by the presence of `prisma/schema.prisma`, Prisma Client usage in `src/lib/prisma.ts`, and its inclusion in `package.json`.
*   **Key Data Models** (defined in `prisma/schema.prisma`):
    *   `User`: Stores user identity, email, authentication details, and subscription-related fields.
    *   `Onboarding`: Manages user onboarding flow, selected languages, learning purpose, and proficiency level.
    *   `Lesson`, `LessonStep`: Define the structure and content of regular learning lessons, including types like prompt, feedback, new_word, practice, instruction, and summary.
    *   `AssessmentLesson`, `AssessmentStep`: Structure initial and ongoing assessments, including question types, expected answers, and user responses.
    *   `AudioMetrics`: Stores detailed analysis of user audio recordings, including scores for pronunciation, fluency, grammar, vocabulary, and overall performance, along with detailed JSON-based assessments.
    *   `LearningProgress`, `TopicProgress`, `WordProgress`: Track the user's journey, mastery of topics and words, strengths, and weaknesses.
    *   `Payment`: Stores records of payment transactions, likely related to subscriptions (integrated with Stripe).

### 3.5. External Services & Integrations

*   **Supabase:** Used for user authentication (email/password, potentially OAuth like Google) and potentially for database hosting (the `DATABASE_URL` in `docker-compose.mac.prod.yml` points to a Supabase pooler URL: `aws-0-us-west-1.pooler.supabase.com`).
*   **Google Cloud AI:**
    *   **Gemini:** Leveraged as the primary Large Language Model for tasks like content generation, analysis, and personalized feedback (e.g., `src/services/ai.service.ts`).
    *   **Text-to-Speech (TTS):** Used for generating audio from text content for lessons and assessments (e.g., `src/services/google-tts.service.ts`).
    *   **Speech-to-Text (STT):** Utilized for transcribing user's spoken audio responses (e.g., `src/services/stt.service.ts`).
*   **AWS Polly:** An alternative Text-to-Speech service available in the system (e.g., `src/services/polly.service.ts`).
*   **Vercel:**
    *   **Deployment & Hosting:** The application is deployed on Vercel (inferred from `lessay-app.vercel.app` URLs and Vercel-specific components).
    *   **Vercel Blob:** Used for storing uploaded files, particularly audio recordings (e.g., `src/utils/vercel_blob-upload.ts`, `src/app/api/upload-token/route.ts`).
    *   **Vercel Speed Insights & Analytics:** Integrated for performance monitoring and usage analytics (`@vercel/speed-insights` and `@vercel/analytics` in `src/app/layout.tsx`).
*   **Stripe (Integrated/Planned):** Intended for handling payments and subscriptions. This is suggested by the `Payment` model in `prisma/schema.prisma`, Stripe-related fields on the `User` model, and commented-out code for Stripe webhooks (`src/app/api/payments/webhook.ts`) and checkout forms (`src/components/CheckoutForm.tsx`).
*   **PostHog:** Used for product analytics and tracking user behavior (`src/context/posthog-context.tsx`, `src/components/PostHogPageView.tsx`).



## 4. Key Features and Functionalities

### 4.1. User Onboarding

The application features a comprehensive, multi-step onboarding process designed to gather essential information about the user and prepare them for personalized learning. This process is managed by components within `src/components/onboarding/`:

*   **Welcome (`WelcomeStep.tsx`):** Greets the user and initiates the onboarding flow.
*   **Language Selection (`LanguageSelectionStep.tsx`):** Collects the user's native language and the target language they wish to learn.
*   **Learning Purpose (`LearningPurposeStep.tsx`):** Asks the user for their primary motivation for learning the language (e.g., travel, business, academic).
*   **Proficiency Assessment (`ProficiencyStep.tsx`):** Allows users to self-assess their current proficiency level in the target language (e.g., beginner, intermediate, advanced).
*   **Initial Language Assessment (`AssessmentStep.tsx` & `AssessmentChat.tsx`):** The onboarding process culminates in an interactive, voice-based initial language assessment. This assessment evaluates the user's current skills in the target language.

All data collected during onboarding (preferences, assessment status) is stored in the `Onboarding` table, while the assessment itself and its results are stored in the `AssessmentLesson` and related tables (see `prisma/schema.prisma`).

### 4.2. AI-Powered Language Assessment

The platform utilizes AI to conduct detailed language assessments, providing users with valuable insights into their abilities.

*   **Process:** Assessments are interactive and voice-based, presenting users with various question types. The `AssessmentChat.tsx` component facilitates this interaction.
*   **Dynamic Generation:** Assessment steps can be dynamically generated by the `src/services/assessment-generator.service.ts`, tailoring the assessment to the user's target language and proficiency.
*   **Audio Analysis:** User's spoken responses are captured and processed. This involves:
    *   Uploading audio recordings (managed by `src/services/recording.service.ts`).
    *   Transcribing audio to text using Speech-to-Text services (handled by `src/services/stt.service.ts`).
    *   Analyzing the transcribed text and audio features for linguistic accuracy and characteristics.
*   **Detailed Feedback:** The system provides comprehensive feedback, with metrics stored in the `AudioMetrics` and `AssessmentLesson` tables. This includes:
    *   Pronunciation scores
    *   Fluency scores
    *   Grammar accuracy
    *   Vocabulary range
    *   Overall proficiency estimation, often mapped to CEFR levels (e.g., A1, B2).
    *   Identification of specific strengths and weaknesses in their spoken language.
    *   Proposed topics and focus areas for subsequent personalized learning.
*   **Data Structure:** The structure for assessment results and audio analysis is exemplified in mock files like `src/__mocks__/assessment-data.mock.ts` (for assessment structure) and `src/__mocks__/generated-audio-metrics.mock.ts` (for detailed audio analysis feedback).

### 4.3. Personalized Lesson Generation & Delivery

Lessons are tailored to individual user needs based on a variety of inputs, ensuring a relevant and effective learning experience.

*   **Personalization Inputs:**
    *   Results from the initial language assessment (specifically `AssessmentLesson.proposedTopics`).
    *   User's ongoing performance and tracked learning progress (from `LearningProgress`, `TopicProgress`, `WordProgress` tables).
    *   Identified areas for improvement from `AudioMetrics` (e.g., specific pronunciation challenges, grammatical errors).
*   **Core Services:**
    *   `LessonService.ts`: Orchestrates lesson management, including retrieval, creation, and completion.
    *   `LessonGeneratorService.ts`: Responsible for dynamically generating the content and structure of lessons based on the personalization inputs and AI capabilities.
*   **Lesson Structure & Delivery:**
    *   **Interactive Chat Interface:** Lessons are delivered through an interactive, voice-based chat interface, primarily managed by `src/components/lessons/lessonChat.tsx`, with supporting components `ChatInput.tsx` (for user input handling) and `ChatMessages.tsx` (for displaying the conversation flow).
    *   **Multi-Step Format:** Each lesson consists of multiple `LessonStep` (defined in `prisma/schema.prisma`), which can include:
        *   `instruction`: Explanations or guidance.
        *   `new_word`: Introduction of new vocabulary in context.
        *   `practice`/`prompt`: Exercises requiring user response.
        *   `feedback`: AI-generated feedback on user responses.
        *   `summary`: Recap of the lesson content.
    *   **Audio Prompts:** Text-to-Speech (TTS) technology (`src/services/tts.service.ts`, integrating `GoogleTTS` and `PollyService`) is used to generate audio for lesson prompts and model answers, enhancing the auditory learning experience.
*   **Data Storage:** Lesson structures and user progress within lessons are stored in the `Lesson` and `LessonStep` tables.

### 4.4. Accent and Pronunciation Analysis

A core strength of "lessay" is its detailed analysis of user accent and pronunciation.

*   **Recording Interface:** Users record their voice primarily through the interface provided by `src/components/Recording.tsx`.
*   **Comprehensive Analysis:** The system analyzes various aspects of speech:
    *   **Phonetic Analysis:** Evaluation of individual phoneme production.
    *   **Suprasegmental Features:** Assessment of intonation, rhythm, and stress patterns.
    *   The components `src/components/BasicAnalysis.tsx` and `src/components/DetailedAnalysis.tsx` are used to display these results.
*   **AI Response Structure:** The detailed structure of the AI's analysis feedback is defined in `src/models/AiResponse.model.ts`, specifically through the `AIResponse` and `DetailedAIResponse` interfaces.
*   **Interactive Feedback:** The `src/components/PhonemePlayer.tsx` allows users to listen to and compare the target pronunciation of specific phonemes with their own observed pronunciation, facilitating self-correction.

### 4.5. Learning Progress Tracking

The platform meticulously tracks user progress to adapt the learning path and provide insights into their development.

*   **Data Models:** Progress is stored across several related tables defined in `prisma/schema.prisma`:
    *   `LearningProgress`: Captures the user's overall learning status.
    *   `TopicProgress`: Tracks mastery for specific learning topics.
    *   `WordProgress`: Monitors user's familiarity with individual vocabulary items.
*   **Tracked Metrics:**
    *   Overall proficiency level (e.g., beginner, intermediate, advanced) and a calculated overall score.
    *   Mastery levels for topics and words (e.g., NotStarted, Seen, Learning, Practiced, Known, Mastered).
    *   Dynamically updated lists of strengths and weaknesses.
    *   A learning trajectory indicator (e.g., steady, accelerating, plateauing).
*   **Service:** The `LearningProgressService.ts` is responsible for updating these progress metrics based on user performance in lessons and assessments.

### 4.6. User Authentication and Profile Management

Secure user authentication and personalized profile management are key to the platform.

*   **Authentication Provider:** Supabase is used for user authentication, supporting email/password sign-up and login. Google OAuth is also likely supported, as inferred from the `googleLogin` case in `src/app/api/mock-auth/route.ts`.
*   **User Profiles:** Authenticated users have profiles accessible via `src/app/app/profile/page.tsx`. These profiles store user preferences (like native and target languages from onboarding) and serve as a central point to link to their learning data.
*   **Data Storage:** Core user information is stored in the `User` table (`prisma/schema.prisma`).
*   **Server-Side Logic:** Authentication flows (login, registration, session management) and profile updates are handled by Server Actions found in `src/lib/server-actions/auth-actions.ts` and `src/lib/server-actions/user-actions.ts`.

### 4.7. Subscription and Payments (Planned/Integrated)

The application is designed to support a subscription-based model, likely leveraging Stripe for payment processing.

*   **Subscription Management:** The `User` table in `prisma/schema.prisma` includes fields like `subscriptionStatus`, `subscriptionId`, `subscriptionEndDate`, `subscriptionPlan`, and `stripeCustomerId`, indicating a robust system for managing user subscriptions. The `SubscriptionStatus` enum (`NONE`, `TRIAL`, `ACTIVE`, `CANCELED`, `PAST_DUE`, `EXPIRED`) details the possible states of a subscription.
*   **Payment Processing:** Stripe is the inferred payment gateway. This is suggested by:
    *   The `Payment` table in `prisma/schema.prisma` for recording payment transactions, including `stripePaymentIntentId`.
    *   Commented-out code related to Stripe webhooks (`src/app/api/payments/webhook.ts`) for handling events like successful payments or subscription updates.
    *   A commented-out Stripe `CheckoutForm.tsx` component.
*   **Lifecycle Management:** The system appears designed to manage the full subscription lifecycle, including trial periods (`trialStartDate`, `trialEndDate`), active subscriptions, cancellations (`cancelAtPeriodEnd`), and payment tracking.

## 5. Backend for External Clients (e.g., Flutter)

The existing Next.js backend can be effectively leveraged to support external clients like a Flutter mobile application. This would involve consuming existing API routes and potentially exposing functionality currently within Server Actions through new, dedicated API routes.

### 5.1. API Endpoints (Next.js API Routes)

The Next.js API Routes defined under `src/app/api/` can be directly called by a Flutter application using standard HTTP request methods (GET, POST, etc.). Key relevant endpoints include:

*   **`/api/recording` (`src/app/api/recording/route.ts`):**
    *   **Purpose:** Submitting audio recordings for accent and pronunciation analysis.
    *   **Input (Flutter):** `POST` request with `FormData` containing the audio file, `recordingTime` (milliseconds), `recordingSize` (bytes), and `isDeepAnalysis` (boolean).
    *   **Output:** JSON response containing the AI's analysis (conforming to `AIResponse` or `DetailedAIResponse` from `src/models/AiResponse.model.ts`).
*   **`/api/tts` (`src/app/api/tts/route.ts`):**
    *   **Purpose:** Generating Text-to-Speech audio for prompts, model answers, etc.
    *   **Input (Flutter):** `POST` request with JSON body containing `text` (string to synthesize) and `language` (target language code).
    *   **Output:** Audio stream/buffer (e.g., `audio/mpeg`). Flutter would need to handle this binary response.
*   **`/api/subscribe` (`src/app/api/subscribe/route.ts`):**
    *   **Purpose:** Allows users to subscribe to a waitlist.
    *   **Input (Flutter):** `POST` request with JSON body containing `email` and optional `source`.
    *   **Output:** JSON confirmation or error message.
    *   *Note:* This might be more relevant for a pre-launch phase. For an authenticated app, direct feature access is typical.
*   **`/api/upload-token` (`src/app/api/upload-token/route.ts`):**
    *   **Purpose:** Generates a token for direct client-side uploads to Vercel Blob storage.
    *   **Flutter Integration:** The Flutter app could potentially use this endpoint to get a token and then upload directly to Vercel Blob. Alternatively, if a different upload strategy is preferred for mobile (e.g., Flutter sends audio to the Next.js backend, which then uploads to Vercel Blob), this endpoint might be less relevant, or a new backend-mediated upload API route might be created.
*   **`/api/mock-auth` (`src/app/api/mock-auth/route.ts`):**
    *   **Purpose:** Provides mock authentication endpoints for development and testing of the web application.
    *   **Flutter Integration:** This endpoint **should not** be used by a production Flutter application. The Flutter app will authenticate directly with Supabase.

### 5.2. Server Actions as Potential Endpoints

Much of the core business logic is currently encapsulated within Next.js Server Actions (`src/lib/server-actions/`). While Server Actions are primarily designed for tight integration with Next.js client components, their underlying logic can be exposed to a Flutter app by creating new API Routes that call these service methods.

Key functionalities from Server Actions that would require API Route wrappers:

*   **Authentication (`auth-actions.ts`):**
    *   `loginAction`, `registerAction`, `getSessionAction`, `logoutAction`: The Flutter application should handle these operations by **interacting directly with the Supabase authentication service** using the Supabase Flutter SDK. These server actions would not be directly called.
*   **User Profile Management (`user-actions.ts`):**
    *   Logic within `getUserProfileAction`, `createUserProfileAction`, `updateUserProfileAction`, and `deleteUserProfileAction` would need to be exposed via new, secured API Routes (e.g., `GET /api/users/profile`, `POST /api/users/profile`, `PUT /api/users/profile`, `DELETE /api/users/profile`).
*   **Onboarding (`onboarding-actions.ts`):**
    *   All actions (`createOnboardingAction`, `getOnboardingAction`, `updateOnboardingAction`, `markOnboardingCompleteAndGenerateInitialLessonsAction`, `getAssessmentLessonAction`, `completeAssessmentLessonAction`, `recordAssessmentStepAttemptAction`, `updateOnboardingLessonAction`, `processAssessmentLessonRecordingAction`) represent critical business logic. Each of these would require corresponding API Routes for the Flutter app to manage the onboarding flow and initial assessment.
*   **Lessons (`lesson-actions.ts`):**
    *   Functions like `getLessonsAction`, `getLessonByIdAction`, `completeLessonAction`, `recordStepAttemptAction`, `checkAndGenerateNewLessonsAction`, and `processLessonRecordingAction` would need API Route equivalents (e.g., `GET /api/lessons`, `GET /api/lessons/{id}`, `POST /api/lessons/{id}/complete`, etc.).
    *   `createLessonAction` might be relevant if users can create custom content; otherwise, lesson generation is typically backend-driven.
*   **Learning Progress (`learning_progress-actions.ts`):**
    *   Actions like `getLearningProgressAction` and `getPracticeWordsAction` would need API Route wrappers to provide progress data to the Flutter app.
*   **Payments (`payment-actions.ts` - currently commented out):**
    *   If payment functionalities (e.g., `createCheckoutSessionAction`) are implemented, they would need API Route versions to initiate payment flows from the Flutter app.

### 5.3. Authentication and Authorization

*   **Client-Side Authentication:** The Flutter application should integrate the **Supabase Flutter SDK** to handle user sign-up, sign-in (email/password, Google OAuth), and session management directly with the Supabase authentication service.
*   **Token-Based API Authorization:**
    *   Upon successful authentication with Supabase, the Flutter app will receive a Supabase session token (JWT).
    *   This JWT **must be sent with every API request** from the Flutter app to the Next.js backend, typically in the `Authorization` header as a Bearer token (e.g., `Authorization: Bearer <SUPABASE_JWT>`).
*   **Backend Token Validation:**
    *   The Next.js API routes designed for Flutter consumption will need to be adapted to validate this incoming Supabase JWT.
    *   The current server-side Supabase client setup (`src/utils/supabase/server.ts`) and middleware (`src/middleware.ts`) are primarily configured for cookie-based sessions from web clients.
    *   A mechanism will be required in the backend (either in middleware or directly in API routes) to:
        1.  Extract the JWT from the `Authorization` header.
        2.  Verify the JWT using Supabase's libraries (e.g., `@supabase/supabase-js` can validate a JWT if configured correctly, or a dedicated Supabase Admin client might be used for server-to-server validation if necessary).
        3.  Establish user context for the request based on the validated token.

### 5.4. Data Exchange Format

**JSON (JavaScript Object Notation)** will be the primary data exchange format for both request payloads and response bodies between the Flutter application and the Next.js backend APIs.

### 5.5. Considerations for Flutter Integration

*   **API Versioning:** If significant divergence between web and mobile client needs is anticipated, implementing API versioning (e.g., prefixing routes with `/api/v1/...` or `/api/mobile/v1/...`) is advisable from the start to manage changes gracefully.
*   **Error Handling:** API routes should return clear, consistent, and machine-parsable error responses. This includes using standard HTTP status codes (e.g., 400 for bad requests, 401 for unauthorized, 403 for forbidden, 404 for not found, 500 for server errors) and providing JSON error objects with descriptive messages or error codes.
*   **Security:**
    *   **JWT Validation:** Rigorous validation of the Supabase JWT on all protected API routes is paramount.
    *   **Input Validation:** The backend must perform thorough validation on all data received from the Flutter app to prevent injection attacks and ensure data integrity.
    *   **HTTPS:** Communication between the Flutter app and the backend must be over HTTPS.
*   **Scalability:** The backend infrastructure (Next.js server, database, external AI services) must be designed and monitored to handle concurrent requests from both web and potentially a large number of mobile clients.
*   **Offline Support:** The current backend architecture is inherently online-dependent. Any offline capabilities (e.g., caching lessons, progress synchronization) would need to be implemented within the Flutter application itself, along with logic for data synchronization when connectivity is restored.

## 6. Flutter Frontend Integration

This section outlines how the provided Flutter application can be integrated with the "lessay" Next.js backend. The Flutter application has an existing structure with its own services, UI, and state management (Riverpod). Integration will primarily involve redirecting its backend calls to the Next.js API endpoints.

### 6.1. Core Principles for Integration

*   **API-Driven Communication:** The Flutter app will communicate with the Next.js backend by making HTTP requests to the API endpoints detailed in Section 5.
*   **Separate Codebases:** The Flutter frontend (Dart, Flutter widgets) and the Next.js web frontend (TypeScript, React components) are distinct. UI components are not directly portable. The Flutter app will maintain its own native UI.
*   **Shared Supabase Project:** To ensure a unified user base and authentication system, the Flutter app must be configured to use the same Supabase project as the Next.js web application.

### 6.2. Key Flutter Project Components for Backend Interaction

The existing Flutter project (`repomix-output.xml` for Flutter) contains several components that will be key to, or require modification for, backend integration:

*   **Configuration (`lib/config/`):**
    *   `config.dart`: The `Config().serverUrl` must be updated to point to the deployed URL of the Lessay Next.js backend API.
*   **API Client (`lib/core/http/api_client.dart`):**
    *   The existing `ApiClient` in Flutter can be used to make HTTP requests to the Next.js backend.
    *   It **must be modified** to include the Supabase JWT (obtained by the Flutter app after user authentication) in the `Authorization: Bearer <token>` header for all authenticated requests to the Next.js backend.
*   **Authentication (`lib/core/user/user_service.dart`, `lib/core/user/user_provider.dart`):**
    *   The Flutter `UserService` should utilize the **Supabase Flutter SDK** for all direct authentication operations (sign-up, sign-in with email/password, Google Sign-In, sign-out, session management).
    *   It should authenticate against the shared Supabase project.
    *   It should *not* attempt to call Next.js server actions or custom Next.js API routes for these primary authentication functions.
*   **Feature Services (Requiring significant refactoring):**
    *   Many services within the Flutter app (e.g., in `lib/features/learning/domain/services/`, `lib/voicer/services/`) currently appear to interact with other backend services (like `llaserver-jwxfjkmitq-uc.a.run.app` via `lib/core/api/services/voice_api_service.dart`) or might be set up for direct AI SDK calls (e.g., the commented-out `google_ai_api.dart`).
    *   These services need to be **rewired** to call the appropriate API routes on the Lessay Next.js backend. For instance:
        *   **Speech Analysis:** Flutter's `SpeechAnalysisService` (in `lib/voicer/services/`) and potentially `lib/features/learning/domain/services/speech_analysis_service.dart` must use the Flutter `ApiClient` to send audio data to the Next.js `/api/recording` endpoint (or new specific analysis endpoints like `/api/lessons/{id}/analyze-audio`) and receive structured analysis results.
        *   **Initial Assessment & Learning Path:** Flutter's `InitialAssessmentService` (`lib/features/learning/domain/services/initial_assesment_service.dart`) and `LearningPathService` (`lib/features/learning/domain/services/learning_path_service.dart`) should interact with new API routes on the Next.js backend that expose the logic from `OnboardingService.ts` and `LessonService.ts`.
        *   **Exercise Management:** Flutter's `ExerciseService` (`lib/features/learning/domain/services/exercise_service.dart`) would fetch exercise content and submit answers via new Next.js API routes.
        *   **Translation:** The `ApiTranslationService` in Flutter (`lib/features/translator/services/api_translation_service.dart`) currently uses `Config().serverUrl + /generateTranslation`. If this points to the old `llaserver`, it needs to be re-routed to a new translation endpoint on the Next.js backend (if this functionality is to be centralized).
*   **Repositories (`lib/features/learning/data/repositories/`, etc.):**
    *   Flutter repositories (like `HiveLearningPathRepository`, `HiveExerciseRepository`) currently manage local data persistence using Hive. While local caching is valuable, the primary source of truth for learning paths, generated exercises, and assessments should become the Next.js backend. These repositories might transition to primarily caching data fetched from the backend or managing offline queueing.
*   **Providers (Riverpod):**
    *   Riverpod providers (`learning_path_provider.dart`, `initial_assessment_provider.dart`, `translator_provider.dart`, `adaptive_exercises_provider.dart`, etc.) will manage the state within the Flutter app. They will trigger data fetching and updates by calling the refactored Flutter services, which in turn communicate with the Next.js backend.
*   **Models (`lib/features/**/models/`, `lib/voicer/models/`):**
    *   The Dart data models within the Flutter application (e.g., `SpeechAnalysisResponse`, `InitialAssessmentResponse`, `ExerciseModels`, `LearningPathModel`) must be aligned with the JSON request and response structures of the Next.js backend APIs. This might involve updating existing Dart models or creating new ones to accurately represent the data exchanged. The existing `SpeechAnalysisRequest` and `SpeechAnalysisResponse` in Flutter, for example, will need to match the API contract of the Next.js backend.

### 6.3. Authentication Flow in Flutter

1.  **Supabase Flutter SDK:** The Flutter app will use the official Supabase Flutter SDK for all authentication processes (sign-up, sign-in, OAuth, password recovery, sign-out).
2.  **Token Storage & Management:** The Supabase Flutter SDK will securely manage the user's session, including storing and refreshing JWTs on the device.
3.  **API Requests to Next.js Backend:** For authenticated requests to the Next.js backend API routes, the Flutter app must retrieve the current valid Supabase JWT from the SDK and include it in the `Authorization` header as a Bearer token: `Authorization: Bearer <SUPABASE_JWT>`.
4.  **Token Refresh:** The Supabase Flutter SDK handles automatic token refreshing. The Flutter `ApiClient` should be robust to potential 401 errors and perhaps trigger a token refresh and retry mechanism if appropriate, or rely on the SDK to manage this transparently before subsequent calls.

### 6.4. Data Flow Example: Performing an Assessment Step

1.  **User Interaction (Flutter UI):** The user interacts with an assessment screen in the Flutter app (e.g., a screen built from `InitialAssessmentScreen.dart` logic). They record their voice for a pronunciation task.
2.  **Audio Capture (Flutter):** The Flutter app captures the audio using device microphone capabilities (e.g., via `record` package as seen in `lib/voicer/services/recording_service.dart`).
3.  **Service Call (Flutter):** The relevant Flutter service (e.g., a refactored `InitialAssessmentService` or a dedicated `OnboardingService` client) is called with the captured audio data and context (assessment ID, step ID, language).
4.  **API Request (Flutter `ApiClient`):** The Flutter `ApiClient` constructs an HTTP `POST` request (likely `multipart/form-data` for audio) to a specific Next.js backend API endpoint (e.g., a new `/api/v1/onboarding/assessment/step/{step_id}/record` or similar, which would wrap the logic from `recordAssessmentStepAttemptAction` and `processAssessmentLessonRecordingAction`). The Supabase JWT is included in the `Authorization` header.
5.  **Backend Processing (Next.js):**
    *   The Next.js API route receives the request.
    *   It validates the Supabase JWT to authenticate the user.
    *   It calls the appropriate backend service (e.g., `OnboardingService.ts`).
    *   The service processes the audio (e.g., using `RecordingService.ts`, `STTService.ts`, `AIService.ts`), updates the database via its repository (`OnboardingRepository.ts`), and generates feedback.
    *   The backend returns a JSON response containing the analysis and feedback.
6.  **API Response (Flutter `ApiClient`):** The Flutter `ApiClient` receives the JSON response from the Next.js backend.
7.  **Data Parsing & State Update (Flutter):**
    *   The Flutter service parses the JSON response into the corresponding Dart data models.
    *   The relevant Riverpod provider (e.g., `initialAssessmentProvider`) updates its state with the new data.
8.  **UI Update (Flutter):** The Flutter UI widgets listening to the provider rebuild to display the feedback and assessment results to the user.

### 6.5. UI/UX Considerations for Flutter

*   **Native Experience:** The Flutter app will provide a user interface and experience tailored to mobile platforms (iOS and Android), which will be distinct from the web application's React-based UI.
*   **Platform-Specific Features:** Flutter allows leveraging native device features like advanced microphone controls, local notifications, haptic feedback, and platform-specific UI conventions (e.g., Cupertino widgets as seen in the codebase).
*   **State Management:** The Flutter app uses Riverpod (`flutter_riverpod` in `pubspec.yaml`) for state management, which is well-suited for managing the application's complex state, including asynchronous data from the backend.
*   **Local Data Persistence:** Hive (`hive`, `hive_flutter` in `pubspec.yaml`) is used for local data storage (e.g., user preferences, cached learning data, favorites, history). This can enhance offline capabilities and reduce redundant API calls.
*   **Asset Management:** Flutter uses its own asset management system (`assets/` folder in `pubspec.yaml`). Any visual assets (images, custom fonts) would be managed within the Flutter project.
*   **Navigation:** GoRouter (`go_router` in `pubspec.yaml`) is used for declarative routing within the Flutter app.


## 7. Backend API Development Plan for Flutter Support

To enable the Flutter application to fully interact with the Lessay platform, the following new API routes need to be developed in the Next.js backend. These routes will expose the necessary business logic currently handled by Server Actions or provide mobile-specific data views.

### 7.1. General API Design Principles

The new APIs developed for Flutter (and potentially other external clients) should adhere to the following principles:

*   **RESTful or Resource-Oriented:** Design endpoints around resources (e.g., `/profile`, `/lessons`, `/onboarding`). While not strictly REST in all cases (some actions are operations), aim for clear resource identification.
*   **Stateless & JWT Authenticated:** All protected endpoints must validate a Supabase JWT passed in the `Authorization: Bearer <token>` header. The server should not rely on session cookies for these APIs.
*   **JSON for Data Exchange:** Use JSON exclusively for request and response bodies.
*   **Standard HTTP Methods:** Utilize GET for retrieval, POST for creation, PUT for updates (or PATCH for partial updates), and DELETE for removal.
*   **Clear Error Responses:** Implement consistent error handling. Return appropriate HTTP status codes (e.g., 400, 401, 403, 404, 500) and include a JSON error object in the response body detailing the error.
*   **Idempotency:** Ensure PUT and DELETE operations are idempotent where applicable. POST operations for creation should typically return a 201 Created status with a Location header or the created resource.
*   **Data Validation:** Implement robust input validation on the backend for all data received from client applications to ensure data integrity and security.

### 7.2. Required API Endpoint Groups

The following groups of API endpoints are proposed, largely by exposing the functionalities of existing Server Actions:

*   **User Profile Management (Base: `/api/v1/profile`)**
    *   `GET /`: Get the current authenticated user's profile. (Wraps logic from `getUserProfileAction` in `user-actions.ts`)
    *   `POST /`: Create the current authenticated user's profile. This is typically used for initial setup after Supabase authentication if a profile doesn't exist. Should be idempotent. (Wraps logic from `createUserProfileAction`)
    *   `PUT /`: Update the current authenticated user's profile. (Wraps logic from `updateUserProfileAction`)
    *   `DELETE /`: Delete the current authenticated user's profile and their Supabase authentication account. (Wraps logic from `deleteUserProfileAction`)

*   **Onboarding & Initial Assessment (Base: `/api/v1/onboarding`)**
    *   `GET /status`: Get the current user's onboarding status, including native/target languages, proficiency, and initial assessment completion. (Combines logic from `getOnboardingAction` and `getStatusAction` in `onboarding-actions.ts`)
    *   `POST /steps/{stepName}`: Update the user's progress for a specific onboarding step (e.g., language selection, purpose). Request body would contain step-specific data. (Wraps logic from `updateOnboardingAction`)
    *   `POST /complete`: Mark the main onboarding flow (pre-assessment) as complete and trigger the generation of initial lessons. (Wraps logic from `markOnboardingCompleteAndGenerateInitialLessonsAction`)
    *   `GET /assessment`: Get the structure and current state of the user's initial assessment lesson. If one doesn't exist, it might trigger its generation. (Wraps logic from `getAssessmentLessonAction`)
    *   `POST /assessment/steps/{stepId}/attempt`: Submit a user's response for a specific assessment step and get immediate feedback/next step. (Wraps logic from `recordAssessmentStepAttemptAction`)
    *   `POST /assessment/complete`: Signal that the user has completed all interactive parts of the assessment, triggering final result calculation and summary generation. (Wraps logic from `completeAssessmentLessonAction`)
    *   `POST /assessment/audio`: Submit the full audio recording of an assessment session for detailed backend analysis (e.g., `AudioMetrics`). (Wraps logic from `processAssessmentLessonRecordingAction`)

*   **Lessons (Base: `/api/v1/lessons`)**
    *   `GET /`: Retrieve a list of all lessons available to the current user. (Wraps logic from `getLessonsAction` in `lesson-actions.ts`)
    *   `GET /{lessonId}`: Fetch details for a specific lesson by its ID. (Wraps logic from `getLessonByIdAction`)
    *   `POST /{lessonId}/complete`: Mark a lesson as completed. The backend would calculate performance metrics based on attempts. (Wraps logic from `completeLessonAction`)
    *   `POST /{lessonId}/steps/{stepId}/attempt`: Submit a user's response for a specific lesson step. (Wraps logic from `recordStepAttemptAction`)
    *   `POST /{lessonId}/audio`: Submit the full audio recording of a lesson session for detailed `AudioMetrics` analysis. (Wraps logic from `processLessonRecordingAction`)
    *   `POST /check-generate`: Endpoint to check if new lessons should be generated based on progress, and trigger generation if conditions are met. (Wraps logic from `checkAndGenerateNewLessonsAction`)

*   **Learning Progress (Base: `/api/v1/progress`)**
    *   `GET /summary`: Get the user's overall learning progress summary, including proficiency, scores, strengths, and weaknesses. (Wraps logic from `getLearningProgressAction` in `learning_progress-actions.ts`)
    *   `GET /practice-words`: Retrieve a list of words/phrases the user needs to practice, based on their mastery levels. (Wraps logic from `getPracticeWordsAction`)

*   **Audio Processing (Existing Endpoints - Review for Flutter)**
    *   `POST /api/recording`: This existing endpoint is used by the web app for general audio analysis. The Flutter app might use this directly, or more context-specific endpoints (like `/api/v1/onboarding/assessment/audio` or `/api/v1/lessons/{lessonId}/audio`) might be preferred for better separation of concerns and contextual processing.
    *   `POST /api/tts`: This existing endpoint can be used by Flutter for Text-to-Speech generation.

### 7.3. Next Steps for Backend Development

The following high-level tasks would be required for @roo to implement the backend API support for the Flutter application:

1.  **Define DTOs (Data Transfer Objects):** For each API endpoint, clearly define the expected JSON request and response structures (schemas). These will form the contract between the Flutter app and the Next.js backend.
2.  **Implement API Routes:**
    *   Create new API route handlers under `src/app/api/v1/` (or a similar versioned path) for each of the endpoints listed above.
    *   These handlers will parse incoming requests, validate data, and call the appropriate existing service methods from `src/services/`.
3.  **Implement JWT Authentication:**
    *   Develop or integrate a robust mechanism within each new API route (or via a shared middleware for these routes) to:
        *   Extract the Supabase JWT from the `Authorization: Bearer <token>` header.
        *   Validate the token against Supabase to authenticate the user and retrieve their ID.
        *   Deny access if the token is missing, invalid, or expired.
4.  **Service Layer Interaction:** Ensure API routes correctly call the existing service methods, passing necessary parameters and handling their return values or errors.
5.  **Error Handling:** Implement consistent error handling within API routes. Catch errors from service calls and transform them into standardized JSON error responses with appropriate HTTP status codes.
6.  **Logging:** Add comprehensive logging within the API routes for request/response cycles, errors, and key operations.
7.  **Testing:**
    *   Write unit tests for any new logic within the API routes.
    *   Write integration tests to verify that the API routes correctly interact with services and that authentication/authorization works as expected.


    ### 6.6. Flutter Client Modification Plan Outline

Integrating the existing Flutter application with the new Next.js backend requires modifications to several key areas of the Flutter codebase. The following outlines the primary steps involved:

1.  **Configure API Client & Authentication:**
    *   Update Flutter's `.env` file to set `SERVER_URL` to the deployed URL of the Lessay Next.js backend API.
    *   Modify `lib/config/config.dart` to ensure it correctly loads this `SERVER_URL`.
    *   Enhance `lib/core/http/api_client.dart`:
        *   Integrate with the Supabase Flutter SDK to retrieve the current user's JWT.
        *   Automatically include the JWT in the `Authorization: Bearer <token>` header for all authenticated requests made to the Next.js backend.
        *   Improve error handling to parse JSON error responses from the Next.js API and throw appropriate `AppException`s (using `lib/core/exceptions/app_exception.dart` and `lib/core/services/error_handler_service.dart`).
    *   Verify or implement Supabase Flutter SDK initialization in `lib/main.dart` using the shared Supabase project credentials (same URL and Anon Key as the Next.js backend).
    *   (Recommended) Create or adapt an auth helper service (e.g., `lib/core/auth/supabase_auth_helper.dart` or adapt `lib/core/user/user_service.dart`) for centralized Supabase interactions, especially for JWT retrieval and direct Supabase authentication flows.

2.  **Refactor Feature Services:**
    *   Identify Flutter services in directories like `lib/features/**/services/` and `lib/voicer/services/` that currently interact with other backends (e.g., `llaserver-jwxfjkmitq-uc.a.run.app` via `lib/core/api/services/voice_api_service.dart`) or use mock data.
    *   Modify these services to use the updated Flutter `ApiClient` (from step 1) to call the newly created Next.js backend API routes (as defined in Section 7.2 of this document).
    *   Example: Flutter's `SpeechAnalysisService` in `lib/voicer/services/speech_analysis_service.dart` should be refactored to call the Next.js `/api/recording` endpoint (or a new dedicated analysis endpoint like `/api/v1/audio/analyze`) instead of `ApiVoiceService` pointing to `llaserver`. Similarly, services like `InitialAssessmentService` or `ExerciseService` will need to be updated.

3.  **Align Data Models:**
    *   Review and update Dart data models within the Flutter application (e.g., in `lib/features/**/models/`, `lib/voicer/models/`) to ensure they precisely match the JSON request and response structures (DTOs) of the Next.js backend APIs. This may involve modifying existing models or creating new ones.

4.  **Update State Management (Riverpod Providers):**
    *   Ensure Riverpod providers (e.g., in `lib/features/**/providers/`, `lib/voicer/providers/`) correctly trigger data fetching and state updates through the refactored Flutter services.
    *   Providers should manage loading, data, and error states based on responses received from the Next.js backend via the services and `ApiClient`.

5.  **Adapt UI Screens:**
    *   Modify Flutter UI screens (primarily within `lib/features/**/presentation/`) to consume data from Riverpod providers that are now powered by the Next.js backend.
    *   Ensure UI elements (buttons, forms) correctly trigger actions that call the refactored Flutter services, which in turn make authenticated API calls to the Next.js backend.

6.  **Review Local Data Persistence (Hive):**
    *   Evaluate how Hive is currently used for local data storage (e.g., via services like `lib/features/learn/services/deck/deck_localstorage_service.dart`, `lib/features/favorites/services/favorite_service.dart`, `lib/features/history/services/history_service.dart`, and repositories in `lib/features/learning/data/repositories/`).
    *   While local caching and offline support are valuable, the Next.js backend should become the primary source of truth for most dynamic and user-specific data (e.g., learning paths, assessment results, detailed progress).
    *   Adapt Hive usage primarily for caching fetched data to improve performance, managing user preferences that don't need to be server-synced constantly, or for basic offline support functionalities, rather than as a primary data store for server-authoritative data.
</file>

<file path="src/app/app/login/page.tsx">
'use client'

import { useState, useEffect } from 'react'
import { useRouter } from 'next/navigation'
import { useAuth } from '@/context/auth-context'
import logger from '@/utils/logger'
import { useAppInitializer } from '@/context/app-initializer-context' // Import the hook

export default function LoginPage() {
  const router = useRouter()
  const [email, setEmail] = useState('')
  const [password, setPassword] = useState('')
  const [isRegistering, setIsRegistering] = useState(false)
  const { login, register, error, loading: authActionLoading, user, clearError } = useAuth() // Renamed loading
  const { status: appInitializerStatus } = useAppInitializer(); // Get app initializer status

  // Determine overall loading state
  const isLoading = authActionLoading || appInitializerStatus === 'initializing';

  useEffect(() => {
    // Redirect logic remains the same, but might be handled by AppInitializer now
    if (user && appInitializerStatus === 'idle') { // Ensure initializer is idle before redirecting
      // Redirect logic is now primarily handled by AppInitializerProvider's redirection effect
      // router.push('/app/lessons'); // Keep this as a fallback? Or remove if initializer handles it reliably.
      logger.info("LoginPage: User exists and initializer idle, relying on AppInitializer for redirect.");
    }
  }, [user, appInitializerStatus, router])

  const handleLogin = async (e: React.FormEvent) => {
    e.preventDefault()
    clearError()
    // Prevent action if app is still initializing
    if (appInitializerStatus === 'initializing') {
      logger.warn("Login attempt blocked: App Initializer is still running.");
      // Optionally show a toast or message
      return;
    }
    try {
      await login(email, password)
      // Navigation is handled in the AuthContext or AppInitializer
    } catch (error: any) {
      logger.log('Login failed:', error)

      // Auto-registration logic remains
      if (error.message?.includes('Invalid login credentials') ||
        error.message?.includes('user not found')) {
        try {
          setIsRegistering(true)
          logger.log('Attempting to register instead...')
          await register(email, password)
          // Registration successful, navigation handled elsewhere
        } catch (registerError) {
          logger.log('Registration failed:', registerError)
          setIsRegistering(false)
        }
      }
    }
  }

  // const handleGoogleLogin = async () => {
  //   clearError()
  //   if (appInitializerStatus === 'initializing') {
  //       logger.warn("Google login attempt blocked: App Initializer is still running.");
  //       return;
  //   }
  //   try {
  //     await loginWithGoogle()
  //     // Redirect is handled by Supabase OAuth
  //   } catch (error) {
  //     logger.log('Google login failed:', error)
  //   }
  // }

  // Determine button text based on loading states
  let buttonText = 'Continue';
  if (appInitializerStatus === 'initializing') {
    buttonText = 'Initializing App...';
  } else if (authActionLoading) {
    buttonText = isRegistering ? 'Creating account...' : 'Signing in...';
  }

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 py-12 px-4 sm:px-6 lg:px-8">
      <div className="max-w-md w-full space-y-8">
        <div>
          <h2 className="mt-6 text-center text-3xl font-extrabold text-gray-900">
            {isRegistering ? 'Creating your account' : 'Sign in to your account'}
          </h2>
          {isRegistering && (
            <p className="mt-2 text-center text-sm text-gray-600">
              We&apos;re creating a new account for you...
            </p>
          )}
        </div>
        <form className="mt-8 space-y-6" onSubmit={handleLogin}>
          {error && (
            <div className="text-red-500 text-sm text-center">{error}</div>
          )}
          <div className="rounded-md shadow-sm -space-y-px">
            <div>
              <input
                type="email"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-t-md focus:outline-none focus:ring-primary focus:border-primary focus:z-10 sm:text-sm"
                placeholder="Email address"
                value={email}
                onChange={(e) => setEmail(e.target.value)}
                disabled={isLoading} // Use combined loading state
              />
            </div>
            <div>
              <input
                type="password"
                required
                className="appearance-none rounded-none relative block w-full px-3 py-2 border border-gray-300 placeholder-gray-500 text-gray-900 rounded-b-md focus:outline-none focus:ring-primary focus:border-primary focus:z-10 sm:text-sm"
                placeholder="Password"
                value={password}
                onChange={(e) => setPassword(e.target.value)}
                disabled={isLoading} // Use combined loading state
              />
            </div>
          </div>
          <div>
            <button
              type="submit"
              className="group relative w-full flex justify-center py-2 px-4 border border-transparent text-sm font-medium rounded-md text-white bg-black hover:bg-black/90 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary disabled:opacity-50"
              disabled={isLoading} // Use combined loading state
            >
              {/* Display text based on combined loading state */}
              {isLoading && appInitializerStatus === 'initializing' ? (
                <span className="flex items-center">
                  <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                    <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                    <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                  </svg>
                  {buttonText}
                </span>
              ) : isLoading ? (
                <span className="flex items-center">
                  <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                    <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                    <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                  </svg>
                  {buttonText}
                </span>
              ) : (
                buttonText
              )}
            </button>
          </div>

          {/* Google Login Button Placeholder */}
          {/* <div>
            <button
              type="button"
              onClick={handleGoogleLogin}
              className="w-full flex justify-center py-2 px-4 border border-gray-300 rounded-md shadow-sm text-sm font-medium text-gray-700 bg-white hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-primary"
              disabled={isLoading} // Use combined loading state
            >
              Sign in with Google
            </button>
          </div> */}

          <div className="text-sm text-center text-gray-600">
            Enter your email and password to continue. If you don&apos;t have an account yet, we&apos;ll create one for you.
          </div>
        </form>
      </div>
    </div>
  )
}
</file>

<file path="src/app/app/layout.tsx">
// src/app/app/layout.tsx
import { AuthProvider } from '@/context/auth-context';
import '@/app/globals.css';
import { Toaster } from '@/components/Toaster';
import { OnboardingProvider } from '@/context/onboarding-context';
import { LessonProvider } from '@/context/lesson-context';
import { UserProfileProvider } from '@/context/user-profile-context';
import { AppInitializerProvider } from '@/context/app-initializer-context';
import { ErrorProvider } from '@/hooks/useError'; // Assuming you have this
// import { PostHogProvider } from '@/context/posthog-context'; // Assuming you have this

export default function AdminLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    // Optional Utility Providers first
    <ErrorProvider>
      {/* <PostHogProvider> */}
      {/* Core Application Logic Providers */}
      <AuthProvider>
        <UserProfileProvider>
          <OnboardingProvider> {/* Provides isOnboardingComplete */}
            <AppInitializerProvider> {/* Needs Auth, Profile; Consumes Onboarding for redirection */}
              <LessonProvider> {/* Needs Auth, Onboarding, AppInitializer */}
                {/* The main content area */}
                <div className="min-h-screen bg-neutral-1">
                  <main>{children}</main>
                </div>
                <Toaster />
              </LessonProvider>
            </AppInitializerProvider>
          </OnboardingProvider>
        </UserProfileProvider>
      </AuthProvider>
      {/* </PostHogProvider> */}
    </ErrorProvider>
  );
}
</file>

<file path="src/components/lessons/ChatInput.tsx">
import React from 'react';

interface ChatInputProps {
  userResponse: string;
  isListening: boolean;
  feedback: string;
  onToggleListening: () => void;
  onSubmit: () => void;
  disableSubmit: boolean;
  onSkip: () => void;
  disableSkip: boolean;
  onUpdateResponse?: (text: string) => void;
}

const ChatInput = React.memo(function ChatInput({
  userResponse,
  isListening,
  feedback,
  onToggleListening,
  onSubmit,
  disableSubmit,
  disableSkip,
  onUpdateResponse,
  onSkip
}: ChatInputProps) {
  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    if (onUpdateResponse) {
      onUpdateResponse(e.target.value);
    }
  };

  return (
    <div className="border-t p-4 bg-white shrink-0">
      <div className="mb-4 min-h-[60px] p-2 border rounded-[4px] bg-neutral-2">
        {onUpdateResponse ? (
          <textarea 
            value={userResponse}
            onChange={handleTextChange}
            className="w-full h-full min-h-[60px] bg-transparent resize-none focus:outline-none"
            data-testid="text-input" 
            placeholder={isListening ? 'Listening...' : 'Ready to listen'}
          />
        ) : (
          <div>{userResponse || (isListening ? 'Listening...' : 'Ready to listen')}</div>
        )}
      </div>
      {feedback && (
        <div className="text-sm text-neutral-11 mb-2">{feedback}</div>
      )}
      <div className="flex gap-2">
        <button
          type="button"
          onClick={onToggleListening}
          className={`flex-1 py-2 px-4 border border-transparent rounded-[4px] shadow-sm text-sm font-medium text-white ${
          isListening ? 'bg-accent-9 hover:bg-accent-10' : 'bg-accent-7 hover:bg-accent-8 disabled:opacity-50' // Add disabled style
         } ${disableSubmit ? 'opacity-50 cursor-not-allowed' : ''
          } focus:outline-none focus:ring-2 focus:ring-accent-8`}
        >
          {isListening ? 'Pause Listening' : 'Start Listening'}
        </button>
        <button
          type="button"
          onClick={onSkip}
          disabled={disableSkip}
          className="flex-1 py-2 px-4 border border-transparent rounded-[4px] shadow-sm text-sm font-medium text-white bg-neutral-12 hover:bg-neutral-11 focus:outline-none focus:ring-2 focus:ring-neutral-11 disabled:opacity-50"
        >
          Skip & Continue
        </button>
      </div>
    </div>
  );
});

export default ChatInput;
</file>

<file path="src/repositories/payment.repository.ts">
// // src/repositories/payment.repository.ts
// import { PaymentModel } from '@/models/AppAllModels.model';
// import prisma from '@/lib/prisma';
// import { PaymentStatus } from '@prisma/client';
// import logger from '@/utils/logger';

// export interface IPaymentRepository {
//   createPayment(data: {
//     userId: string;
//     amount: number;
//     currency: string;
//     productId?: string | null;
//     productType?: string | null;
//     status: PaymentStatus;
//     stripePaymentIntentId?: string | null;
//   }): Promise<PaymentModel>;

//   updatePayment(id: string, data: {
//     stripePaymentIntentId?: string;
//     status?: PaymentStatus;
//     errorMessage?: string | null;
//   }): Promise<PaymentModel>;

//   findPaymentById(id: string): Promise<PaymentModel | null>;

//   findPaymentByIntentId(stripePaymentIntentId: string): Promise<PaymentModel | null>;

// }


// export class PaymentRepository implements IPaymentRepository {

//   async createPayment(data: {
//     userId: string;
//     amount: number;
//     currency: string;
//     productId?: string | null;
//     productType?: string | null;
//     status: PaymentStatus;
//     stripePaymentIntentId?: string | null;
//   }): Promise<PaymentModel> {
//     try {
//       const payment = await prisma.payment.create({
//         data: {
//           userId: data.userId,
//           amount: data.amount,
//           currency: data.currency,
//           productId: data.productId,
//           productType: data.productType,
//           status: data.status,
//           stripePaymentIntentId: data.stripePaymentIntentId || null,
//         },
//       });
//       return payment;
//     } catch (error) {
//       logger.error('Error creating payment record in repository:', error);
//       throw error;
//     }
//   }

//   async updatePayment(id: string, data: {
//     stripePaymentIntentId?: string;
//     status?: PaymentStatus;
//     errorMessage?: string | null;
//   }): Promise<PaymentModel> {
//     try {
//       const payment = await prisma.payment.update({
//         where: { id },
//         data: {
//           stripePaymentIntentId: data.stripePaymentIntentId,
//           status: data.status,
//           errorMessage: data.errorMessage,
//           // Ensure updatedAt is handled automatically by Prisma or add manually if needed
//         },
//       });
//       return payment;
//     } catch (error) {
//       logger.error(`Error updating payment record ${id} in repository:`, error);
//       throw error;
//     }
//   }

//   async findPaymentById(id: string): Promise<PaymentModel | null> {
//     try {
//       const payment = await prisma.payment.findUnique({
//         where: { id },
//       });
//       return payment;
//     } catch (error) {
//       logger.error(`Error finding payment by ID ${id} in repository:`, error);
//       return null; // Or rethrow depending on desired error handling
//     }
//   }

//   async findPaymentByIntentId(stripePaymentIntentId: string): Promise<PaymentModel | null> {
//     try {
//       const payment = await prisma.payment.findUnique({
//         where: { stripePaymentIntentId },
//       });
//       return payment;
//     } catch (error) {
//       logger.error(`Error finding payment by Intent ID ${stripePaymentIntentId} in repository:`, error);
//       return null; // Or rethrow
//     }
//   }
// }
</file>

<file path="src/app/app/profile/page.tsx">
'use client'

import { useState, useEffect } from 'react'
import { useRouter } from 'next/navigation'
import { useAuth } from '@/context/auth-context'
import { useUserProfile } from '@/context/user-profile-context'
import { deleteUserProfileAction } from '@/lib/server-actions/user-actions'
import logger from '@/utils/logger'
import { Button } from '@/components/ui/button'
import {
  AlertDialog,
  AlertDialogAction,
  AlertDialogCancel,
  AlertDialogContent,
  AlertDialogDescription,
  AlertDialogFooter,
  AlertDialogHeader,
  AlertDialogTitle,
  AlertDialogTrigger,
} from "@/components/ui/alert-dialog"
import { getLearningProgressAction } from '@/lib/server-actions/learning_progress-actions'
import { ProficiencyLevel } from '@prisma/client'
import { LearningProgressModel } from '@/models/AppAllModels.model'

export default function ProfilePage() {
  const router = useRouter()
  const { user, logout, loading: authLoading } = useAuth()
  const { profile, loading: profileLoading, error: profileError } = useUserProfile()
  const [isDeleting, setIsDeleting] = useState(false)
  const [deleteError, setDeleteError] = useState<string | null>(null)
  const [learningProgress, setLearningProgress] = useState<LearningProgressModel | null>(null)
  const [progressLoading, setProgressLoading] = useState(true)
  const [isLoggingOut, setIsLoggingOut] = useState(false);

  const handleDeleteAccount = async () => {
    if (!user) {
      setDeleteError("You must be logged in to delete your account.");
      return;
    }

    setIsDeleting(true);
    setDeleteError(null);
    logger.warn(`User ${user.id} confirmed account deletion.`);

    try {
  
      await deleteUserProfileAction();
      // Call logout, which now handles the redirect internally
      await logout();
    } catch (error: any) { // Catch specific errors if needed
      logger.error(`Unexpected error during account deletion for user ${user.id}:`, error);
   
      setDeleteError(error.message || 'An unexpected error occurred. Please try again.');
    } finally {
      setIsDeleting(false);
    }
  }



 const handleLogout = async () => {
   setIsLoggingOut(true);
   try {
     await logout();
     // Auth context listener should handle redirect to /app/login
     // router.push('/app/login'); // Explicit push is likely redundant
   } catch (error) {
     logger.error('Logout failed on profile page:', error);
     // Error should be handled by AuthContext's toast
   } finally {
     setIsLoggingOut(false);
   }
 }

  useEffect(() => {
    const fetchProgress = async () => {
      if (user?.id) {
        try {
          const progress = await getLearningProgressAction(user.id)
          setLearningProgress(progress)
        } catch (error) {
          logger.error('Error loading learning progress:', error)
        } finally {
          setProgressLoading(false)
        }
      }
    }
    fetchProgress()
  }, [user?.id])

  // Helper to calculate proficiency progress
  const getProficiencyProgress = (level: ProficiencyLevel) => {
    switch(level) {
      case ProficiencyLevel.beginner: return 33
      case ProficiencyLevel.intermediate: return 66
      case ProficiencyLevel.advanced: return 100
      default: return 0
    }
  }

  if (profileLoading) {
    return <div className="p-4">Loading profile...</div>
  }

  if (profileError) {
    return <div className="p-4 text-red-600">Error loading profile: {profileError}</div>
  }

  if (!profile) {
    // This might happen briefly or if there's an issue creating the profile initially
    return <div className="p-4">Profile not found.</div>
  }

  return (
    <div className="container mx-auto p-4 md:p-8">
      <div className="flex justify-between items-center mb-6">
        <h1 className="text-2xl font-bold">User Profile</h1>
        <Button
          variant="outline"
          onClick={() => router.push('/app/lessons')}
        >
          Back to Lessons
        </Button>
      </div>

      <div className="bg-white shadow rounded-lg p-6 mb-6">
        <h2 className="text-xl font-semibold mb-4">Account Information</h2>
        <div className="space-y-2">
          <p><strong>Email:</strong> {profile.email}</p>
          <p><strong>Name:</strong> {profile.name || 'Not set'}</p>
          {/* Add other profile details here if needed */}
          <p><strong>User ID:</strong> {profile.userId}</p>
          <p><strong>Joined:</strong> {new Date(profile.createdAt).toLocaleDateString()}</p>
        </div>

      {/* --- Add Logout Button Section --- */}
      <div className="bg-white shadow rounded-lg p-6 mb-6">
        <h2 className="text-xl font-semibold mb-4">Account Actions</h2>
        <Button
          variant="outline"
          onClick={handleLogout}
          disabled={authLoading || isLoggingOut} // Disable while auth is loading or logging out
        >
          {isLoggingOut ? 'Logging out...' : 'Logout'}
        </Button>
      </div>
      </div>

      <div className="bg-white shadow rounded-lg p-6 mb-6">
        <h2 className="text-xl font-semibold mb-4">Learning Progress</h2>
        {progressLoading ? (
          <div className="animate-pulse space-y-4">
            <div className="h-4 bg-gray-200 rounded w-1/2"></div>
            <div className="h-4 bg-gray-200 rounded"></div>
            <div className="h-4 bg-gray-200 rounded"></div>
          </div>
        ) : learningProgress ? (
          <div className="space-y-4">
            <div>
              <div className="flex justify-between mb-1">
                <span className="text-sm font-medium">Proficiency Level</span>
                <span className="text-sm text-gray-500">
                  {learningProgress.estimatedProficiencyLevel}
                </span>
              </div>
              <div className="w-full bg-gray-200 rounded-full h-2.5">
                <div 
                  className="bg-blue-600 rounded-full h-2.5" 
                  style={{ width: `${getProficiencyProgress(learningProgress.estimatedProficiencyLevel)}%` }}
                ></div>
              </div>
            </div>

            {learningProgress.overallScore !== null && (
              <div>
                <div className="flex justify-between mb-1">
                  <span className="text-sm font-medium">Overall Score</span>
                  <span className="text-sm text-gray-500">
                    {learningProgress.overallScore}%
                  </span>
                </div>
                <div className="w-full bg-gray-200 rounded-full h-2.5">
                  <div 
                    className="bg-green-600 rounded-full h-2.5" 
                    style={{ width: `${learningProgress.overallScore}%` }}
                  ></div>
                </div>
              </div>
            )}

            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
              <div className="p-4 bg-blue-50 rounded-lg">
                <h3 className="font-semibold mb-2 text-blue-800">Strengths</h3>
                {learningProgress.strengths?.length > 0 ? (
                  <ul className="list-disc pl-4 space-y-1">
                    {learningProgress.strengths.map((strength: string, index: number) => (
                      <li key={index} className="text-sm text-blue-700">{strength}</li>
                    ))}
                  </ul>
                ) : (
                  <p className="text-sm text-gray-500">No strengths recorded yet</p>
                )}
              </div>

              <div className="p-4 bg-orange-50 rounded-lg">
                <h3 className="font-semibold mb-2 text-orange-800">Areas to Improve</h3>
                {learningProgress.weaknesses?.length > 0 ? (
                  <ul className="list-disc pl-4 space-y-1">
                    {learningProgress.weaknesses.map((weakness: string, index: number) => (
                      <li key={index} className="text-sm text-orange-700">{weakness}</li>
                    ))}
                  </ul>
                ) : (
                  <p className="text-sm text-gray-500">No weaknesses recorded yet</p>
                )}
              </div>
            </div>
          </div>
        ) : (
          <p className="text-gray-500">No learning progress data available</p>
        )}
      </div>

      <div className="bg-red-50 border border-red-200 shadow rounded-lg p-6">
        <h2 className="text-xl font-semibold text-red-800 mb-4">Danger Zone</h2>
        <p className="text-red-700 mb-4">
          Deleting your account is permanent and cannot be undone. All your learning progress,
          lesson history, and personal data associated with this account will be permanently removed.
        </p>

        {deleteError && (
          <div className="mb-4 p-3 bg-red-100 text-red-700 border border-red-300 rounded">
            {deleteError}
          </div>
        )}

        <AlertDialog>
          <AlertDialogTrigger asChild>
            <Button
              variant="destructive"
              disabled={isDeleting}
            >
              {isDeleting ? 'Deleting...' : 'Delete My Account'}
            </Button>
          </AlertDialogTrigger>
          <AlertDialogContent>
            <AlertDialogHeader>
              <AlertDialogTitle>Are you absolutely sure?</AlertDialogTitle>
              <AlertDialogDescription>
                This action cannot be undone. This will permanently delete your
                account and remove all your data from our servers.
              </AlertDialogDescription>
            </AlertDialogHeader>
            <AlertDialogFooter>
              <AlertDialogCancel disabled={isDeleting}>Cancel</AlertDialogCancel>
              <AlertDialogAction
                onClick={handleDeleteAccount}
                disabled={isDeleting}
                className="bg-red-600 hover:bg-red-700" // Style confirmation button
              >
                {isDeleting ? 'Deleting...' : 'Yes, delete my account'}
              </AlertDialogAction>
            </AlertDialogFooter>
          </AlertDialogContent>
        </AlertDialog>

      </div>
    </div>
  )
}
</file>

<file path="src/context/user-profile-context.tsx">
'use client'
import { createContext, useContext, useEffect, useState, useCallback } from 'react';
import { useAuth } from '@/context/auth-context';
import { UserProfileModel } from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import {
  getUserProfileAction,
  createUserProfileAction,
  updateUserProfileAction,
} from '@/lib/server-actions/user-actions';
import { SubscriptionStatus } from '@prisma/client';
import { Result } from '@/lib/server-actions/_withErrorHandling'; // Import Result type

interface UserProfileContextType {
  profile: UserProfileModel | null;
  loading: boolean;
  error: string | null;
  updateProfile: (data: Partial<UserProfileModel>) => Promise<void>;
  // saveInitialProfile is removed as creation is handled within fetchUserProfile
  clearError: () => void;
  hasActiveSubscription: () => boolean;
}

const UserProfileContext = createContext<UserProfileContextType | undefined>(
  undefined
);

export function UserProfileProvider({
  children,
}: {
  children: React.ReactNode;
}) {
  const { user, loading: authLoading } = useAuth();
  const [profile, setProfile] = useState<UserProfileModel | null>(null);
  const [loading, setLoading] = useState<boolean>(false); // Tracks profile-specific loading
  const [error, setError] = useState<string | null>(null);

  // Helper to call server actions and handle loading/errors for this context
  const callUserAction = useCallback(async <T,>(
    action: () => Promise<Result<T>>,
  ): Promise<Result<T>> => {
    setLoading(true);
    setError(null);
    try {
      const result = await action();
      if (result.error) {
        setError(result.error);
        logger.error('User action failed:', result.error);
      }
      return result;
    } catch (err: any) {
      const message = err.message || 'An unexpected error occurred during user action.';
      setError(message);
      logger.error('Unexpected error in callUserAction:', err);
      return { error: message }; // Return error structure
    } finally {
      setLoading(false);
    }
  }, []); // No external dependencies needed for this helper


  // Load user profile when auth user changes
  useEffect(() => {
    const fetchUserProfile = async (userId: string, userEmail: string) => {
      logger.info(`UserProfileProvider: Fetching profile for user ${userId}`);
      const { data, error: fetchError } = await callUserAction(() => getUserProfileAction(userId));

      if (fetchError) {
        // Error already logged by callUserAction
        setProfile(null); // Clear profile on error
        return; // Stop processing
      }

      if (data) {
        // Profile found
        setProfile(data);
        logger.info(`UserProfileProvider: Profile found for user ${userId}.`);
      } else {
        // Profile not found, attempt to create it
        logger.warn(`UserProfileProvider: Profile not found for user ${userId}, attempting creation.`);
        const { data: createdData, error: createError } = await callUserAction(() =>
          createUserProfileAction({ userId, email: userEmail })
        );

        if (createError) {
          // Error already logged by callUserAction
          setError(`Failed to create profile: ${createError}`); // Set specific error
          setProfile(null);
        } else if (createdData) {
          setProfile(createdData);
          logger.info(`UserProfileProvider: Profile created successfully for user ${userId}.`);
        } else {
          // This case indicates a problem with createUserProfileAction if no data/error returned
          logger.error(`UserProfileProvider: createUserProfileAction returned no data and no error for user ${userId}.`);
          setError('Failed to create or retrieve profile.');
          setProfile(null);
        }
      }
    };

    // Don't do anything until auth is settled
    if (authLoading) {
      setLoading(true); // Reflect that we are waiting for auth before fetching profile
      return;
    };

    if (user?.id && user.email) {
      // Only set loading true when we actually start fetching/creating
      setLoading(true);
      fetchUserProfile(user.id, user.email);
    } else {
      // No user, clear profile state
      setProfile(null);
      setError(null);
      setLoading(false); // Ensure loading is false if no user
    }
  }, [user, authLoading, callUserAction]); // Depend on user and authLoading


  // Update profile function
  const updateProfile = async (data: Partial<UserProfileModel>) => {
    if (!profile || !user?.id) {
      setError('No profile to update or user not authenticated');
      return;
    }

    const { subscriptionStatus, subscriptionEndDate, ...updateData } = data; // Exclude read-only fields
    if (Object.keys(updateData).length === 0) {
      logger.warn('updateProfile called with no updatable fields.');
      return;
    }

    const { data: updated, error: updateError } = await callUserAction(() =>
      updateUserProfileAction(user.id!, updateData) // Use non-null assertion for user.id
    );

    if (!updateError && updated) {
      setProfile(updated); // Update local state on success
      logger.info(`Profile updated successfully for user ${user.id}.`);
    }
    // Error is handled by callUserAction
  };

  // Helper function to check subscription status
  const hasActiveSubscription = (): boolean => {
    if (!profile) return false;
    const isActive = profile.subscriptionStatus === SubscriptionStatus.ACTIVE;
    const isTrial = profile.subscriptionStatus === SubscriptionStatus.TRIAL;
    const now = new Date();
    const endDate = profile.subscriptionEndDate ? new Date(profile.subscriptionEndDate) : null;
    const hasValidEndDate = endDate ? endDate > now : true;

    return (isActive || isTrial) && hasValidEndDate;
  };

  const clearError = () => setError(null);

  return (
    <UserProfileContext.Provider
      value={{
        profile,
        loading,
        error,
        updateProfile,
        // saveInitialProfile is removed
        hasActiveSubscription,
        clearError,
      }}
    >
      {children}
    </UserProfileContext.Provider>
  );
}

export const useUserProfile = () => {
  const context = useContext(UserProfileContext);
  if (context === undefined) {
    throw new Error('useUserProfile must be used within a UserProfileProvider');
  }
  return context;
};
// --- NEW CODE END ---
</file>

<file path="src/lib/server-actions/lesson-actions.ts">
'use server';

import LessonService from '@/services/lesson.service';
import { LessonRepository } from '@/repositories/lesson.repository';
import { LessonModel, LessonStep } from '@/models/AppAllModels.model';
import { OnboardingModel } from '@/models/AppAllModels.model';
import { MockLessonGeneratorService } from '@/__mocks__/generated-lessons.mock';
import { OnboardingRepository } from '@/repositories/onboarding.repository';
import logger from '@/utils/logger';
import LessonGeneratorService from '@/services/lesson-generator.service';
import AIService from '@/services/ai.service';
import { GoogleTTS } from '@/services/google-tts.service';
import { uploadFile } from '@/utils/vercel_blob-upload';
import { withServerErrorHandling, Result } from './_withErrorHandling'
import { revalidatePath } from 'next/cache';

// TODO: Convert to container
function createLessonService() {
  const repository = new LessonRepository();
  return new LessonService(
    repository,
    new LessonGeneratorService(new AIService(), new GoogleTTS(), uploadFile),
    new OnboardingRepository()
  );
}

export async function getLessonsAction(): Promise<Result<LessonModel[]>> {
  return withServerErrorHandling(async () => {
    const svc = createLessonService()
    return await svc.getLessons()
  })
}

export async function getLessonByIdAction(lessonId: string): Promise<Result<LessonModel | null>> {
  return withServerErrorHandling(async () => {
    if (!lessonId) throw new Error('Lesson ID is required');
    const svc = createLessonService();
    return await svc.getLessonById(lessonId);
  });
}

export async function createLessonAction(data: {
  focusArea: string;
  targetSkills: string[];
  steps: LessonStep[];
}): Promise<Result<LessonModel>> {
  return withServerErrorHandling(async () => {
    if (!data.focusArea || !data.targetSkills.length || !data.steps.length) {
      throw new Error('All lesson data is required');
    }
    const svc = createLessonService();
    return await svc.createLesson(data);
  });
}

export async function updateLessonAction(
  lessonId: string,
  lessonData: Partial<LessonModel>
): Promise<Result<LessonModel>> {
  return withServerErrorHandling(async () => {
    if (!lessonId) throw new Error('Lesson ID is required');
    const svc = createLessonService();
    return await svc.updateLesson(lessonId, lessonData);
  });
}

export async function completeLessonAction(
  lessonId: string
): Promise<Result<LessonModel>> {
  return withServerErrorHandling(async () => {
    if (!lessonId) throw new Error('Lesson ID is required');
    const svc = createLessonService();
    return await svc.completeLesson(lessonId);
  });
}

export async function deleteLessonAction(lessonId: string): Promise<Result<null>> {
  return withServerErrorHandling(async () => {
    if (!lessonId) throw new Error('Lesson ID is required');
    const svc = createLessonService();
    await svc.deleteLesson(lessonId);
    return null;
  });
}

export async function generateInitialLessonsAction(): Promise<Result<LessonModel[]>> {
  return withServerErrorHandling(async () => {
    logger.info('generateInitialLessonsAction: Triggered.');
    const lessonService = createLessonService();
    const generatedLessons = await lessonService.generateInitialLessons();
    logger.info(`generateInitialLessonsAction: Generated ${generatedLessons.length} lessons.`);
    return generatedLessons;
  });
}

export async function recordStepAttemptAction(
  lessonId: string,
  stepId: string,
  userResponse: string
): Promise<Result<LessonStep>> {
  return withServerErrorHandling(async () => {
    if (!lessonId || !stepId) throw new Error('Lesson ID and Step ID are required');
    const svc = createLessonService();
    return await svc.recordStepAttempt(lessonId, stepId, userResponse);
  });
}

export async function getStepHistoryAction(
  lessonId: string,
  stepId: string
): Promise<Result<LessonStep[]>> {
  return withServerErrorHandling(async () => {
    if (!lessonId || !stepId) {
      throw new Error('Lesson ID and Step ID are required');
    }
    const svc = createLessonService();
    return await svc.getStepHistory(lessonId, stepId);
  });
}

export async function generateNewLessonsAction(): Promise<Result<LessonModel[]>> {
  return withServerErrorHandling(async () => {
    const svc = createLessonService();
    return await svc.generateNewLessonsBasedOnProgress();
  });
}

export async function checkAndGenerateNewLessonsAction(): Promise<Result<LessonModel[]>> {
  return withServerErrorHandling(async () => {
    const svc = createLessonService();
    const newLessons = await svc.checkAndGenerateNewLessons();
    // Revalidate the lessons page path to show new lessons
    revalidatePath('/app/lessons');
    return newLessons;
  });
}

export async function processLessonRecordingAction(
  sessionRecording: Blob,
  recordingTime: number,
  recordingSize: number,
  lesson: LessonModel
): Promise<Result<LessonModel>> {
  return withServerErrorHandling(async () => {
    validateLessonRecording(sessionRecording, recordingTime, recordingSize, lesson);
    const svc = createLessonService();
    return await svc.processLessonRecording(
      sessionRecording,
      recordingTime,
      recordingSize,
      lesson
    );
  });
}

function validateLessonRecording(
  sessionRecording: Blob,
  recordingTime: number,
  recordingSize: number,
  lesson: LessonModel
) {
  if (!sessionRecording) {
    throw new Error('No session recording provided');
  }
  if (!lesson) {
    throw new Error('No lesson provided');
  }
  if (!recordingTime) {
    throw new Error('No recording time provided');
  }
  if (!recordingSize) {
    throw new Error('No recording size provided');
  }
}
</file>

<file path="tests/servises/onboarding-ui.test.tsx">
// File: /tests/components/onboarding/AssessmentStep.test.tsx

import React from 'react';
import { render, screen, waitFor, act } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import '@testing-library/jest-dom';

import AssessmentStep from '@/components/onboarding/AssessmentStep';
import {
  AssessmentLesson,
  AudioMetrics,
  isAssessmentMetrics,
  LessonStep, // Import LessonStep if used in handleStepComplete type
  AssessmentStep as AssessmentStepModel, // Alias to avoid naming conflict
} from '@/models/AppAllModels.model';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import { toast } from 'react-hot-toast';
import logger from '@/utils/logger';

// --- Mocks ---

// Mock useOnboarding hook
const mockRecordAssessmentStepAttempt = jest.fn();
jest.mock('@/context/onboarding-context', () => ({
  useOnboarding: () => ({
    recordAssessmentStepAttempt: mockRecordAssessmentStepAttempt,
  }),
}));

// Mock LessonChat component
jest.mock('@/components/lessons/lessonChat', () => {
  // eslint-disable-next-line react/display-name
  return ({ onComplete, onStepComplete, loading, lesson }: any) => (
    <div data-testid="lesson-chat">
      <button
        onClick={() => onStepComplete(lesson.steps[0], 'User step response')}
      >
        Complete Step
      </button>
      <button
        onClick={() => {
          // Create the actual Blob
          const baseBlob = new Blob(['mockaudio'], { type: 'audio/webm' });
          // Create the RecordingBlob object
          const mockRecordingBlob = Object.assign(baseBlob, {
            recordingTime: 5678,
          }) as RecordingBlob;
          // Pass the RecordingBlob instance
          onComplete(mockRecordingBlob);
        }}
      >
        Complete Lesson Chat
      </button>
      <div>Loading: {loading ? 'true' : 'false'}</div>
      <div>Lesson ID: {lesson?.id}</div>
    </div>
  );
});


const mockToastFunctions = {
  error: jest.fn(),
  success: jest.fn(),
  loading: jest.fn(),
  custom: jest.fn(),
  dismiss: jest.fn(),
  remove: jest.fn(),
  promise: jest.fn(),
};

// Mock logger
jest.mock('@/utils/logger', () => ({
  log: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  info: jest.fn(),
}));

// Mock toast
jest.mock('react-hot-toast', () => ({
  __esModule: true,
  default: {
    error: jest.fn(),
  },
}));


// --- Test Data ---

const mockBaseLesson: AssessmentLesson = {
  id: 'assess-test-1',
  userId: 'user-test-1',
  description: 'Test Assessment',
  completed: false,
  sourceLanguage: 'English',
  targetLanguage: 'German',
  metrics: null,
  audioMetrics: null,
  proposedTopics: [],
  summary: null,
  steps: [
    {
      id: 'step-1',
      assessmentId: 'assess-test-1',
      stepNumber: 1,
      type: 'instruction',
      content: 'Welcome',
      maxAttempts: 1,
      attempts: 0,
      correct: false,
      feedback: null,
      createdAt: new Date(),
      updatedAt: new Date(),
      contentAudioUrl: null,
      expectedAnswer: null,
      expectedAnswerAudioUrl: null,
      translation: null,
      userResponse: null,
      userResponseHistory: null,
      lastAttemptAt: null, // Added missing property
    },
  ],
  createdAt: new Date(),
  updatedAt: new Date(),
  sessionRecordingUrl: null,
};

const mockTextMetrics = {
  accuracy: 80,
  pronunciationScore: 70,
  grammarScore: 85,
  vocabularyScore: 75,
  overallScore: 78,
  strengths: ['greetings'],
  weaknesses: ['verbs'],
};

const mockLessonWithTextMetrics: AssessmentLesson = {
  ...mockBaseLesson,
  completed: true,
  metrics: mockTextMetrics,
  summary: 'Good start.',
  proposedTopics: ['Topic 1'],
  // Ensure steps array is copied correctly
  steps: mockBaseLesson.steps.map(step => ({ ...step })),
};

const mockAudioMetricsData: AudioMetrics = {
  id: 'audio-m-1',
  pronunciationScore: 90,
  fluencyScore: 65,
  grammarScore: 85,
  vocabularyScore: 75,
  overallPerformance: 80,
  proficiencyLevel: 'A2',
  learningTrajectory: 'steady',
  pronunciationAssessment: {
    overall_score: 90,
    native_language_influence: { level: 'minimal', specific_features: [] },
    phoneme_analysis: [],
    problematic_sounds: ['ü'],
    strengths: ['clear vowels'],
    areas_for_improvement: ['ü sound'],
  },
  fluencyAssessment: {
    overall_score: 65,
    speech_rate: { words_per_minute: 90, evaluation: 'slow' },
    hesitation_patterns: {
      frequency: 'occasional',
      average_pause_duration: 1.2,
      typical_contexts: [],
    },
    rhythm_and_intonation: {
      naturalness: 60,
      sentence_stress_accuracy: 70,
      intonation_pattern_accuracy: 65,
    },
  },
  grammarAssessment: {
    overall_score: 85,
    error_patterns: [],
    grammar_rules_to_review: [],
    grammar_strengths: [],
  },
  vocabularyAssessment: {
    overall_score: 75,
    range: 'adequate',
    appropriateness: 70,
    precision: 65,
    areas_for_expansion: [],
  },
  exerciseCompletion: {
    overall_score: 0,
    exercises_analyzed: [],
    comprehension_level: 'fair',
  },
  suggestedTopics: [],
  grammarFocusAreas: [],
  vocabularyDomains: [],
  nextSkillTargets: [],
  preferredPatterns: [],
  effectiveApproaches: [],
  audioRecordingUrl: 'mock-url',
  recordingDuration: 5678,
  createdAt: new Date(),
  updatedAt: new Date(),
  // Add potentially missing relationship IDs if needed by component logic, though likely null here
  lessonId: null,
  assessmentLessonId: mockBaseLesson.id, // Link to assessment
};

const mockLessonWithAllMetrics: AssessmentLesson = {
  ...mockLessonWithTextMetrics,
  audioMetrics: mockAudioMetricsData,
  // Ensure steps array is copied correctly
  steps: mockLessonWithTextMetrics.steps.map(step => ({ ...step })),
};

// --- Test Suite ---

describe('AssessmentStep Component', () => {
  let mockOnAssessmentComplete: jest.Mock;
  let mockOnGoToLessonsButtonClick: jest.Mock;
  let mockProcessAssessmentLessonRecording: jest.Mock;

  beforeEach(() => {
    jest.clearAllMocks();
    mockOnAssessmentComplete = jest.fn();
    mockOnGoToLessonsButtonClick = jest.fn();
    // Mock the processing function - specific implementations per test
    mockProcessAssessmentLessonRecording = jest.fn();
 
  });

  it('renders initial loading state', () => {
    render(
      <AssessmentStep
        areMetricsGenerated={false}
        loading={true}
        targetLanguage="German"
        lesson={null}
        onAssessmentComplete={mockOnAssessmentComplete}
        onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
        processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
      />
    );
    expect(screen.getByText('Loading assessment...')).toBeInTheDocument();
  });

  it('renders LessonChat when lesson is loaded and not completed', () => {
    render(
      <AssessmentStep
        areMetricsGenerated={false}
        loading={false}
        targetLanguage="German"
        lesson={mockBaseLesson}
        onAssessmentComplete={mockOnAssessmentComplete}
        onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
        processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
      />
    );
    expect(screen.getByTestId('lesson-chat')).toBeInTheDocument();
    expect(
      screen.getByText(`Lesson ID: ${mockBaseLesson.id}`)
    ).toBeInTheDocument();
  });

  it('calls recordAssessmentStepAttempt when step is completed in LessonChat', async () => {
    // Mock the return value for the step attempt if needed by subsequent logic
    mockRecordAssessmentStepAttempt.mockResolvedValue({
        ...mockBaseLesson.steps[0],
        attempts: 1,
        userResponse: 'User step response',
        lastAttemptAt: new Date(),
    });

    render(
      <AssessmentStep
        areMetricsGenerated={false}
        loading={false}
        targetLanguage="German"
        lesson={mockBaseLesson}
        onAssessmentComplete={mockOnAssessmentComplete}
        onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
        processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
      />
    );

    await act(async () => {
      userEvent.click(screen.getByRole('button', { name: 'Complete Step' }));
    });

    await waitFor(() => {
      expect(mockRecordAssessmentStepAttempt).toHaveBeenCalledWith(
        mockBaseLesson.id,
        mockBaseLesson.steps[0].id,
        'User step response'
      );
    });

    await waitFor(() => {
      expect(mockRecordAssessmentStepAttempt).toHaveBeenCalledTimes(1);
    });
  });

  it('calls onAssessmentComplete and triggers audio processing on LessonChat completion automatically', async () => {
     // Mock the processing function to simulate delay and return the final lesson state
     mockProcessAssessmentLessonRecording.mockResolvedValue(mockLessonWithAllMetrics);

    render(
      <AssessmentStep
        areMetricsGenerated={false}
        loading={false}
        targetLanguage="German"
        lesson={mockBaseLesson} // Start with base lesson
        onAssessmentComplete={mockOnAssessmentComplete}
        onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
        processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
      />
    );

  });

  // it('renders "Analyzing responses..." when lesson is complete but metrics are not yet available', () => {
  //   const lessonJustCompleted = {
  //     ...mockBaseLesson,
  //     completed: true,
  //     metrics: null, // No text metrics yet
  //     // Ensure steps array is copied correctly
  //     steps: mockBaseLesson.steps.map(step => ({ ...step })),
  //   };
  //   render(
  //     <AssessmentStep
  //       areMetricsGenerated={false}
  //       loading={false}
  //       targetLanguage="German"
  //       lesson={lessonJustCompleted}
  //       onAssessmentComplete={mockOnAssessmentComplete}
  //       onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
  //       processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
  //     />
  //   );
  //   // The component uses showResults state, which depends on lesson.completed AND lesson.metrics
  //   // Since metrics are null, showResults should be false, leading to the "Analyzing..." view
  //   expect(screen.getByText('Analyzing your responses...')).toBeInTheDocument();
  //   expect(
  //     screen.getByText('Please wait while we process your assessment results.')
  //   ).toBeInTheDocument();
  //   // Ensure results view isn't shown
  //   expect(screen.queryByText('Assessment Results')).not.toBeInTheDocument();
  // });

  // it('renders results view with text metrics when available', () => {
  //   render(
  //     <AssessmentStep
  //       areMetricsGenerated={false}
  //       loading={false}
  //       targetLanguage="German"
  //       lesson={mockLessonWithTextMetrics} // Lesson now has text metrics
  //       onAssessmentComplete={mockOnAssessmentComplete}
  //       onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
  //       processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
  //     />
  //   );

  //   // Check for results view elements
  //   expect(screen.getByText('Assessment Results')).toBeInTheDocument();
  //   expect(screen.getByText('Summary')).toBeInTheDocument();
  //   expect(
  //     screen.getByText(mockLessonWithTextMetrics.summary!)
  //   ).toBeInTheDocument();
  //   expect(screen.getByText('Overall Score')).toBeInTheDocument();
  //   expect(
  //     screen.getByText(`${mockTextMetrics.overallScore}%`) // Check percentage rendering
  //   ).toBeInTheDocument();
  //   expect(screen.getByText('Accuracy')).toBeInTheDocument();
  //   expect(
  //     screen.getByText(`${mockTextMetrics.accuracy}%`)
  //   ).toBeInTheDocument();
  //    // Check other scores displayed
  //    expect(screen.getByText('Grammar')).toBeInTheDocument();
  //    expect(
  //      screen.getByText(`${mockTextMetrics.grammarScore}%`)
  //    ).toBeInTheDocument();
  //    expect(screen.getByText('Vocabulary')).toBeInTheDocument();
  //    expect(
  //      screen.getByText(`${mockTextMetrics.vocabularyScore}%`)
  //    ).toBeInTheDocument();
  //    expect(screen.getByText('Pronunciation (Initial)')).toBeInTheDocument();
  //    expect(
  //      screen.getByText(`${mockTextMetrics.pronunciationScore}%`)
  //    ).toBeInTheDocument();

  //   expect(screen.getByText('Strengths')).toBeInTheDocument();
  //   expect(screen.getByText(mockTextMetrics.strengths![0])).toBeInTheDocument();
  //   expect(screen.getByText('Areas for Improvement')).toBeInTheDocument();
  //   expect(
  //     screen.getByText(mockTextMetrics.weaknesses![0])
  //   ).toBeInTheDocument();
  //   expect(screen.getByText('Recommended Learning Topics')).toBeInTheDocument();
  //   expect(
  //     screen.getByText(mockLessonWithTextMetrics.proposedTopics[0])
  //   ).toBeInTheDocument();

  //   // Audio metrics section should NOT be present yet
  //   expect(
  //     screen.queryByText('Detailed Pronunciation & Fluency Analysis')
  //   ).not.toBeInTheDocument();
  //   // Check for the specific audio loading indicator - it shouldn't be there if not processing
  //   expect(
  //     screen.queryByText('Analyzing pronunciation and fluency...')
  //   ).not.toBeInTheDocument();
  // });

  // it('renders results view, shows audio loading, then shows audio metrics', async () => {
  //     // 1. Setup controllable mock for audio processing
  //     let resolveAudioProcessing: (value: AssessmentLesson) => void;
  //     const audioProcessingPromise = new Promise<AssessmentLesson>((resolve) => {
  //       resolveAudioProcessing = resolve;
  //     });
  //     mockProcessAssessmentLessonRecording.mockImplementation(() => {
  //       logger.info('Mock processAssessmentLessonRecording called, returning promise...');
  //       return audioProcessingPromise;
  //     });

  //     // 2. Setup state and mocks to simulate parent behavior
  //     let currentLessonState: AssessmentLesson | null = mockBaseLesson; // Start with base lesson

  //     // This mock simulates the parent calling completeAssessmentLessonAction,
  //     // getting text metrics back, and updating the lesson prop via rerender.
  //     const mockParentOnAssessmentComplete = jest.fn(async () => {
  //       logger.info('mockParentOnAssessmentComplete called. Updating lesson state to text metrics...');
  //       // IMPORTANT: Ensure the new state is a distinct object for React reconciliation
  //       currentLessonState = { ...mockLessonWithTextMetrics };
  //       rerenderComponent(); // Trigger rerender with the new lesson state
  //     });

  //     // Helper component to manage rerenders easily
  //     const TestComponent = () => (
  //       <AssessmentStep
  //         areMetricsGenerated={false}
  //         loading={false}
  //         targetLanguage="German"
  //         lesson={currentLessonState}
  //         onAssessmentComplete={mockParentOnAssessmentComplete} // Use the mock that triggers rerender
  //         onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
  //         processAssessmentLessonRecording={mockProcessAssessmentLessonRecording} // Use the controllable mock
  //       />
  //     );

  //     // Initial render with the base lesson (shows LessonChat)
  //     const { rerender } = render(<TestComponent />);
  //     const rerenderComponent = () => rerender(<TestComponent />); // Function to rerender with current state

  //     // 3. Simulate LessonChat completion
  //     expect(screen.getByTestId('lesson-chat')).toBeInTheDocument();
  //     await act(async () => {
  //       logger.info('Simulating click on "Complete Lesson Chat"');
  //       userEvent.click(screen.getByRole('button', { name: 'Complete Lesson Chat' }));
  //       // This click triggers AssessmentStep's handleComplete, which:
  //       // - Sets internal sessionRecording state
  //       // - Calls mockParentOnAssessmentComplete
  //       // mockParentOnAssessmentComplete then updates currentLessonState and calls rerenderComponent
  //     });

  //     // 4. Wait for the results view (with text metrics) to appear after rerender
  //     // The audio processing useEffect should also have been triggered by now.
  //     await waitFor(() => {
  //       expect(screen.getByText('Assessment Results')).toBeInTheDocument();
  //       expect(screen.getByText(`${mockTextMetrics.overallScore}%`)).toBeInTheDocument();
  //       expect(screen.queryByTestId('lesson-chat')).not.toBeInTheDocument();
  //       logger.info('Results view with text metrics rendered.');
  //     });

  //     // 5. Assert the audio loading indicator is now visible
  //     // This confirms the useEffect set lessonAudioMetricsLoading = true
  //     await waitFor(() => {
  //       expect(screen.getByText('Analyzing pronunciation and fluency...')).toBeInTheDocument();
  //       logger.info('Audio loading indicator ("Analyzing...") found.');
  //     });
  //     // Ensure detailed audio section isn't visible yet
  //     expect(screen.queryByText('Detailed Pronunciation & Fluency Analysis')).not.toBeInTheDocument();

  //     // 6. Simulate audio processing finishing by resolving the mock promise
  //     // AND simulate the parent updating the lesson prop with the *final* result
  //     await act(async () => {
  //       logger.info('Resolving audio processing promise and rerendering with all metrics...');
  //       // Simulate the async operation completing and returning the full lesson data
  //       resolveAudioProcessing(mockLessonWithAllMetrics);
  //       // Allow the promise resolution to propagate
  //       await Promise.resolve();
  //       // Simulate the parent component receiving the result and updating the lesson prop
  //       // IMPORTANT: Ensure the new state is a distinct object
  //       currentLessonState = { ...mockLessonWithAllMetrics };
  //       rerenderComponent();
  //     });

  //     // 7. Assert the final state: loading gone, audio metrics visible
  //     await waitFor(() => {
  //       // Loading indicator should disappear
  //       expect(screen.queryByText('Analyzing pronunciation and fluency...')).not.toBeInTheDocument();
  //       // Detailed audio section should now be visible
  //       expect(screen.getByText('Detailed Pronunciation & Fluency Analysis')).toBeInTheDocument();
  //       // Check for specific audio data
  //       expect(screen.getByText(`${mockAudioMetricsData.pronunciationScore}%`)).toBeInTheDocument(); // Check percentage rendering
  //       expect(screen.getByText(mockAudioMetricsData.proficiencyLevel)).toBeInTheDocument();
  //       // Check that text metrics are still there
  //       expect(screen.getByText(`${mockTextMetrics.overallScore}%`)).toBeInTheDocument(); // Check percentage rendering
  //       logger.info('Final state verified: Loading gone, audio metrics displayed.');
  //     });

  //      // 8. Verify mocks were called as expected
  //      expect(mockParentOnAssessmentComplete).toHaveBeenCalledTimes(1);
  //      expect(mockProcessAssessmentLessonRecording).toHaveBeenCalledTimes(1);
  //      // Verify the arguments passed to processAssessmentLessonRecording
  //      const expectedBlobSize = new Blob(['mockaudio']).size; // Size of the blob created in LessonChat mock
  //      expect(mockProcessAssessmentLessonRecording).toHaveBeenCalledWith(
  //         expect.any(Blob),
  //         // IMPORTANT: The effect runs *before* the parent rerenders with text metrics,
  //         // so it's called with the state *at that moment*, which is mockBaseLesson.
  //         mockBaseLesson,
  //         5678, // recordingTime from mock blob assignment in LessonChat mock
  //         expectedBlobSize
  //      );
  // });

  // it('calls onGoToLessonsButtonClick when the button is clicked', async () => {
  //   render(
  //     <AssessmentStep
  //     areMetricsGenerated={false}
  //       loading={false}
  //       targetLanguage="German"
  //       lesson={mockLessonWithAllMetrics} // Render directly in the final state
  //       onAssessmentComplete={mockOnAssessmentComplete}
  //       onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
  //       processAssessmentLessonRecording={mockProcessAssessmentLessonRecording}
  //     />
  //   );

  //   const goToLessonsButton = screen.getByRole('button', {
  //     name: 'Go to Lessons',
  //   });
  //   // Ensure the button is present and enabled in this state
  //   expect(goToLessonsButton).toBeInTheDocument();
  //   expect(goToLessonsButton).toBeEnabled();

  //   await act(async () => {
  //     userEvent.click(goToLessonsButton);
  //   });

  //   // Use waitFor to ensure the assertion runs after the click event is fully processed
  //   await waitFor(() => {
  //     expect(mockOnGoToLessonsButtonClick).toHaveBeenCalledTimes(1);
  //   });
  // });

  // Combined test for disabled button states

  // it('handles error during audio processing', async () => {
  //   // 1. Mock processing to reject
  //   const errorMsg = 'Audio processing failed!';
  //   mockProcessAssessmentLessonRecording.mockRejectedValue(new Error(errorMsg));

  //   // 2. Setup state and mocks for parent behavior
  //   let currentLessonState: AssessmentLesson | null = mockBaseLesson;
  //   const mockParentOnAssessmentComplete = jest.fn(async () => {
  //     currentLessonState = { ...mockLessonWithTextMetrics }; // Update with text metrics
  //     rerenderComponent(); // Rerender
  //   });

  //   const TestComponent = () => (
  //     <AssessmentStep
  //     areMetricsGenerated={false}
  //       loading={false}
  //       targetLanguage="German"
  //       lesson={currentLessonState}
  //       onAssessmentComplete={mockParentOnAssessmentComplete}
  //       onGoToLessonsButtonClick={mockOnGoToLessonsButtonClick}
  //       processAssessmentLessonRecording={mockProcessAssessmentLessonRecording} // Rejecting mock
  //     />
  //   );

  //   const { rerender } = render(<TestComponent />);
  //   const rerenderComponent = () => rerender(<TestComponent />);

  //   // 3. Simulate LessonChat completion (triggers internal state changes and effects)
  //   await act(async () => {
  //     userEvent.click(screen.getByRole('button', { name: 'Complete Lesson Chat' }));
  //   });

  //   // 4. Wait for results view (text metrics) to appear
  //   await waitFor(() => {
  //     expect(screen.getByText('Assessment Results')).toBeInTheDocument();
  //   });

  //   // 5. Wait for the error toast to be called
  //   // The internal useEffect runs, calls the rejecting mock, catches the error, and calls toast.error
  

  //   // 6. Assert final state after error
  //   // Loading indicator should not be present (or should disappear quickly)
  //   expect(screen.queryByText('Analyzing pronunciation and fluency...')).not.toBeInTheDocument();
  //   // Detailed audio section should NOT be rendered
  //   expect(screen.queryByText('Detailed Pronunciation & Fluency Analysis')).not.toBeInTheDocument();
  //   // Button should be enabled again after error handling completes
  //   const goToLessonsButton = screen.getByRole('button', { name: 'Go to Lessons' });
  //   expect(goToLessonsButton).toBeInTheDocument();
  //   expect(goToLessonsButton).toBeEnabled();
  //   // Ensure the rejecting mock was called
  //   expect(mockProcessAssessmentLessonRecording).toHaveBeenCalledTimes(1);
  // });
});
</file>

<file path="src/app/app/lessons/page.tsx">
'use client';

import { useRouter } from 'next/navigation';
import { useLesson } from '@/context/lesson-context';
import { useOnboarding } from '@/context/onboarding-context';
import { LessonModel } from '@/models/AppAllModels.model';
import HeaderWithProfile from '@/components/HeaderWithProfile';
import { useEffect, useState } from 'react';
import logger from '@/utils/logger';

export default function LessonsPage() {
  const router = useRouter();
  const { onboarding } = useOnboarding();
  const { lessons, loading, initialized, refreshLessons, isGeneratingInitial, error } = useLesson(); // Add isGeneratingInitial and error
  const [hasAttemptedRefetch, setHasAttemptedRefetch] = useState(false);

  const handleStartLesson = (lesson: LessonModel) => {
    router.push(`/app/lessons/${lesson.id}`);
  };

  // Effect to trigger refetch if initialized with no lessons (remains the same, but added isGeneratingInitial check)
  useEffect(() => {
    if (initialized && !loading && lessons.length === 0 && !hasAttemptedRefetch && !isGeneratingInitial) { // Don't refetch if generating
      logger.warn("LessonsPage: Initialized but no lessons found. Attempting refetch.");
      setHasAttemptedRefetch(true);
      refreshLessons().catch(err => {
        logger.error("LessonsPage: Error during automatic refetch:", err);
      });
    }
  }, [initialized, loading, lessons.length, hasAttemptedRefetch, refreshLessons, isGeneratingInitial]); // Add isGeneratingInitial

  // Initial loading state (before context is initialized or while generating)
  if (!initialized || isGeneratingInitial) {
    return (
      <div className="min-h-screen flex flex-col items-center justify-center bg-neutral-1">
        <div className="animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-accent-6 mb-4"></div>
        <p className="text-xl text-neutral-12">
          {isGeneratingInitial ? "Generating Your First Lessons..." : "Loading your learning plan..."}
        </p>
        <p className="text-sm text-neutral-8 mt-2">
          {isGeneratingInitial ? "This might take a moment..." : "Please wait..."}
        </p>
      </div>
    );
  }

  // Loading state (while fetching/refreshing after initialization)
  if (loading) {
    return (
      <div className="container mx-auto py-8 px-4 bg-neutral-1 min-h-screen">
        <HeaderWithProfile />
        <h1 className="text-3xl font-bold mb-8 text-neutral-12">Your Lessons</h1>
        <div className="text-center py-12 border rounded-[4px] p-8 bg-neutral-2">
          <div className="animate-spin rounded-full h-8 w-8 border-t-2 border-b-2 border-accent-6 mx-auto mb-4"></div>
          <h2 className="text-2xl font-bold mb-4 text-neutral-12">
            Loading Lessons...
          </h2>
          <p className="text-neutral-10">
            Please wait...
          </p>
        </div>
      </div>
    );
  }

  // Content rendering after loading/generation is complete
  return (
    <div className="container mx-auto py-8 px-4 bg-neutral-1 min-h-screen">
      <HeaderWithProfile />
      <h1 className="text-3xl font-bold mb-8 text-neutral-12">Your Lessons</h1>

      {/* Handle potential errors during fetch/generation */}
      {error && !loading && !isGeneratingInitial && (
        <div className="text-center py-12 border border-red-300 rounded-[4px] p-8 bg-red-50 text-red-700">
          <h2 className="text-2xl font-bold mb-4">
            Oops! Something went wrong.
          </h2>
          <p className="mb-6">
            {error}
          </p>
          <button
            onClick={() => {
              setHasAttemptedRefetch(false); // Allow manual refresh to try again
              refreshLessons();
            }}
            className="px-4 py-2 bg-red-600 text-white rounded-[4px] hover:bg-red-700 text-sm"
            disabled={loading || isGeneratingInitial} // Disable while loading/generating
          >
            {loading ? "Retrying..." : "Try Again"}
          </button>
        </div>
      )}

      {/* Handle case where no lessons exist AND no error occurred */}
      {!error && lessons.length === 0 && !loading && !isGeneratingInitial ? (
        <div className="text-center py-12 border rounded-[4px] p-8 bg-neutral-2">
          <h2 className="text-2xl font-bold mb-4 text-neutral-12">
            No Lessons Found Yet
          </h2>
          <p className="text-neutral-10 mb-6">
            It seems your initial lessons haven&apos;t been generated or loaded correctly.
          </p>
          <button
            onClick={() => {
              setHasAttemptedRefetch(false); // Allow manual refresh to try again
              refreshLessons();
            }}
            className="px-4 py-2 bg-accent-6 text-white rounded-[4px] hover:bg-accent-7 text-sm"
            disabled={loading || isGeneratingInitial} // Disable while loading/generating
          >
            {loading ? "Refreshing..." : "Try Refreshing"}
          </button>
          <p className="text-xs text-neutral-8 mt-4">
            If the problem persists after refreshing, please contact support.
          </p>
        </div>
      ) : null}

      {/* Display lessons if they exist and there's no error */}
      {!error && lessons.length > 0 && !loading && !isGeneratingInitial ? (
        <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
          {lessons.map((lesson) => (
            <div
              key={lesson.id}
              className="border rounded-[4px] overflow-hidden shadow-sm hover:shadow-md transition-shadow bg-neutral-2"
            >
              <div className="p-6">
                <h2 className="text-xl font-semibold mb-2 text-neutral-12">
                  {lesson.focusArea}
                </h2>
                <div className="mb-4">
                  <p className="text-sm text-neutral-8">
                    {lesson.targetSkills.join(', ')}
                  </p>
                </div>
                <div className="flex justify-between items-center">
                  <span
                    className={`px-2 py-1 text-xs rounded-full ${lesson.completed
                        ? 'bg-accent-1 text-accent-9'
                        : 'bg-accent-2 text-accent-10'
                      }`}
                  >
                    {lesson.completed ? 'Completed' : 'In Progress'}
                  </span>
                  <button
                    onClick={() => handleStartLesson(lesson)}
                    className="px-4 py-2 bg-accent-6 text-white rounded-[4px] hover:bg-accent-7 text-sm"
                  >
                    {lesson.completed ? 'Review' : 'Start'}
                  </button>
                </div>
              </div>
            </div>
          ))}
        </div>
      ) : null}
    </div>
  );
}
// --- NEW CODE END ---
</file>

<file path="src/app/app/onboarding/page.tsx">
// File: /src/app/app/onboarding/page.tsx
'use client';

import { useState, useEffect } from 'react';
import { useRouter } from 'next/navigation';
import { useAuth } from '@/context/auth-context';
import { useOnboarding } from '@/context/onboarding-context';
import { toast } from 'react-hot-toast';
import logger from '@/utils/logger';
import WelcomeStep from '@/components/onboarding/WelcomeStep';
import LanguageSelectionStep from '@/components/onboarding/LanguageSelectionStep';
import LearningPurposeStep from '@/components/onboarding/LearningPurposeStep';
import ProficiencyStep from '@/components/onboarding/ProficiencyStep';
import AssessmentStep from '@/components/onboarding/AssessmentStep';
import { AssessmentLesson } from '@/models/AppAllModels.model';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import { useError } from '@/hooks/useError';

export default function OnboardingPage() {
  const router = useRouter();
  const { user } = useAuth();
  const {
    isOnboardingComplete,
    markStepComplete,
    loading,
    getOnboarding,
    getAssessmentLesson,
    markOnboardingAsCompleteAndGenerateLessons,
    processAssessmentLessonRecording,
    completeAssessmentLesson,
    goToLessonsWithOnboardingComplete,
  } = useOnboarding();
  const [currentStep, setCurrentStep] = useState<string>('welcome');
  const [formData, setFormData] = useState({
    nativeLanguage: '',
    targetLanguage: '',
    learningPurpose: '',
    proficiencyLevel: '',
  });


  useEffect(() => {
    console.log('onboarding data form onbarding page', formData);
  }, [formData]);

  // State to hold the generated assessment lesson and its loading status
  const [assessmentLesson, setAssessmentLesson] =
    useState<AssessmentLesson | null>(null);
  const [assessmentLoading, setAssessmentLoading] = useState<boolean>(false);
  const [areMetricsGenerated, setAreMetricsGenerated] = useState<boolean>(false);

  // Rehydrate state from onboarding session
  useEffect(() => {
    const fetchOnboardingData = async () => {
      try {
        const onboarding = await getOnboarding();
        if (onboarding) {
          // Update form data
          setFormData({
            nativeLanguage: onboarding.nativeLanguage || '',
            targetLanguage: onboarding.targetLanguage || '',
            learningPurpose: onboarding.learningPurpose || '',
            proficiencyLevel: onboarding.proficiencyLevel || '',
          });
          logger.info('formData', formData);

          // Determine current step based on completed steps
          const stepsOrder = [
            'welcome',
            'languages',
            'purpose',
            'proficiency',
            'assessment',
          ];
          const completedSteps = Object.entries(onboarding.steps || {})
            .filter(([_, isCompleted]) => isCompleted)
            .map(([step]) => step)
            .sort((a, b) => stepsOrder.indexOf(a) - stepsOrder.indexOf(b));
          logger.info('completedSteps', completedSteps);
          const lastCompletedStep = completedSteps[completedSteps.length - 1];
          logger.info('lastCompletedStep', lastCompletedStep);
          if (lastCompletedStep) {
            const nextStep = getNextStep(lastCompletedStep);
            logger.info('nextStep', nextStep);
            setCurrentStep(nextStep);
          } else {
            setCurrentStep(stepsOrder[0]);
          }
        }
      } catch (error) {
        logger.error('Error fetching onboarding data:', error);
      }
    };

    fetchOnboardingData();
  }, []); // Removed getOnboarding from dependency array if it causes loops, ensure it's stable or called appropriately

  // Check if onboarding is complete
  useEffect(() => {
    if (isOnboardingComplete && user) {
      router.push('/app/lessons');
    }
  }, [isOnboardingComplete, user, router]);

  useEffect(() => {
    console.log('assessmentLesson on page.tsx', assessmentLesson);
    console.log('currentStep on page.tsx', currentStep);
    if (currentStep === 'assessment' && !assessmentLesson) {
      generateAssessmentLesson();
    }
    // This effect correctly waits for both metrics before triggering lesson generation
    if (
      assessmentLesson &&
      assessmentLesson.completed &&
      assessmentLesson.metrics && assessmentLesson.audioMetrics
    ) {
      logger.info('generating the initial lessons');
      markOnboardingAsCompleteAndGenerateLessons();
    }
  }, [assessmentLesson, currentStep]); // Removed markOnboardingAsCompleteAndGenerateLessons from deps if unstable

  const handleNextStep = async (step: string, data?: any) => {
    // Merge new data with existing form data immediately
    const mergedFormData = data ? { ...formData, ...data } : formData;

    try {
      // Update local state
      if (data) {
        setFormData(mergedFormData);
      }
      console.log('mergedFormData', mergedFormData);
      // Pass the merged data to the backend
      await markStepComplete(step, mergedFormData);
      setCurrentStep(getNextStep(step));
    } catch (error) {
      logger.error('Error moving to next step:', error);
    }
  };

  const getNextStep = (currentStep: string): string => {
    const steps = [
      'welcome',
      'languages',
      'purpose',
      'proficiency',
      'assessment',
    ];
    const currentIndex = steps.indexOf(currentStep);
    return steps[currentIndex + 1] || 'assessment';
  };

  // Generate assessment lesson after proficiency is submitted
  const generateAssessmentLesson = async () => {
    setAssessmentLoading(true);
    try {
      const lesson = await getAssessmentLesson();
      if (!lesson) {
        return;
      }
      setAssessmentLesson(lesson);
    } catch (error) {
      logger.error('Error generating assessment lesson:', error);
    } finally {
      setAssessmentLoading(false);
    }
  };

  // complete assessment lesson (generates text-based metrics)
  const handleOnAssessmentComplete = async () => {
    if (!assessmentLesson) {
      return;
    }
    setAreMetricsGenerated(false);
    try {
      const lessonWithMetrics = await completeAssessmentLesson(
        assessmentLesson.id,
        'Assessment completed'
      );
      if (!lessonWithMetrics) {
        return;
      }
      setAssessmentLesson(prev => ({ ...prev, ...lessonWithMetrics }));
      logger.info('LessonWithMetrics (Text-based)', lessonWithMetrics);
    } catch (error) {
      logger.error('Error completing assessment lesson:', error);
    } finally {
      setAreMetricsGenerated(true);
    }
  };

  // just re-route to lessons page
  const handleGoToLessonsButtonClick = async () => {
    goToLessonsWithOnboardingComplete();
  };

  // Process audio recording (generates audioMetrics)
  const onProcessAssessmentLessonRecording = async (sessionRecording: RecordingBlob, lesson: AssessmentLesson, recordingTime: number, recordingSize: number) => {
    logger.info('processing assessment lesson recording', { sessionRecording, lesson, recordingTime, recordingSize });
    try {
      const lessonWithAudioMetrics = await processAssessmentLessonRecording(sessionRecording, lesson, recordingTime, recordingSize);
      if (!lessonWithAudioMetrics) {
        return;
      }
      setAssessmentLesson(prev => ({ ...prev, ...lessonWithAudioMetrics }));
      logger.info('LessonWithAudioMetrics (Audio included)', lessonWithAudioMetrics);
      return lessonWithAudioMetrics;
    } catch (error) {
      logger.error('Error processing assessment recording on page:', error);
      return;
    }
  };

  const renderStep = () => {
    switch (currentStep) {
      case 'welcome':
        return (
          <WelcomeStep
            onNext={() => handleNextStep('welcome')}
            loading={loading}
          />
        );
      case 'languages':
        return (
          <LanguageSelectionStep
            onNext={(data) => handleNextStep('languages', data)}
            formData={formData}
            loading={loading}
          />
        );
      case 'purpose':
        return (
          <LearningPurposeStep
            onNext={(data) => handleNextStep('purpose', data)}
            formData={formData}
            loading={loading}
          />
        );
      case 'proficiency':
        return (
          <ProficiencyStep
            onNext={(data) => handleNextStep('proficiency', data)}
            onAssessmentGeneration={generateAssessmentLesson} // This might be redundant if assessment step auto-loads
            formData={formData}
            loading={loading}
          />
        );
      case 'assessment':
        return (
          <AssessmentStep
            areMetricsGenerated={areMetricsGenerated}
            onAssessmentComplete={handleOnAssessmentComplete} // Renamed for clarity
            loading={assessmentLoading || loading} // Combine loading states if needed
            targetLanguage={formData.targetLanguage}
            lesson={assessmentLesson}
            onGoToLessonsButtonClick={handleGoToLessonsButtonClick}
            processAssessmentLessonRecording={onProcessAssessmentLessonRecording}
          />
        );
      default:
        return (
          <WelcomeStep
            onNext={() => handleNextStep('welcome')}
            loading={loading}
          />
        );
    }
  };

  return (
    <div className="min-h-screen flex justify-center items-center bg-gray-50  lg:px-8">
      <div className=" w-full h-full max-w-xl space-y-8">{renderStep()}</div>
    </div>
  );
}
</file>

<file path="src/context/auth-context.tsx">
'use client'

import { createContext, useContext, useEffect, useRef, useState } from 'react'
import React  from 'react'
import { Session, User, AuthError } from '@supabase/supabase-js'
import { useRouter } from 'next/navigation'
import logger from '@/utils/logger'
import { UserProfileProvider } from '@/context/user-profile-context'
import { loginAction, registerAction, loginWithGoogleAction, logoutAction, getSessionAction } from '@/lib/server-actions/auth-actions'
import { createClient } from '@/utils/supabase/client'

interface AuthContextType {
  user: User | null
  session: Session | null
  loading: boolean
  error: string | null
  login: (email: string, password: string) => Promise<void>
  register: (email: string, password: string) => Promise<void>
  loginWithGoogle: () => Promise<void>
  logout: () => Promise<void>
  clearError: () => void
}

const AuthContext = createContext<AuthContextType | undefined>(undefined)


export function AuthProvider({ children }: { children: React.ReactNode }) {
  const isMock = process.env.NEXT_PUBLIC_IS_MOCK === 'true';
  const supabase = useRef(createClient()).current;

  logger.log('isMock', isMock)


  const [session, setSession] = useState<Session | null>(null)
  const [user, setUser] = useState<User | null>(null)
  const [loading, setLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)
  const router = useRouter()

    const isMounted = useRef(true);

    useEffect(() => {
      isMounted.current = true; 
      logger.log("AuthProvider Effect: Mounting / Running");
  
      setLoading(true); 
      getSessionAction().then(({ data, error }) => {
        if (error) {
          setError(error)
        } else {
          setSession(data ?? null)
          setUser(data?.user ?? null)
        }
      }).finally(() => setLoading(false))

      const { data: { subscription } } = supabase.auth.onAuthStateChange(
        async (event, changedSession) => {
          // Only update state if the component is still mounted
          if (isMounted.current) {
              logger.log("AuthProvider Effect: onAuthStateChange fired", event, changedSession);
              setSession(changedSession);
              setUser(changedSession?.user ?? null);
          } else {
              logger.log("AuthProvider Effect: onAuthStateChange fired AFTER unmount, ignoring.");
          }
        }
      );
  
      return () => {
        logger.log("AuthProvider Effect: Unmounting");
        isMounted.current = false; // Set false on cleanup
        subscription.unsubscribe();
      };
    }, [router, supabase.auth]);
  
    const checkErrorMessageAndGiveTheUserError = (errorMessage: string) => {
      if (errorMessage.includes('Invalid login credentials') || errorMessage.includes('invalid_credentials')) {
        return 'Invalid credentials. Please try again or sign up.';
      }
      return errorMessage;
    }

    const login = async (email: string, password: string) => {
      setLoading(true)
      const { data, error: loginError } = await loginAction(email, password); // Renamed error
      if (loginError) {
        const userFriendlyError = checkErrorMessageAndGiveTheUserError(loginError);
        setError(userFriendlyError);
        throw new Error(userFriendlyError); // Throw the user-friendly message
      }
      setUser(data!.user)
      setSession(data!.session)
      setError(null)
      setLoading(false)
      router.push('/app/lessons');
    }

    const register = async (email: string, password: string) => {
      setLoading(true)
    
      const { data, error: registerError } = await registerAction(email, password); // Renamed error
      if (registerError) {
        setError(registerError);
        throw new Error(registerError);
      }
      setUser(data!.user)
      setSession(data!.session)
      setError(null)
      setLoading(false)
      router.push('/app/onboarding');
    }

  

    const loginWithGoogle = async () => {
      if (!isMounted.current) return;
      setError(null)
      setLoading(true)
      try {
        const { error: actionError } = await loginWithGoogleAction()
        if (actionError) {
       
          setError(actionError.message); // Set error state
          throw new Error(actionError.message); // Also throw for consistency
        }
        // No need to set user/session here as it will be handled by the auth state change
      } catch (caughtError: any) {
          if (isMounted.current) {
              const message = caughtError?.message ? caughtError.message : 'Google login failed';
          
              setError(message); // Set error state
              throw new Error(message); // Re-throw
          }
      } finally {
        if (isMounted.current) {
          setLoading(false);
        }
      }
    }

  

    const logout = async (options: { redirect?: boolean } = { redirect: true }) => {
      if (!isMounted.current) return;
      setLoading(true);
      setError(null); // Clear previous errors

      try {
        // Attempt server-side logout, but don't block client-side cleanup if it fails
        const { error: serverLogoutError } = await logoutAction();
        if (serverLogoutError) {
          // Log the error, but proceed with client-side cleanup
          logger.warn('Server-side logout action failed (might be expected if user was just deleted):', serverLogoutError);
          // Optionally set the error state if it's not an expected "user not found" type error
          // setError(serverLogoutError.message);
        }
      } catch (caughtError: any) {
        // Catch errors from the action call itself
        logger.error('Error calling logoutAction:', caughtError);
        // setError(caughtError.message || 'Logout failed');
      } finally {
        // Always clear client-side state regardless of server action outcome
        if (isMounted.current) {
          logger.info('Clearing client-side auth state in logout function.');
          setUser(null);
          setSession(null);
          setLoading(false);

          const currentPath = window.location.pathname;
          if (options.redirect && currentPath.startsWith('/app')) {
              logger.info("AuthProvider logout: Redirecting to /app/login");
              router.replace('/app/login'); // Use replace to avoid back button issues
          }
        }
      }
    };
    // --- NEW CODE END ---
  
    const clearError = () => {
        if (isMounted.current) {
          setError(null);
        }
    }
  

  return (
    <AuthContext.Provider value={{
      user,
      session,
      loading,
      error,
      login,
      register,
      loginWithGoogle,
      logout,
      clearError
    }}>
      <UserProfileProvider>
        {children}
      </UserProfileProvider>
    </AuthContext.Provider>
  )
}

export const useAuth = () => {
  const context = useContext(AuthContext)
  if (context === undefined) {
    throw new Error('useAuth must be used within an AuthProvider')
  }
  return context
}
</file>

<file path="src/lib/server-actions/auth-actions.ts">
'use server';

import { withServerErrorHandling, Result } from './_withErrorHandling';
import logger from '@/utils/logger';
import { Session, User } from '@supabase/supabase-js';
import { AuthError } from '@supabase/supabase-js';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import UserService from '@/services/user.service'; // Import UserService
import { UserRepository } from '@/repositories/user.repository'; // Import UserRepository
type AuthData = { user: User | null; session: Session | null };

// LOGIN (with fallback→signup)
export async function loginAction(
  email: string,
  password: string
): Promise<Result<AuthData>> {
  return withServerErrorHandling(async () => {
    const supabase = await createSupabaseServerClient();
    const { data, error } = await supabase.auth.signInWithPassword({
      email,
      password,
    });

    if (error?.code === 'invalid_credentials') {
      // auto‐signup
      const { data: d2, error: e2 } = await supabase.auth.signUp({
        email,
        password,
      });
      if (e2) throw new Error(e2.message);
      return { user: d2.user, session: d2.session };
    }
    if (error) throw new Error(error.message);

    return { user: data.user, session: data.session };
  });
}

// SIGNUP
export async function registerAction(
  email: string,
  password: string
): Promise<Result<AuthData>> {
  return withServerErrorHandling(async () => {
    const supabase = await createSupabaseServerClient();
    const { data, error } = await supabase.auth.signUp({ email, password });
    if (error) throw new Error(error.message);
    // --- START: Create Prisma User Profile ---
    if (data.user) {
      logger.info(
        `Supabase user created: ${data.user.id}. Creating Prisma profile...`
      );
      try {
        const userService = new UserService(new UserRepository()); // Instantiate service
        await userService.createUserProfile({
          userId: data.user.id,
          email: data.user.email!,
        });
        logger.info(
          `Prisma profile created successfully for user: ${data.user.id}`
        );
      } catch (profileError: any) {
        // Log the error but don't necessarily fail the whole registration
        // The UserProfileProvider might catch it later, or we might need cleanup logic.
        logger.error(
          `Failed to create Prisma profile during registration for user ${data.user.id}:`,
          profileError
        );
        // Optionally re-throw if profile creation is absolutely critical *here*
      }
    }
    // --- END: Create Prisma User Profile ---
    return { user: data.user, session: data.session };
  });
}

// LOGOUT
export async function logoutAction(): Promise<Result<null>> {
  return withServerErrorHandling(async () => {
    const supabase = await createSupabaseServerClient();
    const { error } = await supabase.auth.signOut();
    if (error) throw new Error(error.message);
    return null;
  });
}

// GET SESSION
export async function getSessionAction(): Promise<Result<Session | null>> {
  return withServerErrorHandling(async () => {
    const supabase = await createSupabaseServerClient();
    const {
      data: { session },
      error,
    } = await supabase.auth.getSession();
    if (error) throw new Error(error.message);
    return session;
  });
}

export async function loginWithGoogleAction(): Promise<{
  error: AuthError | null;
}> {
  const supabase = await createSupabaseServerClient();
  const { error } = await supabase.auth.signInWithOAuth({
    provider: 'google',
    options: {
      redirectTo: `${process.env.NEXT_PUBLIC_SITE_URL}/app/lessons`,
    },
  });
  if (error) {
    logger.error('Google login error:', error);
    return { error };
  }
  return { error: null };
}
</file>

<file path="src/repositories/user.repository.ts">
import logger from '@/utils/logger';
import { UserProfileModel } from '@/models/AppAllModels.model';
import prisma from '@/lib/prisma';
import { Prisma, SubscriptionStatus } from '@prisma/client';
import { createSupabaseServerClient } from '@/utils/supabase/server';
import { SupabaseClient } from '@supabase/supabase-js';
import supabaseAdmin from '@/utils/supabase/admin';

export interface IUserRepository {
  getUserProfile(userId: string): Promise<UserProfileModel | null>;
  createUserProfile(profileData: { userId: string; email: string }): Promise<UserProfileModel>; // Simplified input
  updateUserProfile(userId: string, profile: Partial<UserProfileModel>): Promise<UserProfileModel>;
  deleteUserProfile(userId: string): Promise<void>;
}

export class UserRepository implements IUserRepository {
  private supabase: SupabaseClient | null = null;

  constructor() {
    if (typeof window === 'undefined') {
      this.supabase = null;
      this.getSupabaseClient = async () => {
        if (!this.supabase) {
          this.supabase = await createSupabaseServerClient() as SupabaseClient | null;
        }
        return this.supabase;
      };
    }
  }

  private getSupabaseClient?: () => Promise<SupabaseClient | null>;

  // Helper to get authenticated session (server-side)
  private async getSession() {
    if (typeof window === 'undefined' && this.getSupabaseClient) {
      const supabase = await this.getSupabaseClient();
      if (!supabase) throw new Error('Supabase client not available');
      const { data: { session }, error } = await supabase.auth.getSession();
      if (error) throw new Error(`Supabase getSession error: ${error.message}`);
      if (!session?.user?.id) throw new Error('Unauthorized: No active session');
      return session;
    }
    throw new Error('getSession can only be called server-side in this repository');
  }

  // Maps Prisma User (with onboarding) to UserProfileModel
  private mapToUserProfile(user: Prisma.UserGetPayload<{ include: { onboarding: true } }>): UserProfileModel {
    return {
      id: user.id,
      userId: user.id,
      email: user.email || '',
      name: user.name || undefined,
      nativeLanguage: user.onboarding?.nativeLanguage || undefined,
      targetLanguage: user.onboarding?.targetLanguage || undefined,
      proficiencyLevel: user.onboarding?.proficiencyLevel || undefined,
      learningPurpose: user.onboarding?.learningPurpose || undefined,
      onboardingCompleted: user.onboarding?.completed || false,
      initialAssessmentCompleted: user.onboarding?.initialAssessmentCompleted || false,
      subscriptionStatus: user.subscriptionStatus,
      subscriptionId: user.subscriptionId,
      subscriptionPlan: user.subscriptionPlan,
      trialStartDate: user.trialStartDate,
      trialEndDate: user.trialEndDate,
      subscriptionStartDate: user.subscriptionStartDate,
      subscriptionEndDate: user.subscriptionEndDate,
      billingCycle: user.billingCycle,
      paymentMethodId: user.paymentMethodId,
      stripeCustomerId: user.stripeCustomerId,
      cancelAtPeriodEnd: user.cancelAtPeriodEnd,
      createdAt: user.createdAt,
      updatedAt: user.updatedAt,
    };
  }

  // Fetches the user profile, returns null if not found. Does NOT create.
  async getUserProfile(userId: string): Promise<UserProfileModel | null> {
    try {
      const session = await this.getSession();
      if (session.user.id !== userId) {
        logger.error(`Unauthorized attempt to get profile. Logged in user: ${session.user.id}, Requested user: ${userId}`);
        throw new Error('Unauthorized to access this profile');
      }

      const user = await prisma.user.findUnique({
        where: { id: userId },
        include: { onboarding: true },
      });

      if (!user) {
        logger.info(`User profile not found in DB for user ${userId}.`);
        return null; // Explicitly return null if not found
      }

      return this.mapToUserProfile(user);
    } catch (error) {
      // Don't log expected "Unauthorized" as error here, let caller handle
      if (!(error instanceof Error && error.message.startsWith('Unauthorized'))) {
        logger.error(`Error fetching user profile for ${userId}:`, error);
      }
      throw error; // Re-throw other errors
    }
  }

  // Creates the user profile. Assumes it doesn't exist. Handles email conflict.
  async createUserProfile(profileData: { userId: string; email: string }): Promise<UserProfileModel> {
    const { userId, email } = profileData;
    logger.info(`Attempting to create profile for user ${userId} with email ${email}`);
    try {
      // No need to re-verify session here if called from an authenticated context like UserProfileProvider

      // Create the user with minimal information and default onboarding
      const user = await prisma.user.create({
        data: {
          id: userId,
          email: email,
          subscriptionStatus: SubscriptionStatus.NONE, // Default status
          onboarding: {
            create: { steps: {}, completed: false }, // Default onboarding state
          },
        },
        include: { onboarding: true },
      });

      logger.info(`Successfully created profile for user ${userId}`);
      return this.mapToUserProfile(user);

    } catch (error: any) {
      // Handle unique constraint violation (likely email)
      if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === 'P2002') {
        logger.warn(`UserRepository.createUserProfile: Unique constraint violation (likely email: ${email}). Attempting to fetch existing profile for user ${userId}.`);
        // Attempt to fetch the existing profile by userId, as the email conflict implies the user might exist under that ID
        const existingUser = await prisma.user.findUnique({
          where: { id: userId },
          include: { onboarding: true },
        });
        if (existingUser) {
          logger.info(`Found existing profile for user ${userId} after email conflict.`);
          return this.mapToUserProfile(existingUser);
        } else {
          // This is an unusual state: email exists, but user ID doesn't match? Log and throw.
          logger.error(`Critical error: Email ${email} exists, but user ${userId} not found after P2002 error.`);
          throw new Error(`Failed to resolve profile conflict for email ${email}.`);
        }
      }
      // Log and re-throw other errors
      logger.error(`Error creating user profile for ${userId}:`, error);
      throw error;
    }
  }

  // Updates the user profile.
  async updateUserProfile(userId: string, profile: Partial<UserProfileModel>): Promise<UserProfileModel> {
    try {
      const session = await this.getSession();
      if (session.user.id !== userId) {
        throw new Error('Unauthorized to update this profile');
      }

      const onboardingData: any = {};
      if ('nativeLanguage' in profile) onboardingData.nativeLanguage = profile.nativeLanguage;
      if ('targetLanguage' in profile) onboardingData.targetLanguage = profile.targetLanguage;
      if ('proficiencyLevel' in profile) onboardingData.proficiencyLevel = profile.proficiencyLevel;
      if ('learningPurpose' in profile) onboardingData.learningPurpose = profile.learningPurpose;
      if ('onboardingCompleted' in profile) onboardingData.completed = profile.onboardingCompleted;
      if ('initialAssessmentCompleted' in profile) onboardingData.initialAssessmentCompleted = profile.initialAssessmentCompleted;

      const userUpdateData: Prisma.UserUpdateInput = {
        name: profile.name,
        // Add other direct User fields if needed (e.g., subscription fields handled by webhooks)
      };

      // Only include onboarding update if there's data for it
      if (Object.keys(onboardingData).length > 0) {
        userUpdateData.onboarding = {
          upsert: {
            // Provide minimal create data, Prisma requires it even if we expect update
            create: { steps: {}, completed: false, ...onboardingData },
            update: onboardingData,
          },
        };
      }

      const user = await prisma.user.update({
        where: { id: userId },
        data: userUpdateData,
        include: { onboarding: true },
      });

      return this.mapToUserProfile(user);
    } catch (error) {
      logger.error(`Error updating user profile for ${userId}:`, error);
      throw error;
    }
  }

  // Deletes the user profile and associated data.
  async deleteUserProfile(userId: string): Promise<void> {
    try {
      const session = await this.getSession();
      if (session.user.id !== userId) {
        logger.error(`Unauthorized delete attempt. Session user: ${session.user.id}, Target: ${userId}`);
        throw new Error('Unauthorized: You can only delete your own profile.');
      }

      logger.warn(`Starting deletion process for user: ${userId}`);

      // Use Prisma transaction for atomicity
      await prisma.$transaction(async (tx) => {
        // Delete related data first (adjust based on your schema relations and cascade settings)
        // Example: Delete LessonSteps, Lessons, Onboarding, AudioMetrics, Progress etc.
        // If cascade deletes are set up in Prisma schema, some of these might be automatic.
        await tx.lessonStep.deleteMany({ where: { lesson: { userId: userId } } });
        await tx.audioMetrics.deleteMany({ where: { OR: [{ lesson: { userId: userId } }, { assessmentLesson: { userId: userId } }] } });
        await tx.lesson.deleteMany({ where: { userId: userId } });
        await tx.assessmentStep.deleteMany({ where: { assessment: { userId: userId } } });
        await tx.assessmentLesson.deleteMany({ where: { userId: userId } });
        await tx.onboarding.deleteMany({ where: { userId: userId } });
        await tx.payment.deleteMany({ where: { userId: userId } }); // Assuming Payment model exists
        await tx.topicProgress.deleteMany({ where: { learningProgress: { userId: userId } } });
        await tx.wordProgress.deleteMany({ where: { learningProgress: { userId: userId } } });
        await tx.learningProgress.deleteMany({ where: { userId: userId } });

        // Finally, delete the user record itself
        await tx.user.delete({ where: { id: userId } });
        logger.info(`DB deletion transaction complete for user: ${userId}`);
      });

      // Delete the user from the Auth provider (Supabase Auth)
      if (typeof window === 'undefined') { // Ensure server-side context
        const { error: authError } = await supabaseAdmin.auth.admin.deleteUser(userId);
        if (authError) {
          // Log error but don't necessarily throw if DB deletion succeeded,
          // as the user might be partially deleted. Depends on desired behavior.
          logger.error(`Auth Provider user deletion failed for ${userId}: ${authError.message}`);
          // Consider throwing a specific error if auth deletion failure is critical
          // throw new Error(`Failed to delete user from Auth Provider: ${authError.message}`);
        } else {
          logger.info(`Auth Provider user deleted successfully: ${userId}`);
        }
      }

      logger.warn(`Deletion process fully completed for user: ${userId}`);

    } catch (error: any) {
      // Handle specific Prisma "Record not found" error during deletion gracefully
      if (error instanceof Prisma.PrismaClientKnownRequestError && error.code === 'P2025') {
        logger.warn(`User profile or related data not found during deletion for userId: ${userId}. Assuming already deleted.`);
        // Attempt Auth deletion just in case it's an orphaned auth user
        if (typeof window === 'undefined') {
          try {
            const { error: authError } = await supabaseAdmin.auth.admin.deleteUser(userId);
            if (authError && authError.message !== 'User not found') { // Ignore "User not found" error here
              logger.error(`Auth Provider deletion failed for potentially orphaned user ${userId}: ${authError.message}`);
            } else if (!authError) {
              logger.info(`Auth Provider user deleted successfully for potentially orphaned user ${userId}.`);
            }
          } catch (authCatchError) {
            logger.error(`Exception during Auth Provider deletion for potentially orphaned user ${userId}:`, authCatchError);
          }
        }
        return; // Consider deletion successful if record wasn't found
      }
      // Log and re-throw other errors
      logger.error(`Error during user profile deletion for userId: ${userId}:`, error);
      throw new Error(`Failed to delete user profile: ${error.message}`);
    }
  }
}
// --- NEW CODE END ---
</file>

<file path="src/services/lesson-generator.service.ts">
import { IAIService } from '@/interfaces/ai-service.interface';
import { models } from './ai.service';
import logger from '@/utils/logger';
import { retryOperation } from '@/utils/retryWithOperation';
import { MockLessonGeneratorService } from '@/__mocks__/generated-lessons.mock';
import { GeneratedLesson, LessonStep } from '@/models/AppAllModels.model';
import { MockAssessmentGeneratorService } from '@/__mocks__/generated-assessment-lessons.mock';
import { ITTS } from '@/interfaces/tts.interface';
import path from 'path';
import fs from 'fs';
import { LessonModel } from '@/models/AppAllModels.model';
import { AdaptiveLessonGenerationRequest } from '@/models/AppAllModels.model';

export interface ILessonGeneratorService {
  generateLesson: (
    topic: string,
    targetLanguage: string,
    difficultyLevel: string,
    sourceLanguage: string,
    adaptiveRequest?: AdaptiveLessonGenerationRequest
  ) => Promise<Record<string, unknown>>;
  generateAudioForSteps: (
    steps: LessonStep[],
    language: string,
    sourceLanguage: string
  ) => Promise<LessonStep[]>;
  generateLessonCompletionResults: (
    lesson: LessonModel,
    userResponses: { stepId: string; response: string }[]
  ) => Promise<{
    metrics: {
      accuracy: number;
      pronunciationScore: number;
      grammarScore: number;
      vocabularyScore: number;
      overallScore: number;
      strengths: string[];
      weaknesses: string[];
    };
    summary: string;
    nextLessonSuggestions: string[];
  }>;
}

class LessonGeneratorService implements ILessonGeneratorService {
  private aiService: IAIService;
  private useLessonGeneratorMock: boolean;
  private useAudioGeneratorMock: boolean;
  private useAudioUploadMock: boolean;
  private ttsService: ITTS;
  private uploadFunction: (
    file: Buffer,
    filename: string,
    contentType: string
  ) => Promise<string>;

  constructor(
    aiService: IAIService,
    ttsService: ITTS,
    uploadFunction: (
      file: Buffer,
      filename: string,
      contentType: string
    ) => Promise<string>
  ) {
    this.aiService = aiService;
    this.ttsService = ttsService;
    this.uploadFunction = uploadFunction;

    this.useLessonGeneratorMock =
      process.env.NEXT_PUBLIC_MOCK_LESSON_GENERATOR === 'true';
    // this.useLessonGeneratorMock = false;
    this.useAudioGeneratorMock =
      process.env.NEXT_PUBLIC_MOCK_AUDIO_GENERATOR === 'true';
    this.useAudioUploadMock =
      process.env.NEXT_PUBLIC_USE_AUDIO_UPLOAD_MOCK === 'true';
    logger.info('LessonGeneratorService initialized', {
      useLessonGeneratorMock: this.useLessonGeneratorMock,
      useAudioGeneratorMock: this.useAudioGeneratorMock,
      useAudioUploadMock: this.useAudioUploadMock,
    });
  }

  async generateLesson(
    topic: string,
    targetLanguage: string,
    difficultyLevel: string,
    sourceLanguage: string,
    adaptiveRequest?: AdaptiveLessonGenerationRequest
  ): Promise<Record<string, unknown>> {
    // Derive effective values from adaptive request
    const effectiveTopic = adaptiveRequest?.focusTopic || topic;
    const effectiveTargetLanguage =
      adaptiveRequest?.userInfo?.targetLanguage || targetLanguage;
    const effectiveSourceLanguage =
      adaptiveRequest?.userInfo?.nativeLanguage || sourceLanguage;
    const effectiveDifficulty =
      adaptiveRequest?.overallProgress?.estimatedProficiencyLevel ||
      adaptiveRequest?.userInfo?.proficiencyLevel ||
      difficultyLevel;

    logger.info('Generating adaptive lesson', {
      effectiveTopic,
      effectiveTargetLanguage,
      effectiveSourceLanguage,
      effectiveDifficulty,
      hasProgressData: !!adaptiveRequest?.overallProgress,
      hasAudioAnalysis: !!adaptiveRequest?.detailedAudioAnalysis,
    });

    // Generate prompts with full adaptive context
    const prompts = this.generateLessonPrompts(
      effectiveTopic,
      effectiveTargetLanguage,
      effectiveSourceLanguage,
      effectiveDifficulty,
      adaptiveRequest
    );

    let aiResponse: Record<string, unknown> | Record<string, unknown>[] = [];
    try {
      if (this.useLessonGeneratorMock) {
        logger.info('Using mock lesson generator for topic:', effectiveTopic);
        const mockLesson = await MockLessonGeneratorService.generateLesson(
          effectiveTopic,
          effectiveTargetLanguage,
          effectiveDifficulty
        );
        logger.info('Mock lesson generated', { effectiveTopic, mockLesson });
        aiResponse = mockLesson;
      } else {
        logger.info('Generated prompts for lesson', { prompts });

        aiResponse = await retryOperation(() =>
          this.aiService.generateContent(
            '', // No file URI needed
            prompts.userPrompt,
            prompts.systemPrompt,
            models.gemini_2_0_flash
          )
        );
        logger.info('AI response received for lesson generation', {
          aiResponse,
        });
      }

      const lessonsArray = Array.isArray(aiResponse)
        ? aiResponse
        : [aiResponse];

      try {
        lessonsArray.map((lesson) => this.validateLessonsResponse(lesson));
      } catch (error) {
        logger.error('Error validating lessons response:', { error });
        if (!this.useLessonGeneratorMock) {
          aiResponse = await retryOperation(() =>
            this.aiService.generateContent(
              '', // No file URI needed
              prompts.userPrompt,
              prompts.systemPrompt,
              models.gemini_2_0_flash
            )
          );
          logger.info('AI response received for lesson generation', {
            aiResponse,
          });
        }
      }

      const generatedLessons = lessonsArray.map((lesson) =>
        this.formatLessonResponse(lesson)
      );
      logger.info('Formatted lessons', { generatedLessons });

      return { data: generatedLessons };
    } catch (error) {
      logger.error('Error generating lesson:', {
        effectiveTopic,
        effectiveTargetLanguage,
        effectiveDifficulty,
        error,
      });
      throw error;
    }
  }

  private validateLessonsResponse(aiResponse: Record<string, unknown>): void {
    logger.info('Validating lessons response', { aiResponse });

    const stepsWithExpectedAnswer = ['practice', 'prompt', 'new_word'];
    const lessonData =
      (aiResponse as { data?: unknown[] }).data?.[0] || aiResponse;

    const steps = (lessonData as any).steps;

    if (steps.length < 0) {
      throw new Error('Invalid lesson format: steps are empty ');
    }

    for (const step of steps) {
      const stepType = step.type;
      const hasExpectedAnswer = step.expectedAnswer !== undefined;

      // Practice and prompt steps must have expected answers
      if (stepsWithExpectedAnswer.includes(stepType) && !hasExpectedAnswer) {
        throw new Error(
          `Step ${step.content} of type ${stepType} is missing expectedAnswer`
        );
      }

      // Other step types should not have expected answers
      if (!stepsWithExpectedAnswer.includes(stepType) && hasExpectedAnswer) {
        throw new Error(
          `Step ${step.content} of type ${stepType} should not have expectedAnswer`
        );
      }
    }
  }

  public async generateAudioForSteps(
    steps: LessonStep[],
    language: string,
    sourceLanguage: string
  ): Promise<LessonStep[]> {
    logger.info('Generating audio for lesson steps', { steps });

    try {
      if (this.useAudioGeneratorMock) {
        logger.info('Using mock audio generator');
        for (const step of steps) {
          const audioBase64 =
            await MockLessonGeneratorService.generateAudioForStep(
              step.content,
              language
            );
          const audioBuffer = Buffer.from(audioBase64, 'base64');

          if (this.useAudioUploadMock) {
            const audioFile = this.createAudioFile(
              audioBuffer,
              `content_step_${step.stepNumber}.mp3`
            );
            step.contentAudioUrl = await this.saveAudioLocally(
              audioFile,
              'lessay/lessonStep/audio'
            );
          } else {
            step.contentAudioUrl = await this.uploadFunction(
              audioBuffer,
              `content_step_${step.stepNumber}.mp3`,
              'audio/mp3'
            );
          }

          if (step.expectedAnswer) {
            const answerAudioBase64 =
              await MockLessonGeneratorService.generateAudioForStep(
                step.expectedAnswer!,
                language
              );
            const answerAudioBuffer = Buffer.from(answerAudioBase64, 'base64');

            if (this.useAudioUploadMock) {
              const audioFile = this.createAudioFile(
                answerAudioBuffer,
                `answer_step_${step.stepNumber}.mp3`
              );
              step.expectedAnswerAudioUrl = await this.saveAudioLocally(
                audioFile,
                'lessay/lessonStep/audio'
              );
            } else {
              step.expectedAnswerAudioUrl = await this.uploadFunction(
                answerAudioBuffer,
                `answer_step_${step.stepNumber}.mp3`,
                'audio/mp3'
              );
            }
          }
        }
        logger.info('Mock audio generated', { steps });
      } else {
        // Real implementation
        for (const step of steps) {
          // Generate content audio in source language
          const contentVoice = this.ttsService.getVoice(
            sourceLanguage,
            'basic'
          );
          const contentAudioBase64 = await retryOperation(() =>
            this.ttsService.synthesizeSpeech(
              step.content,
              sourceLanguage,
              contentVoice
            )
          );
          const contentAudioBuffer = Buffer.from(contentAudioBase64, 'base64');

          if (this.useAudioUploadMock) {
            const contentFile = this.createAudioFile(
              contentAudioBuffer,
              `content_step_${step.stepNumber}.mp3`
            );
            step.contentAudioUrl = await this.saveAudioLocally(
              contentFile,
              'lessay/lessonStep/audio'
            );
          } else {
            step.contentAudioUrl = await this.uploadFunction(
              contentAudioBuffer,
              `content_step_${step.stepNumber}.mp3`,
              'audio/mp3'
            );
          }

          // Generate expected answer audio in target language if exists
          if (step.expectedAnswer) {
            const answerVoice = this.ttsService.getVoice(language, 'basic');
            const answerAudioBase64 = await retryOperation(() =>
              this.ttsService.synthesizeSpeech(
                step.expectedAnswer!,
                language,
                answerVoice
              )
            );
            const answerAudioBuffer = Buffer.from(answerAudioBase64, 'base64');

            if (this.useAudioUploadMock) {
              const answerFile = this.createAudioFile(
                answerAudioBuffer,
                `answer_step_${step.stepNumber}.mp3`
              );
              step.expectedAnswerAudioUrl = await this.saveAudioLocally(
                answerFile,
                'lessay/lessonStep/audio'
              );
            } else {
              step.expectedAnswerAudioUrl = await this.uploadFunction(
                answerAudioBuffer,
                `answer_step_${step.stepNumber}.mp3`,
                'audio/mp3'
              );
            }
          }
        }
      }
      return steps;
    } catch (error) {
      logger.error('Error generating audio for lesson:', { error });
      throw error;
    }
  }

  private async saveAudioLocally(
    file: File,
    pathPrefix: string
  ): Promise<string> {
    try {
      const publicDir = path.join(process.cwd(), 'public');
      const targetDir = path.join(publicDir, pathPrefix);

      if (!fs.existsSync(targetDir)) {
        fs.mkdirSync(targetDir, { recursive: true });
      }

      const timestamp = Date.now();
      const filename = `${timestamp}-${file.name}`;
      const filePath = path.join(targetDir, filename);

      const arrayBuffer = await file.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      fs.writeFileSync(filePath, buffer);

      return `/${pathPrefix}/${filename}`;
    } catch (error) {
      logger.error('Error saving audio locally', { error });
      throw error;
    }
  }

  // Helper method to create a File from audio buffer
  private createAudioFile(
    audioBuffer: string | Buffer | ArrayBuffer, // Updated to also accept Buffer
    filename: string
  ): File {
    let blob: Blob;

    // If the audioBuffer is a Node.js Buffer, convert it to an ArrayBuffer before proceeding.
    if (typeof audioBuffer !== 'string' && Buffer.isBuffer(audioBuffer)) {
      audioBuffer = audioBuffer.buffer.slice(
        audioBuffer.byteOffset,
        audioBuffer.byteOffset + audioBuffer.byteLength
      ) as ArrayBuffer;
    }

    logger.info(
      'audioBuffer',
      typeof audioBuffer === 'string'
        ? audioBuffer.slice(0, 100)
        : 'ArrayBuffer received'
    );

    if (typeof audioBuffer === 'string') {
      // If it's a base64 string, convert it to a Blob using Buffer
      const base64Data = audioBuffer.includes(',')
        ? audioBuffer.split(',')[1] // Extract from data URL if necessary
        : audioBuffer;
      const buffer = Buffer.from(base64Data, 'base64');
      blob = new Blob([buffer], { type: 'audio/mp3' });
    } else {
      // If it's already an ArrayBuffer
      blob = new Blob([audioBuffer], { type: 'audio/mp3' });
    }

    return new File([blob], filename, { type: 'audio/mp3' });
  }

  private formatLessonResponse(
    aiResponse: Record<string, unknown>
  ): GeneratedLesson {
    logger.info('Formatting lesson response', { aiResponse });

    // Assert that aiResponse.data is an array if it exists
    const lessonData =
      (aiResponse as { data?: unknown[] }).data?.[0] || aiResponse;

    return {
      id: '', // Populated when saved to the database.
      userId: '', // Will be assigned in the lesson service.
      lessonId: '', // To be autogenerated.
      focusArea: (lessonData as any).focusArea || 'General Conversation',
      targetSkills: (lessonData as any).targetSkills || [
        'Vocabulary',
        'Grammar',
      ],
      steps: (lessonData as any).steps || [],
      completed: false,
      createdAt: new Date(),
      updatedAt: new Date(),
    };
  }

  private generateLessonPrompts(
    topic: string,
    targetLanguage: string,
    sourceLanguage: string,
    difficultyLevel: string,
    adaptiveRequest?: AdaptiveLessonGenerationRequest
  ): { userPrompt: string; systemPrompt: string } {
    // Build context sections
    const contextSections = {
      overallProgress: this.buildOverallProgressContext(
        adaptiveRequest?.overallProgress
      ),
      performanceMetrics: this.buildPerformanceContext(
        adaptiveRequest?.performanceMetrics
      ),
      audioAnalysis: this.buildAudioAnalysisContext(
        adaptiveRequest?.detailedAudioAnalysis
      ),
      previousLesson: this.buildPreviousLessonContext(
        adaptiveRequest?.previousLesson
      ),
    };

    return {
      systemPrompt: this.buildSystemPrompt(
        targetLanguage,
        sourceLanguage,
        difficultyLevel,
        contextSections
      ),
      userPrompt: this.buildUserPrompt(
        topic,
        targetLanguage,
        sourceLanguage,
        difficultyLevel,
        contextSections
      ),
    };
  }

  private buildSystemPrompt(
    targetLanguage: string,
    sourceLanguage: string,
    difficultyLevel: string,
    contexts: { [key: string]: string }
  ): string {
    return `## ROLE: Expert Language Tutor & Lesson Designer (Voice-First)

You are an expert language tutor specializing in creating structured, pedagogically sound lessons for learning **${targetLanguage}**, designed for learners whose native language is **${sourceLanguage}**. The lessons will be delivered via a voice-based interface.

## CORE OBJECTIVE:

Generate a complete, single lesson focused on a specific topic, adhering strictly to the defined step structure and field requirements. The lesson should be appropriate for a **${difficultyLevel}** proficiency level and leverage the provided adaptive learning context.

## GUIDING PRINCIPLES & CONSTRAINTS:

1.  **Pedagogical Flow:** Lessons must follow a logical sequence: Introduction -> New Content/Vocabulary -> Practice -> Feedback -> Summary.
2.  **Voice-First Design:** All steps must be suitable for audio playback and voice responses (captured via Speech-to-Text). Phrasing must be clear and concise.
3.  **Strict Step Structure & Field Usage:** Adhere precisely to the defined \`LessonStepType\` and field requirements:
    *   **\`instruction\`**: Use for introductions, explanations, or transitions.
        *   \`content\`: The instruction text (primarily in **${sourceLanguage}**).
        *   \`translation\`: Should be \`null\`.
        *   \`expectedAnswer\`: Must be \`null\`.
        *   \`maxAttempts\`: 1.
    *   **\`new_word\`**: Use to introduce new vocabulary within a sentence context.
        *   \`content\`: A sentence in **${targetLanguage}** that uses the new word/phrase.
        *   \`translation\`: The meaning of the *sentence* in **${sourceLanguage}**.
        *   \`expectedAnswer\`: The *same sentence* from the \`content\` field in **${targetLanguage}** (for repetition/pronunciation practice).
        *   \`maxAttempts\`: 3.
    *   **\`practice\` / \`prompt\`**: Use for exercises testing recall, application, or simple production.
        *   \`content\`: The question or instruction, usually in **${sourceLanguage}** (e.g., "How do you say X?", "Translate Y").
        *   \`translation\`: The **${targetLanguage}** translation of the \`content\` prompt.
        *   \`expectedAnswer\`: The *correct user response* in **${targetLanguage}**. This field is **mandatory** for these types.
        *   \`maxAttempts\`: 3.
    *   **\`feedback\`**: Use for brief, encouraging feedback after practice steps (can be positive or corrective).
        *   \`content\`: Feedback text (primarily in **${sourceLanguage}**).
        *   \`translation\`: Should be \`null\`.
        *   \`expectedAnswer\`: Must be \`null\`.
        *   \`maxAttempts\`: 1.
    *   **\`summary\`**: Use for concluding the lesson.
        *   \`content\`: Summary text (primarily in **${sourceLanguage}**).
        *   \`translation\`: Should be \`null\`.
        *   \`expectedAnswer\`: Must be \`null\`.
        *   \`maxAttempts\`: 1.
4.  **Adaptive Learning:** Use the provided context (overall progress, recent performance, audio analysis) to tailor the lesson content:
    *   Address identified weaknesses (grammar, vocab, pronunciation).
    *   Reinforce low-mastery topics/words.
    *   Adjust difficulty slightly based on trajectory and recent scores.
    *   Incorporate suggested focus areas or skill targets.
5.  **Language Usage:**
    *   Instructions, feedback, summaries, and practice prompts (\`content\`) should generally be in **${sourceLanguage}**.
    *   New words (\`content\`) and expected answers (\`expectedAnswer\`) must be in **${targetLanguage}**.
    *   Translations (\`translation\`) must be accurate and relevant.
6.  **Output Format:** Generate a **single, valid JSON object** representing the lesson, strictly following the specified format in the user prompt. Ensure all required fields are present and correctly typed for each step.

## PROVIDED ADAPTIVE CONTEXT (Use this to personalize the lesson):

${contexts.overallProgress || 'Overall Progress: No specific data provided.'}
${contexts.performanceMetrics ||
      'Recent Performance: No specific data provided.'
      }
${contexts.audioAnalysis || 'Audio Analysis: No specific data provided.'}
${contexts.previousLesson || 'Previous Lesson: No specific data provided.'}
`;
  }

  private buildUserPrompt(
    topic: string,
    targetLanguage: string,
    sourceLanguage: string,
    difficultyLevel: string,
    contexts: { [key: string]: string }
  ): string {
    return `## TASK: Generate an Adaptive Language Lesson

    Create a complete, structured language lesson focused on the topic: **"${topic}"**.
    The lesson is for a **${difficultyLevel}** learner of **${targetLanguage}** whose native language is **${sourceLanguage}**.
    
    **INSTRUCTIONS:**
    
    1.  **Use Adaptive Context:** Personalize the lesson content based on the provided context below. Focus on addressing weaknesses and reinforcing learning goals.
    2.  **Structure (15+ Steps):** Follow a standard pedagogical flow:
        *   Start with an \`instruction\` step (intro).
        *   Introduce new concepts/vocabulary using \`new_word\` steps.
        *   Include several \`practice\` or \`prompt\` steps for active recall and application.
        *   Provide brief \`feedback\` steps after some practice steps.
        *   End with a \`summary\` step.
    3.  **Strict Field Requirements:**
        *   **\`instruction\` / \`feedback\` / \`summary\`**: \`content\` in ${sourceLanguage}, \`expectedAnswer\` must be \`null\`, \`maxAttempts\` = 1.
        *   **\`new_word\`**: \`content\` in ${targetLanguage}, \`translation\` in ${sourceLanguage}, \`expectedAnswer\` = \`content\` (for repetition), \`maxAttempts\` = 3.
        *   **\`practice\` / \`prompt\`**: \`content\` (question/instruction) in ${sourceLanguage}, \`translation\` (prompt in ${targetLanguage}), \`expectedAnswer\` (correct user response in ${targetLanguage}) **is mandatory**, \`maxAttempts\` = 3.
    4.  **Content:** Ensure content is relevant to the topic, appropriate for the difficulty level, and addresses points from the adaptive context if applicable.
    5.  **Voice-First:** Keep text concise and clear for audio delivery and voice input.
    
    **ADAPTIVE CONTEXT FOR THIS LESSON:**
    ${contexts.overallProgress || 'Overall Progress: No specific data provided.'
      }
    ${contexts.performanceMetrics ||
      'Recent Performance: No specific data provided.'
      }
    ${contexts.audioAnalysis || 'Audio Analysis: No specific data provided.'}
    ${contexts.previousLesson || 'Previous Lesson: No specific data provided.'}
    
    **OUTPUT FORMAT (Single JSON Object):**
    
    Generate a **single, valid JSON object** containing the lesson structure. Adhere strictly to this format:
    
    \`\`\`json
    {
      "focusArea": "Lesson Topic ",
      "targetSkills": ["Skill 1", "Skill 2", "..."], // List skills addressed
      "steps": [
        {
          "stepNumber": 1,
          "type": "instruction", // Must be one of: instruction, new_word, practice, prompt, feedback, summary
          "content": "Instruction text in ${sourceLanguage}...",
          "translation": null, // Should be null for instruction/feedback/summary
          "expectedAnswer": null, // MUST be null for instruction/feedback/summary
          "maxAttempts": 1 // Should be 1 for instruction/feedback/summary
        },
        {
          "stepNumber": 2,
          "type": "new_word",
          "content": "Sentence using the new word in ${targetLanguage}.",
          "translation": "Meaning of the sentence in ${sourceLanguage}.",
          "expectedAnswer": "Sentence using the new word in ${targetLanguage}.", // Same as content for repetition
          "maxAttempts": 3 // Should be 3 for new_word/practice/prompt
        },
        {
          "stepNumber": 3,
          "type": "practice", // or "prompt"
          "content": "Question or task in ${sourceLanguage}...",
          "translation": "Question or task translated to ${targetLanguage}",
          "expectedAnswer": "CorrectResponseIn${targetLanguage}", // MANDATORY for practice/prompt
          "maxAttempts": 3
        },
        {
          "stepNumber": 4,
          "type": "feedback",
          "content": "Feedback text in ${sourceLanguage}...",
          "translation": null,
          "expectedAnswer": null, // MUST be null
          "maxAttempts": 1
        },
        // ... more steps (13-20 total) ...
        {
          "stepNumber": 15, // Example final step
          "type": "summary",
          "content": "Summary text in ${sourceLanguage}...",
          "translation": null,
          "expectedAnswer": null, // MUST be null
          "maxAttempts": 1
        }
      ]
    }
    \`\`\`
    
    Ensure the generated JSON is valid and complete according to these instructions.
    `;
  }

  private buildOverallProgressContext(
    progress?: AdaptiveLessonGenerationRequest['overallProgress']
  ): string {
    if (!progress) return '';
    return `
        Overall Progress:
        - Proficiency: ${progress.estimatedProficiencyLevel}
        - Score: ${progress.overallScore || 'N/A'}
        - Trajectory: ${progress.learningTrajectory}
        - Strengths: ${progress.persistentStrengths.slice(0, 3).join(', ')}
        - Weaknesses: ${progress.persistentWeaknesses.slice(0, 3).join(', ')}
        - Low Mastery Topics: ${progress.lowMasteryTopics?.slice(0, 3).join(', ') || 'None'
      }
        - Vocabulary Needs: ${progress.lowMasteryWordsCount || 0
      } words needing practice`;
  }

  private buildPerformanceContext(
    metrics?: AdaptiveLessonGenerationRequest['performanceMetrics']
  ): string {
    if (!metrics) return '';
    return `
        Recent Performance:
        - Accuracy: ${metrics.avgAccuracy?.toFixed(0) || 'N/A'}%
        - Pronunciation: ${metrics.avgPronunciationScore?.toFixed(0) || 'N/A'
      }/100
        - Grammar: ${metrics.avgGrammarScore?.toFixed(0) || 'N/A'}/100
        - Vocabulary: ${metrics.avgVocabularyScore?.toFixed(0) || 'N/A'}/100
        - Top Strengths: ${metrics.strengths.slice(0, 2).join(', ') || 'None'}
        - Top Weaknesses: ${metrics.weaknesses.slice(0, 2).join(', ') || 'None'
      }`;
  }

  private buildAudioAnalysisContext(
    audio?: AdaptiveLessonGenerationRequest['detailedAudioAnalysis']
  ): string {
    if (!audio) return '';
    return `
        Audio Analysis:
        - Problematic Sounds: ${audio.problematicSounds.slice(0, 3).join(', ') || 'None'
      }
        - Grammar Focus: ${audio.grammarRulesToReview
        .slice(0, 2)
        .map((r) => `${r.rule} (${r.priority})`)
        .join(', ')}
        - Vocabulary Expansion: ${audio.vocabularyAreasForExpansion
        .slice(0, 2)
        .map(
          (v) => `${v.topic}: ${v.suggestedVocabulary.slice(0, 3).join(', ')}`
        )
        .join('; ')}
        - Suggested Focus: ${audio.nextSkillTargets.slice(0, 2).join(', ') || 'None'
      }`;
  }

  private buildPreviousLessonContext(
    lesson?: AdaptiveLessonGenerationRequest['previousLesson']
  ): string {
    if (!lesson) return '';
    return `
        Previous Lesson:
        - Focus: ${lesson.focusArea}
        - Skills: ${lesson.targetSkills.slice(0, 3).join(', ')}`;
  }

  async generateLessonCompletionResults(
    lesson: LessonModel,
    userResponses: { stepId: string; response: string }[]
  ): Promise<{
    metrics: {
      accuracy: number;
      pronunciationScore: number;
      grammarScore: number;
      vocabularyScore: number;
      overallScore: number;
      strengths: string[];
      weaknesses: string[];
    };
    summary: string;
    nextLessonSuggestions: string[];
  }> {
    logger.info('Generating lesson completion results', {
      lessonId: lesson.id,
      responseCount: userResponses.length,
    });

    const prompts = this.generateLessonCompletionPrompts(lesson, userResponses);

    try {
      let aiResponse;

      if (this.useLessonGeneratorMock) {
        logger.info('Using mock data for lesson completion results');
        // Mock results for testing
        aiResponse = {
          metrics: {
            accuracy: 85,
            pronunciationScore: 78,
            grammarScore: 82,
            vocabularyScore: 80,
            overallScore: 81,
            strengths: ['Basic vocabulary usage', 'Question formation'],
            weaknesses: ['Article usage', 'Verb conjugation in past tense'],
          },
          summary: `Good progress with ${lesson.focusArea}. You demonstrated solid understanding of the core concepts, though there are some areas to improve.`,
          nextLessonSuggestions: [
            'Grammar fundamentals',
            'Past tense expressions',
            'Everyday conversation',
          ],
        };
      } else {
        const result = await retryOperation(() =>
          this.aiService.generateContent(
            '',
            prompts.userPrompt,
            prompts.systemPrompt,
            models.gemini_2_0_flash
          )
        );

        aiResponse = this.formatLessonCompletionResults(result);
        logger.info(
          'Generated real lesson completion results in not mocked mode',
          { aiResponse }
        );
      }

      return aiResponse;
    } catch (error) {
      logger.error('Error generating lesson completion results', { error });
      throw new Error('Failed to generate lesson completion analysis');
    }
  }

  private formatLessonCompletionResults(aiResponse: Record<string, unknown>): {
    metrics: {
      accuracy: number;
      pronunciationScore: number;
      grammarScore: number;
      vocabularyScore: number;
      overallScore: number;
      strengths: string[];
      weaknesses: string[];
    };
    summary: string;
    nextLessonSuggestions: string[];
  } {
    return {
      metrics: aiResponse.metrics as any,
      summary: aiResponse.summary as string,
      nextLessonSuggestions: aiResponse.nextLessonSuggestions as string[],
    };
  }

  private generateLessonCompletionPrompts(
    lesson: LessonModel,
    userResponses: { stepId: string; response: string }[]
  ): { userPrompt: string; systemPrompt: string } {
    // Create a map of step ID to user response for easier lookup
    const responseMap = new Map(
      userResponses.map((item) => [item.stepId, item.response])
    );

    // Format steps with user responses for analysis
    const stepsWithResponses = lesson.steps.map((step) => {
      const userResponse = responseMap.get(step.id) || '';
      const userResponseHistory = step.userResponseHistory
        ? (JSON.parse(step.userResponseHistory as string) as string[])
        : [];

      return {
        stepNumber: step.stepNumber,
        type: step.type,
        content: step.content,
        expectedAnswer: step.expectedAnswer,
        userResponse,
        userResponseHistory,
        correct: step.correct,
        attempts: step.attempts,
      };
    });

    return {
      systemPrompt: `You are an expert language learning analyst. Your task is to evaluate a student's performance in a language lesson and provide comprehensive feedback.
      
      Analyze each step of the lesson, considering:
      1. Accuracy - how correctly the student responded to exercises
      2. Pronunciation - quality of spoken responses (inferred from text)
      3. Grammar - proper sentence structure and form
      4. Vocabulary - appropriate word choice and breadth of vocabulary
      5. Overall performance - holistic assessment
      
      Identify specific strengths and areas for improvement based on patterns in the student's responses. 
      Provide a summary that is encouraging but honest, and suggest topics for future lessons that would help address any weaknesses.`,

      userPrompt: `Analyze the following completed language lesson and provide detailed feedback and metrics.
      
      Lesson focus: ${lesson.focusArea}
      Target skills: ${lesson.targetSkills.join(', ')}
      
      Steps with user responses:
      ${JSON.stringify(stepsWithResponses, null, 2)}
      
      Format your response as JSON:
      {
        "metrics": {
          "accuracy": number (0-100),
          "pronunciationScore": number (0-100),
          "grammarScore": number (0-100),
          "vocabularyScore": number (0-100),
          "overallScore": number (0-100),
          "strengths": [array of 2-4 specific strengths],
          "weaknesses": [array of 2-4 specific areas for improvement]
        },
        "summary": "A 2-3 sentence personalized summary of the student's performance",
        "nextLessonSuggestions": [array of 2-4 recommended lesson topics]
      }`,
    };
  }
}

export default LessonGeneratorService;
</file>

<file path="src/services/onboarding.service.ts">
import {
  AssessmentLesson,
  AssessmentStep,
  AudioMetrics,
  getExerciseCompletion,
  getFluencyAssessment,
  getGrammarAssessment,
  getPronunciationAssessment,
  getVocabularyAssessment,
  LessonModel,
  OnboardingModel,
} from '@/models/AppAllModels.model';
import {
  AiAdaptiveSuggestions,
  AiLessonAnalysisResponse,
  AiPerformanceMetrics,
  AiProgressTracking,
  IOnboardingRepository,
} from '@/lib/interfaces/all-interfaces';
import logger from '@/utils/logger';
import LessonService from './lesson.service';
import { IAssessmentGeneratorService } from './assessment-generator.service';
import RecordingService from './recording.service';
import { mockAudioMetrics } from '@/__mocks__/generated-audio-metrics.mock';
import {
  ComprehensionLevel,
  HesitationFrequency,
  LanguageInfluenceLevel,
  LearningTrajectory,
  SpeechRateEvaluation,
  VocabularyRange,
} from '@prisma/client';
import { JsonValue } from '@prisma/client/runtime/library';
import { LearningProgressRepository } from '@/repositories/learning-progress.repository';
import LearningProgressService from './learning-progress.service';
import { randomUUID } from 'crypto';

export default class OnboardingService {
  private onboardingRepository: IOnboardingRepository;
  private lessonService: LessonService;
  private assessmentGeneratorService: IAssessmentGeneratorService;
  private recordingService: RecordingService;
  private learningProgressService: LearningProgressService;
  constructor(
    onboardingRepository: IOnboardingRepository,
    lessonService: LessonService,
    assessmentGeneratorService: IAssessmentGeneratorService
  ) {
    this.onboardingRepository = onboardingRepository;
    this.lessonService = lessonService;
    this.assessmentGeneratorService = assessmentGeneratorService;
    this.recordingService = new RecordingService();
    const progressRepository = new LearningProgressRepository();
    this.learningProgressService = new LearningProgressService(
      progressRepository
    ); // Instantiate it here
  }

  getOnboarding = async (): Promise<OnboardingModel | null> => {
    const onboarding = await this.onboardingRepository.getOnboarding();
    logger.info('Onboarding:', onboarding);
    return onboarding;
  };

  createOnboarding = async (): Promise<OnboardingModel> => {
    return this.onboardingRepository.createOnboarding();
  };

  updateOnboarding = async (
    step: string,
    formData: any
  ): Promise<OnboardingModel> => {
    return this.onboardingRepository.updateOnboarding(step, formData);
  };

  markOnboardingAsCompleteAndGenerateLessons =
    async (): Promise<OnboardingModel> => {
      const onboarding = await this.onboardingRepository.completeOnboarding();
      await this.lessonService.generateInitialLessons();
      return onboarding;
    };

  deleteOnboarding = async (): Promise<void> => {
    return this.onboardingRepository.deleteOnboarding();
  };

  getStatus = async (): Promise<boolean> => {
    return this.onboardingRepository.getStatus();
  };

  async getAssessmentLesson(): Promise<AssessmentLesson> {
    try {
      // First check if there's already an assessment lesson
      const existingAssessment =
        await this.onboardingRepository.getAssessmentLesson();
      if (existingAssessment) {
        return existingAssessment;
      }

      // Get onboarding data to get language preferences
      const onboarding = await this.onboardingRepository.getOnboarding();

      if (
        !onboarding?.targetLanguage ||
        !onboarding?.nativeLanguage ||
        !onboarding?.proficiencyLevel
      ) {
        throw new Error('Missing required parameters');
      }

      // Generate assessment steps
      const steps =
        await this.assessmentGeneratorService.generateAssessmentSteps(
          onboarding?.targetLanguage,
          onboarding?.nativeLanguage,
          onboarding?.proficiencyLevel
        );

      logger.info(`Generated ${steps} assessment steps without audio`);

      const audioSteps =
        await this.assessmentGeneratorService.generateAudioForSteps(
          steps,
          onboarding?.targetLanguage || 'English',
          onboarding?.nativeLanguage || 'English'
        );
      logger.info('generated audio steps', audioSteps);

      const assessmentLesson = {
        userId: onboarding?.userId,
        description: `Comprehensive ${
          onboarding?.targetLanguage || 'German'
        } language assessment`,
        completed: false,
        sourceLanguage: onboarding?.nativeLanguage || 'English',
        targetLanguage: onboarding?.targetLanguage || 'German',
        metrics: {
          accuracy: 0,
          pronunciationScore: 0,
          grammarScore: 0,
          vocabularyScore: 0,
          overallScore: 0,
          strengths: [],
          weaknesses: [],
        },
        proposedTopics: [],
        summary: null,
        steps: audioSteps,
      };

      logger.info(`Assessment lesson: ${JSON.stringify(assessmentLesson)}`);
      // Save to database
      return this.onboardingRepository.createAssessmentLesson(
        onboarding?.userId,
        assessmentLesson
      );
    } catch (error) {
      logger.error('Error generating assessment lesson:', error);
      throw error;
    }
  }

  async completeAssessmentLesson(
    lessonId: string,
    userResponse: string
  ): Promise<AssessmentLesson> {
    // get assessment lesson
    const assessmentLesson =
      await this.onboardingRepository.getAssessmentLessonById(lessonId);
    if (!assessmentLesson) {
      throw new Error('Assessment lesson not found');
    }

    const results =
      await this.assessmentGeneratorService.generateAssessmentResult(
        assessmentLesson
      );

    logger.info('results in completeAssessmentLesson', results);

    assessmentLesson.metrics = results.metrics;
    assessmentLesson.summary = results.summary;
    assessmentLesson.proposedTopics = results.proposedTopics;


    // complete assessment lesson
    const completedLesson =
      await this.onboardingRepository.completeAssessmentLesson(
        assessmentLesson,
        {
          summary: results.summary,
          metrics: results.metrics,
          proposedTopics: results.proposedTopics,
        }
      );

    this.learningProgressService
      .updateProgressAfterAssessment(completedLesson.userId, completedLesson)
      .catch((err) => {
        logger.error(
          'Failed to update learning progress after assessment completion',
          {
            userId: completedLesson.userId,
            assessmentId: completedLesson.id,
            error: err,
          }
        );
      });

    const completedOnboarding =
      await this.onboardingRepository.completeOnboarding();
    logger.info('completed onboarding', completedOnboarding);
    logger.info('completed lesson', completedLesson);
    return completedLesson;
  }

  async recordStepAttempt(
    lessonId: string,
    stepId: string,
    userResponse: string
  ): Promise<AssessmentStep> {
    logger.info('recordStepAttempt', { lessonId, stepId, userResponse });

    try {
      const lesson = await this.onboardingRepository.getAssessmentLessonById(
        lessonId
      );
      if (!lesson) {
        throw new Error('Assessment lesson not found');
      }
      const step = lesson.steps.find((s) => s.id === stepId);
      if (!step) {
        throw new Error('Step not found');
      }

      // Check if max attempts has been reached
      if (step.attempts >= step.maxAttempts) {
        logger.info('Maximum attempts reached', {
          stepId,
          attempts: step.attempts,
          maxAttempts: step.maxAttempts,
        });

        // Record the attempt but mark as incorrect, preserving user response
        return this.onboardingRepository.recordStepAttempt(lessonId, stepId, {
          userResponse: step.expectedAnswer || '',
          correct: true, // to proceed on the frontend
        });
      }

      // Validate user response for most step types
      if (
        step.type !== 'instruction' &&
        step.type !== 'summary' &&
        step.type !== 'feedback'
      ) {
        if (!userResponse) {
          throw new Error('No response provided');
        }
        if (userResponse.length <= 1) {
          throw new Error('Response is too short');
        }
      }
      let correct = false;

      logger.info('processing the step attempt', { step, userResponse });

      // Handle different assessment step types
      switch (step.type) {
        case 'question':
          // For questions, compare with the expectedAnswer if available
          if (step.expectedAnswer) {
            logger.info('step.expectedAnswer', step.expectedAnswer);
            logger.info('userResponse', userResponse);
            if (userResponse.toLowerCase().includes('skip')) {
              correct = true;
              break;
            }
            // Normalize user response by removing punctuation and special characters
            const normalizedUserResponse = userResponse
              .trim()
              .toLowerCase()
              // Remove punctuation, ellipses, and extra whitespace
              .replace(/[.,!?;:"'""''()[\]…]+/g, '')
              .replace(/\s+/g, ' ');

            // Normalize expected answer the same way
            const normalizedExpectedAnswer = step.expectedAnswer
              .trim()
              .toLowerCase()
              // Remove punctuation, ellipses, and extra whitespace
              .replace(/[.,!?;:"'""''()[\]…]+/g, '')
              .replace(/\s+/g, ' ');

            // Main comparison: Check if normalized user response includes
            // the essential part of the normalized expected answer

            // First check if expected answer without ellipses is in user response
            const essentialExpectedPart = normalizedExpectedAnswer
              .replace(/\.{3,}/g, '')
              .trim();

            logger.info('Normalized user response:', normalizedUserResponse);
            logger.info('Essential expected part:', essentialExpectedPart);

            // Check if either there's a very close match, or the user response
            // contains the essential part of the expected answer
            if (normalizedUserResponse === essentialExpectedPart) {
              correct = true;
            } else if (normalizedUserResponse.includes(essentialExpectedPart)) {
              correct = true;
            } else if (essentialExpectedPart.includes(normalizedUserResponse)) {
              // For responses that may be shorter but still valid
              // For example, if expected is "hallo ich heiße" and user just said "hallo"
              const essentialWords = essentialExpectedPart.split(' ');
              const userWords = normalizedUserResponse.split(' ');

              // If user said at least half of the essential words, consider it correct
              // This helps with partial responses that are still meaningful
              const matchedWordCount = userWords.filter(
                (word) => essentialWords.includes(word) && word.length > 1
              ).length;

              correct = matchedWordCount / essentialWords.length >= 0.5;
            }
          } else {
            // If no expected answer, consider it correct (open-ended question)
            correct = true;
          }
          break;

        case 'instruction':
        case 'summary':
        case 'feedback':
          // These types just need acknowledgment
          correct = true;
          // For these types, we use a default "Acknowledged" response if none provided
          userResponse = userResponse || 'Acknowledged';
          break;

        default:
          logger.warn(`Unknown assessment step type: ${step.type}`);
          correct = false;
      }

      // Record the attempt
      const updatedStep = await this.onboardingRepository.recordStepAttempt(
        lessonId,
        stepId,
        {
          userResponse,
          correct,
        }
      );
      logger.info('updatedStep', { updatedStep });

      // return updated step with user response as expected answer
      return {
        ...updatedStep,
        userResponse: step.expectedAnswer || '',
      };
    } catch (error) {
      logger.error('Error recording step attempt:', error);
      throw error;
    }
  }

  updateOnboardingAssessmentLesson = async (
    lessonId: string,
    lessonData: Partial<AssessmentLesson>
  ) => {
    if (!lessonId) {
      throw new Error('Lesson ID is required');
    }

    return this.onboardingRepository.updateOnboardingAssessmentLesson(
      lessonId,
      lessonData
    );
  };
  async processAssessmentLessonRecording(
    sessionRecording: Blob,
    lesson: AssessmentLesson,
    recordingTime: number,
    recordingSize: number
  ) {
    //1. get user onboarding data with lagnuages
    const onboardingData = await this.onboardingRepository.getOnboarding();
    if (!onboardingData) {
      throw new Error('User onboarding data not found');
    }
    const targetLanguage = onboardingData.targetLanguage || 'English';
    const sourceLanguage = onboardingData.nativeLanguage || 'English';

    // 2. process recording
    const arrayBuffer = await sessionRecording.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // 3. Determine proper mime type
    const mimeType = sessionRecording.type || 'audio/webm';

    // 4. Upload the file
    const fileName = `lesson-${lesson.id}-${Date.now()}.webm`;
    logger.info('Uploading recording file', {
      fileName,
      mimeType,
      size: buffer.length,
    });

    const fileUri = await this.recordingService.uploadFile(
      buffer,
      mimeType,
      fileName
    );
    logger.log('File URI:', fileUri);

    logger.log('Sending recording to AI for analysis');

    // send recording to AI
    let aiResponse: Record<string, unknown>;
    if (false) {
      // if (process.env.NEXT_PUBLIC_MOCK_RECORDING_AI_ANALYSIS === 'true') {
      aiResponse = mockAudioMetrics;
    } else {
      aiResponse = await this.recordingService.submitLessonRecordingSession(
        fileUri, // Now using file URI instead of base64
        Number(recordingTime),
        Number(recordingSize),
        { targetLanguage, nativeLanguage: sourceLanguage },
        lesson
      );
    }

    // 3. convert ai  response to audioMetrics model.
    const audioMetrics = this.convertAiResponseToAudioMetrics(aiResponse);

  
    // 4. update lesson with sessionRecordingMetrics, lesson should have a foreign key to audioMetrics
    return this.onboardingRepository.updateOnboardingAssessmentLesson(
      lesson.id,
      { audioMetrics }
    );
  }

  private convertAiResponseToAudioMetrics(
    aiResponse: AiLessonAnalysisResponse // Use the specific interface type
  ): AudioMetrics {
   

    // Safely access nested objects
    const performanceMetrics: AiPerformanceMetrics | undefined =
      aiResponse.performance_metrics;
    const progressTracking: AiProgressTracking | undefined =
      aiResponse.progress_tracking;
    const adaptiveSuggestions: AiAdaptiveSuggestions | undefined =
      aiResponse.adaptive_learning_suggestions;

    // Extract top-level metrics safely, providing defaults if objects or properties are missing
    const pronunciationScore =
      typeof performanceMetrics?.pronunciation_score === 'number'
        ? performanceMetrics.pronunciation_score
        : 0;
    const fluencyScore =
      typeof performanceMetrics?.fluency_score === 'number'
        ? performanceMetrics.fluency_score
        : 0;
    const grammarScore =
      typeof performanceMetrics?.grammar_accuracy === 'number' // Use correct source key
        ? performanceMetrics.grammar_accuracy
        : 0;
    const vocabularyScore =
      typeof performanceMetrics?.vocabulary_score === 'number'
        ? performanceMetrics.vocabulary_score
        : 0;
    const overallPerformance =
      typeof performanceMetrics?.overall_performance === 'number'
        ? performanceMetrics.overall_performance
        : 0;

    const id = randomUUID();

    // Extract CEFR level and learning trajectory safely
    const proficiencyLevel =
      typeof progressTracking?.estimated_proficiency_level === 'string'
        ? progressTracking.estimated_proficiency_level
        : 'A1'; // Default

    let learningTrajectory: LearningTrajectory = 'steady'; // Default
    const trajectoryFromAI = progressTracking?.learning_trajectory;
    if (trajectoryFromAI === 'accelerating') {
      learningTrajectory = 'accelerating';
    } else if (trajectoryFromAI === 'plateauing') {
      learningTrajectory = 'plateauing';
    }

    // Extract detailed assessment data - Pass the correct top-level objects
    // Use optional chaining `?.` in case the assessment object itself is missing
    const pronunciationAssessment = getPronunciationAssessment(
      aiResponse?.pronunciation_assessment as JsonValue
    ) || {
      overall_score: pronunciationScore,
      native_language_influence: {
        level: 'moderate' as LanguageInfluenceLevel,
        specific_features: [],
      },
      phoneme_analysis: [],
      problematic_sounds: [],
      strengths: [],
      areas_for_improvement: [],
    };

    const fluencyAssessment = getFluencyAssessment(
      aiResponse?.fluency_assessment as JsonValue
    ) || {
      overall_score: fluencyScore,
      speech_rate: {
        words_per_minute: 0,
        evaluation: 'appropriate' as SpeechRateEvaluation,
      },
      hesitation_patterns: {
        frequency: 'occasional' as HesitationFrequency,
        average_pause_duration: 0,
        typical_contexts: [],
      },
      rhythm_and_intonation: {
        naturalness: 0,
        sentence_stress_accuracy: 0,
        intonation_pattern_accuracy: 0,
      },
    };

    const grammarAssessment = getGrammarAssessment(
      aiResponse?.grammar_assessment as JsonValue
    ) || {
      overall_score: grammarScore,
      error_patterns: [],
      grammar_rules_to_review: [],
      grammar_strengths: [],
    };

    const vocabularyAssessment = getVocabularyAssessment(
      aiResponse?.vocabulary_assessment as JsonValue
    ) || {
      overall_score: vocabularyScore,
      range: 'adequate' as VocabularyRange,
      appropriateness: 0,
      precision: 0,
      areas_for_expansion: [],
    };

    const exerciseCompletion = getExerciseCompletion(
      aiResponse?.exercise_completion as JsonValue
    ) || {
      overall_score: 0,
      exercises_analyzed: [],
      comprehension_level: 'fair' as ComprehensionLevel,
    };

    // Helper to extract string arrays safely
    const extractStringArray = (value: unknown): string[] => {
      if (Array.isArray(value)) {
        return value.filter((item) => typeof item === 'string') as string[];
      }
      return [];
    };

    // Extract learning suggestions safely using optional chaining
    const suggestedTopics = extractStringArray(
      adaptiveSuggestions?.suggested_topics
    );
    const grammarFocusAreas = extractStringArray(
      adaptiveSuggestions?.grammar_focus_areas
    );
    const vocabularyDomains = extractStringArray(
      adaptiveSuggestions?.vocabulary_domains
    );
    const nextSkillTargets = extractStringArray(
      adaptiveSuggestions?.next_skill_targets
    );
    // Handle potential nesting within learning_style_observations or direct access
    const preferredPatterns = extractStringArray(
      adaptiveSuggestions?.preferred_patterns ||
        adaptiveSuggestions?.learning_style_observations?.preferred_patterns
    );
    const effectiveApproaches = extractStringArray(
      adaptiveSuggestions?.effective_approaches ||
        adaptiveSuggestions?.learning_style_observations?.effective_approaches
    );

    // Extract metadata safely
    const audioRecordingUrl =
      typeof aiResponse?.audioRecordingUrl === 'string'
        ? aiResponse.audioRecordingUrl
        : null;
    const recordingDuration =
      typeof aiResponse?.recordingDuration === 'number'
        ? aiResponse.recordingDuration
        : null;

    // Construct and return the AudioMetrics object
    const finalAudioMetrics: AudioMetrics = {
      // Explicitly type the final object
      id,
      pronunciationScore,
      fluencyScore,
      grammarScore,
      vocabularyScore,
      overallPerformance,
      proficiencyLevel,
      learningTrajectory,
      pronunciationAssessment,
      fluencyAssessment,
      grammarAssessment,
      vocabularyAssessment,
      exerciseCompletion,
      suggestedTopics,
      grammarFocusAreas,
      vocabularyDomains,
      nextSkillTargets,
      preferredPatterns,
      effectiveApproaches,
      audioRecordingUrl,
      recordingDuration,
      createdAt: new Date(),
      updatedAt: new Date(),
    };

    logger.debug(
      '<<< convertAiResponseToAudioMetrics OUTPUT:',
      JSON.stringify(finalAudioMetrics, null, 2)
    );
    return finalAudioMetrics;
  }
}
</file>

<file path="src/context/app-initializer-context.tsx">
'use client'
import React, {
  createContext,
  useContext,
  useState,
  useEffect,
  ReactNode,
} from 'react';
import { useAuth } from './auth-context';
import { useUserProfile } from './user-profile-context';
import { useOnboarding } from './onboarding-context'; // Import useOnboarding for redirection logic
import { useRouter, usePathname } from 'next/navigation';
import logger from '@/utils/logger';
import AppLoadingIndicator from '@/components/AppLoadingIndicator';
import {
  getOnboardingAction,
  createOnboardingAction,
} from '@/lib/server-actions/onboarding-actions'; // Import onboarding actions

type InitializationStatus = 'initializing' | 'idle' | 'error';

interface AppInitializerContextType {
  status: InitializationStatus;
  error: string | null;
  // No need to pass initial onboarding state down if redirection uses live state
}

const AppInitializerContext = createContext<AppInitializerContextType | undefined>(
  undefined
);

export function AppInitializerProvider({ children }: { children: ReactNode }) {
  const [status, setStatus] = useState<InitializationStatus>('initializing');
  const [error, setError] = useState<string | null>(null);

  const { user, loading: authLoading } = useAuth();
  const { profile, loading: profileLoading, error: profileError } = useUserProfile();
  // Get live onboarding state for redirection logic
  const { isOnboardingComplete } = useOnboarding();

  const router = useRouter();
  const pathname = usePathname();

  // --- Initialization Sequence ---
  useEffect(() => {
    let isMounted = true;

    const initializeApp = async () => {
      if (!isMounted) return;

      logger.info('AppInitializer: Starting initialization sequence...');
      setStatus('initializing');
      setError(null);

      // 1. Wait for Auth
      if (authLoading) {
        logger.info('AppInitializer: Waiting for auth...');
        return;
      }
      logger.info('AppInitializer: Auth settled.', { user: !!user });

      // 2. Handle No User
      if (!user) {
        logger.info('AppInitializer: No user found. Setting status to idle.');
        if (isMounted) setStatus('idle');
        return;
      }

      // 3. Wait for Profile
      if (profileLoading) {
        logger.info('AppInitializer: Waiting for profile...');
        return;
      }
      logger.info('AppInitializer: Profile settled.', { profile: !!profile, profileError });

      // 4. Handle Profile Error
      if (profileError) {
        logger.error('AppInitializer: Profile error encountered.', { profileError });
        if (isMounted) {
          setError(`Profile Error: ${profileError}`);
          setStatus('error');
        }
        return;
      }

      // 5. Handle Missing Profile
      if (!profile) {
        logger.error('AppInitializer: Profile is null after loading without error.');
        if (isMounted) {
          setError('Failed to load or create user profile.');
          setStatus('error');
        }
        return;
      }
      logger.info('AppInitializer: Profile loaded successfully.');

      // 6. Check/Create Onboarding (Crucial step before idle)
      logger.info('AppInitializer: Checking/Creating Onboarding...');
      try {
        const { data: onboardingData, error: getError } = await getOnboardingAction();

        if (getError && !getError.includes('Not found')) {
          logger.error('AppInitializer: Error fetching onboarding.', { getError });
          throw new Error(`Failed to fetch onboarding status: ${getError}`);
        }

        let initialCompleteStatus = false; // Default to incomplete

        if (onboardingData) {
          initialCompleteStatus = onboardingData.completed;
          logger.info('AppInitializer: Onboarding found.', { completed: initialCompleteStatus });
        } else {
          logger.info('AppInitializer: Onboarding not found, creating...');
          const { data: createdOnboarding, error: createError } = await createOnboardingAction();
          if (createError) {
            logger.error('AppInitializer: Error creating onboarding.', { createError });
            throw new Error(`Failed to create onboarding profile: ${createError}`);
          }
          if (!createdOnboarding) {
            logger.error('AppInitializer: createOnboardingAction returned no data and no error.');
            throw new Error('Failed to create onboarding profile.');
          }
          initialCompleteStatus = createdOnboarding.completed; // Should be false
          logger.info('AppInitializer: Onboarding created successfully.');
          // Note: We don't need to update OnboardingContext here; it will fetch its own data based on the user.
        }

        logger.info('AppInitializer: Onboarding check/create complete.');

        // 7. Set final status to idle *after* onboarding check/create
        if (isMounted) setStatus('idle');
        logger.info('AppInitializer: Initialization sequence complete. Status set to idle.');

      } catch (err: any) {
        logger.error('AppInitializer: Onboarding check/create failed.', err);
        if (isMounted) {
          setError(err.message || 'Failed during onboarding check.');
          setStatus('error');
        }
      }
    };

    initializeApp();

    return () => {
      isMounted = false;
      logger.info('AppInitializer: Unmounting initialization effect.');
    };
  }, [authLoading, user, profileLoading, profile, profileError]); // Removed onboarding context dependencies


  // --- Redirection Logic ---
  useEffect(() => {
    logger.info('AppInitializer: Running redirection check...', { status, user: !!user, isOnboardingComplete, pathname });

    // Only run redirection logic when initialization is complete and successful
    if (status !== 'idle') {
      logger.info('AppInitializer: Skipping redirect, status is not idle.');
      return;
    }

    const isLoginPage = pathname === '/app/login';
    const isOnboardingPage = pathname === '/app/onboarding';
    const isLessonsPage = pathname.startsWith('/app/lessons'); // Check if it's the lessons page or a sub-page
    const isProfilePage = pathname.startsWith('/app/profile');

    // 1. Handle unauthenticated users
    if (!user) {
      if (!isLoginPage) {
        logger.info('AppInitializer: No user, redirecting to login.');
        router.replace('/app/login');
      } else {
        logger.info('AppInitializer: No user, already on login page.');
      }
      return; // Stop further checks if no user
    }

    // --- User is authenticated from here ---

    // 2. Allow access to profile pages regardless of onboarding status
    if (isProfilePage) {
      logger.info('AppInitializer: Allowing access to profile page.');
      return;
    }

    // 3. Handle users needing onboarding
    if (!isOnboardingComplete) {
      if (!isOnboardingPage) {
        logger.info('AppInitializer: User needs onboarding, redirecting to onboarding.');
        router.replace('/app/onboarding');
      } else {
        logger.info('AppInitializer: User needs onboarding, already on onboarding page.');
      }
      return; // Stop further checks
    }

    // --- User is authenticated AND onboarding is complete ---

    // 4. Redirect to lessons if not already there (or on profile)
    if (!isLessonsPage) {
      // This covers cases like being on /app, /app/login, /app/onboarding after completion
      logger.info('AppInitializer: User onboarded, redirecting to lessons.');
      router.replace('/app/lessons');
    } else {
      logger.info('AppInitializer: User onboarded, already on lessons page.');
    }

  }, [status, user, isOnboardingComplete, pathname, router]);

  return (
    <AppInitializerContext.Provider value={{ status, error }}>
      {status === 'initializing' && <AppLoadingIndicator />}
      {status === 'error' && (
        <div className="fixed inset-0 z-50 flex items-center justify-center bg-red-100 p-4">
          <div className="text-center text-red-800">
            <h2 className="text-xl font-bold mb-2">Application Error</h2>
            <p>Failed to initialize the application.</p>
            <p className="mt-2 text-sm">{error}</p>
          </div>
        </div>
      )}
      {(status === 'idle' || status === 'error') && children}
    </AppInitializerContext.Provider>
  );
}

export const useAppInitializer = () => {
  const context = useContext(AppInitializerContext);
  if (context === undefined) {
    throw new Error('useAppInitializer must be used within an AppInitializerProvider');
  }
  return context;
};
// --- NEW CODE END ---
</file>

<file path="src/components/onboarding/AssessmentStep.tsx">
import React, { useEffect, useState } from 'react';
import { useOnboarding } from '@/context/onboarding-context';
import {
  AssessmentLesson,
  AssessmentStep as AssessmentStepModel,
  AudioMetrics,
  LessonStep,
  isAssessmentMetrics,
} from '@/models/AppAllModels.model';
import { toast } from 'react-hot-toast';
import LessonChat from '@/components/lessons/lessonChat';
import router from 'next/router';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import logger from '@/utils/logger';
import { useError } from '@/hooks/useError';

interface AssessmentStepProps {
  areMetricsGenerated: boolean;
  loading: boolean;
  targetLanguage: string;
  lesson: AssessmentLesson | null;
  onAssessmentComplete: () => Promise<void>;
  onGoToLessonsButtonClick: () => Promise<void>;
  processAssessmentLessonRecording: (
    sessionRecording: RecordingBlob,
    lesson: AssessmentLesson,
    recordingTime: number,
    recordingSize: number
  ) => Promise<AssessmentLesson | undefined>;
}

export default function AssessmentStep({
  areMetricsGenerated,
  loading,
  targetLanguage,
  lesson,
  onAssessmentComplete,
  onGoToLessonsButtonClick,
  processAssessmentLessonRecording,
}: AssessmentStepProps) {
  const { recordAssessmentStepAttempt } =
    useOnboarding();
  const [isCompleting, setIsCompleting] = useState(false);
  const [showResults, setShowResults] = useState(false);
  const [sessionRecording, setSessionRecording] =
    useState<RecordingBlob | null>(null);
  // Handle step completion - align with lesson page approach
    useState<AudioMetrics | null>(null);
  const [lessonAudioMetricsLoading, setLessonAudioMetricsLoading] =
    useState<boolean>(false);

  const handleStepComplete = async (
    step: LessonStep | AssessmentStepModel,
    userResponse: string
  ): Promise<AssessmentStepModel | LessonStep> => {
    try {
      if (!lesson) {
        return step;
      }
      // Record the step attempt, similar to how lessons work
     const updatedStep = await recordAssessmentStepAttempt(
        lesson.id,
        step.id,
        userResponse
     );
      if (!updatedStep) {
        return step;
      }
      return updatedStep;

      // Update local state if needed
      // (This matches how the lesson page updates local lesson state)
    } catch (error) {
      return step;
    }
  };

  // Handle assessment completion
  const handleComplete = async (recording: RecordingBlob | null) => {
    setIsCompleting(true);
    try {
      if (!lesson) {
        setIsCompleting(false);
        return;
      }
      setSessionRecording(recording);

      // const result = await completeAssessmentLesson(lesson.id, 'Assessment completed');
      await onAssessmentComplete();
      // After completion, show results instead of immediately navigating
    } catch (error) {
    } finally {
      setIsCompleting(false);
    }
  };

  useEffect(() => {
    if (lesson && lesson.metrics && isAssessmentMetrics(lesson.metrics)) {
      setShowResults(true);
    }
  }, [lesson?.metrics]);

  useEffect(() => {
    const processPronunciation = async () => {

      logger.info('sessionRecording', sessionRecording);
      logger.info('lesson', lesson);
      if (sessionRecording && lesson) {
        if (!sessionRecording.lastModified || !sessionRecording.size) {
          return;
        }
        setLessonAudioMetricsLoading(true);
        try {
          const recordingTime = sessionRecording.recordingTime || 10000;
          const recordingSize = sessionRecording.size;

          logger.info('processing pronunciation', { recordingTime, recordingSize });

          const lessonWithAudioMetrics = await processAssessmentLessonRecording(
            sessionRecording,
            lesson,
            recordingTime,
            recordingSize
          );
          if (!lessonWithAudioMetrics) {
            return;
          }
          if (!lessonWithAudioMetrics.audioMetrics) {
            return;
          }
          logger.info('lessonWithAudioMetrics', lessonWithAudioMetrics);
          
        } catch (error) {
          logger.error('Failed to process pronunciation:', error);
        } finally {
          setLessonAudioMetricsLoading(false);
        }
      }
    };
    processPronunciation();
  }, [sessionRecording]);

  // Navigate to lessons after viewing results
  const handleFinishAndGoToLessons = () => {
    // markOnboardingAsCompleteAndGenerateLessons();
    // onComplete();
    onGoToLessonsButtonClick();
  };

  // Check if the assessment was already completed previously
  // useEffect(() => {
  //   console.log('lesson', lesson);
  //   if (lesson && lesson.completed) {
  //     setShowResults(true);
  //   }
  // }, [lesson]);

    


  if (!lesson) {
    return (
      <div className="flex justify-center items-center py-12">
        <div className="animate-spin mr-3 h-5 w-5 text-accent-6">
          <svg
            xmlns="http://www.w3.org/2000/svg"
            fill="none"
            viewBox="0 0 24 24"
          >
            <circle
              className="opacity-25"
              cx="12"
              cy="12"
              r="10"
              stroke="currentColor"
              strokeWidth="4"
            ></circle>
            <path
              className="opacity-75"
              fill="currentColor"
              d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
            ></path>
          </svg>
        </div>
        <span className="text-neutral-9">Loading assessment...</span>
      </div>
    );
  }
  if (!areMetricsGenerated && lesson.completed) {
    return (
      <div className="space-y-6 animate-fade-in">
        <div className="bg-neutral-1 border border-neutral-4 rounded-lg overflow-hidden shadow-sm">
          <div className="bg-accent-6 text-neutral-1 p-5">
            <h2 className="text-xl font-semibold text-center">
              Analysing your responses...
            </h2>
          </div>
        </div>
      </div>
    );
  }

  // Results view after assessment is completed
  if (showResults && areMetricsGenerated) {
    const metrics =
      lesson.metrics && isAssessmentMetrics(lesson.metrics)
        ? lesson.metrics
        : null;

    return (
      <div className="space-y-6 animate-fade-in">
        <div className="bg-neutral-1 border border-neutral-4 rounded-lg overflow-hidden shadow-sm">
          <div className="bg-accent-6 text-neutral-1 p-5">
            <h2 className="text-xl font-semibold text-center">
              Assessment Results
            </h2>
          </div>

          <div className="p-6 space-y-6">
            {/* Summary */}
            <div className="p-4 bg-neutral-2 rounded-lg border border-neutral-4">
              <h3 className="font-medium text-lg mb-2">Summary</h3>
              <p className="text-neutral-9">
                {lesson.summary ||
                  "Your assessment has been completed. Based on your responses, we've prepared personalized lessons for you."}
              </p>
            </div>

            {/* Scores */}
            {metrics && (
              <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
                <div className="bg-neutral-2 p-4 rounded-lg border border-neutral-4 text-center">
                  <p className="text-sm text-neutral-7">Overall Score</p>
                  <p className="text-2xl font-bold text-accent-8">
                    {metrics.overallScore || 0}%
                  </p>
                </div>
                <div className="bg-neutral-2 p-4 rounded-lg border border-neutral-4 text-center">
                  <p className="text-sm text-neutral-7">Accuracy</p>
                  <p className="text-2xl font-bold text-accent-8">
                    {metrics.accuracy || 0}%
                  </p>
                </div>
                <div className="bg-neutral-2 p-4 rounded-lg border border-neutral-4 text-center">
                  <p className="text-sm text-neutral-7">Grammar</p>
                  <p className="text-2xl font-bold text-accent-8">
                    {metrics.grammarScore || 0}%
                  </p>
                </div>
              </div>
            )}

            {lessonAudioMetricsLoading && (
             <div className="flex justify-center items-center py-12">
             <div className="animate-spin mr-3 h-5 w-5 text-accent-6">
               {/* SVG Spinner */}
               <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                 <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                 <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
               </svg>
             </div>
             <span className="text-neutral-9">Analyzing pronunciation and fluency...</span>
           </div>
            )}

            {/* Pronunciation Results */}
            {lesson.audioMetrics && (
              <div className="p-4 bg-neutral-2 rounded-lg border border-neutral-4">
                <h3 className="font-medium text-lg mb-3">Pronunciation Analysis</h3>
                
                {/* Pronunciation Overview */}
                <div className="mb-4">
                  <div className="grid grid-cols-2 md:grid-cols-4 gap-3 mb-4">
                    <div className="bg-neutral-1 p-3 rounded border border-neutral-3 text-center">
                      <p className="text-sm text-neutral-7">Pronunciation</p>
                      <p className="text-xl font-bold text-accent-8">
                        {lesson.audioMetrics.pronunciationScore}%
                      </p>
                    </div>
                    <div className="bg-neutral-1 p-3 rounded border border-neutral-3 text-center">
                      <p className="text-sm text-neutral-7">Fluency</p>
                      <p className="text-xl font-bold text-accent-8">
                        {lesson.audioMetrics.fluencyScore}%
                      </p>
                    </div>
                    <div className="bg-neutral-1 p-3 rounded border border-neutral-3 text-center">
                      <p className="text-sm text-neutral-7">CEFR Level</p>
                      <p className="text-xl font-bold text-accent-8">
                        {lesson.audioMetrics.proficiencyLevel}
                      </p>
                    </div>
                    <div className="bg-neutral-1 p-3 rounded border border-neutral-3 text-center">
                      <p className="text-sm text-neutral-7">Trajectory</p>
                      <p className="text-xl font-bold text-accent-8">
                        {lesson.audioMetrics.learningTrajectory}
                      </p>
                    </div>
                  </div>
                </div>
                
                {/* Detailed Pronunciation */}
                {lesson.audioMetrics.pronunciationAssessment && (
                  <div className="mb-4">
                    <h4 className="text-md font-medium text-accent-8 mb-2">Pronunciation Details</h4>
                    
                    {/* Native Language Influence */}
                    <div className="mb-3">
                      <p className="text-sm font-medium">Native Language Influence: 
                        <span className="ml-1 font-normal">
                          {lesson.audioMetrics.pronunciationAssessment.native_language_influence.level}
                        </span>
                      </p>
                      {lesson.audioMetrics.pronunciationAssessment.native_language_influence.specific_features.length > 0 && (
                        <div className="mt-1">
                          <p className="text-sm text-neutral-7">Specific features:</p>
                          <ul className="list-disc pl-5 text-sm">
                            {lesson.audioMetrics.pronunciationAssessment.native_language_influence.specific_features.map((feature, idx) => (
                              <li key={idx} className="text-neutral-8">{feature}</li>
                            ))}
                          </ul>
                        </div>
                      )}
                    </div>
                    
                    {/* Problematic Sounds */}
                    {lesson.audioMetrics.pronunciationAssessment.problematic_sounds.length > 0 && (
                      <div className="mb-3">
                        <p className="text-sm font-medium">Sounds to Practice:</p>
                        <div className="flex flex-wrap gap-2 mt-1">
                          {lesson.audioMetrics.pronunciationAssessment.problematic_sounds.map((sound, idx) => (
                            <span key={idx} className="bg-warning-light text-warning-dark px-2 py-1 rounded text-sm">
                              {sound}
                            </span>
                          ))}
                        </div>
                      </div>
                    )}
                    
                    {/* Pronunciation Strengths */}
                    {lesson.audioMetrics.pronunciationAssessment.strengths.length > 0 && (
                      <div className="mb-3">
                        <p className="text-sm font-medium text-success">Strengths:</p>
                        <ul className="list-disc pl-5 text-sm">
                          {lesson.audioMetrics.pronunciationAssessment.strengths.map((strength, idx) => (
                            <li key={idx} className="text-neutral-8">{strength}</li>
                          ))}
                        </ul>
                      </div>
                    )}
                    
                    {/* Areas for Improvement */}
                    {lesson.audioMetrics.pronunciationAssessment.areas_for_improvement.length > 0 && (
                      <div>
                        <p className="text-sm font-medium text-warning">Areas to Improve:</p>
                        <ul className="list-disc pl-5 text-sm">
                          {lesson.audioMetrics.pronunciationAssessment.areas_for_improvement.map((area, idx) => (
                            <li key={idx} className="text-neutral-8">{area}</li>
                          ))}
                        </ul>
                      </div>
                    )}
                  </div>
                )}
                
                {/* Fluency Assessment */}
                {lesson.audioMetrics.fluencyAssessment && (
                  <div className="mb-4 border-t border-neutral-3 pt-3 mt-4">
                    <h4 className="text-md font-medium text-accent-8 mb-2">Fluency Analysis</h4>
                    
                    <div className="grid grid-cols-1 md:grid-cols-3 gap-3 mb-3">
                      <div className="bg-neutral-1 p-3 rounded border border-neutral-3">
                        <p className="text-sm text-neutral-7">Speech Rate</p>
                        <p className="text-md">
                          <span className="font-medium">{lesson.audioMetrics.fluencyAssessment.speech_rate.words_per_minute}</span> words/min
                          <span className="ml-2 text-sm">({lesson.audioMetrics.fluencyAssessment.speech_rate.evaluation})</span>
                        </p>
                      </div>
                      
                      <div className="bg-neutral-1 p-3 rounded border border-neutral-3">
                        <p className="text-sm text-neutral-7">Hesitation</p>
                        <p className="text-md">
                          <span className="font-medium">{lesson.audioMetrics.fluencyAssessment.hesitation_patterns.frequency}</span>
                          <span className="ml-2 text-sm">({lesson.audioMetrics.fluencyAssessment.hesitation_patterns.average_pause_duration.toFixed(1)}s avg pause)</span>
                        </p>
                      </div>
                      
                      <div className="bg-neutral-1 p-3 rounded border border-neutral-3">
                        <p className="text-sm text-neutral-7">Naturalness</p>
                        <p className="text-md font-medium">
                          {lesson.audioMetrics.fluencyAssessment.rhythm_and_intonation.naturalness}%
                        </p>
                      </div>
                    </div>
                  </div>
                )}
              </div>
            )}


            {/* Action Button */}
            <div className="text-center pt-4">
              <button
                onClick={handleFinishAndGoToLessons}
                disabled={loading || isCompleting}
                className="py-3 px-6 bg-accent-6 text-neutral-1 rounded-md transition-colors hover:bg-accent-7
                          focus:outline-none focus:ring-2 focus:ring-accent-8 focus:ring-offset-2 disabled:opacity-50
                          text-sm font-medium"
              >
                {loading || isCompleting || lessonAudioMetricsLoading ? (
                  <span className="flex items-center">
                    <svg
                      className="animate-spin -ml-1 mr-2 h-4 w-4 text-neutral-1"
                      xmlns="http://www.w3.org/2000/svg"
                      fill="none"
                      viewBox="0 0 24 24"
                    >
                      <circle
                        className="opacity-25"
                        cx="12"
                        cy="12"
                        r="10"
                        stroke="currentColor"
                        strokeWidth="4"
                      ></circle>
                      <path
                        className="opacity-75"
                        fill="currentColor"
                        d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                      ></path>
                    </svg>
                    Processing...
                  </span>
                ) : (
                  'Go to Lessons'
                )}
              </button>
            </div>
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className="animate-fade-in h-screen flex flex-col">
      <LessonChat
        lesson={lesson}
        onComplete={handleComplete}
        onStepComplete={handleStepComplete}
        loading={loading || isCompleting}
        targetLanguage={targetLanguage}
        isAssessment={true}
      />
    </div>
  );
}
</file>

<file path="src/context/onboarding-context.tsx">
'use client'
import { createContext, useContext, useEffect, useState, useCallback } from 'react';
import {
  createOnboardingAction,
  getOnboardingAction,
  updateOnboardingAction,
  deleteOnboardingAction,
  markOnboardingCompleteAndGenerateInitialLessonsAction,
  getStatusAction,
  getAssessmentLessonAction,
  completeAssessmentLessonAction,
  recordAssessmentStepAttemptAction,
  updateOnboardingLessonAction,
  processAssessmentLessonRecordingAction,
} from '@/lib/server-actions/onboarding-actions';
import toast from 'react-hot-toast';
import logger from '@/utils/logger';
import { useRouter } from 'next/navigation';
import { AssessmentLesson, AssessmentStep, OnboardingModel } from '@/models/AppAllModels.model';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import { useAuth } from './auth-context';
import { Result } from '@/lib/server-actions/_withErrorHandling';
import { useError } from '@/hooks/useError';
// Removed useAppInitializer import

interface OnboardingContextType {
  isOnboardingComplete: boolean;
  onboarding: OnboardingModel | null;
  loading: boolean; // General loading for actions initiated within this context
  error: string | null;
  // Add setters for AppInitializer to update state (if needed, but likely handled internally now)
  setOnboarding: React.Dispatch<React.SetStateAction<OnboardingModel | null>>;
  setIsOnboardingComplete: React.Dispatch<React.SetStateAction<boolean>>;

  startOnboarding: () => Promise<void>;
  checkOnboardingStatus: () => Promise<boolean>;
  markStepComplete: (step: string, formData: any) => Promise<void>;
  getOnboarding: () => Promise<OnboardingModel | null>; // Keep for manual refresh

  getAssessmentLesson: () => Promise<AssessmentLesson | undefined>;
  completeAssessmentLesson: (
    lessonId: string,
    userResponse: string
  ) => Promise<AssessmentLesson | undefined>;
  markOnboardingAsCompleteAndGenerateLessons: () => Promise<void>;

  recordAssessmentStepAttempt: (
    lessonId: string,
    stepId: string,
    userResponse: string
  ) => Promise<AssessmentStep | undefined>;

  updateOnboardingLesson: (
    lessonId: string,
    lessonData: Partial<AssessmentLesson>
  ) => Promise<AssessmentLesson | undefined>;

  processAssessmentLessonRecording: (
    recording: RecordingBlob,
    lesson: AssessmentLesson,
    recordingTime: number,
    recordingSize: number
  ) => Promise<AssessmentLesson | undefined>;

  clearError: () => void;
  goToLessonsWithOnboardingComplete: () => void;
}


const OnboardingContext = createContext<OnboardingContextType | undefined>(undefined);

export function OnboardingProvider({ children }: { children: React.ReactNode }) {
  const router = useRouter();
  const { user } = useAuth(); // Only need user from auth

  const [isOnboardingComplete, setIsOnboardingComplete] = useState(false);
  const [onboarding, setOnboarding] = useState<OnboardingModel | null>(null);
  const [loading, setLoading] = useState(false); // Loading for specific actions
  const [error, setError] = useState<string | null>(null);
  const { showError } = useError();

  // Helper to call server actions
  const callAction = useCallback(async <T,>(
    action: () => Promise<Result<T>>,
    setGlobalLoading = true
  ): Promise<T | undefined> => {
    if (setGlobalLoading) setLoading(true);
    setError(null);
    let resultData: T | undefined;
    try {
      const { data, error: msg } = await action();
      if (msg) {
        setError(msg);
        showError(msg);
      } else {
        resultData = data;
      }
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      setError(message);
      showError(message);
    } finally {
      if (setGlobalLoading) setLoading(false);
    }
    return resultData;
  }, [showError]);

  // Effect to fetch onboarding data when user logs in (after initializer ensures it exists)
  useEffect(() => {
    const fetchOnboardingData = async () => {
      if (user && onboarding === null) { // Fetch only if user exists and local state is null
        logger.info("OnboardingProvider: User logged in, fetching onboarding data...");
        setLoading(true); // Indicate loading for this context's fetch
        const data = await callAction(() => getOnboardingAction(), false); // Don't set global loading
        if (data) {
          setOnboarding(data);
          setIsOnboardingComplete(data.completed);
          logger.info("OnboardingProvider: Onboarding data fetched and context updated.", { completed: data.completed });
        } else {
          logger.warn("OnboardingProvider: getOnboardingAction returned null/undefined even though user exists.");
          // This might indicate an issue if the initializer didn't create it properly.
          // Optionally, try creating it here as a fallback?
          // await startOnboarding(); // Be cautious with automatic creation here
        }
        setLoading(false);
      } else if (!user) {
        // Clear local state if user logs out
        setOnboarding(null);
        setIsOnboardingComplete(false);
      }
    };

    fetchOnboardingData();
  }, [user, callAction]); // Depend only on user


  // --- Onboarding Actions (remain largely the same) ---
  const startOnboarding = async (): Promise<void> => {
    const data = await callAction(() => createOnboardingAction());
    if (data) {
      setOnboarding(data);
      setIsOnboardingComplete(false);
    }
  };

  const checkOnboardingStatus = async (): Promise<boolean> => {
    const status = await callAction(() => getStatusAction());
    const complete = status ?? false;
    setIsOnboardingComplete(complete);
    return complete;
  };

  const markStepComplete = async (step: string, formData: any): Promise<void> => {
    const updatedOnboarding = await callAction(() => updateOnboardingAction(step, formData));
    if (updatedOnboarding) {
      setOnboarding(updatedOnboarding);
      setIsOnboardingComplete(updatedOnboarding.completed);
    }
  };

  const getOnboarding = async (): Promise<OnboardingModel | null> => {
    // This can be used for manual refresh
    const data = await callAction(() => getOnboardingAction());
    if (data) {
      setOnboarding(data);
      setIsOnboardingComplete(data.completed);
    }
    return data ?? null;
  };

  const markOnboardingAsCompleteAndGenerateLessons = async (): Promise<void> => {
    const completed = await callAction(() => markOnboardingCompleteAndGenerateInitialLessonsAction());
    if (completed) {
      setOnboarding(completed);
      setIsOnboardingComplete(true);
      toast.success('Onboarding completed! Lessons generated!');
      // Navigation is handled by AppInitializer
    }
  };

  const goToLessonsWithOnboardingComplete = (): void => {
    setIsOnboardingComplete(true);
    router.replace('/app/lessons');
  };

  // --- Assessment Actions (remain the same) ---
  const getAssessmentLesson = async (): Promise<AssessmentLesson | undefined> => {
    return await callAction(() => getAssessmentLessonAction());
  }

  const completeAssessmentLesson = async (id: string, resp: string): Promise<AssessmentLesson | undefined> => {
    return await callAction(() => completeAssessmentLessonAction(id, resp));
  }

  const recordAssessmentStepAttempt = async (lessonId: string, stepId: string, userResponse: string): Promise<AssessmentStep | undefined> => {
    return await callAction(() => recordAssessmentStepAttemptAction(lessonId, stepId, userResponse), false);
  }

  const updateOnboardingLesson = async (lessonId: string, data: Partial<AssessmentLesson>): Promise<AssessmentLesson | undefined> => {
    return await callAction(() => updateOnboardingLessonAction(lessonId, data));
  }

  const processAssessmentLessonRecording = async (recording: RecordingBlob, lesson: AssessmentLesson, recordingTime: number, recordingSize: number): Promise<AssessmentLesson | undefined> => {
    return await callAction(() => processAssessmentLessonRecordingAction(recording, lesson, recordingTime, recordingSize));
  }

  const deleteOnboarding = async (): Promise<void> => {
    await callAction(() => deleteOnboardingAction());
    setOnboarding(null);
    setIsOnboardingComplete(false);
  }

  const clearError = () => setError(null);

  return (
    <OnboardingContext.Provider
      value={{
        isOnboardingComplete,
        onboarding,
        loading,
        error,
        setOnboarding, // Expose setter
        setIsOnboardingComplete, // Expose setter
        startOnboarding,
        checkOnboardingStatus,
        markStepComplete,
        getOnboarding,
        getAssessmentLesson,
        completeAssessmentLesson,
        recordAssessmentStepAttempt,
        updateOnboardingLesson,
        processAssessmentLessonRecording,
        markOnboardingAsCompleteAndGenerateLessons,
        goToLessonsWithOnboardingComplete,
        clearError,
      }}
    >
      {children}
    </OnboardingContext.Provider>
  );
}

export const useOnboarding = (): OnboardingContextType => {
  const ctx = useContext(OnboardingContext);
  if (!ctx) throw new Error('useOnboarding must be used within OnboardingProvider');
  return ctx;
};
// --- NEW CODE END ---
</file>

<file path="src/services/lesson.service.ts">
import {
  AudioMetrics,
  getExerciseCompletion,
  getFluencyAssessment,
  getGrammarAssessment,
  getPronunciationAssessment,
  getVocabularyAssessment,
  LearningProgressModel,
  LessonModel,
  LessonStep,
  OnboardingModel,
  isPerformanceMetrics,
  AssessmentLesson,
  AdaptiveLessonGenerationRequest,
} from '@/models/AppAllModels.model';

import {
  AiAdaptiveSuggestions,
  AiLessonAnalysisResponse,
  AiPerformanceMetrics,
  AiProgressTracking,
  ILessonRepository,
  IOnboardingRepository,
} from '@/lib/interfaces/all-interfaces';
import logger from '@/utils/logger';
import { ILessonGeneratorService } from './lesson-generator.service';
import RecordingService from './recording.service';

import { JsonValue } from '@prisma/client/runtime/library';
import { mockAudioMetrics } from '@/__mocks__/generated-audio-metrics.mock';
import {
  ComprehensionLevel,
  HesitationFrequency,
  LanguageInfluenceLevel,
  LearningTrajectory,
  SpeechRateEvaluation,
  VocabularyRange,
  MasteryLevel,
} from '@prisma/client';
import LearningProgressService from './learning-progress.service';
import { LearningProgressRepository } from '@/repositories/learning-progress.repository';

import { randomUUID } from 'crypto';
import { createElement } from 'react';

interface LessonGenerationConfig {
  defaultLanguage: string;
  defaultProficiency: string;
  defaultPurpose: string;
}

// interface AdaptiveRequest {
//   completedAssessment: boolean;
//   audioMetricsAvailable: boolean;
//   metrics: any;
//   audioMetrics?: AudioMetricsPayload;
//   proposedTopics: string[];
//   summary: string;
// }

interface AudioMetricsPayload {
  pronunciationScore: number;
  fluencyScore: number;
  grammarScore: number;
  vocabularyScore: number;
  overallPerformance: number;
  problematicSounds: string[];
  grammarRulesToReview: string[];
  vocabularyAreasForExpansion: string[];
  suggestedTopics: string[];
  proficiencyLevel: string;
}

export default class LessonService {
  private lessonRepository: ILessonRepository;
  private lessonGeneratorService: ILessonGeneratorService;
  private onboardingRepository: IOnboardingRepository;
  private recordingService: RecordingService;

  private learningProgressService: LearningProgressService;

  // Add class-level configuration constant
  private readonly lessonConfig: LessonGenerationConfig = {
    defaultLanguage: 'German',
    defaultProficiency: 'beginner',
    defaultPurpose: 'general',
  };

  constructor(
    lessonRepository: ILessonRepository,
    lessonGeneratorService: ILessonGeneratorService,
    onboardingRepository: IOnboardingRepository
  ) {
    this.lessonRepository = lessonRepository;
    this.lessonGeneratorService = lessonGeneratorService;
    this.onboardingRepository = onboardingRepository;
    this.recordingService = new RecordingService();
    const progressRepository = new LearningProgressRepository();
    this.learningProgressService = new LearningProgressService(
      progressRepository
    ); // Instantiate it here
  }

  async getLessons(): Promise<LessonModel[]> {
    // Simply fetch and return existing lessons. Generation is handled elsewhere.
    const lessons = await this.lessonRepository.getLessons();
    logger.info(`LessonService.getLessons: Found ${lessons?.length ?? 0} lessons.`);
    return lessons || []; // Return empty array if null/undefined
  }

  async getLessonById(lessonId: string): Promise<LessonModel | null> {
    const lesson = await this.lessonRepository.getLessonById(lessonId);
    if (lesson) {
      // Sort steps by stepNumber
      lesson.steps = lesson.steps.sort((a, b) => a.stepNumber - b.stepNumber);
    }
    logger.info('getLessonById', { lesson });
    return lesson;
  }

  async createLesson(lessonData: {
    focusArea: string;
    targetSkills: string[];
    steps: LessonStep[];
  }): Promise<LessonModel> {
    logger.info('Creating lesson', {
      focusArea: lessonData.focusArea,
      targetSkills: lessonData.targetSkills,
      stepsLength: lessonData.steps.length,
    });

    try {
      const createdLesson = await this.lessonRepository.createLesson(
        lessonData
      );

      logger.info('Lesson created successfully', {
        lessonId: createdLesson.id,
        steps: createdLesson.steps,
        userId: createdLesson.userId,
      });
      return createdLesson;
    } catch (error) {
      logger.error('Error creating lesson', {
        error: (error as Error).message,
        lessonData: {
          focusArea: lessonData.focusArea,
          targetSkills: lessonData.targetSkills,
          stepsLength: lessonData.steps.length,
        },
      });
      throw error;
    }
  }

  async updateLesson(
    lessonId: string,
    lessonData: Partial<LessonModel>
  ): Promise<LessonModel> {
    return this.lessonRepository.updateLesson(lessonId, lessonData);
  }

  async completeLesson(
    lessonId: string,
    performanceMetrics?: {
      accuracy?: number;
      pronunciationScore?: number;
      errorPatterns?: string[];
    }
  ): Promise<LessonModel> {
    // Get the lesson with all steps to analyze performance
    const lesson = await this.getLessonById(lessonId);
    logger.info('completing lesson', { lesson });
    if (!lesson) {
      throw new Error(
        `Cannot complete lesson: Lesson with ID ${lessonId} not found`
      );
    }

    // If metrics were provided externally, use those
    if (performanceMetrics) {
      return this.lessonRepository.completeLesson(lessonId, performanceMetrics);
    }

    try {
      // Collect all user responses from the steps
      const userResponses = lesson.steps
        .filter((step) => step.attempts > 0)
        .map((step) => {
          // Get responses from history if available, otherwise use single response
          const responseHistory = step.userResponseHistory
            ? (JSON.parse(step.userResponseHistory as string) as string[])
            : [];

          // Use the most recent response (either from history or the single field)
          const latestResponse =
            responseHistory.length > 0
              ? responseHistory[responseHistory.length - 1]
              : step.userResponse || '';

          return {
            stepId: step.id,
            response: latestResponse,
            // Optionally include full history if needed by analysis
            allResponses:
              responseHistory.length > 0
                ? responseHistory
                : step.userResponse
                  ? [step.userResponse]
                  : [],
          };
        });

      logger.info('Collected user responses for analysis', {
        responseCount: userResponses.length,
      });

      // Generate comprehensive lesson analysis using the LessonGeneratorService
      const completionResults =
        await this.lessonGeneratorService.generateLessonCompletionResults(
          lesson,
          userResponses
        );

      logger.info('Lesson completion analysis generated', {
        completionResults,
      });

      // Prepare comprehensive metrics for saving
      const fullMetrics = {
        accuracy: completionResults.metrics.accuracy,
        pronunciationScore: completionResults.metrics.pronunciationScore,
        grammarScore: completionResults.metrics.grammarScore,
        vocabularyScore: completionResults.metrics.vocabularyScore,
        overallScore: completionResults.metrics.overallScore,
        strengths: completionResults.metrics.strengths,
        weaknesses: completionResults.metrics.weaknesses,
        summary: completionResults.summary,
        nextLessonSuggestions: completionResults.nextLessonSuggestions,
      };

      // Update the lesson repository with comprehensive metrics
      const completedLesson = await this.lessonRepository.completeLesson(
        lessonId,
        fullMetrics
      );

      this.learningProgressService
        .updateProgressAfterLesson(completedLesson.userId, completedLesson)
        .catch((err) => {
          logger.error(
            'Failed to update learning progress after lesson completion',
            {
              userId: completedLesson.userId,
              lessonId: completedLesson.id,
              error: err,
            }
          );
          // Decide if this failure needs further handling
        });

      return completedLesson;
    } catch (error) {
      logger.error('Error completing lesson with AI analysis', { error });

      // Fallback to basic metrics calculation if AI analysis fails
      const steps = lesson.steps;
      const attemptedSteps = steps.filter((step) => step.attempts > 0);
      const correctSteps = steps.filter((step) => step.correct);

      const accuracy =
        attemptedSteps.length > 0
          ? Math.round((correctSteps.length / attemptedSteps.length) * 100)
          : 0;

      // Calculate a simple pronunciation score
      const pronunciationScore = Math.min(
        100,
        Math.max(0, accuracy - 10 + Math.random() * 20)
      );

      // Basic fallback metrics
      const fallbackMetrics = {
        accuracy,
        pronunciationScore: Math.round(pronunciationScore),
        errorPatterns: [], // No detailed error patterns in fallback mode
        grammarScore: Math.round(accuracy * 0.9),
        vocabularyScore: Math.round(accuracy * 0.95),
        overallScore: accuracy,
        strengths: [],
        weaknesses: [],
        summary: 'Lesson completed successfully.',
        nextLessonSuggestions: [],
      };

      logger.info('Using fallback metrics for lesson completion', {
        fallbackMetrics,
      });

      return this.lessonRepository.completeLesson(lessonId, fallbackMetrics);
    }
  }

  async deleteLesson(lessonId: string): Promise<void> {
    return this.lessonRepository.deleteLesson(lessonId);
  }

  private constructAdaptiveRequest(
    assessment: AssessmentLesson,
    onboardingData: OnboardingModel
  ): any {
    if (!assessment) {
      return undefined;
    }

    if (!assessment.audioMetrics) {
      return {
        completedAssessment: true,
        audioMetricsAvailable: false,
        metrics: assessment.metrics,
        proposedTopics: assessment.proposedTopics || [],
        summary: assessment.summary || '',
      };
    }
    const userInfo = {
      targetLanguage:
        onboardingData.targetLanguage || this.lessonConfig.defaultLanguage,
      proficiencyLevel:
        onboardingData.proficiencyLevel?.toLowerCase() ||
        this.lessonConfig.defaultProficiency,
      learningPurpose:
        onboardingData.learningPurpose || this.lessonConfig.defaultPurpose,
      sourceLanguage: onboardingData.nativeLanguage || 'English',
    };
    // TODO: FINISH
    logger.debug('constructAdaptiveRequest', { userInfo });

    const audioMetrics = assessment.audioMetrics;
    return {
      completedAssessment: true,
      audioMetricsAvailable: true,
      metrics: assessment.metrics,
      audioMetrics: {
        pronunciationScore: audioMetrics.pronunciationScore,
        fluencyScore: audioMetrics.fluencyScore,
        grammarScore: audioMetrics.grammarScore,
        vocabularyScore: audioMetrics.vocabularyScore,
        overallPerformance: audioMetrics.overallPerformance,
        problematicSounds:
          audioMetrics.pronunciationAssessment.problematic_sounds,
        grammarRulesToReview:
          audioMetrics.grammarAssessment.grammar_rules_to_review,
        vocabularyAreasForExpansion:
          audioMetrics.vocabularyAssessment.areas_for_expansion,
        suggestedTopics: audioMetrics.suggestedTopics,
        proficiencyLevel: audioMetrics.proficiencyLevel,
      },
      userInfo,
      proposedTopics: assessment.proposedTopics || [],
      summary: assessment.summary || '',
    };
  }

  private async validateAssessmentData(): Promise<{
    onboardingData: OnboardingModel;
    assessment: AssessmentLesson;
  }> {
    const onboardingData = await this.onboardingRepository.getOnboarding();
    if (!onboardingData) {
      throw new Error('User onboarding data not found');
    }

    if (!onboardingData.initialAssessmentCompleted) {
      throw new Error('Initial assessment not completed');
    }

    const assessment = await this.onboardingRepository.getAssessmentLesson();
    if (!assessment) {
      throw new Error('Completed assessment not found');
    }

    return { onboardingData, assessment };
  }
  private getLanguageConfig(onboardingData: OnboardingModel) {
    return {
      targetLanguage:
        onboardingData.targetLanguage || this.lessonConfig.defaultLanguage,
      proficiencyLevel:
        onboardingData.proficiencyLevel?.toLowerCase() ||
        this.lessonConfig.defaultProficiency,
      learningPurpose:
        onboardingData.learningPurpose || this.lessonConfig.defaultPurpose,
      sourceLanguage: onboardingData.nativeLanguage || 'English',
    };
  }

  private async generateLessonsForTopic(
    topic: string,
    languageConfig: ReturnType<typeof this.getLanguageConfig>,
    adaptiveRequest: AdaptiveLessonGenerationRequest
  ): Promise<LessonModel[]> {
    try {
      const generatedResult = await this.lessonGeneratorService.generateLesson(
        topic,
        languageConfig.targetLanguage,
        languageConfig.proficiencyLevel,
        languageConfig.sourceLanguage,
        adaptiveRequest
      );
      

      const lessonItems = Array.isArray(generatedResult.data)
        ? generatedResult.data
        : generatedResult.data
          ? [generatedResult.data]
          : [];

      // Check if the array is empty or contains only falsy values
      if (lessonItems.length === 0 || !lessonItems[0]) {
        // Log the error as expected by the test when AI returns no usable data
        logger.error('Failed to generate lesson for topic', {
          topic,
          reason: 'AI returned empty or invalid result',
        });
        return []; // Return empty array gracefully
      }

      return Promise.all(
        lessonItems.map(async (lessonItem: any) => {
          if (!lessonItem || !lessonItem.steps) {
            logger.warn('Invalid lesson item structure received from AI', {
              topic,
              lessonItem,
            });
            return null; // Skip this invalid item
          }
          const audioSteps =
            await this.lessonGeneratorService.generateAudioForSteps(
              lessonItem.steps as LessonStep[],
              languageConfig.targetLanguage,
              languageConfig.sourceLanguage
            );
          // Ensure createLesson receives valid data
          if (!lessonItem.focusArea || !lessonItem.targetSkills) {
            logger.warn(
              'Missing focusArea or targetSkills in generated lesson item',
              { topic, lessonItem }
            );
            return null; // Skip creation if essential data is missing
          }

          return this.createLesson({
            focusArea: lessonItem.focusArea,
            targetSkills: lessonItem.targetSkills,
            steps: audioSteps,
          });
        })
      ).then(
        (results) =>
          results.filter((lesson) => lesson !== null) as LessonModel[]
      );
    } catch (error) {
      logger.error('Failed to generate lesson for topic', { topic, error });
      return []; // Return empty array to prevent failing entire batch
    }
  }

  async generateInitialLessons(): Promise<LessonModel[]> {
    const { onboardingData, assessment } = await this.validateAssessmentData();
    const languageConfig = this.getLanguageConfig(onboardingData);

    const assessmentTopics = assessment.proposedTopics || [];
    const adaptiveRequest = this.constructAdaptiveRequest(
      assessment,
      onboardingData
    );
    const learningPurposeTopics = this.getTopicsFromLearningPurpose(
      languageConfig.learningPurpose
    );
    const suggestedTopicsFromAudioAnalysys = adaptiveRequest?.detailedAudioAnalysis?.suggestedTopics || [];

    logger.debug('suggested topics form audio analysys', suggestedTopicsFromAudioAnalysys);

    const selectedTopics = this.selectPrioritizedTopics(
      assessmentTopics,
      suggestedTopicsFromAudioAnalysys, // Pass suggested topics from audio analysis
      learningPurposeTopics,
      languageConfig.proficiencyLevel,
      1
    );

    logger.info('Starting lesson generation for topics', { selectedTopics });

    const lessonPromises = selectedTopics.map((topic) =>
      this.generateLessonsForTopic(topic, languageConfig, adaptiveRequest)
    );

    try {
      const lessonsNested = await Promise.all(lessonPromises);
      return lessonsNested.flat();
    } catch (error) {
      logger.error('Critical error in lesson generation', { error });
      throw new Error('Failed to generate initial lessons');
    }
  }

  // New helper method to intelligently select and prioritize topics
  private selectPrioritizedTopics(
    assessmentTopics: string[],
    audioMetricsTopics: string[],
    learningPurposeTopics: string[],
    proficiencyLevel: string,
    numberOfTopicsToGenerate: number = 3 // Make the quantity configurable, default to 3
  ): string[] {
    // Create a map to score topics based on their source and frequency
    const topicScores: Record<string, number> = {};

    // Score topics from different sources with different weights
    // Audio metrics topics get highest priority as they're most personalized
    audioMetricsTopics.forEach((topic) => {
      const normalizedTopic = this.normalizeTopic(topic);
      topicScores[normalizedTopic] = (topicScores[normalizedTopic] || 0) + 3;
    });

    // Assessment topics get second priority
    assessmentTopics.forEach((topic) => {
      const normalizedTopic = this.normalizeTopic(topic);
      topicScores[normalizedTopic] = (topicScores[normalizedTopic] || 0) + 2;
    });

    // Learning purpose topics get lowest priority but ensure some basics are covered
    learningPurposeTopics.forEach((topic) => {
      const normalizedTopic = this.normalizeTopic(topic);
      topicScores[normalizedTopic] = (topicScores[normalizedTopic] || 0) + 1;
    });

    // For beginners, ensure basic topics are included
    if (proficiencyLevel === 'beginner') {
      const basicTopics = ['Greetings', 'Introductions', 'Basic Phrases'];
      basicTopics.forEach((topic) => {
        const normalizedTopic = this.normalizeTopic(topic);
        topicScores[normalizedTopic] =
          (topicScores[normalizedTopic] || 0) + 1.5;
      });
    }

    // Sort topics by score and limit to the desired number of topics
    const sortedTopics = Object.entries(topicScores)
      .sort((a, b) => b[1] - a[1])
      .map(([topic]) => topic)
      .slice(0, numberOfTopicsToGenerate);

    // If we ended up with less than the desired number of topics, fill with defaults
    if (sortedTopics.length < numberOfTopicsToGenerate) {
      const defaultTopics = [
        'Daily Conversations',
        'Practical Vocabulary',
        'Essential Grammar',
      ];

      for (const topic of defaultTopics) {
        if (sortedTopics.length < numberOfTopicsToGenerate && !sortedTopics.includes(topic)) {
          sortedTopics.push(topic);
        }
      }
    }

    return sortedTopics;
  }

  // Helper to normalize topic strings for comparison
  private normalizeTopic(topic: string): string {
    return topic.trim().toLowerCase().replace(/\s+/g, '-');
  }

  async recordStepAttempt(
    lessonId: string,
    stepId: string,
    userResponse: string
  ): Promise<LessonStep> {
    const lesson = await this.getLessonById(lessonId);
    if (!lesson) {
      throw new Error('Assessment lesson not found');
    }
    const step = lesson?.steps.find((s) => s.id === stepId);
    if (!step) {
      throw new Error('Step not found');
    }

    // Check if max attempts has been reached
    if (step.attempts >= step.maxAttempts) {
      logger.info('Maximum attempts reached', {
        stepId,
        attempts: step.attempts,
        maxAttempts: step.maxAttempts,
      });

      if (!step.expectedAnswer) {
        throw new Error('Expected answer not found');
      }

      // Record the attempt but mark as incorrect, preserving user response
      return this.lessonRepository.recordStepAttempt(lessonId, stepId, {
        userResponse: step.expectedAnswer,
        correct: true, // to proceed on the frontend
      });
    }

    logger.info('step.type ', step.type);

    // Validate user response for most step types
    if (
      step.type !== 'instruction' &&
      step.type !== 'summary' &&
      step.type !== 'feedback'
    ) {
      if (!userResponse) {
        throw new Error('No response provided');
      }
      if (userResponse.length <= 1) {
        throw new Error('Response is too short');
      }
      if (!step.expectedAnswer) {
        throw new Error('Expected answer not found');
      }
    }
    let correct = false;
    switch (step.type) {
      case 'feedback':
      case 'instruction':
      case 'summary':
        correct = true;
        userResponse = userResponse || 'Acknowledged';
        break;

      case 'practice':
      case 'prompt':
      case 'new_word':
        if (step.expectedAnswer) {
          logger.info('step.expectedAnswer', step.expectedAnswer);
          logger.info('userResponse', userResponse);

          if (userResponse.toLowerCase().includes('skip')) {
            correct = true;
            break;
          }
          // Normalize user response by removing punctuation and special characters
          const normalizedUserResponse = userResponse
            .trim()
            .toLowerCase()
            // Remove punctuation, ellipses, and extra whitespace
            .replace(/[.,!?;:"'""''()[\]…]+/g, '')
            .replace(/\s+/g, ' ');

          // Normalize expected answer the same way
          const normalizedExpectedAnswer = step.expectedAnswer
            .trim()
            .toLowerCase()
            // Remove punctuation, ellipses, and extra whitespace
            .replace(/[.,!?;:"'""''()[\]…]+/g, '')
            .replace(/\s+/g, ' ');

          // Main comparison: Check if normalized user response includes
          // the essential part of the normalized expected answer

          // First check if expected answer without ellipses is in user response
          const essentialExpectedPart = normalizedExpectedAnswer
            .replace(/\.{3,}/g, '')
            .trim();

          logger.info('Normalized user response:', normalizedUserResponse);
          logger.info('Essential expected part:', essentialExpectedPart);

          // Check if either there's a very close match, or the user response
          // contains the essential part of the expected answer
          if (normalizedUserResponse === essentialExpectedPart) {
            correct = true;
          } else if (normalizedUserResponse.includes(essentialExpectedPart)) {
            correct = true;
          } else if (essentialExpectedPart.includes(normalizedUserResponse)) {
            // For responses that may be shorter but still valid
            // For example, if expected is "hallo ich heiße" and user just said "hallo"
            const essentialWords = essentialExpectedPart.split(' ');
            const userWords = normalizedUserResponse.split(' ');

            // If user said at least half of the essential words, consider it correct
            // This helps with partial responses that are still meaningful
            const matchedWordCount = userWords.filter(
              (word) => essentialWords.includes(word) && word.length > 1
            ).length;

            correct = matchedWordCount / essentialWords.length >= 0.5;
          }
        } else {
          // If no expected answer, consider it correct (open-ended question)
          correct = true;
        }
        break;

      default:
        correct = false;
    }
    const updatedStep = await this.lessonRepository.recordStepAttempt(
      lessonId,
      stepId,
      {
        userResponse,
        correct,
      }
    );
    logger.info('updatedStep', { updatedStep });
    return { ...updatedStep, userResponse: step.expectedAnswer || '' };
  }

  async getStepHistory(
    lessonId: string,
    stepId: string
  ): Promise<LessonStep[]> {
    return this.lessonRepository.getStepHistory(lessonId, stepId);
  }

  private getTopicsFromLearningPurpose(purpose: string): string[] {
    // Map learning purposes to relevant topics
    const topicMap: Record<string, string[]> = {
      travel: ['Airport Navigation', 'Hotel Booking', 'Restaurant Ordering'],
      business: [
        'Business Meeting',
        'Email Communication',
        'Phone Conversations',
      ],
      academic: [
        'Classroom Vocabulary',
        'Academic Writing',
        'Study Discussions',
      ],
      general: ['Daily Greetings', 'Shopping', 'Directions'],
      // Add more purpose-to-topics mappings as needed
    };

    // Return topics for the given purpose, or default to general topics
    return topicMap[purpose.toLowerCase()] || topicMap['general'];
  }

  async checkAndGenerateNewLessons(): Promise<LessonModel[]> {
    const currentLessons = await this.lessonRepository.getLessons();
    logger.info('currentLessons', { currentLessons });
    // If there are no lessons or not all are complete, just return
    if (currentLessons.length === 0) throw new Error('No lessons found');
    const allComplete = currentLessons.every((lesson) => lesson.completed);

    logger.info('GENERATING NEW LESSONS BASED ON PROGRESS if neccessary', allComplete);
    if (!allComplete) return [];

    const newLessons = await this.generateNewLessonsBasedOnProgress();
    return newLessons;
  }

  async generateNewLessonsBasedOnProgress(): Promise<LessonModel[]> {
    // Get all completed lessons to analyze performance
    const allLessons = await this.getLessons();
    const completedLessons = allLessons.filter((lesson) => lesson.completed);
    const onboardingData = await this.onboardingRepository.getOnboarding();

    if (!onboardingData) {
      throw new Error('User onboarding data not found');
    }

    if (completedLessons.length === 0) {
      throw new Error('No completed lessons found to analyze');
    }

    const userId = onboardingData.userId;

    let learningProgress: LearningProgressModel | null = null;
    try {
      learningProgress =
        await this.learningProgressService.getLearningProgressWithDetails(
          userId
        );
      if (!learningProgress) {
        logger.warn(
          'Learning progress not found for user, proceeding with lesson metrics only.',
          { userId }
       );
      }
    } catch (error) {
      logger.error(
        'Failed to fetch learning progress, proceeding without it.',
        { userId, error }
      );
    }

    // Extract base preferences
    const targetLanguage = onboardingData.targetLanguage;
    const proficiencyLevel =
      learningProgress?.estimatedProficiencyLevel?.toLowerCase() ||
      onboardingData.proficiencyLevel?.toLowerCase() ||
      'beginner';

    const sourceLanguage = onboardingData.nativeLanguage;

    if (!targetLanguage || !sourceLanguage) {
      throw new Error('Target language or source language not found');
    }

    // Aggregate metrics from completed lessons (both performance metrics and audio metrics)
    const aggregatedMetrics = this.aggregateMetrics(
      completedLessons,
      learningProgress
    );

    logger.debug('aggregatedMetrics in generateNewLessonsBasedOnProgress', aggregatedMetrics);

    // Determine focus areas based on aggregated metrics
    const focusAreas = this.determineFocusAreas(
      aggregatedMetrics,
      proficiencyLevel,
      learningProgress
    );
    logger.debug('focus areas for generating new lessons', focusAreas);

    // Generate new lessons for each focus area
    const lessonPromises = focusAreas.map(async (topic) => {
      // Create a request with user's learning data for more personalized lessons
      const adaptiveRequest = this.createAdaptiveLessonRequest(
        completedLessons,
        aggregatedMetrics,
        onboardingData,
        learningProgress, // Pass learningProgress
        topic
      );
      logger.debug('adaptive request to generate a new lesson', adaptiveRequest);

      // Generate lesson with adaptive data when available
      const generatedResult = await this.lessonGeneratorService.generateLesson(
        topic,
        targetLanguage,
        proficiencyLevel, // Use potentially updated proficiency
        sourceLanguage,
        adaptiveRequest // Pass the enhanced adaptive request
      );

      const lessonItems = Array.isArray(generatedResult.data)
        ? generatedResult.data
        : [generatedResult.data];

      // Create lessons from generated content
      const createdLessons = await Promise.all(
        lessonItems.map(async (lessonItem: any) => {
          const audioSteps =
            await this.lessonGeneratorService.generateAudioForSteps(
              lessonItem.steps as LessonStep[],
              targetLanguage,
              sourceLanguage
            );
          logger.info('generating audio for LESSON steps', { audioSteps });
          const lessonData = {
            focusArea: lessonItem.focusArea,
            targetSkills: lessonItem.targetSkills,
            steps: audioSteps,
          };
          return this.createLesson(lessonData);
        })
      );

      logger.debug('created lessons', createdLessons);

      return createdLessons;
    });

    // Flatten and return all new lessons
    const lessonsNested = await Promise.all(lessonPromises);
    logger.debug('lessons nested in generate based on progress', lessonsNested);
    return lessonsNested.flat();
  }

  // Add new method to aggregate metrics from completed lessons
  private aggregateMetrics(
    completedLessons: LessonModel[],
    learningProgress: LearningProgressModel | null
  ): {
    avgAccuracy: number;
    avgPronunciationScore: number;
    avgGrammarScore: number;
    avgVocabularyScore: number;
    avgFluencyScore: number;
    weaknesses: string[]; // Combined weaknesses
    strengths: string[]; // Combined strengths
    audioAnalysisAvailable: boolean;
    recommendedTopics: string[];
    mostRecentAudioMetrics?: AudioMetrics;
    // Add overall progress info if needed directly here, or rely on passing learningProgress down
    overallScore?: number | null;
    learningTrajectory?: LearningTrajectory;
  } {
    // Initialize with learning progress data
    const allWeaknesses = new Set<string>(learningProgress?.weaknesses ?? []);
    const allStrengths = new Set<string>(learningProgress?.strengths ?? []);
    const allTopics = new Set<string>();

    // Initialize aggregated metrics
    const result = {
      errorPatterns: this.aggregateErrorPatterns(completedLessons),
      avgAccuracy: this.calculateAverageAccuracy(completedLessons),
      avgPronunciationScore: 0,
      avgGrammarScore: 0,
      avgVocabularyScore: 0,
      avgFluencyScore: 0,
      weaknesses: [] as string[],
      strengths: [] as string[],
      audioAnalysisAvailable: false,
      recommendedTopics: [] as string[],
      mostRecentAudioMetrics: undefined as AudioMetrics | undefined,
      overallScore: learningProgress?.overallScore, // Add overall score
      learningTrajectory: learningProgress?.learningTrajectory, // Add trajectory
    };

    // Find lessons with audio metrics
    const lessonsWithAudioMetrics = completedLessons
      .filter((lesson) => lesson.audioMetrics)
      .sort(
        (a, b) =>
          new Date(b.updatedAt).getTime() - new Date(a.updatedAt).getTime()
      );

    if (lessonsWithAudioMetrics.length > 0) {
      result.audioAnalysisAvailable = true;

      // Store most recent audio metrics for detailed insights
      result.mostRecentAudioMetrics =
        lessonsWithAudioMetrics[0].audioMetrics ?? undefined;

      // Calculate average scores from audio metrics
      // TODO: initial lessons are not being generated / gemini 503 issue
      // TODO: user profile can delete the data
      // TODO: basic learning progress integration
      const audioMetricsScores = {
        pronunciation: [] as number[],
        grammar: [] as number[],
        vocabulary: [] as number[],
        fluency: [] as number[],
      };

      // Collect strengths, weaknesses, and topics from all audio metrics
      lessonsWithAudioMetrics.forEach((lesson) => {
        if (lesson.audioMetrics) {
          // Add scores for averaging
          audioMetricsScores.pronunciation.push(
            lesson.audioMetrics.pronunciationScore
          );
          audioMetricsScores.grammar.push(lesson.audioMetrics.grammarScore);
          audioMetricsScores.vocabulary.push(
            lesson.audioMetrics.vocabularyScore
          );
          audioMetricsScores.fluency.push(lesson.audioMetrics.fluencyScore);

          // Collect areas for improvement
          lesson.audioMetrics.pronunciationAssessment.areas_for_improvement.forEach(
            (area) => allWeaknesses.add(area)
          );

          // Collect strengths
          lesson.audioMetrics.pronunciationAssessment.strengths.forEach(
            (strength) => allStrengths.add(strength)
          );
          lesson.audioMetrics.grammarAssessment.grammar_strengths.forEach(
            (strength) => allStrengths.add(strength)
          );

          // Collect suggested topics
          lesson.audioMetrics.suggestedTopics.forEach((topic) =>
            allTopics.add(topic)
          );
        }
      });

      // Calculate averages
      const calculateAverage = (arr: number[]) =>
        arr.length > 0
          ? arr.reduce((sum, val) => sum + val, 0) / arr.length
          : 0;

      result.avgPronunciationScore = calculateAverage(
        audioMetricsScores.pronunciation
      );
      result.avgGrammarScore = calculateAverage(audioMetricsScores.grammar);
      result.avgVocabularyScore = calculateAverage(
        audioMetricsScores.vocabulary
      );
      result.avgFluencyScore = calculateAverage(audioMetricsScores.fluency);

      // Store weaknesses, strengths, and topics
      result.weaknesses = Array.from(allWeaknesses);
      result.strengths = Array.from(allStrengths);
      result.recommendedTopics = Array.from(allTopics);
    }

    // Add lesson performance metrics
    completedLessons.forEach((lesson) => {
      // First check if performanceMetrics exists
      if (lesson.performanceMetrics) {
        // Then use type guard on the JsonValue
        if (isPerformanceMetrics(lesson.performanceMetrics)) {
          if (Array.isArray(lesson.performanceMetrics.weaknesses)) {
            lesson.performanceMetrics.weaknesses.forEach((w: string) =>
              allWeaknesses.add(w)
            );
          }
          if (Array.isArray(lesson.performanceMetrics.strengths)) {
            lesson.performanceMetrics.strengths.forEach((s: string) =>
              allStrengths.add(s)
            );
          }
        }
      }
    });

    return result;
  }

  // Updated method to determine focus areas based on rich metrics data
  private determineFocusAreas(
    metrics: ReturnType<typeof this.aggregateMetrics>,
    proficiencyLevel: string,
    learningProgress: LearningProgressModel | null
  ): string[] {
    const focusAreas = new Set<string>();

    // Prioritize learning progress weaknesses
    if (learningProgress?.weaknesses) {
      learningProgress.weaknesses
        .slice(0, 2)
        .forEach((weakness) => focusAreas.add(this.normalizeTopic(weakness)));
    }

    // Add low mastery topics from learning progress
    if (learningProgress?.topics) {
      learningProgress.topics
        .filter(
          (t) =>
            t.masteryLevel === MasteryLevel.NotStarted ||
            t.masteryLevel === MasteryLevel.Seen ||
            t.masteryLevel === MasteryLevel.Learning
        )
        .sort(
          (a, b) =>
            (a.lastStudiedAt?.getTime() ?? 0) -
            (b.lastStudiedAt?.getTime() ?? 0)
        )
        .slice(0, 2)
        .forEach((t) => focusAreas.add(this.normalizeTopic(t.topicName)));
    }

    // If we have audio analysis, use it to determine priorities
    if (metrics.audioAnalysisAvailable && metrics.mostRecentAudioMetrics) {
      // First prioritize topics directly recommended from audio analysis
      if (metrics.recommendedTopics.length > 0) {
        // Take the top 2 recommended topics
        metrics.recommendedTopics
          .slice(0, 2)
          .forEach((topic) => focusAreas.add(topic));
      }

      // Then prioritize areas of weakness
      const audioMetrics = metrics.mostRecentAudioMetrics;

      // Identify weakest area to focus on
      const scoreMap = [
        {
          area: 'Pronunciation Practice',
          score: metrics.avgPronunciationScore,
        },
        { area: 'Grammar Skills', score: metrics.avgGrammarScore },
        { area: 'Vocabulary Building', score: metrics.avgVocabularyScore },
        { area: 'Speaking Fluency', score: metrics.avgFluencyScore },
      ];

      // Sort by lowest score first
      scoreMap.sort((a, b) => a.score - b.score);

      // Add the weakest area if not already covered by recommendations
      if (
        scoreMap[0].score < 75 &&
        !Array.from(focusAreas).some((topic) =>
          topic.toLowerCase().includes(scoreMap[0].area.toLowerCase())
        )
      ) {
        focusAreas.add(scoreMap[0].area);
      }

      // Add grammar focus areas if grammar is weak
      if (metrics.avgGrammarScore < 70) {
        audioMetrics.grammarFocusAreas
          .slice(0, 1)
          .forEach((area) => focusAreas.add(area));
      }

      // Add vocabulary domains if vocabulary is weak
      if (metrics.avgVocabularyScore < 70) {
        audioMetrics.vocabularyDomains
          .slice(0, 1)
          .forEach((domain) => focusAreas.add(domain));
      }
    } else {
      // Fall back to error pattern-based focus areas if no audio metrics
      // Adjust based on accuracy
      if (metrics.avgAccuracy < 50) {
        focusAreas.add('Vocabulary Building');
      } else if (metrics.avgAccuracy > 80 && proficiencyLevel === 'beginner') {
        focusAreas.add('Conversational Practice');
      }
    }

    // Ensure we have at least one topic
    if (focusAreas.size === 0) {
      focusAreas.add('General Practice');
    }

    // Limit to 3 focus areas
    return Array.from(focusAreas).slice(0, 3);
  }

  // Helper method to create an adaptive lesson request based on user's learning data
  private createAdaptiveLessonRequest(
    completedLessons: LessonModel[],
    metrics: ReturnType<typeof this.aggregateMetrics>,
    onboardingData: OnboardingModel,
    learningProgress: LearningProgressModel | null,
    focusTopic: string
  ): any {
    // Use the most recent audio metrics if available
    if (!metrics.mostRecentAudioMetrics) {
      return undefined;
    }

    const audioMetrics = metrics.mostRecentAudioMetrics;
    const mostRecentLesson = completedLessons.sort(
      (a, b) =>
        new Date(b.updatedAt).getTime() - new Date(a.updatedAt).getTime()
    )[0];

    // Extract grammar rules to focus on
    const grammarRulesToFocus =
      audioMetrics.grammarAssessment.grammar_rules_to_review.map((rule) => ({
        rule:
          typeof rule === 'object' && 'rule' in rule ? rule.rule : String(rule),
        priority:
          typeof rule === 'object' && 'priority' in rule
            ? String(rule.priority)
            : 'medium',
      }));

    // Extract common grammar errors (handling possible type variations)
    const grammarCommonErrors =
      audioMetrics.grammarAssessment.error_patterns.map((pattern) => ({
        category:
          typeof pattern === 'object' && 'category' in pattern
            ? pattern.category
            : 'general',
        description:
          typeof pattern === 'object' && 'description' in pattern
            ? pattern.description
            : String(pattern),
      }));

    // Extract vocabulary areas for improvement
    const vocabularyAreas =
      audioMetrics.vocabularyAssessment.areas_for_expansion.map((area) => ({
        topic:
          typeof area === 'object' && 'topic' in area ? area.topic : 'general',
        suggestedVocabulary:
          typeof area === 'object' && 'suggested_vocabulary' in area
            ? Array.isArray(area.suggested_vocabulary)
              ? area.suggested_vocabulary
              : []
            : [],
      }));

    return {
      userInfo: {
        nativeLanguage: onboardingData.nativeLanguage || 'English',
        targetLanguage: onboardingData.targetLanguage || 'English',
        proficiencyLevel:
          learningProgress?.estimatedProficiencyLevel || 'beginner',
        learningPurpose: onboardingData.learningPurpose || 'general',
      },
      focusTopic,
      overallProgress: learningProgress
        ? {
          estimatedProficiencyLevel:
            learningProgress.estimatedProficiencyLevel,
          overallScore: learningProgress.overallScore,
          learningTrajectory: learningProgress.learningTrajectory,
          persistentWeaknesses: learningProgress.weaknesses,
          lowMasteryTopics:
            learningProgress.topics
              ?.filter((t) => t.masteryLevel !== MasteryLevel.Mastered)
              .map((t) => t.topicName) ?? [],
        }
        : undefined,
      performanceMetrics: {
        avgAccuracy: metrics.avgAccuracy,
        avgPronunciationScore: metrics.avgPronunciationScore,
        avgGrammarScore: metrics.avgGrammarScore,
        avgVocabularyScore: metrics.avgVocabularyScore,
        avgFluencyScore: metrics.avgFluencyScore,
        strengths: metrics.strengths,
        weaknesses: metrics.weaknesses,
      },
      improvementAreas: {
        pronunciation: audioMetrics.pronunciationAssessment.problematic_sounds,
        grammar: {
          rulesToFocus: grammarRulesToFocus,
          commonErrors: grammarCommonErrors,
        },
        vocabulary: vocabularyAreas,
      },
      learningRecommendations: {
        suggestedTopics: audioMetrics.suggestedTopics,
        focusAreas: audioMetrics.grammarFocusAreas,
        nextSkillTargets: audioMetrics.nextSkillTargets,
      },
      learningStyle: {
        effectiveApproaches: audioMetrics.effectiveApproaches,
        preferredPatterns: audioMetrics.preferredPatterns,
      },
      previousLesson: mostRecentLesson
        ? {
          id: mostRecentLesson.id,
          focusArea: mostRecentLesson.focusArea,
          targetSkills: mostRecentLesson.targetSkills,
        }
        : undefined,
    };
  }

  private aggregateErrorPatterns(completedLessons: LessonModel[]): string[] {
    // Collect all error patterns from completed lessons
    const allErrorPatterns: string[] = [];

    completedLessons.forEach((lesson) => {
      if (
        lesson.performanceMetrics &&
        typeof lesson.performanceMetrics === 'object' &&
        !Array.isArray(lesson.performanceMetrics) &&
        'errorPatterns' in lesson.performanceMetrics &&
        Array.isArray(lesson.performanceMetrics.errorPatterns)
      ) {
        allErrorPatterns.push(
          ...(lesson.performanceMetrics.errorPatterns as string[])
        );
      }
    });

    // Count occurrences
    const patternCount: Record<string, number> = {};
    allErrorPatterns.forEach((pattern) => {
      if (pattern) {
        patternCount[pattern] = (patternCount[pattern] || 0) + 1;
      }
    });

    // Return top patterns sorted by frequency
    return Object.entries(patternCount)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 5)
      .map(([pattern]) => pattern);
  }

  private calculateAverageAccuracy(completedLessons: LessonModel[]): number {
    const accuracies: number[] = [];

    completedLessons.forEach((lesson) => {
      if (
        lesson.performanceMetrics &&
        typeof lesson.performanceMetrics === 'object' &&
        !Array.isArray(lesson.performanceMetrics) &&
        'accuracy' in lesson.performanceMetrics &&
        typeof lesson.performanceMetrics.accuracy === 'number'
      ) {
        accuracies.push(lesson.performanceMetrics.accuracy);
      }
    });

    if (accuracies.length === 0) return 0;

    return Math.round(
      accuracies.reduce((sum, acc) => sum + acc, 0) / accuracies.length
    );
  }

  async processLessonRecording(
    sessionRecording: Blob,
    recordingTime: number,
    recordingSize: number,
    lesson: LessonModel
  ) {
    //1. get user onboarding data with lagnuages
    const onboardingData = await this.onboardingRepository.getOnboarding();
    if (!onboardingData) {
      throw new Error('User onboarding data not found');
    }
    const targetLanguage = onboardingData.targetLanguage || 'English';
    const sourceLanguage = onboardingData.nativeLanguage || 'English';

    // 3. Determine proper mime type
    // 2. Convert the Blob to a Buffer for upload
    const arrayBuffer = await sessionRecording.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // 3. Determine proper mime type
    const mimeType = sessionRecording.type || 'audio/webm';

    // 4. Upload the file
    const fileName = `lesson-${lesson.id}-${Date.now()}.webm`;
    logger.info('Uploading recording file', {
      fileName,
      mimeType,
      size: buffer.length,
    });

    const fileUri = await this.recordingService.uploadFile(
      buffer,
      mimeType,
      fileName
    );
    logger.log('File URI:', fileUri);

    logger.log('Sending recording to AI for analysis');
    // send recording to AI
    let aiResponse: Record<string, unknown>;
    if (process.env.MOCK_RECORDING_AI_ANALYSIS === 'true') {
      aiResponse = mockAudioMetrics;
    } else {
      logger.info('Sending recording to AI for analysis');
      aiResponse = await this.recordingService.submitLessonRecordingSession(
        fileUri, // Now using file URI instead of base64
        Number(recordingTime),
        Number(recordingSize),
        { targetLanguage, nativeLanguage: sourceLanguage },
        lesson
      );
    }

    logger.info('AI response received', { aiResponse });

    // 3. convert ai  response to audioMetrics model.
    const audioMetrics = this.convertAiResponseToAudioMetrics(aiResponse);
    logger.info('Audio metrics generated', { audioMetrics });

    return this.lessonRepository.updateLesson(lesson.id, { audioMetrics });
  }

  private convertAiResponseToAudioMetrics(
    aiResponse: AiLessonAnalysisResponse // Use the specific interface type
  ): AudioMetrics {


    // Safely access nested objects
    const performanceMetrics: AiPerformanceMetrics | undefined =
      aiResponse.performance_metrics;
    const progressTracking: AiProgressTracking | undefined =
      aiResponse.progress_tracking;
    const adaptiveSuggestions: AiAdaptiveSuggestions | undefined =
      aiResponse.adaptive_learning_suggestions;

    // Extract top-level metrics safely, providing defaults if objects or properties are missing
    const pronunciationScore =
      typeof performanceMetrics?.pronunciation_score === 'number'
        ? performanceMetrics.pronunciation_score
        : 0;
    const fluencyScore =
      typeof performanceMetrics?.fluency_score === 'number'
        ? performanceMetrics.fluency_score
        : 0;
    const grammarScore =
      typeof performanceMetrics?.grammar_accuracy === 'number' // Use correct source key
        ? performanceMetrics.grammar_accuracy
        : 0;
    const vocabularyScore =
      typeof performanceMetrics?.vocabulary_score === 'number'
        ? performanceMetrics.vocabulary_score
        : 0;
    const overallPerformance =
      typeof performanceMetrics?.overall_performance === 'number'
        ? performanceMetrics.overall_performance
        : 0;

    const id = randomUUID();

    // Extract CEFR level and learning trajectory safely
    const proficiencyLevel =
      typeof progressTracking?.estimated_proficiency_level === 'string'
        ? progressTracking.estimated_proficiency_level
        : 'A1'; // Default

    let learningTrajectory: LearningTrajectory = 'steady'; // Default
    const trajectoryFromAI = progressTracking?.learning_trajectory;
    if (trajectoryFromAI === 'accelerating') {
      learningTrajectory = 'accelerating';
    } else if (trajectoryFromAI === 'plateauing') {
      learningTrajectory = 'plateauing';
    }

    // Extract detailed assessment data - Pass the correct top-level objects
    // Use optional chaining `?.` in case the assessment object itself is missing
    const pronunciationAssessment = getPronunciationAssessment(
      aiResponse?.pronunciation_assessment as JsonValue
    ) || {
      overall_score: pronunciationScore,
      native_language_influence: {
        level: 'moderate' as LanguageInfluenceLevel,
        specific_features: [],
      },
      phoneme_analysis: [],
      problematic_sounds: [],
      strengths: [],
      areas_for_improvement: [],
    };

    const fluencyAssessment = getFluencyAssessment(
      aiResponse?.fluency_assessment as JsonValue
    ) || {
      overall_score: fluencyScore,
      speech_rate: {
        words_per_minute: 0,
        evaluation: 'appropriate' as SpeechRateEvaluation,
      },
      hesitation_patterns: {
        frequency: 'occasional' as HesitationFrequency,
        average_pause_duration: 0,
        typical_contexts: [],
      },
      rhythm_and_intonation: {
        naturalness: 0,
        sentence_stress_accuracy: 0,
        intonation_pattern_accuracy: 0,
      },
    };

    const grammarAssessment = getGrammarAssessment(
      aiResponse?.grammar_assessment as JsonValue
    ) || {
      overall_score: grammarScore,
      error_patterns: [],
      grammar_rules_to_review: [],
      grammar_strengths: [],
    };

    const vocabularyAssessment = getVocabularyAssessment(
      aiResponse?.vocabulary_assessment as JsonValue
    ) || {
      overall_score: vocabularyScore,
      range: 'adequate' as VocabularyRange,
      appropriateness: 0,
      precision: 0,
      areas_for_expansion: [],
    };

    const exerciseCompletion = getExerciseCompletion(
      aiResponse?.exercise_completion as JsonValue
    ) || {
      overall_score: 0,
      exercises_analyzed: [],
      comprehension_level: 'fair' as ComprehensionLevel,
    };

    // Helper to extract string arrays safely
    const extractStringArray = (value: unknown): string[] => {
      if (Array.isArray(value)) {
        return value.filter((item) => typeof item === 'string') as string[];
      }
      return [];
    };

    // Extract learning suggestions safely using optional chaining
    const suggestedTopics = extractStringArray(
      adaptiveSuggestions?.suggested_topics
    );
    const grammarFocusAreas = extractStringArray(
      adaptiveSuggestions?.grammar_focus_areas
    );
    const vocabularyDomains = extractStringArray(
      adaptiveSuggestions?.vocabulary_domains
    );
    const nextSkillTargets = extractStringArray(
      adaptiveSuggestions?.next_skill_targets
    );
    // Handle potential nesting within learning_style_observations or direct access
    const preferredPatterns = extractStringArray(
      adaptiveSuggestions?.preferred_patterns ||
      adaptiveSuggestions?.learning_style_observations?.preferred_patterns
    );
    const effectiveApproaches = extractStringArray(
      adaptiveSuggestions?.effective_approaches ||
      adaptiveSuggestions?.learning_style_observations?.effective_approaches
    );

    // Extract metadata safely
    const audioRecordingUrl =
      typeof aiResponse?.audioRecordingUrl === 'string'
        ? aiResponse.audioRecordingUrl
        : null;
    const recordingDuration =
      typeof aiResponse?.recordingDuration === 'number'
        ? aiResponse.recordingDuration
        : null;

    // Construct and return the AudioMetrics object
    const finalAudioMetrics: AudioMetrics = {
      // Explicitly type the final object
      id,
      pronunciationScore,
      fluencyScore,
      grammarScore,
      vocabularyScore,
      overallPerformance,
      proficiencyLevel,
      learningTrajectory,
      pronunciationAssessment,
      fluencyAssessment,
      grammarAssessment,
      vocabularyAssessment,
      exerciseCompletion,
      suggestedTopics,
      grammarFocusAreas,
      vocabularyDomains,
      nextSkillTargets,
      preferredPatterns,
      effectiveApproaches,
      audioRecordingUrl,
      recordingDuration,
      createdAt: new Date(),
      updatedAt: new Date(),
    };

    logger.debug(
      '<<< convertAiResponseToAudioMetrics OUTPUT:',
      JSON.stringify(finalAudioMetrics, null, 2)
    );
    return finalAudioMetrics;
  }
}
</file>

<file path="src/context/lesson-context.tsx">
'use client';

import { createContext, useCallback, useContext, useState, useEffect, useRef } from 'react';
import {
  getLessonsAction,
  getLessonByIdAction,
  createLessonAction,
  updateLessonAction,
  completeLessonAction,
  deleteLessonAction,
  recordStepAttemptAction,
  getStepHistoryAction,
  generateNewLessonsAction,
  processLessonRecordingAction,
  checkAndGenerateNewLessonsAction,
  generateInitialLessonsAction, // Import the new action
} from '@/lib/server-actions/lesson-actions';
import logger from '@/utils/logger';
import {
  LessonModel,
  LessonStep,
  AssessmentStep as AssessmentStepModel,
} from '@/models/AppAllModels.model';
import toast from 'react-hot-toast';
import { useUpload } from '@/hooks/use-upload';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import { useAuth } from '@/context/auth-context';
import { Result } from '@/lib/server-actions/_withErrorHandling';
import { usePathname } from 'next/navigation';
import { useOnboarding } from './onboarding-context';
import { useError } from '@/hooks/useError';
import { useAppInitializer } from './app-initializer-context';

interface LessonContextType {
  currentLesson: LessonModel | null;
  lessons: LessonModel[];
  loading: boolean; // General loading for fetch/refresh
  isGeneratingInitial: boolean; // Specific loading for initial generation
  error: string | null;
  initialized: boolean; // Tracks if lessons have been fetched *at least once* successfully for the current session/conditions
  clearError: () => void;
  getLessons: () => Promise<LessonModel[] | undefined>; // Renamed from refreshLessons for clarity
  getLessonById: (lessonId: string) => Promise<LessonModel | null>;
  createLesson: (lessonData: {
    focusArea: string;
    targetSkills: string[];
    steps: LessonStep[];
  }) => Promise<LessonModel>;
  updateLesson: (
    lessonId: string,
    lessonData: Partial<LessonModel>
  ) => Promise<LessonModel>;
  completeLesson: (
    lessonId: string,
    sessionRecording: Blob | null
  ) => Promise<LessonModel>;
  deleteLesson: (lessonId: string) => Promise<void>;
  recordStepAttempt: (
    lessonId: string,
    stepId: string,
    userResponse: string
  ) => Promise<LessonStep | AssessmentStepModel>;
  getStepHistory: (lessonId: string, stepId: string) => Promise<LessonStep[]>;
  setCurrentLesson: (lesson: LessonModel | null) => void;
  checkAndGenerateNewLessons: () => Promise<void>;
  processLessonRecording: (
    sessionRecording: Blob,
    lesson: LessonModel,
    recordingTime: number,
    recordingSize: number
  ) => Promise<LessonModel>;
  refreshLessons: () => Promise<LessonModel[]>; // Keep refreshLessons exposed if needed externally
}

const LessonContext = createContext<LessonContextType | undefined>(undefined);

export function LessonProvider({ children }: { children: React.ReactNode }) {
  const { uploadFile } = useUpload();
  const { user } = useAuth();
  const { isOnboardingComplete, onboarding } = useOnboarding();
  const { status: appInitializerStatus } = useAppInitializer();
  const [lessons, setLessons] = useState<LessonModel[]>([]);
  const [currentLesson, setCurrentLesson] = useState<LessonModel | null>(null);
  const [loading, setLoading] = useState(false);
  const [isGeneratingInitial, setIsGeneratingInitial] = useState(false); // New state
  const [initialGenerationAttempted, setInitialGenerationAttempted] = useState(false); // New state
  const [error, setError] = useState<string | null>(null);
  const [initialized, setInitialized] = useState(false);
  const { showError } = useError();
  const pathname = usePathname();

  const callAction = useCallback(async <T,>(
    action: () => Promise<Result<T>>,
    setGlobalLoading = true // Default to setting the main loading state
  ): Promise<T> => {
    if (setGlobalLoading) setLoading(true);
    setError(null);
    try {
      const { data, error: actionError } = await action(); // Renamed error variable
      if (actionError) {
        setError(actionError);
        showError(actionError);
        throw new Error(actionError);
      }
      if (data === undefined) {
        // Allow undefined for void actions like delete
        if (action.toString().includes('deleteLessonAction')) {
          return undefined as T; // Return undefined for void actions
        }
        throw new Error('Action returned successfully but with undefined data.');
      }
      return data;
    } catch (err) {
      // Avoid double-setting/showing error if it was already handled above
      if (!(err instanceof Error && error === err.message)) {
        const message = err instanceof Error ? err.message : 'An unknown error occurred';
        setError(message);
        showError(message);
      }
      throw err; // Re-throw the original error
    } finally {
      if (setGlobalLoading) setLoading(false);
    }
  }, [showError, error]); // Added `error` dependency

  const getLessons = useCallback(async (): Promise<LessonModel[]> => {
    logger.info('LessonContext: getLessons called...');

    // --- Pre-conditions for fetching ---
    if (appInitializerStatus !== 'idle') {
      logger.warn('LessonContext: Skipping getLessons, app not initialized.');
      return lessons;
    }
    if (!user) {
      logger.warn('LessonContext: Skipping getLessons, no user.');
      setLessons([]);
      setInitialized(false);
      setInitialGenerationAttempted(false); // Reset generation attempt on user change
      return [];
    }
    if (!isOnboardingComplete) {
      logger.warn('LessonContext: Skipping getLessons, onboarding not complete.');
      setLessons([]);
      setInitialized(false);
      setInitialGenerationAttempted(false); // Reset generation attempt
      return [];
    }
    if (pathname !== '/app/lessons') {
      logger.info('LessonContext: Skipping getLessons, not on lessons page.', { pathname });
      return lessons;
    }
    // --- End Pre-conditions ---

    logger.info('LessonContext: Conditions met, proceeding with lesson fetch.');
    setLoading(true); // Set loading before the fetch attempt
    setError(null);
    let generatedLessons: LessonModel[] | undefined; // Variable to hold generated lessons if needed

    try {
      const { data: fetchedLessons, error: fetchError } = await getLessonsAction();

      if (fetchError) {
        setError(fetchError);
        showError(fetchError);
        setLessons([]);
        setInitialized(false); // Consider if initialization should fail here
        setInitialGenerationAttempted(false); // Reset on error
        setLoading(false);
        return [];
      }

      const currentLessons = fetchedLessons || [];
      setLessons(currentLessons);
      setInitialized(true); // Mark as initialized *after* successful fetch
      logger.info(`LessonContext: Fetched lessons, count: ${currentLessons.length}. Initialized: true.`);

      // --- Initial Generation Logic ---
      if (currentLessons.length === 0 && !initialGenerationAttempted) {
        logger.info("LessonContext: No lessons found and generation not attempted. Triggering initial generation.");
        setInitialGenerationAttempted(true); // Mark attempt *before* calling action
        setIsGeneratingInitial(true); // Set specific loading state
        setLoading(false); // Turn off general loading while generating

        try {
          // Use callAction for generation as well, but don't set global loading
          generatedLessons = await callAction(() => generateInitialLessonsAction(), false);

          if (generatedLessons) {
            setLessons(generatedLessons); // Update state with newly generated lessons
            logger.info(`LessonContext: Successfully generated ${generatedLessons.length} initial lessons.`);
          } else {
            // This case means callAction caught an error or returned undefined unexpectedly
            logger.warn('LessonContext: generateInitialLessonsAction call resulted in undefined data or error was handled by callAction.');
            // Error state should already be set by callAction if there was an error
            // Keep lessons empty
          }
        } catch (genErr) {
          // Catch unexpected errors during the action call itself (if callAction re-throws)
          const message = genErr instanceof Error ? genErr.message : 'Unknown generation error';
          // Error state/toast is likely already handled by callAction, just log here
          logger.error('LessonContext: Unexpected error during initial lesson generation call', { genErr });
        } finally {
          setIsGeneratingInitial(false); // Reset generation loading state
        }
        // Return the lessons state *after* generation attempt
        setLoading(false); // Ensure loading is false after generation attempt
        return lessons; // Return the current state of lessons (might be generated or empty on error)
      }
      // --- End Initial Generation Logic ---

      setLoading(false); // Turn off general loading if fetch was successful and no generation needed
      return currentLessons;

    } catch (refreshError) {
      // This catch block might be redundant if callAction handles errors, but keep for safety
      logger.error('LessonContext: Unexpected error during getLessons process', refreshError);
      const message = refreshError instanceof Error ? refreshError.message : 'Failed to load lessons';
      setError(message);
      showError(message);
      setLessons([]);
      setInitialized(false);
      setInitialGenerationAttempted(false);
      setLoading(false);
      setIsGeneratingInitial(false);
      return [];
    }
  }, [
    // Dependencies for getLessons useCallback
    appInitializerStatus,
    user,
    isOnboardingComplete,
    pathname,
    initialGenerationAttempted,
    callAction, // callAction is stable if its dependencies are correct
    lessons, // Include lessons if returned directly
    showError, // Include showError from useError
    error // Include error state if used within callAction's dependency array
  ]);

  // Effect to trigger initial fetch/refresh based on conditions
  useEffect(() => {
    logger.debug('LessonProvider: Initial fetch effect triggered.', { appInitializerStatus, user: !!user, isOnboardingComplete, pathname, initialized });

    if (
      appInitializerStatus === 'idle' &&
      user &&
      isOnboardingComplete &&
      pathname === '/app/lessons' &&
      !initialized // Only run if not yet initialized under these conditions
    ) {
      logger.info('LessonProvider: Conditions met for initial lesson fetch/refresh.');
      getLessons(); // Call getLessons which now contains fetch and generation logic
    } else {
      logger.debug('LessonProvider: Conditions not met for initial fetch/refresh.');
    }

    // Reset state if user logs out or app initializer status changes from idle
    if (!user || (appInitializerStatus !== 'idle' && appInitializerStatus !== 'initializing')) {
      if (initialized || lessons.length > 0 || isGeneratingInitial || initialGenerationAttempted) {
        logger.info('LessonProvider: Resetting lessons state due to user logout or app status change.');
        setLessons([]);
        setCurrentLesson(null);
        setInitialized(false);
        setError(null);
        setIsGeneratingInitial(false);
        setInitialGenerationAttempted(false); // Reset generation flag
      }
    }

  }, [appInitializerStatus, user, isOnboardingComplete, pathname, initialized, getLessons]); // Use getLessons as dependency

  // --- Other context methods (remain largely unchanged) ---

  const getLessonById = async (id: string): Promise<LessonModel | null> => {
    // Use callAction for consistency, though individual loading might not be needed here
    const lesson = await callAction(() => getLessonByIdAction(id), false); // Don't set global loading
    setCurrentLesson(lesson ?? null); // Handle potential undefined from callAction
    return lesson ?? null;
  };

  const createLesson = async (ld: {
    focusArea: string;
    targetSkills: string[];
    steps: LessonStep[];
  }): Promise<LessonModel> => {
    const lesson = await callAction(() => createLessonAction(ld));
    setLessons((prev) => [lesson, ...prev]);
    setCurrentLesson(lesson);
    return lesson;
  };

  const updateLesson = async (
    lessonId: string,
    lessonData: Partial<LessonModel>
  ): Promise<LessonModel> => {
    const lesson = await callAction(() => updateLessonAction(lessonId, lessonData));
    setLessons((prev) =>
      prev.map((l) => (l.id === lessonId ? lesson : l))
    );
    if (currentLesson?.id === lessonId) setCurrentLesson(lesson);
    return lesson;
  };

  const checkAndGenerateNewLessons = useCallback(async (): Promise<void> => {
    // Use callAction to handle loading/errors for the generation check itself
    logger.info("LessonContext: Checking and generating new lessons...");
    try {
      // Don't set global loading for this background check
      const newLessons = await callAction(() => checkAndGenerateNewLessonsAction(), false);
      if (newLessons && newLessons.length > 0) {
        // Refresh the list to include the new lessons
        await getLessons(); // Call getLessons to update the state
        toast.success('New lessons generated based on your progress!');
      } else {
        logger.info("checkAndGenerateNewLessonsAction completed but returned no new lessons.");
        // Optionally inform the user if needed, or just refresh silently
        // Consider if a refresh is needed even if no new lessons are generated
        // await getLessons(); // Refresh even if no new lessons generated? Maybe not needed.
      }
    } catch (error) {
      logger.error("LessonContext: Error during checkAndGenerateNewLessons", error);
      // Error is handled by callAction
    }
  }, [callAction, getLessons]); // Add dependencies

  const completeLesson = async (
    lessonId: string,
    sessionRecording: Blob | null // Keep signature, even if not used directly here
  ): Promise<LessonModel> => {
    // completeLessonAction likely triggers the analysis including recording if needed
    const lesson = await callAction(() => completeLessonAction(lessonId));
    setLessons((prev) =>
      prev.map((l) => (l.id === lessonId ? lesson : l))
    );
    if (currentLesson?.id === lessonId) setCurrentLesson(lesson);
    // Trigger check for new lessons after completion
    checkAndGenerateNewLessons(); // Call this after a lesson is completed
    return lesson;
  };

  const deleteLesson = async (lessonId: string): Promise<void> => {
    await callAction(() => deleteLessonAction(lessonId)); // callAction handles void return
    setLessons((prev) => prev.filter((l) => l.id !== lessonId));
    if (currentLesson?.id === lessonId) setCurrentLesson(null);
  };

  const recordStepAttempt = async (
    lessonId: string,
    stepId: string,
    userResponse: string
  ): Promise<LessonStep | AssessmentStepModel> => {
    // No global loading for step attempts
    const { data: step, error: stepError } = await recordStepAttemptAction(
      lessonId,
      stepId,
      userResponse
    );
    if (stepError) {
      setError(stepError);
      showError(stepError);
      throw new Error(stepError);
    }
    if (!step) {
      throw new Error('Step attempt action returned no data.');
    }
    // Update local currentLesson state optimistically or based on response
    setCurrentLesson((prev) => {
      if (!prev || prev.id !== lessonId) return prev;
      return {
        ...prev,
        steps: prev.steps.map((s) =>
          s.id === stepId ? { ...s, ...step } : s // Use ID for matching
        ),
      };
    });
    return step;
  };

  const getStepHistory = async (
    lessonId: string,
    stepId: string
  ): Promise<LessonStep[]> => {
    // Use callAction for consistency if desired, or keep direct call
    const history = await callAction(() => getStepHistoryAction(
      lessonId,
      stepId
    ), false); // No global loading
    return history;
  };

  const processLessonRecording = async (
    sessionRecording: RecordingBlob,
    lesson: LessonModel,
    recordingTime: number,
    recordingSize: number
  ): Promise<LessonModel> => {
    const processedLesson = await callAction(() => processLessonRecordingAction(
      sessionRecording,
      recordingTime,
      recordingSize,
      lesson
    ));
    // Update local state after processing
    setLessons((prev) =>
      prev.map((l) => (l.id === processedLesson.id ? processedLesson : l))
    );
    if (currentLesson?.id === processedLesson.id) setCurrentLesson(processedLesson);
    return processedLesson;
  };

  const clearError = () => setError(null);

  // Expose refreshLessons which is just an alias for getLessons now
  const refreshLessons = getLessons;

  return (
    <LessonContext.Provider
      value={{
        currentLesson,
        lessons,
        loading,
        isGeneratingInitial, // Expose new state
        error,
        initialized,
        clearError,
        getLessons, // Expose getLessons
        getLessonById,
        createLesson,
        updateLesson,
        completeLesson,
        deleteLesson,
        recordStepAttempt,
        getStepHistory,
        setCurrentLesson,
        checkAndGenerateNewLessons,
        processLessonRecording,
        refreshLessons, // Keep alias if used elsewhere
      }}
    >
      {children}
    </LessonContext.Provider>
  );
}

export const useLesson = () => {
  const context = useContext(LessonContext);
  if (context === undefined) {
    throw new Error('useLesson must be used within a LessonProvider');
  }
  return context;
};
// --- NEW CODE END ---
</file>

<file path="src/components/lessons/lessonChat.tsx">
import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  AssessmentLesson,
  AssessmentStep,
  LessonModel,
  LessonStep,
} from '@/models/AppAllModels.model';
import logger from '@/utils/logger';
import { mapLanguageToCode } from '@/utils/map-language-to-code.util';
import ChatMessages, { ChatMessage } from './ChatMessages';
import ChatInput from './ChatInput';
import { ArrowLeft } from 'lucide-react';
import { usePathname, useRouter } from 'next/navigation';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
// TODO: play the expectedAudio when answer is correct

// Add this interface at the top of the file
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
}
interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

export interface SpeechRecognition extends EventTarget {
  new (): SpeechRecognition;
  start(): void;
  stop(): void;
  abort(): void;
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  onstart: (() => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: Event) => void) | null;
  onend: (() => void) | null;
}

declare global {
  interface Window {
    webkitSpeechRecognition: SpeechRecognition;
  }
}

interface LessonChatProps {
  lesson: LessonModel | AssessmentLesson;
  onComplete: (recording: RecordingBlob | null) => void;
  onStepComplete: (
    step: LessonStep | AssessmentStep,
    userResponse: string
  ) => Promise<AssessmentStep | LessonStep>;
  loading: boolean;
  targetLanguage: string;
  isAssessment?: boolean; // Add this flag to differentiate between lesson and assessment
}
const isMockMode = process.env.NEXT_PUBLIC_MOCK_USER_RESPONSES === 'true';

logger.info('isMockMode', isMockMode);

export default function LessonChat({
  lesson,
  onComplete,
  onStepComplete,
  loading,
  targetLanguage,
  isAssessment = false,
}: LessonChatProps) {
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [userResponse, setUserResponse] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [feedback, setFeedback] = useState('');
  const [chatHistory, setChatHistory] = useState<ChatMessage[]>([]);

  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const lastSpeechTimestampRef = useRef<number>(0);
  const SILENCE_TIMEOUT_MS = 1000; // 1 second silence detection
  const router = useRouter();
  const recognitionRef = useRef<any>(null);
  const manuallyStoppedRef = useRef(false); // Flag to track if the user manually stopped recording
  const chatMessagesRef = useRef<HTMLDivElement>(null);

  const debounceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [shouldPlayAudio, setShouldPlayAudio] = useState(true);
  const [audioQueue, setAudioQueue] = useState<string[]>([]);
  const [isPlayingAudio, setIsPlayingAudio] = useState(false);
  const [initialUserInteractionDone, setInitialUserInteractionDone] =
    useState(false);

  // recording state
  const [isRecording, setIsRecording] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingStartTimeRef = useRef<number>(0);
  const recordingPausedTimeRef = useRef<number>(0);
  const [fullSessionRecording, setFullSessionRecording] =
    useState<RecordingBlob | null>(null);
  const [lessonCompleted, setLessonCompleted] = useState(false);

  // Add state for recording playback
  const [recordingAudioURL, setRecordingAudioURL] = useState<string | null>(
    null
  );
  const [isPlayingRecording, setIsPlayingRecording] = useState(false);
  const recordingAudioRef = useRef<HTMLAudioElement | null>(null);

  // Add state to track if lesson is complete but waiting for manual completion in mock mode
  const [lessonReadyToComplete, setLessonReadyToComplete] = useState(false);
  const pathname = usePathname();
  const showBackButton = pathname.includes('/lessons');
  const stopRecordingCompletely = useCallback(() => {
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== 'inactive'
    ) {
      try {
        mediaRecorderRef.current.stop(); // onstop handler will set state and process blob
        logger.info('Recording stopped completely triggered');
        // setIsRecording(false); // Let onstop handle this
      } catch (error) {
        logger.error('Error stopping recording completely:', error);
        setIsRecording(false); // Ensure state is correct on error
      }
    }
  }, []);

  // Start session recording function
  const startRecording = useCallback(() => {
    if (!mediaRecorderRef.current || isRecording) {
      logger.warn('Media recorder not initialized or already recording');
      return;
    }
    try {
      if (mediaRecorderRef.current.state === 'inactive') {
        recordingStartTimeRef.current = Date.now();
        recordingPausedTimeRef.current = 0; // Reset pause time on new start
        audioChunksRef.current = []; // Clear previous chunks
        mediaRecorderRef.current.start(1000); // Collect data every second
        setIsRecording(true);
        logger.info('Recording started');
      } else if (mediaRecorderRef.current.state === 'paused') {
        mediaRecorderRef.current.resume();
        // Adjust start time based on pause duration
        recordingStartTimeRef.current +=
          Date.now() - recordingPausedTimeRef.current;
        recordingPausedTimeRef.current = 0; // Reset pause time
        setIsRecording(true);
        logger.info('Recording resumed');
      }
    } catch (error) {
      logger.error('Error starting recording:', error);
      setIsRecording(false);
    }
  }, [isRecording]);

  // Pause recording function
  const pauseRecording = useCallback(() => {
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state === 'recording'
    ) {
      try {
        mediaRecorderRef.current.pause();
        recordingPausedTimeRef.current = Date.now(); // Record pause time
        setIsRecording(false);
        logger.info('Recording paused');
      } catch (error) {
        logger.error('Error pausing recording:', error);
        setIsRecording(false); // Ensure state is correct on error
      }
    }
  }, []);

  const pauseListening = useCallback(() => {
    if (!recognitionRef.current || !isListening) return;
    try {
      recognitionRef.current.stop();
      logger.info('LessonChat: Paused listening triggered');
      // setIsListening(false); // onend handles this
    } catch (error) {
      logger.error('LessonChat: Error stopping listening', { error });
      // Ensure state is correct if stop fails unexpectedly
      setIsListening(false);
    }
  }, [isListening]);

  const handleSubmitStep = useCallback(
    async (step: LessonStep | AssessmentStep, userInput: string) => {
      try {
        logger.info(
          'handleSubmitStep called for step:',
          step.id,
          'Type:',
          step.type,
          'Input:',
          userInput
        );

        // Pause listening and recording *before* processing the response
        // This prevents capturing feedback audio or silence detection during processing
        if (isListening) {
          pauseListening();
        }
        if (isRecording) {
          pauseRecording();
        }

        // Handle instruction, summary, feedback steps (Auto-advance logic)
        if (
          step.type === 'instruction' ||
          step.type === 'summary' ||
          step.type === 'feedback'
        ) {
          logger.info(
            `Processing auto-advance for ${step.type} step: ${step.id}`
          );
          await onStepComplete(step, 'Acknowledged'); // Mark as seen

          const nextStepIndex = currentStepIndex + 1;
          logger.info(
            'Next step index after auto-advance:',
            nextStepIndex,
            'Total steps:',
            lesson.steps.length
          );

          if (nextStepIndex < lesson.steps.length) {
            const nextStep = lesson.steps[nextStepIndex];
            setCurrentStepIndex(nextStepIndex);

            setChatHistory((prev) => [
              ...prev,
              // Optional: Add acknowledgment message if desired
              // { type: 'response', content: 'OK, got it!' },
              { type: 'prompt', content: nextStep.content },
            ]);
            setUserResponse(''); // Clear input for the next step
            setShouldPlayAudio(true); // Queue audio for the next step

            // --- IMPORTANT ---
            // Do NOT automatically start listening/recording here.
            // The audio 'ended' listener for the *new* step's audio will handle that.
            logger.info(
              `Advanced to step ${nextStepIndex}. Audio queued. Waiting for audio end to potentially start listening.`
            );
          } else {
            // Last step was non-interactive, complete the lesson
            logger.info('Last step was non-interactive. Completing lesson.');
            stopRecordingCompletely(); // Stop recording fully
            setLessonCompleted(true);
            // Handle mock mode completion button display
            if (isMockMode) {
              setLessonReadyToComplete(true);
              setChatHistory((prev) => [
                ...prev,
                { type: 'prompt', content: 'Lesson complete! (Mock Mode)' },
              ]);
            }
            // Non-mock mode completion is handled by useEffect watching fullSessionRecording
          }
          return; // Exit early for non-interactive steps
        }

        // --- Handle interactive steps (practice, prompt, question, etc.) ---
        logger.info(
          `Processing interactive step: ${step.id}, User input: ${userInput}`
        );
        const updatedStep = await onStepComplete(step, userInput);
        logger.info('Step completion result:', updatedStep);

       
        setUserResponse(''); // Clear input field immediately after submission

        if (!updatedStep.correct) {
          setFeedback('Try again!'); // Provide feedback for incorrect response
          // Do NOT advance. Keep currentStepIndex the same.
          // Set flag to replay audio for the *current* step if needed,
          // or simply wait for user to try again (manual mic click or typing).
          // Let's assume user needs to manually retry for now.
          // setShouldPlayAudio(true); // Replay current step audio? Maybe too intrusive.
          logger.info(`Step ${step.id} incorrect. Waiting for user retry.`);
          // Re-enable listening/recording *if* needed for retry?
          // For now, let's require manual re-activation via button click.
          return; // Exit early if incorrect
        }
         // Add user response to chat history *before* checking correctness/advancing
        // This ensures the user sees their submitted response immediately.
        setChatHistory((prev) => [
          ...prev,
          { type: 'response', content: updatedStep.userResponse || userInput },
        ]);

        // --- Correct Response Handling ---
        setFeedback(''); // Clear feedback on correct

        // Check if this was a forced correct due to max attempts
        if (
          updatedStep.attempts >= updatedStep.maxAttempts &&
          updatedStep.correct
        ) {
          logger.info('Step completed via max attempts override');
          // Queue the expected answer audio if available
          const audioUrlToAdd = updatedStep.expectedAnswerAudioUrl;
          if (audioUrlToAdd) {
            setAudioQueue((prev) => [...prev, audioUrlToAdd]);
            logger.info('Queued expected answer audio after max attempts.');
          }
        }

        // Find the next step
        const nextStepIndex = currentStepIndex + 1; // Calculate based on current index

        if (nextStepIndex < lesson.steps.length) {
          const nextStep = lesson.steps[nextStepIndex];
          logger.info(
            `Advancing to next step: ${nextStep.id} (Index: ${nextStepIndex})`
          );
          setCurrentStepIndex(nextStepIndex); // Advance the step index

          // Add next prompt to chat history
          setChatHistory((prev) => [
            ...prev,
            { type: 'prompt', content: nextStep.content },
          ]);

          // Set flag to play audio for the new step
          setShouldPlayAudio(true);

          // --- IMPORTANT ---
          // Do NOT automatically start listening/recording here.
          // The audio 'ended' listener for the *new* step's audio will handle that.
          logger.info(
            `Advanced to step ${nextStepIndex}. Audio queued. Waiting for audio end to potentially start listening.`
          );
        } else {
          // Last step was interactive and correct, complete the lesson
          logger.info(
            'Last step was interactive and correct. Completing lesson.'
          );
          stopRecordingCompletely(); // Stop recording fully
          setLessonCompleted(true);

          // Handle mock mode completion button display
          if (isMockMode) {
            setLessonReadyToComplete(true);
            setChatHistory((prev) => [
              ...prev,
              { type: 'prompt', content: 'Lesson complete! (Mock Mode)' },
            ]);
            logger.info('Lesson ready to complete in mock mode.');
          }
          // Non-mock mode completion is handled by useEffect watching fullSessionRecording
        }
      } catch (error) {
        setFeedback('Error processing response');
        logger.error('LessonChat: Error in handleSubmitStep', { error });
        // Ensure listening/recording state is reset on error
        if (isListening) pauseListening();
        if (isRecording) pauseRecording(); // Use pause instead of stop completely on error? Maybe pause is better.
      }
    },
    [
      // Dependencies for handleSubmitStep
      currentStepIndex,
      lesson.steps,
      onStepComplete,
      isListening,
      isRecording,
      pauseListening,
      pauseRecording,
      stopRecordingCompletely,
      isMockMode,
      // Add other state setters used inside if they aren't stable refs/dispatchers
      setChatHistory,
      setUserResponse,
      setShouldPlayAudio,
      setFeedback,
      setLessonCompleted,
      setLessonReadyToComplete,
      setAudioQueue, // Needed for max attempts audio queueing
      setCurrentStepIndex,
    ]
  );

  const startListening = useCallback(() => {
    if (!recognitionRef.current || isListening) return;
    try {
      recognitionRef.current.start();
      logger.info('LessonChat: Start listening triggered');
      // setIsListening(true); // onstart handles this
    } catch (error) {
      logger.error('LessonChat: Error starting listening', { error });
      // It might already be started, log a warning
      if ((error as DOMException).name === 'InvalidStateError') {
        logger.warn('LessonChat: Recognition already started');
      } else {
        setIsListening(false); // Ensure state is correct if start fails unexpectedly
      }
    }
  }, [isListening]);

  // Rehydrate chat history
  useEffect(() => {
    if (
      lesson &&
      lesson.steps &&
      Array.isArray(lesson.steps) &&
      chatHistory.length === 0
    ) {
      logger.info('all lesson data', lesson);
      const initialHistory: ChatMessage[] = [];

      // Find the last completed step
      let lastCompletedIndex = -1;
      lesson.steps.forEach((step, index) => {
        if (step.userResponse) {
          lastCompletedIndex = index;
        }
      });

      // Add all completed steps with their prompts and responses
      for (let i = 0; i <= lastCompletedIndex; i++) {
        const step = lesson.steps[i];
        initialHistory.push({ type: 'prompt', content: step.content });
        if (step.userResponse && 
          step.type !== 'instruction' && 
          step.type !== 'summary' && 
          step.type !== 'feedback') {
        initialHistory.push({ type: 'response', content: step.userResponse });
      }
      }

      // Add only the next uncompleted prompt
      if (lastCompletedIndex + 1 < lesson.steps.length) {
        const nextStep = lesson.steps[lastCompletedIndex + 1];
        initialHistory.push({ type: 'prompt', content: nextStep.content });
      }

      setChatHistory(initialHistory);

      // Set current step index to the first uncompleted step
      const firstIncompleteStepIndex = lesson.steps.findIndex(
        (step) => !step.userResponse
      );
      setCurrentStepIndex(
        firstIncompleteStepIndex >= 0
          ? firstIncompleteStepIndex
          : lesson.steps.length - 1
      );
    }

    // At the end of this effect, set shouldPlayAudio to true to play initial audio
    setShouldPlayAudio(true);
  }, [lesson]);

  // Audio playback
  useEffect(() => {
    const playNextInQueue = () => {
      if (audioQueue.length > 0 && !isPlayingAudio) {
        setIsPlayingAudio(true);
        const nextAudio = audioQueue[0];

        if (audioRef.current) {
          audioRef.current.src = nextAudio;
          audioRef.current
            .play()
            .then(() => {
              logger.info('Playing audio:', nextAudio);
            })
            .catch((error) => {
              logger.error('Failed to play audio:', error);
              // Move to next audio in queue if current fails
              setAudioQueue((prevQueue) => prevQueue.slice(1));
              setIsPlayingAudio(false);
            });
        }
      }
    };

    playNextInQueue();
  }, [audioQueue, isPlayingAudio]);

  // Audio playback
  useEffect(() => {
    const handleAudioEnded = () => {
      const wasLastInQueue = audioQueue.length === 1; // Check *before* update

      // Remove the played audio from queue and reset playing state
      setAudioQueue((prevQueue) => prevQueue.slice(1));
      setIsPlayingAudio(false);

      logger.info(
        'Audio ended. Queue length was:',
        wasLastInQueue ? 1 : audioQueue.length,
        'Initial interaction done:',
        initialUserInteractionDone
      );

      if (initialUserInteractionDone && lesson.steps) {
        // --- NEW LOGIC: Auto-start listening/recording for the NEXT interactive step ---
        if (wasLastInQueue) {
          // Only check if the queue for the *current* step is now empty
          const nextStepIndex = currentStepIndex + 1;
          logger.info(
            'Checking next step for auto-start. Next index:',
            nextStepIndex
          );

          if (nextStepIndex < lesson.steps.length) {
            const nextStep = lesson.steps[nextStepIndex];
            logger.info('Next step type:', nextStep.type);

            // Check if the *next* step requires interaction
            if (
              nextStep.type !== 'instruction' &&
              nextStep.type !== 'summary' &&
              nextStep.type !== 'feedback'
            ) {
              logger.info(
                'Next step is interactive. Starting listening and recording automatically.'
              );
              // Start listening and recording if not already active
              if (!isListening) {
                startListening();
              }
              if (!isRecording) {
                startRecording();
              }
            } else {
              logger.info(
                'Next step is non-interactive. Not starting listening/recording automatically.'
              );
              // Optional: Explicitly pause if needed, though should happen naturally when step advances
              // if (isListening) pauseListening();
              // if (isRecording) pauseRecording();
            }
          } else {
            logger.info('No next step found (end of lesson).');
            // End of lesson, recording should be stopped by completion logic
          }
        }
        // --- END NEW LOGIC ---

        // --- ORIGINAL LOGIC: Auto-advance the *CURRENT* non-interactive step ---
        // This should run regardless of the *next* step's type, but only if the current step's audio queue is empty
        if (wasLastInQueue) {
          const currentStep = lesson.steps[currentStepIndex];
          logger.info(
            'Checking current step for auto-advance. Type:',
            currentStep.type
          );
          if (
            currentStep.type === 'instruction' ||
            currentStep.type === 'summary' ||
            currentStep.type === 'feedback'
          ) {
            logger.info(
              `Auto-advancing current ${currentStep.type} step after audio playback`
            );
            // Ensure handleSubmitStep is called correctly
            handleSubmitStep(currentStep, userResponse || 'Acknowledged'); // Pass current userResponse or default
          }
        }
        // --- END ORIGINAL LOGIC ---
      }
    };

    const audioElement = audioRef.current;
    if (audioElement) {
      audioElement.addEventListener('ended', handleAudioEnded);
      logger.info('Added audio ended listener');
    }

    return () => {
      if (audioElement) {
        audioElement.removeEventListener('ended', handleAudioEnded);
        logger.info('Removed audio ended listener');
      }
    };
  }, [
    // Dependencies needed for the logic within handleAudioEnded:
    audioQueue, // To check length *before* update
    currentStepIndex,
    initialUserInteractionDone,
    lesson.steps,
    isListening, // To check if already listening
    isRecording, // To check if already recording
    startListening, // Function ref
    startRecording, // Function ref
    handleSubmitStep, // Function ref for auto-advance
    userResponse, // Needed for handleSubmitStep
    // Removed pauseListening/pauseRecording as they aren't explicitly called here now
  ]);

  // Audio playback
  useEffect(() => {
    if (
      shouldPlayAudio &&
      lesson.steps &&
      lesson.steps[currentStepIndex] &&
      initialUserInteractionDone
    ) {
      const currentStep = lesson.steps[currentStepIndex];
      const newAudioQueue: string[] = [];

      // First play content audio for all step types
      if (currentStep.contentAudioUrl) {
        newAudioQueue.push(currentStep.contentAudioUrl);
      }

      // For practice steps, also queue the expected answer audio
      if (
        currentStep.type === 'practice' &&
        currentStep.expectedAnswerAudioUrl
      ) {
        newAudioQueue.push(currentStep.expectedAnswerAudioUrl);
      }

      if (newAudioQueue.length > 0) {
        setAudioQueue(newAudioQueue);
        logger.info('Queued audio files:', newAudioQueue);
      }

      // Reset the flag after queuing
      setShouldPlayAudio(false);
    }
  }, [
    currentStepIndex,
    lesson.steps,
    shouldPlayAudio,
    initialUserInteractionDone,
  ]);

  // Set up real time speech recognition
  useEffect(() => {
    let isMounted = true;
    logger.info('Setting up speech recognition effect...');

    if (targetLanguage) {
      // Initialize speech recognition
      try {
        if (!('webkitSpeechRecognition' in window)) {
          throw new Error('Speech recognition not supported in this browser');
        }

        const SpeechRecognition = window.webkitSpeechRecognition;
        recognitionRef.current = new SpeechRecognition();
        recognitionRef.current.lang = mapLanguageToCode(targetLanguage);
        recognitionRef.current.continuous = true;
        recognitionRef.current.interimResults = true;

        recognitionRef.current.onstart = () => {
          if (!isMounted) return;
          logger.info('Speech Recognition: Started');
          setIsListening(true);
          manuallyStoppedRef.current = false; // Ensure flag is reset on successful start
        };

        recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
          // Update the last speech timestamp whenever we receive speech
          lastSpeechTimestampRef.current = Date.now();

          const result = event.results[event.results.length - 1];
          const transcript = result[0].transcript;

          // If we have debounce timer, clear it
          if (debounceTimerRef.current) clearTimeout(debounceTimerRef.current);

          // Set user response with the transcript
          setUserResponse(transcript);
        };

        recognitionRef.current.onerror = (
          event: SpeechRecognitionErrorEvent
        ) => {
          // Use specific event type
          if (!isMounted) return;
          // Only log the error here. Let onend handle state and restart.
          logger.error(
            'Speech recognition error event:',
            event.error,
            event.message
          );
          // Optionally provide user feedback for critical errors
          if (
            event.error !== 'no-speech' &&
            event.error !== 'audio-capture' &&
            event.error !== 'not-allowed'
          ) {
            setFeedback(
              `Recognition error: ${event.error}. Please check microphone permissions or network.`
            );
          }
          // NOTE: 'not-allowed' often means the user denied permission permanently. Restarting won't help.
        };

        recognitionRef.current.onend = () => {
          if (!isMounted) {
            logger.info('Speech Recognition: Ended after component unmounted.');
            return;
          }

          const wasManualStop = manuallyStoppedRef.current;
          const isLessonDone = lessonCompleted; // Capture state at the time of execution

          logger.info(
            `Speech Recognition: Ended. isListening=${isListening}, manualStop=${wasManualStop}, lessonCompleted=${isLessonDone}`
          );

          // Always update listening state when it ends
          setIsListening(false);

          if (silenceTimerRef.current) {
            clearTimeout(silenceTimerRef.current);
            silenceTimerRef.current = null;
          }

          // --- Automatic Restart Logic ---
          if (!wasManualStop && !isLessonDone) {
            logger.info('Conditions met for automatic restart check.');
            // Use a small timeout to prevent potential rapid restart loops
            // and allow the browser state to settle.
            const restartTimeout = setTimeout(() => {
              // Check ref and conditions *again* inside timeout, as state might change
              // and ensure component is still mounted
              if (
                isMounted &&
                recognitionRef.current &&
                !manuallyStoppedRef.current &&
                !lessonCompleted
              ) {
                logger.info(
                  'Inside timeout: Attempting to restart recognition...'
                );
                try {
                  recognitionRef.current.start();
                  // onstart will set isListening back to true if successful
                } catch (startError: any) {
                  // Log specific start errors (e.g., InvalidStateError if already started somehow)
                  logger.error(
                    'Error restarting recognition in onend timeout:',
                    startError.name,
                    startError.message
                  );
                  // Ensure state is correct if restart fails
                  if (isMounted) setIsListening(false);
                }
              } else {
                logger.warn('Inside timeout: Recognition restart aborted.', {
                  isMounted,
                  hasRef: !!recognitionRef.current,
                  isManualNow: manuallyStoppedRef.current, // Check ref value again
                  isLessonDoneNow: lessonCompleted, // Check state value again
                });
                // If it was aborted due to manual stop flag being set *during* the timeout, reset it.
                if (manuallyStoppedRef.current) {
                  manuallyStoppedRef.current = false;
                }
              }
            }, 150); // Slightly longer delay (150ms)

            // Store timeout ID for potential cleanup if needed, though unlikely here
            // restartTimerRef.current = restartTimeout;
          } else {
            logger.info(
              'Speech Recognition: End condition met (Manual Stop or Lesson Completed). Not restarting.'
            );
            // Reset the manual stop flag *only if* it was the reason for not restarting
            if (wasManualStop) {
              manuallyStoppedRef.current = false;
              logger.info('Reset manual stop flag.');
            }
          }
          // --- End Automatic Restart Logic ---
        };
      } catch (error) {
        logger.error('Error initializing speech recognition:', error);
      }
    }

    // Clean up function
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        manuallyStoppedRef.current = true;
        recognitionRef.current.onresult = null;
        recognitionRef.current.onstart = null;
        recognitionRef.current.onend = null;
        recognitionRef.current.onerror = null;
        recognitionRef.current = null;
      }

      // Clear any remaining timers
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
        silenceTimerRef.current = null;
      }

      if (debounceTimerRef.current) {
        clearTimeout(debounceTimerRef.current);
        debounceTimerRef.current = null;
      }
    };
  }, [targetLanguage, lessonCompleted]);

  // Add this useEffect to handle silence detection
  useEffect(() => {
    // Only set up silence timer if there's a response and we're listening
    logger.info('userResponse', userResponse);
    logger.info('isListening', isListening);
    if (userResponse && userResponse.trim() && isListening) {
      // Clear any existing silence timer
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
      }

      // Set up a new silence timer
      silenceTimerRef.current = setTimeout(() => {
        logger.log('Auto-submitting after silence detection!!!');
        const currentStep = lesson.steps[currentStepIndex] as LessonStep;
        handleSubmitStep(currentStep, userResponse);
      }, SILENCE_TIMEOUT_MS);
    }

    // Cleanup function
    return () => {
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
        silenceTimerRef.current = null;
      }
    };
  }, [userResponse, isListening]);

  // Update the toggleListening function to handle silence timer
  useEffect(() => {
    const initializeRecorder = async () => {
      try {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          logger.error('Media devices API not supported in this browser');
          return;
        }

        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          },
          video: false,
        });

        const mimeType = MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : 'audio/mp4';

        mediaRecorderRef.current = new MediaRecorder(stream, {
          mimeType: mimeType,
        });

        audioChunksRef.current = [];

        mediaRecorderRef.current.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorderRef.current.onstop = () => {
          const audioBlob = new Blob(audioChunksRef.current, {
            type: mimeType,
          });

          // Calculate recording metrics
          const recordingDuration =
            Date.now() -
            recordingStartTimeRef.current -
            (recordingPausedTimeRef.current || 0);
          const recordingSize = audioBlob.size;

          // Create a new blob with the metadata
          const recordingWithMetadata = new Blob([audioBlob], {
            type: mimeType,
          }) as RecordingBlob;

          // Add metadata properties
          recordingWithMetadata.lastModified = Date.now();
          recordingWithMetadata.recordingTime = recordingDuration;
          recordingWithMetadata.recordingSize = recordingSize;

          logger.info('Recording completed with metadata', {
            size: recordingSize,
            duration: recordingDuration,
            lastModified: recordingWithMetadata.lastModified,
          });

          // Set the full session recording, which will trigger the useEffect
          setFullSessionRecording(recordingWithMetadata);

          // Create URL for playback in mock mode
          if (isMockMode) {
            const url = URL.createObjectURL(audioBlob);
            setRecordingAudioURL(url);
          }
        };
      } catch (error) {
        logger.error('Error initializing media recorder:', error);
      }
    };
    // TODO: STOP RECORDING AFTER 10 SECONDS
    // TODO: initialize rerorder when user starts speaking

    initializeRecorder();

    return () => {
      // Clean up the recorder and stream on unmount
      if (
        mediaRecorderRef.current &&
        mediaRecorderRef.current.state !== 'inactive'
      ) {
        mediaRecorderRef.current.stop();
      }

      // Clean up any object URLs we created
      if (recordingAudioURL) {
        URL.revokeObjectURL(recordingAudioURL);
      }
    };
  }, []);

  // Stop recording on component unmount
  useEffect(() => {
    return () => {
      if (
        mediaRecorderRef.current &&
        mediaRecorderRef.current.state !== 'inactive'
      ) {
        mediaRecorderRef.current.stop();
        logger.info('Recording stopped on component unmount');
      }
    };
  }, []);

  const toggleListening = () => {
    // Set the user interaction flag to true on the first manual click
    if (!initialUserInteractionDone) {
      setInitialUserInteractionDone(true);
      // Trigger audio playback for the *current* step immediately after interaction
      setShouldPlayAudio(true);
      logger.info(
        'Initial user interaction detected. Enabling audio playback.'
      );
    }

    if (isListening) {
      logger.info('Manual pause triggered.');
      manuallyStoppedRef.current = true;
      pauseListening();
      pauseRecording(); // Also pause recording when manually pausing listening
    } else {
      logger.info('Manual start triggered.');
      manuallyStoppedRef.current = false;
      startListening();
      startRecording(); // Also start recording when manually starting listening
    }
  };

  // A wrapper to trigger submission from the input component.
  const handleSubmit = () => {
    if (!initialUserInteractionDone) {
      setInitialUserInteractionDone(true);
      // Optionally trigger audio here too if Enter is the first interaction
      // setShouldPlayAudio(true);
    }

    const currentStep = lesson.steps[currentStepIndex];
    if (currentStep && userResponse.trim()) {
      // Only submit if there's a response
      logger.info('Manual submit triggered (e.g., Enter key)');
      handleSubmitStep(currentStep, userResponse);
    } else {
      logger.warn(
        'Manual submit attempted with no response or no current step.'
      );
    }
  };

  const handleMockResponse = (forStep: boolean) => {
    const currentStep: LessonStep = lesson.steps[
      currentStepIndex
    ] as LessonStep;
    if (!currentStep) return;
    let expectedResponse;
    if (currentStep.expectedAnswer) {
      expectedResponse = currentStep.expectedAnswer!;
    } else {
      expectedResponse = 'OK, lets continue';
    }

    const response = forStep
      ? expectedResponse
      : 'This is a mock response different from the expected';
    setUserResponse(response);
    handleSubmitStep(currentStep, response);
  };

  // Add function to play/pause recording
  const toggleRecordingPlayback = () => {
    if (!recordingAudioRef.current || !recordingAudioURL) return;

    if (isPlayingRecording) {
      recordingAudioRef.current.pause();
      setIsPlayingRecording(false);
    } else {
      recordingAudioRef.current
        .play()
        .then(() => setIsPlayingRecording(true))
        .catch((error) => {
          logger.error('Error playing recording:', error);
          setIsPlayingRecording(false);
        });
    }
  };

  // Add effect to handle recording audio ended event
  useEffect(() => {
    const handleRecordingEnded = () => {
      setIsPlayingRecording(false);
    };

    if (recordingAudioRef.current) {
      recordingAudioRef.current.addEventListener('ended', handleRecordingEnded);
    }

    return () => {
      if (recordingAudioRef.current) {
        recordingAudioRef.current.removeEventListener(
          'ended',
          handleRecordingEnded
        );
      }
    };
  }, []);

  const handleSkip = () => {
    const currentStep = lesson.steps[currentStepIndex] as LessonStep;
    handleSubmitStep(currentStep, 'skip');
  };

  // Update the handleUpdateResponse function to pass to ChatInput
  const handleUpdateResponse = (text: string) => {
    setUserResponse(text);
  };

  // Add a new function to handle lesson completion
  const handleCompleteLesson = () => {
    // Reset the ready state
    setLessonReadyToComplete(false);
    // Call onComplete ONLY when the button is clicked in mock mode
    if (fullSessionRecording) {
      // Ensure recording is available
      onComplete(fullSessionRecording);
    } else {
      logger.warn(
        'Complete Lesson clicked in mock mode, but no recording available yet.'
      );
      // Optionally call onComplete with null or handle differently
      onComplete(null);
    }
  };

  // Add this useEffect to trigger onComplete when recording is ready
  useEffect(() => {
    if (fullSessionRecording && lessonCompleted && !loading && !isMockMode) {
      logger.info('Lesson completed with recording', {
        recordingSize: fullSessionRecording.size,
        recordingTime: (fullSessionRecording as any).recordingTime,
      });

      // Call onComplete with the recording
      onComplete(fullSessionRecording);
    }
  }, [fullSessionRecording, lessonCompleted, loading, onComplete, isMockMode]);

  return (
    lesson && (
      <div className="flex flex-col h-full border rounded-[4px] bg-neutral-2 overflow-hidden">
        {/* Chat Header */}
        <div
          className={`p-4 bg-neutral-12 text-white shrink-0 flex items-center ${
            isAssessment ? 'justify-center' : 'justify-between'
          }`}
        >
          {showBackButton && (
            <button
              onClick={() =>
                router.push(isAssessment ? '/app/onboarding' : '/app/lessons')
              }
              className="flex items-center text-sm font-medium text-white hover:text-neutral-3 transition-colors"
            >
              <ArrowLeft className="w-4 h-4 mr-2" />
              {isAssessment ? 'Back to Assessment' : 'Back to Lessons'}
            </button>
          )}
          <h2
            className={`text-xl font-semibold ${
              isAssessment ? 'mx-auto' : 'flex-1 text-left'
            }`}
          >
            {isAssessment
              ? 'Language Assessment'
              : `Lesson: ${'focusArea' in lesson ? lesson.focusArea : ''}`}
          </h2>
        </div>

        {/* Progress Bar */}
        <div
          className="w-full bg-neutral-3 h-1.5"
          role="progressbar" // Add role
          aria-valuemin={0} // Add aria-valuemin
          aria-valuemax={lesson.steps.length} // Add aria-valuemax
          aria-valuenow={currentStepIndex + 1} // Add aria-valuenow
          aria-label="Lesson Progress"
        >
          <div
            className="bg-accent-6 h-1.5 transition-all duration-300"
            style={{
              width: `${((currentStepIndex + 1) / lesson.steps.length) * 100}%`,
            }}
            data-testid="progress-bar-indicator"
          ></div>
        </div>

        {/* Chat Messages */}
        <div ref={chatMessagesRef} className="flex-1 overflow-y-auto min-h-0">
          <ChatMessages messages={chatHistory} />
          <audio ref={audioRef} />
          <audio ref={recordingAudioRef} src={recordingAudioURL || undefined} />
        </div>

        <ChatInput
          userResponse={userResponse}
          isListening={isListening}
          feedback={feedback}
          onToggleListening={toggleListening}
          onSubmit={handleSubmit}
          disableSubmit={loading}
          disableSkip={loading}
          onUpdateResponse={handleUpdateResponse}
          onSkip={handleSkip}
        />

        {/* Mock buttons */}
        {isMockMode && (
          <div className="flex flex-col space-y-2 mt-4 p-4">
            <div className="flex space-x-2">
              <button
                type="button"
                onClick={() => handleMockResponse(true)}
                className="flex-1 py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-green-600 hover:bg-green-700"
              >
                Mock Correct Response
              </button>
              <button
                type="button"
                onClick={() => handleMockResponse(false)}
                className="flex-1 py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-red-600 hover:bg-red-700"
              >
                Mock Incorrect Response
              </button>
            </div>

            {/* Recording playback controls only show when there's a recording */}
            {recordingAudioURL && (
              <button
                type="button"
                onClick={toggleRecordingPlayback}
                className="py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-blue-600 hover:bg-blue-700 flex items-center justify-center"
              >
                {isPlayingRecording ? (
                  <>
                    <svg
                      className="w-4 h-4 mr-2"
                      fill="currentColor"
                      viewBox="0 0 24 24"
                    >
                      <path d="M6 19h4V5H6v14zm8-14v14h4V5h-4z" />
                    </svg>
                    Pause Recording
                  </>
                ) : (
                  <>
                    <svg
                      className="w-4 h-4 mr-2"
                      fill="currentColor"
                      viewBox="0 0 24 24"
                    >
                      <path d="M8 5v14l11-7z" />
                    </svg>
                    Play Recording
                  </>
                )}
              </button>
            )}

            {/* Complete lesson button - only show when lesson is completed but not yet finalized */}
            {lessonReadyToComplete && (
              <button
                type="button"
                onClick={handleCompleteLesson}
                className="py-2 px-4 border border-transparent rounded-md shadow-sm text-sm font-medium text-white bg-accent-6 hover:bg-accent-7"
              >
                Complete Lesson
              </button>
            )}
          </div>
        )}
      </div>
    )
  );
}
</file>

<file path="tests/servises/lessonChat.test.tsx">
// File: /tests/components/lessons/lessonChat.test.tsx

import React from 'react';
import {
  render,
  screen,
  fireEvent,
  waitFor,
  act,
} from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import '@testing-library/jest-dom';

// import { ArrowLeftIcon } from 'lucide-react';

import LessonChat, { SpeechRecognition } from '@/components/lessons/lessonChat';
import {
  AssessmentLesson,
  AssessmentStep,
  LessonModel,
  LessonStep,
} from '@/models/AppAllModels.model';
import { RecordingBlob } from '@/lib/interfaces/all-interfaces';
import logger from '@/utils/logger';
import { mapLanguageToCode } from '@/utils/map-language-to-code.util';

// --- Mocks ---

// Mock scrollTo and scrollHeight for jsdom environment
Object.defineProperty(window.Element.prototype, 'scrollTo', {
  writable: true,
  value: jest.fn(), // Mock the function itself
});

Object.defineProperty(window.Element.prototype, 'scrollHeight', {
  writable: true,
  value: 500, // Provide a mock value for scrollHeight
});

// Mock next/navigation
const mockRouterPush = jest.fn();
jest.mock('next/navigation', () => ({
  useRouter: () => ({
    push: mockRouterPush,
  }),
}));

// Mock logger
jest.mock('@/utils/logger', () => ({
  info: jest.fn(),
  log: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
}));

// Mock lucide-react icons
jest.mock('lucide-react', () => {
  const originalModule = jest.requireActual('lucide-react');
  return {
    ...originalModule, // Keep original exports
    __esModule: true,
    // Mock specific icons used in LessonChat
    ArrowLeft: jest.fn(() => <svg data-testid="mock-arrow-left" />),
    // Add mocks for Play and Pause icons if they are directly imported and used
    // Play: jest.fn(() => <svg data-testid="mock-play-icon" />),
    // Pause: jest.fn(() => <svg data-testid="mock-pause-icon" />),
    // If icons are used dynamically (e.g., via a helper), this might not be needed
  };
});

// Mock mapLanguageToCode util
jest.mock('@/utils/map-language-to-code.util', () => ({
  mapLanguageToCode: jest.fn((lang) => {
    // Simple mock implementation
    if (lang === 'German') return 'de-DE';
    if (lang === 'English') return 'en-US';
    return 'en-US'; // Default
  }),
}));

// Mock Browser APIs

// -- Mock SpeechRecognition --
let mockRecognitionInstance: any;
const mockSpeechRecognition = jest.fn().mockImplementation(() => {
  mockRecognitionInstance = {
    lang: '',
    continuous: false,
    interimResults: false,
    start: jest.fn(() => {
      if (mockRecognitionInstance.onstart) {
        act(() => mockRecognitionInstance.onstart());
      }
    }),
    stop: jest.fn(() => {
      if (mockRecognitionInstance.onend) {
        act(() => mockRecognitionInstance.onend());
      }
    }),
    abort: jest.fn(),
    onstart: null,
    onresult: null,
    onerror: null,
    onend: null,
    // Helper to simulate a result
    _simulateResult: (transcript: string, isFinal = true) => {
      if (mockRecognitionInstance.onresult) {
        const event = {
          results: [
            [
              {
                transcript: transcript,
                confidence: 0.9,
              },
            ],
          ],
          resultIndex: 0, // or manage index if needed
        } as unknown as SpeechRecognitionEvent;
        // Simulate interim and final results if needed
        event.results[event.results.length - 1].isFinal = isFinal;
        act(() => mockRecognitionInstance.onresult(event));
      }
    },
    // Helper to simulate an error
    _simulateError: (error = 'network') => {
      if (mockRecognitionInstance.onerror) {
        const event = { error } as unknown as Event; // Adjust event structure if needed
        act(() => mockRecognitionInstance.onerror(event));
      }
    },
  };
  return mockRecognitionInstance;
});
// Define the type for the global window object to include webkitSpeechRecognition
declare global {
  interface Window {
    webkitSpeechRecognition: SpeechRecognition;
  }
}
global.window.webkitSpeechRecognition = mockSpeechRecognition as any;

// -- Mock MediaRecorder --
let mockMediaRecorderInstance: any;
let mockMediaRecorderChunks: Blob[] = [];
const mockMediaRecorder = jest.fn().mockImplementation(() => {
  mockMediaRecorderInstance = {
    start: jest.fn(),
    stop: jest.fn(() => {
      if (mockMediaRecorderInstance.onstop) {
        const blob = new Blob(mockMediaRecorderChunks, { type: 'audio/webm' });
        // Simulate adding metadata in the mock
        const recordingBlob = Object.assign(blob, {
          recordingTime:
            Date.now() - (mockMediaRecorderInstance._startTime || Date.now()),
          recordingSize: blob.size,
          lastModified: Date.now(),
        }) as RecordingBlob;
        act(() => mockMediaRecorderInstance.onstop({ data: recordingBlob })); // Pass blob in event if needed by impl
      }
      mockMediaRecorderChunks = []; // Reset chunks
    }),
    pause: jest.fn(),
    resume: jest.fn(),
    ondataavailable: null,
    onstop: null,
    onerror: null,
    state: 'inactive',
    mimeType: 'audio/webm',
    _startTime: 0, // Add property to track start time for mock duration
    // Helper to simulate data
    _simulateDataAvailable: (data: Blob) => {
      if (mockMediaRecorderInstance.ondataavailable) {
        mockMediaRecorderChunks.push(data);
        act(() => mockMediaRecorderInstance.ondataavailable({ data }));
      }
    },
  };
  // Mock static method
  (mockMediaRecorder as any).isTypeSupported = jest.fn((mimeType) => {
    return mimeType === 'audio/webm' || mimeType === 'audio/mp4';
  });
  return mockMediaRecorderInstance;
});
global.MediaRecorder = mockMediaRecorder as any;

// -- Mock MediaDevices --
if (typeof navigator === 'undefined') {
  (global as any).navigator = {};
}
// Ensure mediaDevices exists or define it
if (!navigator.mediaDevices) {
  (navigator as any).mediaDevices = {};
}

// Use Object.defineProperty to mock getUserMedia
Object.defineProperty(navigator.mediaDevices, 'getUserMedia', {
  writable: true, // Make it writable if needed, though just setting value is often enough
  configurable: true, // Allow redefining later if necessary
  value: jest.fn().mockResolvedValue({
    // The mock function
    getTracks: () => [{ stop: jest.fn() }], // Mock stream with tracks
  }),
});

// -- Mock Audio Element --
const mockAudioPlay = jest.fn().mockResolvedValue(undefined);
const mockAudioPause = jest.fn();
const mockAddEventListener = jest.fn();
const mockRemoveEventListener = jest.fn();
let mockAudioSrc = '';

// Store callbacks by event type
let audioEventListeners: Record<string, Function> = {};

// Mock the constructor and methods
global.window.HTMLAudioElement.prototype.play = mockAudioPlay;
global.window.HTMLAudioElement.prototype.pause = mockAudioPause;
global.window.HTMLAudioElement.prototype.addEventListener = jest.fn(
  (event, callback) => {
    audioEventListeners[event] = callback;
  }
);
global.window.HTMLAudioElement.prototype.removeEventListener = jest.fn(
  (event) => {
    delete audioEventListeners[event];
  }
);
Object.defineProperty(global.window.HTMLAudioElement.prototype, 'src', {
  get: () => mockAudioSrc,
  set: (value) => {
    mockAudioSrc = value;
    // Reset listeners when src changes, simulating new audio load
    // audioEventListeners = {}; // Commenting this out as it might clear listeners needed for recording playback
  },
});
// Helper to simulate 'ended' event
const simulateAudioEnded = () => {
  const endedCallback = audioEventListeners['ended'];
  if (endedCallback) {
    act(() => {
      endedCallback();
    });
  }
};

// Helper to simulate 'ended' event for the recording audio element
const simulateRecordingAudioEnded = () => {
  const endedCallback = audioEventListeners['ended']; // Assumes the same listener map is used, might need separate if src change clears it
  if (endedCallback) {
    act(() => {
      endedCallback();
    });
  }
};

// -- Mock URL object methods --
global.URL.createObjectURL = jest.fn(() => 'blob:mockurl/12345');
global.URL.revokeObjectURL = jest.fn();

// --- Test Data ---

const mockStep1: LessonStep = {
  id: 'step-1',
  lessonId: 'lesson-1',
  stepNumber: 1,
  type: 'instruction',
  content: 'Welcome to the lesson!',
  contentAudioUrl: 'audio/welcome.mp3',
  translation: null,
  expectedAnswer: null,
  expectedAnswerAudioUrl: null,
  userResponse: null,
  userResponseHistory: null,
  attempts: 0,
  maxAttempts: 1,
  correct: false,
  lastAttemptAt: null,
  errorPatterns: [],
  createdAt: new Date(),
  updatedAt: new Date(),
};

const mockStep2: LessonStep = {
  id: 'step-2',
  lessonId: 'lesson-1',
  stepNumber: 2,
  type: 'practice',
  content: 'Say "Hello"',
  contentAudioUrl: 'audio/say_hello.mp3',
  translation: 'Hallo',
  expectedAnswer: 'Hello',
  expectedAnswerAudioUrl: 'audio/hello_answer.mp3',
  userResponse: null,
  userResponseHistory: null,
  attempts: 0,
  maxAttempts: 3,
  correct: false,
  lastAttemptAt: null,
  errorPatterns: [],
  createdAt: new Date(),
  updatedAt: new Date(),
};

const mockStep3: LessonStep = {
  id: 'step-3',
  lessonId: 'lesson-1',
  stepNumber: 3,
  type: 'summary',
  content: 'Great job!',
  contentAudioUrl: 'audio/summary.mp3',
  translation: null,
  expectedAnswer: null,
  expectedAnswerAudioUrl: null,
  userResponse: null,
  userResponseHistory: null,
  attempts: 0,
  maxAttempts: 1,
  correct: false,
  lastAttemptAt: null,
  errorPatterns: [],
  createdAt: new Date(),
  updatedAt: new Date(),
};

const mockLesson: LessonModel = {
  id: 'lesson-1',
  userId: 'user-1',
  lessonId: 'lesson-id-1', // Added missing property
  focusArea: 'Greetings',
  targetSkills: ['speaking', 'listening'],
  performanceMetrics: null,
  completed: false,
  createdAt: new Date(),
  updatedAt: new Date(),
  steps: [mockStep1, mockStep2, mockStep3],
  audioMetrics: null,
  sessionRecordingUrl: null,
};

const mockAssessmentLesson: AssessmentLesson = {
  id: 'assess-1',
  userId: 'user-1',
  description: 'Assessment',
  completed: false,
  sourceLanguage: 'English',
  targetLanguage: 'German',
  metrics: null,
  proposedTopics: [],
  summary: null,
  createdAt: new Date(),
  updatedAt: new Date(),
  steps: [
    {
      ...mockStep1,
      id: 'assess-step-1',
      type: 'instruction',
      assessmentId: 'assess-1',
    } as AssessmentStep,
    {
      ...mockStep2,
      id: 'assess-step-2',
      type: 'question',
      assessmentId: 'assess-1',
      expectedAnswer: 'Hallo',
    } as AssessmentStep,
    {
      ...mockStep3,
      id: 'assess-step-3',
      type: 'summary',
      assessmentId: 'assess-1',
    } as AssessmentStep,
  ],
  audioMetrics: null,
  sessionRecordingUrl: null,
};

// --- Test Suite ---

describe('LessonChat Component', () => {
  let mockOnComplete: jest.Mock;
  let mockOnStepComplete: jest.Mock;

  beforeEach(() => {
    jest.clearAllMocks();
    mockOnComplete = jest.fn();
    mockOnStepComplete = jest
      .fn()
      .mockImplementation(async (step, response) => {
        // Default mock: assume correct response for progression
        return {
          ...step,
          userResponse: response,
          correct: true,
          attempts: (step.attempts || 0) + 1,
        };
      });

    // Reset mock states
    mockAudioSrc = '';
    mockMediaRecorderChunks = [];
    audioEventListeners = {}; // Reset audio listeners
    mockMediaRecorderInstance = undefined;
    mockRecognitionInstance = undefined
    // if (mockRecognitionInstance) {
    //   mockRecognitionInstance.onstart = null;
    //   mockRecognitionInstance.onresult = null;
    //   mockRecognitionInstance.onerror = null;
    //   mockRecognitionInstance.onend = null;
    // }
    // if (mockMediaRecorderInstance) {
    //   mockMediaRecorderInstance.ondataavailable = null;
    //   mockMediaRecorderInstance.onstop = null;
    //   mockMediaRecorderInstance.onerror = null;
    //   mockMediaRecorderInstance.state = 'inactive';
    //   mockMediaRecorderInstance._startTime = 0;
    // }

    // Reset timers
    jest.useFakeTimers();
  });

  afterEach(() => {
    jest.runOnlyPendingTimers();
    jest.useRealTimers();
  });

  // --- Rendering and Initialization ---

  it('renders correctly with initial lesson data', () => {
    render(
      <LessonChat
        lesson={mockLesson}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    // Header
    expect(screen.getByText('Back to Lessons')).toBeInTheDocument();
    expect(
      screen.getByText(`Lesson: ${mockLesson.focusArea}`)
    ).toBeInTheDocument();

    // --- FIX START ---
    // Progress Bar - Check container accessibility and inner div style
    const progressBarContainer = screen.getByRole('progressbar');
    expect(progressBarContainer).toHaveAttribute('aria-valuenow', '1'); // Initial step is 0, so value is 0+1 = 1
    expect(progressBarContainer).toHaveAttribute('aria-valuemin', '0');
    expect(progressBarContainer).toHaveAttribute(
      'aria-valuemax',
      `${mockLesson.steps.length}`
    );
    expect(progressBarContainer).toHaveAttribute(
      'aria-label',
      'Lesson Progress'
    );

    // Check the visual indicator's width using the test ID
    const progressBarIndicator = screen.getByTestId('progress-bar-indicator');
    expect(progressBarIndicator).toHaveStyle(
      `width: ${((0 + 1) / mockLesson.steps.length) * 100}%`
    ); // Initial progress
    // --- FIX END ---

    // Initial Prompt
    expect(screen.getByText(mockStep1.content)).toBeInTheDocument(); // First step content
    // Input Area - Check elements within ChatInput
    expect(screen.getByPlaceholderText('Ready to listen')).toBeInTheDocument(); // Placeholder might change based on state
    // expect(screen.getByRole('button', { name: 'Start Listening' })).toBeInTheDocument();
    expect(
      screen.getByRole('button', { name: 'Skip & Continue' })
    ).toBeInTheDocument();
  });

  it('renders correctly in assessment mode', () => {
    render(
      <LessonChat
        lesson={mockAssessmentLesson}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="German"
        isAssessment={true}
      />
    );

    expect(screen.getByText('Back to Assessment')).toBeInTheDocument();
    expect(screen.getByText('Language Assessment')).toBeInTheDocument();
    // Initial Prompt (from assessment lesson)
    expect(
      screen.getByText(mockAssessmentLesson.steps[0].content)
    ).toBeInTheDocument();
  });

  it('renders loading state', () => {
    render(
      <LessonChat
        lesson={mockLesson}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={true} // Loading is true
        targetLanguage="English"
      />
    );
    // Check if buttons are disabled or show loading indicator
    // Note: ChatInput component might handle the disabling, check its implementation if this fails
    // Assuming ChatInput passes the loading prop down to its buttons:
    expect(screen.getByRole('button', { name: 'Start Listening' })).toHaveClass(
      'cursor-not-allowed'
    );
    expect(
      screen.getByRole('button', { name: 'Skip & Continue' })
    ).toBeDisabled();
  });

  it('rehydrates chat history correctly', () => {
    const lessonWithHistory: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Acknowledged', correct: true }, // Step 1 completed
        mockStep2, // Step 2 is next
        mockStep3,
      ],
    };

    render(
      <LessonChat
        lesson={lessonWithHistory}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    // Check history: Step 1 prompt, Step 1 response, Step 2 prompt
    expect(screen.getByText(mockStep1.content)).toBeInTheDocument();
    expect(screen.getByText('Acknowledged')).toBeInTheDocument(); // Response for step 1
    expect(screen.getByText(mockStep2.content)).toBeInTheDocument(); // Prompt for step 2 (current)
    expect(screen.queryByText(mockStep3.content)).not.toBeInTheDocument(); // Step 3 prompt shouldn't show yet
  });

  // --- User Input and Interaction ---

  it('toggles microphone listening state and recording state', async () => {
    // Sanity check: Ensure mocks are globally available before render
    expect(global.MediaRecorder).toBeDefined();
    expect(global.window.webkitSpeechRecognition).toBeDefined();

    render(
      <LessonChat
        lesson={mockLesson}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const micButton = screen.getByRole('button', { name: 'Start Listening' });
    // Initialize mock instances if not already done
    if (!mockRecognitionInstance) {
      mockSpeechRecognition();
    }
    if (!mockMediaRecorderInstance) {
      mockMediaRecorder();
    }

    // --- Start Listening ---
    console.log('[TEST LOG] Clicking Start Listening...');
    act(() => {
      // Trigger speech recognition start
      mockRecognitionInstance.start();
      // Trigger media recorder start
      mockMediaRecorderInstance.start();
      mockMediaRecorderInstance.state = 'recording';
      mockMediaRecorderInstance._startTime = Date.now();
    });
    console.log('[TEST LOG] Clicked Start Listening.');

    console.log('[TEST LOG] Waiting for UI to update (Pause Listening)...');
    await waitFor(() => {
      expect(
        screen.getByRole('button', { name: /Pause Listening/i })
      ).toBeInTheDocument();
    });
  });

  it('updates input field on speech recognition result', async () => {
    render(
      <LessonChat
        lesson={mockLesson}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const micButton = screen.getByRole('button', { name: 'Start Listening' });
    const input = screen.getByRole('textbox'); // Find by role

    // Start listening
    await act(async () => {
      userEvent.click(micButton);
    });
    await waitFor(() =>
      expect(mockRecognitionInstance.start).toHaveBeenCalled()
    );

    // Simulate speech result
    act(() => {
      mockRecognitionInstance._simulateResult('This is speech');
    });

    expect(input).toHaveValue('This is speech');
  });

  it('submits response via skip/enter key', async () => {
    // Advance to step 2 (practice step)
    const lessonAtStep2: LessonModel = {
      ...mockLesson,
      steps: [
        {
          ...mockStep1,
          userResponse: 'Ack',
          correct: true,
          expectedAnswer: 'Hello',
        },
        mockStep2,
        mockStep3,
      ],
    };
    render(
      <LessonChat
        lesson={lessonAtStep2}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const input = screen.getByRole('textbox'); // Find by role
    const skipButton = screen.getByRole('button', { name: 'Skip & Continue' });

    // Assert button is enabled *after* typing
    expect(skipButton).not.toBeDisabled();

    await act(async () => {
      userEvent.click(skipButton);
    });

    // expected response
    // handle submit step called with skip
    await waitFor(
      () => {
        // Check that onStepComplete was called with the current step (step-2)
        // and the specific response 'skip'
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-2' }), // The current step (step 2)
          'skip' // The user response when skipping
        );
      },
      { timeout: 10000 } // Increased timeout just in case
    );
  });

  // --- Step Progression ---

  it('advances to the next step on successful submission', async () => {
    // Start at step 2
    const lessonAtStep2: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Ack', correct: true },
        mockStep2,
        mockStep3,
      ],
    };
    // Mock onStepComplete to return success for step 2
    mockOnStepComplete.mockResolvedValueOnce({
      ...mockStep2,
      userResponse: 'Hello',
      correct: true,
      attempts: 1,
    });

    render(
      <LessonChat
        lesson={lessonAtStep2}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const input = screen.getByRole('textbox'); // Find by role
    const skipButton = screen.getByRole('button', { name: 'Skip & Continue' });

    await act(async () => {
      userEvent.click(skipButton);
    });

    // Wait for state updates and effects
    await waitFor(() => {
      // Check if step 3 prompt is now visible
      expect(screen.getByText(mockStep3.content)).toBeInTheDocument();
    });
    // Check if input field is cleared
    expect(input).toHaveValue('');
    // Check chat history includes the response and the new prompt
    //  expect(screen.getByText('Hello')).toBeInTheDocument(); // User response for step 2
  });

  it('does not advance if onStepComplete returns incorrect', async () => {
    const lessonAtStep2: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Ack', correct: true },
        mockStep2, // Current step is practice
        mockStep3,
      ],
    };
    // Mock onStepComplete to return incorrect for step 2
    mockOnStepComplete.mockResolvedValueOnce({
      ...mockStep2,
      userResponse: 'Wrong', // The incorrect response submitted
      correct: false, // Mark as incorrect
      attempts: 1, // Increment attempts
    });

    render(
      <LessonChat
        lesson={lessonAtStep2}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const input = screen.getByRole('textbox'); // Find the input/textarea by role
    const micButton = screen.getByRole('button', { name: 'Start Listening' });

    await act(async () => {
      userEvent.click(micButton);
    });

    await waitFor(() =>
      expect(mockRecognitionInstance.start).toHaveBeenCalled()
    );
    act(() => {
      mockRecognitionInstance._simulateResult('Wrong');
    });

    expect(input).toHaveValue('Wrong');

    act(() => {
      // Advance time just past the silence threshold (defined as 1000ms in LessonChat)
      jest.advanceTimersByTime(1100);
    });

    // 5. Wait for onStepComplete to be called with the incorrect response
    await waitFor(() => {
      expect(mockOnStepComplete).toHaveBeenCalledWith(
        expect.objectContaining({ id: 'step-2' }), // Check the correct step is passed
        'Wrong' // Check the submitted response
      );
    });
    // 7. Check that step 2 prompt IS still visible (or re-rendered)
    // Need to wait slightly as the component might re-render after submission
    await waitFor(() => {
      expect(screen.getByText(mockStep2.content)).toBeInTheDocument();
    });

    console.log('input value on incorrect submission', input);
    // 6. Check that step 3 prompt is NOT visible (didn't advance)
    expect(screen.queryByText(mockStep3.content)).not.toBeInTheDocument();

    // 7. Check that step 2 prompt IS still visible (or re-rendered)
    // Need to wait slightly as the component might re-render after submission

    // 8. Input should be cleared even on incorrect submission.
    // Add a specific waitFor for this assertion, as the setUserResponse('')
    // happens after the onStepComplete promise resolves.
    await waitFor(() => {
      expect(input).toHaveValue('');
    });
  });

  it('auto-advances instruction/summary/feedback steps', async () => {
    // Start at step 1 (instruction)
    render(
      <LessonChat
        lesson={mockLesson} // Starts with step 1
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    // Simulate user interaction to allow audio playback and auto-advance
    const micButton = screen.getByRole('button', { name: 'Start Listening' });
    await act(async () => {
      userEvent.click(micButton);
    }); // Click mic once

    // Wait for the component to acknowledge interaction and potentially start listening state
    await waitFor(() =>
      // Check that audio playback was initiated for step 1's content
      // This confirms initialUserInteractionDone is true and audio was queued/played
      expect(mockAudioPlay).toHaveBeenCalled()
    );
    // Verify the correct audio source was set
    expect(mockAudioSrc).toBe(mockStep1.contentAudioUrl);

    // Simulate the audio for step 1 finishing playback
    act(() => {
      simulateAudioEnded();
    });

    // Now, wait for the automatic submission triggered by handleAudioEnded
    await waitFor(() => {
      // onStepComplete should be called for the instruction step
      expect(mockOnStepComplete).toHaveBeenCalledWith(
        expect.objectContaining({ id: 'step-1' }), // Check the correct step
        'Acknowledged' // Default response for auto-advance
      );
    });

    // Wait for the UI to update to the next step (step 2)
    await waitFor(() => {
      // Check if step 2 prompt is now visible
      expect(screen.getByText(mockStep2.content)).toBeInTheDocument();
    });
  });




  it('queues and plays audio for steps after user interaction', async () => {
    render(
      <LessonChat
        lesson={mockLesson} // Starts at step 1
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    // No audio initially
    expect(mockAudioPlay).not.toHaveBeenCalled();

    // Simulate user interaction (e.g., clicking mic)
    const micButton = screen.getByRole('button', { name: 'Start Listening' });
    await act(async () => {
      userEvent.click(micButton);
    });
    // Need to wait for state update triggered by interaction
    await waitFor(() => {
      // Now audio for step 1 should be queued and played
      expect(mockAudioPlay).toHaveBeenCalledTimes(1);
    });
    expect(mockAudioSrc).toBe(mockStep1.contentAudioUrl);

    // Simulate audio ending
    act(() => {
      simulateAudioEnded();
    });

    // Wait for auto-advance of step 1
    await waitFor(() => {
      expect(mockOnStepComplete).toHaveBeenCalledWith(
        expect.objectContaining({ id: 'step-1' }),
        'Acknowledged'
      );
    });

    // Wait for step 2 to become active and its audio to play
    await waitFor(() => {
      // Step 2 has content audio AND expected answer audio
      expect(mockAudioPlay).toHaveBeenCalledTimes(2); // Called again for step 2
      expect(mockAudioSrc).toBe(mockStep2.contentAudioUrl); // First plays content audio
    });

    // Simulate step 2 content audio ending
    act(() => {
      simulateAudioEnded();
    });

    // Wait for step 2 expected answer audio to play
    await waitFor(() => {
      expect(mockAudioPlay).toHaveBeenCalledTimes(3); // Called again for step 2 answer
      expect(mockAudioSrc).toBe(mockStep2.expectedAnswerAudioUrl); // Now plays expected answer audio
    });
  });

  // --- Recording ---

  it('calls onComplete when the last step is completed', async () => {
    const lessonAtStep3: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Ack', correct: true },
        { ...mockStep2, userResponse: 'Hello', correct: true }, // Mark step 2 as completed
        mockStep3, // Now the component will correctly start at index 2 (step 3)
      ],
    };

    mockOnStepComplete.mockResolvedValueOnce({
      ...mockStep3,
      userResponse: 'Acknowledged',
      correct: true,
    });

    render(
      <LessonChat
        lesson={lessonAtStep3}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    const micButton = await screen.findByRole('button', {
      name: 'Start Listening',
    });

       // --- Start recording simulation ---
       const startTime = Date.now(); // Get initial time under fake timers
       mockMediaRecorderInstance.state = 'recording';
       mockMediaRecorderInstance._startTime = startTime;
       // --- Simulate time passing ---
       const recordingDurationMs = 1500; // Simulate 1.5 seconds
       act(() => {
           jest.advanceTimersByTime(recordingDurationMs);
       });
       const endTime = startTime + recordingDurationMs; // Calculate expected end time
       // --- End recording simulation ---

    await act(async () => {

      userEvent.click(micButton);
    });

    // mic button should instantiate the recorder

    // Wait for recorder setup
    await waitFor(() => { expect(mockMediaRecorderInstance).toBeDefined(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.ondataavailable).not.toBeNull(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.onstop).not.toBeNull(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.start).toHaveBeenCalled(); });

    mockMediaRecorderInstance.state = 'recording';
    mockMediaRecorderInstance._startTime = Date.now() - 500;

    // Wait for audio play
    await waitFor(() => {
      expect(mockAudioPlay).toHaveBeenCalled();
      expect(mockAudioSrc).toBe(mockStep3.contentAudioUrl);
    });

    // --- FIX: Simulate ondataavailable BEFORE simulating stop/onstop ---
    const mockAudioChunk = new Blob(['audio data chunk'], { type: 'audio/webm' });
    act(() => {
        // Simulate the recorder emitting data
        if (mockMediaRecorderInstance?.ondataavailable) {
            mockMediaRecorderInstance.ondataavailable({ data: mockAudioChunk });
        } else {
             throw new Error('mockMediaRecorderInstance.ondataavailable is null');
        }
    });
    // --- END FIX ---


    // Simulate audio ending, step completion, and recorder stop
    await act(async () => {
      simulateAudioEnded();

      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-3' }),
          'Acknowledged'
        );
      });

      await waitFor(() => {
          expect(mockMediaRecorderInstance.stop).toHaveBeenCalled();
      });
    });
    const finalBlobFromMock = new Blob([mockAudioChunk], { type: 'audio/webm' }) as RecordingBlob;
    // --- FIX: Add metadata using simulated duration ---
    (finalBlobFromMock as any).recordingTime = recordingDurationMs; // Use the simulated duration
    (finalBlobFromMock as any).recordingSize = finalBlobFromMock.size;
    (finalBlobFromMock as any).lastModified = endTime; // Use the calculated end time
    // --- END FIX ---



    act(() => {
      if (mockMediaRecorderInstance?.onstop) {
        // Pass the blob the mock *would* create based on chunks
        mockMediaRecorderInstance.onstop({ data: finalBlobFromMock } as unknown as Event);
      } else {
        throw new Error('mockMediaRecorderInstance.onstop is unexpectedly null');
      }
    });

    await waitFor(() => {
      expect(mockOnComplete).toHaveBeenCalledWith(expect.any(Blob));
      const receivedBlob = mockOnComplete.mock.calls[0][0] as RecordingBlob;
      expect(receivedBlob.size).toBeGreaterThan(0);
      // --- FIX: Check the simulated duration ---
      expect((receivedBlob as any).recordingTime).toBe(recordingDurationMs);
      expect((receivedBlob as any).recordingTime).toBeGreaterThan(0);
      // --- END FIX ---
      expect((receivedBlob as any).recordingSize).toBeGreaterThan(0);
      expect((receivedBlob as any).lastModified).toBe(endTime); // Check end time
    });

    expect(mockOnComplete).toHaveBeenCalledTimes(1);

  });


  it('creates a recording blob on completion', async () => {
    const lessonAtStep3: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Ack', correct: true },
        { ...mockStep2, userResponse: 'Hello', correct: true }, // Mark step 2 as completed
        mockStep3, // Now the component will correctly start at index 2 (step 3)
      ],
    };

     mockOnStepComplete.mockResolvedValueOnce({
       ...mockStep3,
       userResponse: 'Acknowledged',
       correct: true,
     });

    render(
      <LessonChat
        lesson={lessonAtStep3}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );

    // Interact to start recording
    const micButton = screen.getByRole('button', { name: 'Start Listening' });
    await act(async () => {
      userEvent.click(micButton);
    });

    // Wait for recorder setup
    await waitFor(() => { expect(mockMediaRecorderInstance).toBeDefined(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.ondataavailable).not.toBeNull(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.onstop).not.toBeNull(); });
    await waitFor(() => { expect(mockMediaRecorderInstance.start).toHaveBeenCalled(); });

    // --- Start recording simulation ---
    const startTime = Date.now(); // Get initial time under fake timers
    mockMediaRecorderInstance.state = 'recording';
    mockMediaRecorderInstance._startTime = startTime;
    // --- Simulate time passing ---
    const recordingDurationMs = 1200; // Simulate 1.2 seconds
    act(() => {
        jest.advanceTimersByTime(recordingDurationMs);
    });
    const endTime = startTime + recordingDurationMs; // Calculate expected end time

    

    // Wait for UI update
    await waitFor(() => screen.getByRole('button', { name: /Pause Listening/i }));

    // Simulate pausing
    const pauseButton = screen.getByRole('button', { name: /Pause Listening/i });
    await act(async () => { userEvent.click(pauseButton); });
    await waitFor(() => screen.getByRole('button', { name: 'Start Listening' }));
    mockMediaRecorderInstance.state = 'paused';

    // --- FIX: Simulate ondataavailable BEFORE simulating stop/onstop ---
    const mockAudioChunk = new Blob(['chunk1'], { type: 'audio/webm' });
    act(() => {
        // Simulate the recorder emitting data while it was recording
        if (mockMediaRecorderInstance?.ondataavailable) {
            mockMediaRecorderInstance.ondataavailable({ data: mockAudioChunk });
        } else {
             throw new Error('mockMediaRecorderInstance.ondataavailable is null');
        }
    });
     // --- END FIX ---


    // Simulate audio ending, step completion, and recorder stop
    await act(async () => {
        simulateAudioEnded();
        await waitFor(() => {
            expect(mockOnStepComplete).toHaveBeenCalledWith(
                expect.objectContaining({ id: 'step-3' }),
                'Acknowledged'
            );
        });
        await waitFor(() => {
            expect(mockMediaRecorderInstance.stop).toHaveBeenCalled();
        });
    });

    // Simulate recorder stopping and providing data via the onstop handler
    const finalBlobFromMock = new Blob([mockAudioChunk], { type: 'audio/webm' }) as RecordingBlob;
    // Add metadata like the mock does
    (finalBlobFromMock as any).recordingTime = recordingDurationMs; // Use the simulated duration
    (finalBlobFromMock as any).recordingSize = finalBlobFromMock.size;
    (finalBlobFromMock as any).lastModified = endTime; // Use the calculated end time


    // Trigger the onstop handler
    act(() => {
      if (mockMediaRecorderInstance?.onstop) {
        mockMediaRecorderInstance.onstop({ data: finalBlobFromMock } as unknown as Event);
      } else {
        throw new Error('mockMediaRecorderInstance.onstop is unexpectedly null');
      }
    });

    // Wait for onComplete
    await waitFor(
      () => {
        expect(mockOnComplete).toHaveBeenCalledTimes(1); // Expect exactly one call
        const receivedBlob = mockOnComplete.mock.calls[0][0] as RecordingBlob;
        expect(receivedBlob).toBeInstanceOf(Blob);
        expect(receivedBlob.size).toBe(mockAudioChunk.size);
        expect(receivedBlob.type).toBe('audio/webm');
         // --- FIX: Check simulated duration ---
        expect((receivedBlob as any).recordingTime).toBe(recordingDurationMs);
        expect((receivedBlob as any).recordingTime).toBeGreaterThan(0);
         // --- END FIX ---
        expect((receivedBlob as any).recordingSize).toBe(mockAudioChunk.size);
        expect((receivedBlob as any).lastModified).toBe(endTime); // Check end time
      },
      { timeout: 5000 }
    );
  });

  // --- Navigation ---
  // Increase timeout for navigation tests
  const NAVIGATION_TEST_TIMEOUT = 10000; // 10 seconds

  it(
    'calls router.push when back button is clicked (Lesson)',
    async () => {
      render(
        <LessonChat
          lesson={mockLesson}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
          isAssessment={false} // Explicitly lesson mode
        />
      );
      const backButton = screen.getByText('Back to Lessons');
      await act(async () => {
        userEvent.click(backButton);
      });
      await waitFor(() => {
        expect(mockRouterPush).toHaveBeenCalledWith('/app/lessons');
      });
    },
    NAVIGATION_TEST_TIMEOUT
  ); // Apply increased timeout

  it(
    'calls router.push when back button is clicked (Assessment)',
    async () => {
      render(
        <LessonChat
          lesson={mockAssessmentLesson}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="German"
          isAssessment={true} // Explicitly assessment mode
        />
      );
      const backButton = screen.getByText('Back to Assessment');
      await act(async () => {
        userEvent.click(backButton);
      });
      await waitFor(() => {
        expect(mockRouterPush).toHaveBeenCalledWith('/app/onboarding');
      });
    },
    NAVIGATION_TEST_TIMEOUT
  ); // Apply increased timeout

  // --- Silence Detection (Indirect Test) ---
  it('submits response automatically after silence', async () => {
    // Start at step 2
    const lessonAtStep2: LessonModel = {
      ...mockLesson,
      steps: [
        { ...mockStep1, userResponse: 'Ack', correct: true },
        mockStep2,
        mockStep3,
      ],
    };
    render(
      <LessonChat
        lesson={lessonAtStep2}
        onComplete={mockOnComplete}
        onStepComplete={mockOnStepComplete}
        loading={false}
        targetLanguage="English"
      />
    );
    const micButton = screen.getByRole('button', { name: 'Start Listening' });

    // Start listening
    await act(async () => {
      userEvent.click(micButton);
    });
    await waitFor(() =>
      expect(mockRecognitionInstance.start).toHaveBeenCalled()
    );

    // Simulate speech result (triggers silence timer setup)
    act(() => {
      mockRecognitionInstance._simulateResult('Hello');
    });
    // Find the input by role="textbox" instead of placeholder
    const input = screen.getByRole('textbox');
    expect(input).toHaveValue('Hello');
    // Check placeholder changed (assuming ChatInput changes it)
    // Update this based on ChatInput's behavior when listening
    // expect(input).toHaveAttribute('placeholder', 'Listening...');

    // Fast-forward timers past the silence threshold
    act(() => {
      jest.advanceTimersByTime(1100); // Advance by more than SILENCE_TIMEOUT_MS (1000)
    });

    // Check if onStepComplete was called due to silence
    await waitFor(() => {
      expect(mockOnStepComplete).toHaveBeenCalledWith(
        expect.objectContaining({ id: 'step-2' }),
        'Hello'
      );
    });
  });

  // --- Mock Mode (Requires setting ENV var) ---
  describe.skip('Mock Mode', () => {
    const originalEnv = process.env;

    beforeEach(() => {
      // Use beforeEach to ensure it's set for every test
      jest.resetModules(); // Reset modules to re-evaluate top-level constants like isMockMode
      process.env = { ...originalEnv, NEXT_PUBLIC_MOCK_USER_RESPONSES: 'true' };
      // Re-import the component after setting the env var and resetting modules
      // This ensures the isMockMode constant inside the component gets the updated value
      // Note: This assumes LessonChat reads the env var at the module level.
      // If it reads it inside the function body, this might not be strictly necessary,
      // but it's safer.
      jest.isolateModules(() => {
        require('@/components/lessons/lessonChat');
      });
    });

    afterEach(() => {
      // Use afterEach to clean up after every test
      process.env = originalEnv;
    });

    it('renders mock buttons in mock mode', () => {
      render(
        <LessonChat
          lesson={mockLesson}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );
      expect(
        screen.getByRole('button', { name: 'Mock Correct Response' })
      ).toBeInTheDocument();
      expect(
        screen.getByRole('button', { name: 'Mock Incorrect Response' })
      ).toBeInTheDocument();
    });

    it('handles mock correct response click', async () => {
      const lessonAtStep2: LessonModel = {
        ...mockLesson,
        steps: [
          { ...mockStep1, userResponse: 'Ack', correct: true },
          mockStep2, // Current step
          mockStep3,
        ],
      };
      render(
        <LessonChat
          lesson={lessonAtStep2}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );
      const mockCorrectButton = screen.getByRole('button', {
        name: 'Mock Correct Response',
      });

      await act(async () => {
        userEvent.click(mockCorrectButton);
      });

      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-2' }),
          mockStep2.expectedAnswer // Should submit the expected answer
        );
      });
      // Check advancement
      await waitFor(() => {
        expect(screen.getByText(mockStep3.content)).toBeInTheDocument();
      });
    });

    it('handles mock incorrect response click', async () => {
      const lessonAtStep2: LessonModel = {
        ...mockLesson,
        steps: [
          { ...mockStep1, userResponse: 'Ack', correct: true },
          mockStep2, // Current step
          mockStep3,
        ],
      };
      // Mock step completion to return incorrect
      mockOnStepComplete.mockResolvedValueOnce({
        ...mockStep2,
        correct: false,
        attempts: 1,
      });

      render(
        <LessonChat
          lesson={lessonAtStep2}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );
      const mockIncorrectButton = screen.getByRole('button', {
        name: 'Mock Incorrect Response',
      });

      await act(async () => {
        userEvent.click(mockIncorrectButton);
      });

      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-2' }),
          'This is a mock response different from the expected' // The hardcoded incorrect mock response
        );
      });
      // Check NO advancement
      expect(screen.queryByText(mockStep3.content)).not.toBeInTheDocument();
      expect(screen.getByText(mockStep2.content)).toBeInTheDocument();
    });

    it('shows and handles recording playback button in mock mode after completion', async () => {
      // Setup similar to completion test, but in mock mode
      const lessonAtStep3: LessonModel = {
        ...mockLesson,
        steps: [
          { ...mockStep1, userResponse: 'Ack', correct: true },
          { ...mockStep2, userResponse: 'Hello', correct: true },
          mockStep3, // Current step is summary
        ],
      };
      // Mock step 3 completion
      mockOnStepComplete.mockResolvedValueOnce({
        ...mockStep3,
        userResponse: 'Acknowledged',
        correct: true,
        attempts: 1,
      });

      render(
        <LessonChat
          lesson={lessonAtStep3}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );

      // Simulate user interaction (needed for auto-advance of summary step)
      const micButton = screen.getByRole('button', { name: 'Start Listening' });
      await act(async () => {
        userEvent.click(micButton);
      });
      await waitFor(() =>
        screen.getByRole('button', { name: /Listening|Pause/i })
      ); // Use correct text/state
      mockMediaRecorderInstance.state = 'recording'; // Simulate recording started
      mockMediaRecorderInstance._startTime = Date.now() - 1000;
      const stopButton = screen.getByRole('button', {
        name: /Listening|Pause/i,
      }); // Use correct text/state
      await act(async () => {
        userEvent.click(stopButton);
      });
      await waitFor(() =>
        screen.getByRole('button', { name: 'Start Listening' })
      );
      mockMediaRecorderInstance.state = 'paused';

      // Simulate audio ending for step 3 (summary step) - this triggers completion logic
      act(() => {
        simulateAudioEnded();
      });

      // Wait for step 3 completion call
      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-3' }),
          'Acknowledged'
        );
      });

      // Simulate recorder stop and data available
      const mockRecordingBlob = new Blob(['audio data'], {
        type: 'audio/webm',
      }) as RecordingBlob;
      act(() => {
        mockMediaRecorderChunks.push(mockRecordingBlob); // Add chunk before stop
        if (mockMediaRecorderInstance?.onstop) {
          mockMediaRecorderInstance.onstop({}); // Trigger stop event
        }
      });

      // Wait for playback button to appear
      let playbackButton: HTMLElement;
      await waitFor(() => {
        playbackButton = screen.getByRole('button', {
          name: /Play Recording/i,
        });
        expect(playbackButton).toBeInTheDocument();
        expect(global.URL.createObjectURL).toHaveBeenCalledWith(
          expect.any(Blob)
        );
      });

      // Simulate clicking play
      await act(async () => {
        userEvent.click(playbackButton);
      });
      // Audio playback mock might need adjustment if src changes clear listeners
      // Let's assume the recording audio element's play is called
      expect(mockAudioPlay).toHaveBeenCalled(); // Check if play was called at least once after initial plays
      await waitFor(() => {
        expect(
          screen.getByRole('button', { name: /Pause Recording/i })
        ).toBeInTheDocument();
      });

      // Simulate clicking pause
      const pauseButton = screen.getByRole('button', {
        name: /Pause Recording/i,
      });
      await act(async () => {
        userEvent.click(pauseButton);
      });
      expect(mockAudioPause).toHaveBeenCalled();
      await waitFor(() => {
        expect(
          screen.getByRole('button', { name: /Play Recording/i })
        ).toBeInTheDocument();
      });
    });

    it('shows and handles complete lesson button in mock mode', async () => {
      // Setup similar to completion test
      const lessonAtStep3: LessonModel = {
        ...mockLesson,
        steps: [
          { ...mockStep1, userResponse: 'Ack', correct: true },
          { ...mockStep2, userResponse: 'Hello', correct: true },
          mockStep3, // Current step is summary
        ],
      };
      // Mock step 3 completion
      mockOnStepComplete.mockResolvedValueOnce({
        ...mockStep3,
        userResponse: 'Acknowledged',
        correct: true,
        attempts: 1,
      });

      render(
        <LessonChat
          lesson={lessonAtStep3}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );

      // Simulate user interaction
      const micButton = screen.getByRole('button', { name: 'Start Listening' });
      await act(async () => {
        userEvent.click(micButton);
      });
      await waitFor(() =>
        screen.getByRole('button', { name: /Listening|Pause/i })
      ); // Use correct text/state
      mockMediaRecorderInstance.state = 'recording';
      mockMediaRecorderInstance._startTime = Date.now() - 1000;
      const stopButton = screen.getByRole('button', {
        name: /Listening|Pause/i,
      }); // Use correct text/state
      await act(async () => {
        userEvent.click(stopButton);
      });
      await waitFor(() =>
        screen.getByRole('button', { name: 'Start Listening' })
      );
      mockMediaRecorderInstance.state = 'paused';

      // Simulate audio ending for step 3 (summary step) - triggers completion
      act(() => {
        simulateAudioEnded();
      });

      // Wait for step 3 completion call
      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-3' }),
          'Acknowledged'
        );
      });

      // Wait for the "Complete Lesson" button to appear (lessonReadyToComplete state)
      let completeButton: HTMLElement;
      await waitFor(() => {
        completeButton = screen.getByRole('button', {
          name: 'Complete Lesson',
        });
        expect(completeButton).toBeInTheDocument();
        // onComplete should NOT have been called yet in mock mode
        expect(mockOnComplete).not.toHaveBeenCalled();
      });

      // Simulate recorder stop and data available (needed for onComplete call)
      const mockRecordingBlob = new Blob(['audio data'], {
        type: 'audio/webm',
      }) as RecordingBlob;
      // Add mock properties
      (mockRecordingBlob as any).recordingTime = 500;
      (mockRecordingBlob as any).recordingSize = 10;
      (mockRecordingBlob as any).lastModified = Date.now();

      act(() => {
        mockMediaRecorderChunks.push(mockRecordingBlob); // Add chunk before stop
        if (mockMediaRecorderInstance?.onstop) {
          mockMediaRecorderInstance.onstop({}); // Trigger stop event
        }
      });

      // Click the complete button
      await act(async () => {
        userEvent.click(completeButton);
      });

      // Now onComplete should be called
      await waitFor(() => {
        expect(mockOnComplete).toHaveBeenCalledWith(expect.any(Blob));
      });
      // Button should disappear
      expect(
        screen.queryByRole('button', { name: 'Complete Lesson' })
      ).not.toBeInTheDocument();
    });


  });
  describe.only('Auto-starting listening/recording after audio ends', () => {
    // Helper function to simulate initial interaction and wait for mocks
    const simulateInitialInteractionAndWaitForMocks = async (micButton: HTMLElement) => {
      await act(async () => {
        userEvent.click(micButton);
      });
      // Wait for interaction flag and for mocks to be initialized by the component's useEffect
      await new Promise(resolve => setTimeout(resolve, 100));
      await waitFor(() => {
        expect(mockAudioPlay).toHaveBeenCalled(); // Wait for audio side-effect
        // Crucially, wait for the mock instances to be defined
        expect(mockRecognitionInstance).toBeDefined();
        expect(mockMediaRecorderInstance).toBeDefined();
      });
      // Clear the initial play call for subsequent checks if needed
      mockAudioPlay.mockClear();
      // Clear start mocks *after* ensuring instances exist
      mockRecognitionInstance.start.mockClear();
      mockMediaRecorderInstance.start.mockClear();
    };

    it('should auto-start listening and recording if audio ends and the NEXT step is interactive', async () => {
      // Arrange: Lesson where step 2 (practice) follows step 1 (instruction)
      const lessonWithInteractiveNext: LessonModel = {
        ...mockLesson,
        steps: [
          mockStep1, // instruction (current step after interaction)
          mockStep2, // practice (next step - interactive)
          mockStep3, // summary
        ],
      };

      render(
        <LessonChat
          lesson={lessonWithInteractiveNext}
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );

      const micButton = screen.getByRole('button', { name: 'Start Listening' });

      // 1. Simulate initial user interaction & wait for mocks
      await simulateInitialInteractionAndWaitForMocks(micButton);
      expect(mockAudioSrc).toBe(mockStep1.contentAudioUrl); // Audio for step 1 should play

      // 2. Simulate audio ending for step 1 (instruction)
      act(() => {
        simulateAudioEnded();
      });

      // 3. Wait for step 1 to auto-advance
      await waitFor(() => {
        expect(mockOnStepComplete).toHaveBeenCalledWith(
          expect.objectContaining({ id: 'step-1' }),
          'Acknowledged'
        );
        expect(screen.getByText(mockStep2.content)).toBeInTheDocument();
      });

      // 4. Wait for audio of step 2 (content) to start playing
      await waitFor(() => {
        expect(mockAudioPlay).toHaveBeenCalledTimes(1);
        expect(mockAudioSrc).toBe(mockStep2.contentAudioUrl);
      });
      mockAudioPlay.mockClear();

      // 5. Simulate audio ending for step 2's *content* audio
      act(() => {
        simulateAudioEnded();
      });

      // 6. Wait for step 2's *expected answer* audio to play
      await waitFor(() => {
        expect(mockAudioPlay).toHaveBeenCalledTimes(1);
        expect(mockAudioSrc).toBe(mockStep2.expectedAnswerAudioUrl);
      });

      // 7. Simulate audio ending for step 2's *expected answer* audio (last in its queue)
      //    The *next* step (step 3 - summary) is NON-interactive.
      //    So, listening/recording should NOT auto-start here.
      //    Clear mocks *before* the action that might trigger them
      mockRecognitionInstance.start.mockClear();
      mockMediaRecorderInstance.start.mockClear();
      act(() => {
        simulateAudioEnded();
      });

      // Assert: Listening/Recording should NOT have started automatically
      await new Promise(resolve => setTimeout(resolve, 100));
      expect(mockRecognitionInstance.start).not.toHaveBeenCalled();
      expect(mockMediaRecorderInstance.start).not.toHaveBeenCalled();
    });


    it('should NOT auto-start listening/recording if audio ends and the NEXT step is non-interactive', async () => {
      // Arrange: Lesson where step 3 (summary) follows step 2 (practice)
      const lessonWithNonInteractiveNext: LessonModel = {
        ...mockLesson,
        steps: [
          { ...mockStep1, userResponse: 'Ack', correct: true }, // Step 1 done
          mockStep2, // practice (current step)
          mockStep3, // summary (next step - non-interactive)
        ],
      };

      render(
        <LessonChat
          lesson={lessonWithNonInteractiveNext} // Starts effectively at step 2 (index 1)
          onComplete={mockOnComplete}
          onStepComplete={mockOnStepComplete}
          loading={false}
          targetLanguage="English"
        />
      );

      const micButton = screen.getByRole('button', { name: 'Start Listening' });

      // 1. Simulate initial user interaction & wait for mocks
      await simulateInitialInteractionAndWaitForMocks(micButton);
      // Audio for step 2 should play (content first)
      expect(mockAudioSrc).toBe(mockStep2.contentAudioUrl);

      // 2. Simulate audio ending for step 2's *content* audio
      act(() => {
        simulateAudioEnded();
      });

      // 3. Wait for step 2's *expected answer* audio to play
      await waitFor(() => {
        expect(mockAudioPlay).toHaveBeenCalledTimes(1);
        expect(mockAudioSrc).toBe(mockStep2.expectedAnswerAudioUrl);
      });

      // 4. Simulate audio ending for step 2's *expected answer* audio (last in its queue)
      //    The *next* step (step 3 - summary) is NON-interactive.
      //    Clear mocks *before* the action
      mockRecognitionInstance.start.mockClear();
      mockMediaRecorderInstance.start.mockClear();
      act(() => {
        simulateAudioEnded();
      });

      // Assert: Listening/Recording should NOT have started automatically
      await new Promise(resolve => setTimeout(resolve, 100));
      expect(mockRecognitionInstance.start).not.toHaveBeenCalled();
      expect(mockMediaRecorderInstance.start).not.toHaveBeenCalled();
    });

     it('should NOT auto-start listening/recording if audio ends for the LAST step', async () => {
        // Arrange: Lesson where step 3 (summary) is the last step
        const lessonAtLastStep: LessonModel = {
          ...mockLesson,
          steps: [
            { ...mockStep1, userResponse: 'Ack', correct: true },
            { ...mockStep2, userResponse: 'Hello', correct: true },
            mockStep3, // summary (current and last step)
          ],
        };

        render(
          <LessonChat
            lesson={lessonAtLastStep} // Starts effectively at step 3 (index 2)
            onComplete={mockOnComplete}
            onStepComplete={mockOnStepComplete}
            loading={false}
            targetLanguage="English"
          />
        );

        const micButton = screen.getByRole('button', { name: 'Start Listening' });

        // 1. Simulate initial user interaction & wait for mocks
        await simulateInitialInteractionAndWaitForMocks(micButton);
        // Audio for step 3 should play
        expect(mockAudioSrc).toBe(mockStep3.contentAudioUrl);

        // 2. Simulate audio ending for step 3 (last in queue and last step)
        //    Clear mocks *before* the action
        mockRecognitionInstance.start.mockClear();
        mockMediaRecorderInstance.start.mockClear();
        act(() => {
          simulateAudioEnded();
        });

        // 3. Wait for step 3 (summary) to auto-advance (which triggers completion)
        await waitFor(() => {
          expect(mockOnStepComplete).toHaveBeenCalledWith(
            expect.objectContaining({ id: 'step-3' }),
            'Acknowledged'
          );
        });

        // Assert: Listening/Recording should NOT have started automatically as it's the end
        await new Promise(resolve => setTimeout(resolve, 100));
        expect(mockRecognitionInstance.start).not.toHaveBeenCalled();
        expect(mockMediaRecorderInstance.start).not.toHaveBeenCalled();

        // Assert: Recording should have been stopped by completion logic
        await waitFor(() => {
            // Ensure stop was called *after* confirming start wasn't
            expect(mockMediaRecorderInstance.stop).toHaveBeenCalled();
        });
     });

  });






});
</file>

<file path="todo.md">
# TODO

-[] check lessons generation and progress tracking
- [] lesson generation prompt is very bad
- [] checklessons and generate new ones is not working
- [x] Clarified that lesson.focusArea in UI is already user-friendly; normalizeTopic is for internal use only.
- [] disable redirect from onboarding when user is seeing results and waiting for lesson generation 

- [x] mobile ui for onboarding screens 






# TODO: Integrate Google Cloud Speech-to-Text v1 API into LessonChat

**Goal:** Replace the browser's Web Speech API (`webkitSpeechRecognition`) with the server-processed Google Cloud Speech-to-Text v1 API for more reliable and consistent speech recognition across browsers and potentially better accuracy.

---

## Phase 1: Backend Setup (API Endpoint / Server Action)

-   [x] **Install Google Cloud Speech Client Library:**
    -   Add `@google-cloud/speech` to project dependencies (`npm install @google-cloud/speech` or equivalent).
-   [x] **Set up Google Cloud Authentication:**
    -   Create a Google Cloud Service Account with the "Cloud Speech API User" role.
    -   Download the service account key JSON file.
    -   **Securely** store the credentials:
        -   Option A: Set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path of the key file (preferred for local/server environments).
        -   Option B: Store the key file content in a secure environment variable (e.g., `GOOGLE_CREDENTIALS_BASE64`) and configure the client library to use it.
    -   Update `.env.example` and documentation regarding necessary Google Cloud credentials.
    -   Ensure the key file is added to `.gitignore`.
-   [x] **Create Backend API Route/Server Action:**
    -   Create a **Server Action** in `src/lib/server-actions/stt-actions.ts`.
    -   The Server Action should be an exported async function (e.g., `export async function transcribeAudio(formData: FormData)`) that receives audio data and metadata from the client.
    -   Ensure the Server Action is invoked from the frontend using the framework's server action mechanism (e.g., `formAction`, `use server`, or similar).
-   [x] **Implement Audio Reception:**
    -   Update the Server Action to accept audio data via a `FormData` parameter (for `multipart/form-data` uploads).
    -   Extract the audio file/blob and any metadata (e.g., `targetLanguage`, `sampleRate`) from the `FormData` object.
    -   Validate the received data and handle errors gracefully.
-   [x] **Implement Google STT API Call:**
    -   Instantiate the Google Cloud Speech client using the configured credentials.
    -   Configure the `RecognitionConfig`:
        -   Set `encoding` (e.g., `WEBM_OPUS` if using MediaRecorder with default Opus, `LINEAR16` if sending raw PCM).
        -   Set `sampleRateHertz` (e.g., 48000 for Opus, 16000 or higher for LINEAR16). **Crucial for accuracy.**
        -   Set `languageCode` based on the `targetLanguage` passed from the client.
        -   Enable `automaticPunctuation`.
        -   Consider `model` selection (e.g., `telephony`, `latest_long`, `medical_dictation` - `default` or `telephony_short` might be suitable).
        -   Set `enableWordTimeOffsets` or `enableWordConfidence` if needed for advanced feedback later.
    -   Configure the `RecognitionAudio`:
        -   Pass the received audio `content` (as Base64 string or Buffer).
    -   Make the `recognize` API call to Google Cloud STT.
-   [x] **Handle API Response:**
    -   Process the response from Google Cloud STT.
    -   Extract the transcript from the `results`. Handle cases with multiple results or alternatives if necessary (usually take the first result's first alternative with highest confidence).
    -   Handle potential errors returned by the Google API (e.g., authentication errors, quota limits, invalid arguments).
-   [x] **Return Transcript to Client:**
    -   Send the extracted transcript (or an error message) back to the client in a structured JSON response.
-   [x] **Add Authentication/Authorization:**
    -   Secure the backend endpoint/action. Ensure only authenticated users associated with the lesson can submit STT requests. Use Supabase session validation.

## Phase 2: Frontend Integration (`LessonChat.tsx`)

-   [ ] **Remove Web Speech API Integration:**
    -   Delete all code related to `window.webkitSpeechRecognition`.
    -   Remove state variables like `isListening`, `recognitionRef`, `realtimeTranscript` (or repurpose `isListening` to mean "processing on server").
    -   Remove event handlers (`onstart`, `onresult`, `onerror`, `onend`).
    -   Remove silence detection logic based on Web Speech API results (`silenceTimerRef` related to `onresult`).
-   [ ] **Adapt Audio Recording Logic:**
    -   Keep the `MediaRecorder` setup (`initializeRecorder`, `startRecording`, `pauseRecording`, `stopRecordingCompletely`).
    -   Ensure `mediaRecorder.onstop` correctly gathers the audio chunks into a final `Blob` or `File` object.
-   [ ] **Implement Audio Sending:**
    -   Modify the `stopRecording` (or a new `sendAudioToServer`) function:
        -   When recording stops (manually or automatically), get the final audio `Blob`/`File`.
        -   Use `fetch` or a library like `axios` to send this audio data to the new backend API endpoint/action created in Phase 1.
        -   Use `FormData` to package the audio blob/file along with metadata (target language code).
        -   Set `isProcessing` state to true while waiting for the server response.
-   [ ] **Handle Server Response:**
    -   Receive the transcript response from the backend endpoint/action.
    -   On successful response:
        -   Update the `userResponse` state with the received transcript.
        -   Trigger the `handleSubmitStep` logic using the received transcript.
        -   Set `isProcessing` state to false.
    -   On error response:
        -   Display an appropriate error message to the user (update `feedback` state or use toast).
        -   Set `isProcessing` state to false.
-   [ ] **Update UI State and Controls:**
    -   Modify the `ChatInput` component and the main microphone button logic:
        -   The button should now toggle `startRecording` and `stopRecording`.
        -   While recording, the button could show a "Stop Recording" state.
        -   After stopping and sending, display a "Processing..." state (using `isProcessing`). Disable the button during processing.
        -   Remove the visual "Listening..." indicator tied to the old Web Speech API state.
        -   The text area (`userResponse`) should primarily display the *final* transcript received from the server, not real-time updates. Consider clearing it before starting a new recording.
-   [ ] **Refine Silence Detection (Client-Side):**
    -   The previous silence detection relied on `onresult`. A new approach is needed if auto-submission after pauses is desired.
    -   Option A (Simpler): Remove auto-submission. User explicitly clicks "Stop Recording" or a "Submit" button after speaking.
    -   Option B (More Complex): Implement client-side silence detection using `AudioContext` and `AnalyserNode` to monitor the input stream *during* recording and call `stopRecording` automatically after a pause. This adds significant complexity. Start with Option A.

## Phase 3: Configuration & Cleanup

-   [ ] **Environment Variables:**
    -   Ensure `GOOGLE_APPLICATION_CREDENTIALS` or `GOOGLE_CREDENTIALS_BASE64` is configured correctly in all relevant environments (local, Vercel).
-   [ ] **Refactor & Cleanup:**
    -   Remove unused state variables, refs, and functions related to Web Speech API.
    -   Ensure consistent error handling and user feedback.
    -   Review component props and context interactions.
-   [ ] **Documentation:**
    -   Update any internal documentation regarding the STT implementation change and necessary setup (Google Cloud).

## Phase 4: Testing

-   [ ] **Backend Endpoint/Action Tests:**
    -   Write unit/integration tests for the API route/server action.
    -   Mock the Google Cloud Speech client.
    -   Test successful transcript generation.
    -   Test handling of invalid audio data.
    -   Test handling of Google API errors (e.g., auth, quota).
    -   Test authentication/authorization logic.
-   [ ] **Frontend Component Tests (`LessonChat.tsx`):**
    -   Update existing tests or write new ones using `@testing-library/react`.
    -   Mock `fetch` calls to the backend STT endpoint.
    -   Test starting and stopping recording.
    -   Test the "Processing..." state update.
    -   Test handling of successful transcript responses (updating `userResponse`, calling `handleSubmitStep`).
    -   Test handling of error responses from the backend.
    -   Verify UI changes (button states, feedback messages).
-   [ ] **End-to-End Testing (Manual/Automated):**
    -   Perform manual tests in different browsers to ensure recording and STT processing work correctly.
    -   Consider automated E2E tests if feasible.

## Phase 5: Potential Enhancements (Future TODOs)

-   [ ] **Implement Streaming Recognition:**
    -   Replace the batch POST request with a WebSocket connection.
    -   Stream audio chunks from `MediaRecorder` (`ondataavailable`) to the backend.
    -   Backend streams audio to Google STT Streaming API.
    -   Backend sends back interim and final transcripts via WebSocket.
    -   Update frontend to display interim results for better UX.
-   [ ] **Improve Error Handling:** Provide more specific feedback based on Google API error codes.
-   [ ] **Optimize Audio Format/Encoding:** Experiment with different encodings (`LINEAR16`, `FLAC`) and sample rates for cost/accuracy balance.
-   [ ] **Advanced Configuration:** Allow users to select specific recognition models or features if applicable.

---
</file>

</files>
